{
  "distilbert/distilgpt2": [
    "model.safetensors"
  ],
  "openai-community/gpt2-large": [
    "model.safetensors"
  ],
  "openai-community/gpt2-medium": [
    "model.safetensors"
  ],
  "openai-community/gpt2-xl": [
    "model.safetensors"
  ],
  "openai-community/gpt2": [
    "model.safetensors"
  ],
  "openai-community/openai-gpt": [
    "model.safetensors"
  ],
  "Aspect11/DialoGPT-Medium-LiSBot": [
    "model.safetensors"
  ],
  "Asuramaru/DialoGPT-small-rintohsaka": [
    "model.safetensors"
  ],
  "CheonggyeMountain-Sherpa/kogpt-trinity-poem": [
    "model.safetensors"
  ],
  "EleutherAI/gpt-neo-1.3B": [
    "model.safetensors"
  ],
  "EleutherAI/gpt-neo-125m": [
    "model.safetensors"
  ],
  "EleutherAI/gpt-neo-2.7B": [
    "model.safetensors"
  ],
  "GroNLP/gpt2-medium-dutch-embeddings": [
    "model.safetensors"
  ],
  "GroNLP/gpt2-medium-italian-embeddings": [
    "model.safetensors"
  ],
  "GroNLP/gpt2-small-dutch-embeddings": [
    "model.safetensors"
  ],
  "GroNLP/gpt2-small-dutch": [
    "model.safetensors"
  ],
  "GroNLP/gpt2-small-italian-embeddings": [
    "model.safetensors"
  ],
  "GroNLP/gpt2-small-italian": [
    "model.safetensors"
  ],
  "Hamas/DialoGPT-large-jake2": [
    "model.safetensors"
  ],
  "Kirili4ik/ruDialoGpt3-medium-finetuned-telegram": [
    "model.safetensors"
  ],
  "KoboldAI/GPT-Neo-2.7B-Picard": [
    "model.safetensors"
  ],
  "KoboldAI/fairseq-dense-1.3B": [
    "model.safetensors"
  ],
  "KoboldAI/fairseq-dense-125M": [
    "model.safetensors"
  ],
  "KoboldAI/fairseq-dense-2.7B": [
    "model.safetensors"
  ],
  "KoboldAI/fairseq-dense-355M": [
    "model.safetensors"
  ],
  "Kryptone/RinAI": [
    "model.safetensors"
  ],
  "Kryptone/monikAI": [
    "model.safetensors"
  ],
  "LorenzoDeMattei/GePpeTto": [
    "model.safetensors"
  ],
  "Luciano/gpt2-small-portuguese-finetuned-peticoes": [
    "model.safetensors"
  ],
  "Luciano/gpt2-small-portuguese-finetuned-tcu-acordaos": [
    "model.safetensors"
  ],
  "MrGentle/DeltaModel-genius1": [
    "model.safetensors"
  ],
  "NamPE/DialoGPT-medium-Takanashi-Rikka": [
    "model.safetensors"
  ],
  "Narsil/gpt2": [
    "model.safetensors"
  ],
  "Nehc/gpt2_lovecraft_ru": [
    "model.safetensors"
  ],
  "Nehc/gpt2_priest_ru": [
    "model.safetensors"
  ],
  "Norod78/distilgpt2-base-pretrained-he": [
    "model.safetensors"
  ],
  "Norod78/english-sienfeld-distilgpt2": [
    "model.safetensors"
  ],
  "Norod78/hebrew-bad_wiki-gpt_neo-tiny": [
    "model.safetensors"
  ],
  "Norod78/hebrew-gpt_neo-small": [
    "model.safetensors"
  ],
  "Norod78/hebrew-gpt_neo-tiny": [
    "model.safetensors"
  ],
  "Norod78/hebrew-gpt_neo-xl-poetry": [
    "model.safetensors"
  ],
  "Norod78/hebrew-gpt_neo-xl": [
    "model.safetensors"
  ],
  "Norod78/hebrew_poetry-gpt_neo-small": [
    "model.safetensors"
  ],
  "Norod78/hebrew_stories-gpt_neo-small": [
    "model.safetensors"
  ],
  "Norod78/hewiki-articles-distilGPT2py-il": [
    "model.safetensors"
  ],
  "Poly-Pixel/shrek-medium-full": [
    "model.safetensors"
  ],
  "Poly-Pixel/shrek-test-small": [
    "model.safetensors"
  ],
  "RifsxD/DialoGPT-medium-raifu": [
    "model.safetensors"
  ],
  "Spirax/DialoGPT-medium-sheldon": [
    "model.safetensors"
  ],
  "Vamsi/T5_Paraphrase_Paws": [
    "model.safetensors"
  ],
  "abbas/gpt2-horror-stories": [
    "model.safetensors"
  ],
  "abhiramtirumala/DialoGPT-sarcastic-medium": [
    "model.safetensors"
  ],
  "abinayam/gpt-2-tamil": [
    "model.safetensors"
  ],
  "akahana/gpt2-indonesia": [
    "model.safetensors"
  ],
  "akhooli/gpt2-small-arabic-poetry": [
    "model.safetensors"
  ],
  "akhooli/gpt2-small-arabic": [
    "model.safetensors"
  ],
  "anechaev/ru_med_gpt3sm_based_on_gpt2": [
    "model.safetensors"
  ],
  "antoinelouis/belgpt2": [
    "model.safetensors"
  ],
  "archmagos/HourAI": [
    "model.safetensors"
  ],
  "aubmindlab/aragpt2-base": [
    "model.safetensors"
  ],
  "aubmindlab/aragpt2-large": [
    "model.safetensors"
  ],
  "aubmindlab/aragpt2-medium": [
    "model.safetensors"
  ],
  "averyanalex/panorama-rugpt3large": [
    "model.safetensors"
  ],
  "bankholdup/rugpt3_song_writer": [
    "model.safetensors"
  ],
  "bayartsogt/mongolian-gpt2": [
    "model.safetensors"
  ],
  "benjamin/gerpt2-large": [
    "model.safetensors"
  ],
  "benjamin/gerpt2": [
    "model.safetensors"
  ],
  "benjamin/gpt2-wechsel-french": [
    "model.safetensors"
  ],
  "benjamin/gpt2-wechsel-swahili": [
    "model.safetensors"
  ],
  "beomus/lotr-gpt": [
    "model.safetensors"
  ],
  "binwang/xlnet-base-cased": [
    "model.safetensors"
  ],
  "bookbot/gpt2-indo-medium-kids-stories": [
    "model.safetensors"
  ],
  "bookbot/gpt2-indo-small-kids-stories": [
    "model.safetensors"
  ],
  "cahya/gpt2-large-indonesian-522M": [
    "model.safetensors"
  ],
  "cahya/gpt2-medium-indonesian-story": [
    "model.safetensors"
  ],
  "cedpsam/chatbot_fr": [
    "model.safetensors"
  ],
  "christopherastone/distilgpt2-proofs": [
    "model.safetensors"
  ],
  "danurahul/alex_gpt3_Doctextfull": [
    "model.safetensors"
  ],
  "danurahul/alex_gpt3_Doctextfull2": [
    "model.safetensors"
  ],
  "danurahul/german_gpt_4g": [
    "model.safetensors"
  ],
  "dbddv01/gpt2-french-small": [
    "model.safetensors"
  ],
  "dbmdz/german-gpt2-faust": [
    "model.safetensors"
  ],
  "dbmdz/german-gpt2": [
    "model.safetensors"
  ],
  "ddobokki/gpt2_poem": [
    "model.safetensors"
  ],
  "deepparag/Aeona": [
    "model.safetensors"
  ],
  "epsil/bhagvad_gita": [
    "model.safetensors"
  ],
  "ethzanalytics/ai-msgbot-gpt2-L-dialogue": [
    "model.safetensors"
  ],
  "ethzanalytics/ai-msgbot-gpt2-XL-dialogue": [
    "model.safetensors"
  ],
  "ethzanalytics/distilgpt2-tiny-conversational": [
    "model.safetensors"
  ],
  "f00d4tehg0dz/Yoda": [
    "model.safetensors"
  ],
  "facebook/xglm-4.5B": [
    "model.safetensors"
  ],
  "flax-community/dansk-gpt-wiki": [
    "model.safetensors"
  ],
  "flax-community/gpt-2-spanish": [
    "model.safetensors"
  ],
  "flax-community/gpt2-bengali": [
    "model.safetensors"
  ],
  "flax-community/gpt2-persian-question-answering": [
    "model.safetensors"
  ],
  "flax-community/nordic-gpt-wiki": [
    "model.safetensors"
  ],
  "flax-community/norsk-gpt-wiki": [
    "model.safetensors"
  ],
  "flax-community/papuGaPT2-large": [
    "model.safetensors"
  ],
  "flax-community/swe-gpt-wiki": [
    "model.safetensors"
  ],
  "flax-community/t5-base-dutch-demo": [
    "model.safetensors"
  ],
  "flax-community/t5-recipe-generation": [
    "model.safetensors"
  ],
  "indonesian-nlp/gpt2-medium-indonesian": [
    "model.safetensors"
  ],
  "indonesian-nlp/gpt2": [
    "model.safetensors"
  ],
  "johnpaulbin/gpt2-skript-1m-v5": [
    "model.safetensors"
  ],
  "johnpaulbin/gpt2-skript-base": [
    "model.safetensors"
  ],
  "johnpaulbin/meme-titles": [
    "model.safetensors"
  ],
  "kingabzpro/DialoGPT-small-Rick-Bot": [
    "model.safetensors"
  ],
  "mbien/fdh-wikibio": [
    "model.safetensors"
  ],
  "mbien/recipenlg": [
    "model.safetensors"
  ],
  "microsoft/DialoGPT-small": [
    "model.safetensors"
  ],
  "ml6team/gpt2-medium-dutch-finetune-oscar": [
    "model.safetensors"
  ],
  "mofawzy/gpt2-arabic-sentence-generator": [
    "model.safetensors"
  ],
  "monsoon-nlp/ar-seq2seq-gender-decoder": [
    "model.safetensors"
  ],
  "monsoon-nlp/dialect-ar-gpt-2021": [
    "model.safetensors"
  ],
  "monsoon-nlp/gpt-nyc-affirmations": [
    "model.safetensors"
  ],
  "monsoon-nlp/gpt-nyc": [
    "model.safetensors"
  ],
  "monsoon-nlp/no-phone-gpt2": [
    "model.safetensors"
  ],
  "monsoon-nlp/sanaa-dialect": [
    "model.safetensors"
  ],
  "mrm8488/CodeGPT-small-finetuned-python-token-completion": [
    "model.safetensors"
  ],
  "mrm8488/gpt2-finetuned-recipes-cooking": [
    "model.safetensors"
  ],
  "mrm8488/gpt2-finetuned-recipes-cooking_v2": [
    "model.safetensors"
  ],
  "mrm8488/spanish-gpt2": [
    "model.safetensors"
  ],
  "noelmathewisaac/inspirational-quotes-distilgpt2": [
    "model.safetensors"
  ],
  "obss/mt5-base-3task-highlight-tquad2": [
    "model.safetensors"
  ],
  "p208p2002/gpt2-drcd-qg-hl": [
    "model.safetensors"
  ],
  "p208p2002/gpt2-squad-nqg-hl": [
    "model.safetensors"
  ],
  "philippelaban/keep_it_simple": [
    "model.safetensors"
  ],
  "pszemraj/gpt2-medium-vaguely-human-dialogue": [
    "model.safetensors"
  ],
  "r3dhummingbird/DialoGPT-medium-joshua": [
    "model.safetensors"
  ],
  "r3dhummingbird/DialoGPT-medium-neku": [
    "model.safetensors"
  ],
  "r3dhummingbird/DialoGPT-small-harrypotter": [
    "model.safetensors"
  ],
  "r3dhummingbird/DialoGPT-small-neku": [
    "model.safetensors"
  ],
  "razent/SciFive-base-PMC": [
    "model.safetensors"
  ],
  "razent/SciFive-base-Pubmed_PMC": [
    "model.safetensors"
  ],
  "razent/SciFive-large-Pubmed": [
    "model.safetensors"
  ],
  "rinna/japanese-gpt-1b": [
    "model.safetensors"
  ],
  "rinna/japanese-gpt2-medium": [
    "model.safetensors"
  ],
  "rinna/japanese-gpt2-small": [
    "model.safetensors"
  ],
  "rinna/japanese-gpt2-xsmall": [
    "model.safetensors"
  ],
  "rotendahl/cold-bert-base-pre-norm": [
    "model.safetensors"
  ],
  "satkinson/DialoGPT-medium-marvin": [
    "model.safetensors"
  ],
  "shibing624/code-autocomplete-distilgpt2-python": [
    "model.safetensors"
  ],
  "shibing624/code-autocomplete-gpt2-base": [
    "model.safetensors"
  ],
  "surajp/gpt2-hindi": [
    "model.safetensors"
  ],
  "taeminlee/kogpt2": [
    "model.safetensors"
  ],
  "tartuNLP/gpt-for-est-large": [
    "model.safetensors"
  ],
  "toastynews/xlnet-hongkongese-base": [
    "model.safetensors"
  ],
  "truthisneverlinear/EleventhDoctor": [
    "model.safetensors"
  ],
  "twdooley/breitbot": [
    "model.safetensors"
  ],
  "voidful/gpt2-base-ptt": [
    "model.safetensors"
  ],
  "w11wo/indo-gpt2-small": [
    "model.safetensors"
  ],
  "w11wo/javanese-gpt2-small-imdb": [
    "model.safetensors"
  ],
  "w11wo/javanese-gpt2-small": [
    "model.safetensors"
  ],
  "w11wo/sundanese-gpt2-base": [
    "model.safetensors"
  ],
  "wtrClover/DialoGPT-small-Flutterbot": [
    "model.safetensors"
  ],
  "yhavinga/gpt-neo-125M-dutch": [
    "model.safetensors"
  ],
  "yhavinga/gpt2-large-dutch": [
    "model.safetensors"
  ],
  "yhavinga/gpt2-medium-dutch": [
    "model.safetensors"
  ],
  "P0intMaN/PyAutoCode": [
    "model.safetensors"
  ],
  "KoboldAI/GPT-Neo-1.3B-Adventure": [
    "model.safetensors"
  ],
  "l3cube-pune/hing-gpt": [
    "model.safetensors"
  ],
  "l3cube-pune/marathi-gpt": [
    "model.safetensors"
  ],
  "axiomepic/nethack-gpt2": [
    "model.safetensors"
  ],
  "bipin/malayalam-gpt2": [
    "model.safetensors"
  ],
  "Graphcore/gpt2-wikitext-103": [
    "model.safetensors"
  ],
  "Ryukijano/DialoGPT_med_model": [
    "model.safetensors"
  ],
  "l3cube-pune/hing-gpt-devanagari": [
    "model.safetensors"
  ],
  "aihijo/gpt2-zh-21k": [
    "model.safetensors"
  ],
  "0x7o/pyGPT-50M": [
    "model.safetensors"
  ],
  "sagorsarker/emailgenerator": [
    "model.safetensors"
  ],
  "Sakonii/distilgpt2-nepali": [
    "model.safetensors"
  ],
  "AAAA-4/DialoGPT-small-player_03": [
    "model.safetensors"
  ],
  "johnpaulbin/skript-1m-gpt-neo125m": [
    "model.safetensors"
  ],
  "EleutherAI/gpt-neox-20b": [
    "model-00001-of-00046.safetensors",
    "model-00002-of-00046.safetensors",
    "model-00003-of-00046.safetensors",
    "model-00004-of-00046.safetensors",
    "model-00005-of-00046.safetensors",
    "model-00006-of-00046.safetensors",
    "model-00007-of-00046.safetensors",
    "model-00008-of-00046.safetensors",
    "model-00009-of-00046.safetensors",
    "model-00010-of-00046.safetensors",
    "model-00011-of-00046.safetensors",
    "model-00012-of-00046.safetensors",
    "model-00013-of-00046.safetensors",
    "model-00014-of-00046.safetensors",
    "model-00015-of-00046.safetensors",
    "model-00016-of-00046.safetensors",
    "model-00017-of-00046.safetensors",
    "model-00018-of-00046.safetensors",
    "model-00019-of-00046.safetensors",
    "model-00020-of-00046.safetensors",
    "model-00021-of-00046.safetensors",
    "model-00022-of-00046.safetensors",
    "model-00023-of-00046.safetensors",
    "model-00024-of-00046.safetensors",
    "model-00025-of-00046.safetensors",
    "model-00026-of-00046.safetensors",
    "model-00027-of-00046.safetensors",
    "model-00028-of-00046.safetensors",
    "model-00029-of-00046.safetensors",
    "model-00030-of-00046.safetensors",
    "model-00031-of-00046.safetensors",
    "model-00032-of-00046.safetensors",
    "model-00033-of-00046.safetensors",
    "model-00034-of-00046.safetensors",
    "model-00035-of-00046.safetensors",
    "model-00036-of-00046.safetensors",
    "model-00037-of-00046.safetensors",
    "model-00038-of-00046.safetensors",
    "model-00039-of-00046.safetensors",
    "model-00040-of-00046.safetensors",
    "model-00041-of-00046.safetensors",
    "model-00042-of-00046.safetensors",
    "model-00043-of-00046.safetensors",
    "model-00044-of-00046.safetensors",
    "model-00045-of-00046.safetensors",
    "model-00046-of-00046.safetensors"
  ],
  "johnpaulbin/skript-1m-gpt-neo350m": [
    "model.safetensors"
  ],
  "skytnt/gpt2-japanese-lyric-small": [
    "model.safetensors"
  ],
  "bigscience/bigscience-small-testing": [
    "model.safetensors"
  ],
  "Akarsh3053/potter-chat-bot": [
    "model.safetensors"
  ],
  "Crataco/AID-Neo-125M": [
    "model.safetensors"
  ],
  "benjamin/gpt2-large-wechsel-ukrainian": [
    "model.safetensors"
  ],
  "benjamin/gpt2-wechsel-ukrainian": [
    "model.safetensors"
  ],
  "pszemraj/mGPT-Peter-2E": [
    "model.safetensors"
  ],
  "malteos/gpt2-wechsel-german-ds-meg": [
    "model.safetensors"
  ],
  "bigscience/bloom-560m": [
    "model.safetensors"
  ],
  "bigscience/bloom-1b1": [
    "model.safetensors"
  ],
  "bigscience/bloom-1b7": [
    "model.safetensors"
  ],
  "bigscience/bloom-3b": [
    "model.safetensors"
  ],
  "bigscience/bloom-7b1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "bigscience/bloom": [
    "model_00001-of-00072.safetensors",
    "model_00002-of-00072.safetensors",
    "model_00003-of-00072.safetensors",
    "model_00004-of-00072.safetensors",
    "model_00005-of-00072.safetensors",
    "model_00006-of-00072.safetensors",
    "model_00007-of-00072.safetensors",
    "model_00008-of-00072.safetensors",
    "model_00009-of-00072.safetensors",
    "model_00010-of-00072.safetensors",
    "model_00011-of-00072.safetensors",
    "model_00012-of-00072.safetensors",
    "model_00013-of-00072.safetensors",
    "model_00014-of-00072.safetensors",
    "model_00015-of-00072.safetensors",
    "model_00016-of-00072.safetensors",
    "model_00017-of-00072.safetensors",
    "model_00018-of-00072.safetensors",
    "model_00019-of-00072.safetensors",
    "model_00020-of-00072.safetensors",
    "model_00021-of-00072.safetensors",
    "model_00022-of-00072.safetensors",
    "model_00023-of-00072.safetensors",
    "model_00024-of-00072.safetensors",
    "model_00025-of-00072.safetensors",
    "model_00026-of-00072.safetensors",
    "model_00027-of-00072.safetensors",
    "model_00028-of-00072.safetensors",
    "model_00029-of-00072.safetensors",
    "model_00030-of-00072.safetensors",
    "model_00031-of-00072.safetensors",
    "model_00032-of-00072.safetensors",
    "model_00033-of-00072.safetensors",
    "model_00034-of-00072.safetensors",
    "model_00035-of-00072.safetensors",
    "model_00036-of-00072.safetensors",
    "model_00037-of-00072.safetensors",
    "model_00038-of-00072.safetensors",
    "model_00039-of-00072.safetensors",
    "model_00040-of-00072.safetensors",
    "model_00041-of-00072.safetensors",
    "model_00042-of-00072.safetensors",
    "model_00043-of-00072.safetensors",
    "model_00044-of-00072.safetensors",
    "model_00045-of-00072.safetensors",
    "model_00046-of-00072.safetensors",
    "model_00047-of-00072.safetensors",
    "model_00048-of-00072.safetensors",
    "model_00049-of-00072.safetensors",
    "model_00050-of-00072.safetensors",
    "model_00051-of-00072.safetensors",
    "model_00052-of-00072.safetensors",
    "model_00053-of-00072.safetensors",
    "model_00054-of-00072.safetensors",
    "model_00055-of-00072.safetensors",
    "model_00056-of-00072.safetensors",
    "model_00057-of-00072.safetensors",
    "model_00058-of-00072.safetensors",
    "model_00059-of-00072.safetensors",
    "model_00060-of-00072.safetensors",
    "model_00061-of-00072.safetensors",
    "model_00062-of-00072.safetensors",
    "model_00063-of-00072.safetensors",
    "model_00064-of-00072.safetensors",
    "model_00065-of-00072.safetensors",
    "model_00066-of-00072.safetensors",
    "model_00067-of-00072.safetensors",
    "model_00068-of-00072.safetensors",
    "model_00069-of-00072.safetensors",
    "model_00070-of-00072.safetensors",
    "model_00071-of-00072.safetensors",
    "model_00072-of-00072.safetensors"
  ],
  "pszemraj/opt-350m-email-generation": [
    "model.safetensors"
  ],
  "IDEA-CCNL/Wenzhong-GPT2-110M": [
    "model.safetensors"
  ],
  "fabianmmueller/deep-haiku-gpt-2": [
    "model.safetensors"
  ],
  "Anjoe/german-poetry-gpt2": [
    "model.safetensors"
  ],
  "mgfrantz/distilgpt2-finetuned-reddit-tifu": [
    "model.safetensors"
  ],
  "Nehc/AGIRussia": [
    "model.safetensors"
  ],
  "ehcalabres/distilgpt2-abc-irish-music-generation": [
    "model.safetensors"
  ],
  "Anjoe/german-poetry-gpt2-large": [
    "model.safetensors"
  ],
  "JdThe65th/GPT2-Glitchfur-Zenith-JD": [
    "model.safetensors"
  ],
  "DingosGotMyBaby/uhn-twitch-chat": [
    "model.safetensors"
  ],
  "bigscience/test-bloomd": [
    "model.safetensors"
  ],
  "lunde/gpt2-snapsvisor": [
    "model.safetensors"
  ],
  "Moo/kogpt2-proofreader": [
    "model.safetensors"
  ],
  "JulesBelveze/t5-small-headline-generator": [
    "model.safetensors"
  ],
  "erikycd/chatbot_hadita": [
    "model.safetensors"
  ],
  "its5Q/rugpt3large_mailqa": [
    "model.safetensors"
  ],
  "skytnt/gpt2-japanese-lyric-medium": [
    "model.safetensors"
  ],
  "pszemraj/opt-125m-email-generation": [
    "model.safetensors"
  ],
  "faebots/image-gpt2": [
    "model.safetensors"
  ],
  "bigscience/distill-bloom-1b3": [
    "model.safetensors"
  ],
  "bigscience/distill-bloom-1b3-10x": [
    "model.safetensors"
  ],
  "christofid/pgt": [
    "model.safetensors"
  ],
  "crumb/gpt-joke": [
    "model.safetensors"
  ],
  "Den4ikAI/rugpt3_2ch": [
    "model.safetensors"
  ],
  "PyroJack/rp-recap-model": [
    "model.safetensors"
  ],
  "leslyarun/bloom_ncbi_finetuned": [
    "model.safetensors"
  ],
  "ritwikm/gandhi-gpt": [
    "model.safetensors"
  ],
  "postbot/distilgpt2-emailgen": [
    "model.safetensors"
  ],
  "bigscience/bloom-3b-intermediate": [
    "model.safetensors"
  ],
  "bigscience/bloom-1b7-intermediate": [
    "model.safetensors"
  ],
  "bigscience/bloom-560m-intermediate": [
    "model.safetensors"
  ],
  "model-attribution-challenge/gpt2": [
    "model.safetensors"
  ],
  "Someman/gpt2-medium-ne": [
    "model.safetensors"
  ],
  "razhan/PyNeo": [
    "model.safetensors"
  ],
  "laurabernardy/LuxGPT2": [
    "model.safetensors"
  ],
  "uripper/AVA": [
    "model.safetensors"
  ],
  "rinna/japanese-gpt-neox-small": [
    "model.safetensors"
  ],
  "Langboat/bloom-1b4-zh": [
    "model.safetensors"
  ],
  "nschenone/rap-distil": [
    "model.safetensors"
  ],
  "aarya-c111/DialoGPT-small-Rogers": [
    "model.safetensors"
  ],
  "EleutherAI/polyglot-ko-3.8b": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "LasseVKP/DialoGPT-Mogens": [
    "model.safetensors"
  ],
  "Narrativaai/bloom-560m-finetuned-totto-table-to-text": [
    "model.safetensors"
  ],
  "shaurya0512/distilgpt2-finetune-acl22": [
    "model.safetensors"
  ],
  "EleutherAI/polyglot-ko-1.3b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "marcderbauer/vice-headlines": [
    "model.safetensors"
  ],
  "bigscience/bloomz": [
    "model_00001-of-00072.safetensors",
    "model_00002-of-00072.safetensors",
    "model_00003-of-00072.safetensors",
    "model_00004-of-00072.safetensors",
    "model_00005-of-00072.safetensors",
    "model_00006-of-00072.safetensors",
    "model_00007-of-00072.safetensors",
    "model_00008-of-00072.safetensors",
    "model_00009-of-00072.safetensors",
    "model_00010-of-00072.safetensors",
    "model_00011-of-00072.safetensors",
    "model_00012-of-00072.safetensors",
    "model_00013-of-00072.safetensors",
    "model_00014-of-00072.safetensors",
    "model_00015-of-00072.safetensors",
    "model_00016-of-00072.safetensors",
    "model_00017-of-00072.safetensors",
    "model_00018-of-00072.safetensors",
    "model_00019-of-00072.safetensors",
    "model_00020-of-00072.safetensors",
    "model_00021-of-00072.safetensors",
    "model_00022-of-00072.safetensors",
    "model_00023-of-00072.safetensors",
    "model_00024-of-00072.safetensors",
    "model_00025-of-00072.safetensors",
    "model_00026-of-00072.safetensors",
    "model_00027-of-00072.safetensors",
    "model_00028-of-00072.safetensors",
    "model_00029-of-00072.safetensors",
    "model_00030-of-00072.safetensors",
    "model_00031-of-00072.safetensors",
    "model_00032-of-00072.safetensors",
    "model_00033-of-00072.safetensors",
    "model_00034-of-00072.safetensors",
    "model_00035-of-00072.safetensors",
    "model_00036-of-00072.safetensors",
    "model_00037-of-00072.safetensors",
    "model_00038-of-00072.safetensors",
    "model_00039-of-00072.safetensors",
    "model_00040-of-00072.safetensors",
    "model_00041-of-00072.safetensors",
    "model_00042-of-00072.safetensors",
    "model_00043-of-00072.safetensors",
    "model_00044-of-00072.safetensors",
    "model_00045-of-00072.safetensors",
    "model_00046-of-00072.safetensors",
    "model_00047-of-00072.safetensors",
    "model_00048-of-00072.safetensors",
    "model_00049-of-00072.safetensors",
    "model_00050-of-00072.safetensors",
    "model_00051-of-00072.safetensors",
    "model_00052-of-00072.safetensors",
    "model_00053-of-00072.safetensors",
    "model_00054-of-00072.safetensors",
    "model_00055-of-00072.safetensors",
    "model_00056-of-00072.safetensors",
    "model_00057-of-00072.safetensors",
    "model_00058-of-00072.safetensors",
    "model_00059-of-00072.safetensors",
    "model_00060-of-00072.safetensors",
    "model_00061-of-00072.safetensors",
    "model_00062-of-00072.safetensors",
    "model_00063-of-00072.safetensors",
    "model_00064-of-00072.safetensors",
    "model_00065-of-00072.safetensors",
    "model_00066-of-00072.safetensors",
    "model_00067-of-00072.safetensors",
    "model_00068-of-00072.safetensors",
    "model_00069-of-00072.safetensors",
    "model_00070-of-00072.safetensors",
    "model_00071-of-00072.safetensors",
    "model_00072-of-00072.safetensors"
  ],
  "Gustavosta/MagicPrompt-Stable-Diffusion": [
    "model.safetensors"
  ],
  "Gustavosta/MagicPrompt-Dalle": [
    "model.safetensors"
  ],
  "EleutherAI/polyglot-ko-5.8b": [
    "model-00001-of-00013.safetensors",
    "model-00002-of-00013.safetensors",
    "model-00003-of-00013.safetensors",
    "model-00004-of-00013.safetensors",
    "model-00005-of-00013.safetensors",
    "model-00006-of-00013.safetensors",
    "model-00007-of-00013.safetensors",
    "model-00008-of-00013.safetensors",
    "model-00009-of-00013.safetensors",
    "model-00010-of-00013.safetensors",
    "model-00011-of-00013.safetensors",
    "model-00012-of-00013.safetensors",
    "model-00013-of-00013.safetensors"
  ],
  "shohanursobuj/DialoGPT": [
    "model.safetensors"
  ],
  "mrm8488/bloom-560m-finetuned-sd-prompts": [
    "model.safetensors"
  ],
  "mrm8488/bloom-560m-finetuned-common_gen": [
    "model.safetensors"
  ],
  "mrm8488/bloom-560m-finetuned-samsum": [
    "model.safetensors"
  ],
  "bigscience/bloomz-7b1-mt": [
    "model.safetensors"
  ],
  "sdadas/polish-gpt2-small": [
    "model.safetensors"
  ],
  "sdadas/polish-gpt2-medium": [
    "model.safetensors"
  ],
  "postbot/distilgpt2-emailgen-V2": [
    "model.safetensors"
  ],
  "postbot/gpt2-medium-emailgen": [
    "model.safetensors"
  ],
  "Imran1/gpt2-urdu-news": [
    "model.safetensors"
  ],
  "mrm8488/bloom-560m-finetuned-wikilingua-spanish-summarization": [
    "model.safetensors"
  ],
  "lcw99/ko-dialoGPT-korean-chit-chat": [
    "model.safetensors"
  ],
  "0x7o/BulgakovLM-3B": [
    "model.safetensors"
  ],
  "matthh/gpt2-poetry-model": [
    "model.safetensors"
  ],
  "cedpsam/EleutherAI_gpt-neo-125M-stablediffionprompts": [
    "model.safetensors"
  ],
  "cedpsam/cedpsam_EleutherAI_gpt-neo-125M-stablediffionprompts-stablediffionprompts": [
    "model.safetensors"
  ],
  "marblyso/DialoGPT-medium-shepherd": [
    "model.safetensors"
  ],
  "Spectre29/DialoGPT-small-Kaisa": [
    "model.safetensors"
  ],
  "Spectre29/Kaisa-converse-model": [
    "model.safetensors"
  ],
  "bigscience/bloomz-560m": [
    "model.safetensors"
  ],
  "bigscience/bloomz-1b1": [
    "model.safetensors"
  ],
  "bigscience/bloomz-3b": [
    "model.safetensors"
  ],
  "bigscience/bloomz-1b7": [
    "model.safetensors"
  ],
  "enryu43/anifusion_augmenter": [
    "model.safetensors"
  ],
  "binxu/Ziyue-GPT2": [
    "model.safetensors"
  ],
  "stevhliu/my_awesome_eli5_clm-model": [
    "model.safetensors"
  ],
  "shibing624/gpt2-dialogbot-base-chinese": [
    "model.safetensors"
  ],
  "EleutherAI/polyglot-ko-12.8b": [
    "model-00001-of-00028.safetensors",
    "model-00002-of-00028.safetensors",
    "model-00003-of-00028.safetensors",
    "model-00004-of-00028.safetensors",
    "model-00005-of-00028.safetensors",
    "model-00006-of-00028.safetensors",
    "model-00007-of-00028.safetensors",
    "model-00008-of-00028.safetensors",
    "model-00009-of-00028.safetensors",
    "model-00010-of-00028.safetensors",
    "model-00011-of-00028.safetensors",
    "model-00012-of-00028.safetensors",
    "model-00013-of-00028.safetensors",
    "model-00014-of-00028.safetensors",
    "model-00015-of-00028.safetensors",
    "model-00016-of-00028.safetensors",
    "model-00017-of-00028.safetensors",
    "model-00018-of-00028.safetensors",
    "model-00019-of-00028.safetensors",
    "model-00020-of-00028.safetensors",
    "model-00021-of-00028.safetensors",
    "model-00022-of-00028.safetensors",
    "model-00023-of-00028.safetensors",
    "model-00024-of-00028.safetensors",
    "model-00025-of-00028.safetensors",
    "model-00026-of-00028.safetensors",
    "model-00027-of-00028.safetensors",
    "model-00028-of-00028.safetensors"
  ],
  "EleutherAI/pythia-160m-v0": [
    "model.safetensors"
  ],
  "EleutherAI/pythia-1b-v0": [
    "model.safetensors"
  ],
  "EleutherAI/pythia-70m-v0": [
    "model.safetensors"
  ],
  "EleutherAI/pythia-410m-v0": [
    "model.safetensors"
  ],
  "EleutherAI/pythia-160m-deduped-v0": [
    "model.safetensors"
  ],
  "EleutherAI/pythia-1.4b-deduped-v0": [
    "model.safetensors"
  ],
  "EleutherAI/pythia-1b-deduped-v0": [
    "model.safetensors"
  ],
  "malteos/bloom-1b5-clp-german": [
    "model.safetensors"
  ],
  "RamAnanth1/distilgpt2-sd-prompts": [
    "model.safetensors"
  ],
  "neonon/DialoGPT-medium-cloy": [
    "model.safetensors"
  ],
  "neonon/DialoGPT-medium-htccc": [
    "model.safetensors"
  ],
  "EleutherAI/pythia-70m-deduped-v0": [
    "model.safetensors"
  ],
  "EleutherAI/pythia-410m-deduped-v0": [
    "model.safetensors"
  ],
  "crumb/fake-gpt-j-17m": [
    "model.safetensors"
  ],
  "mikegarts/distilgpt2-lotr": [
    "model.safetensors"
  ],
  "andrewkroening/GalaxyFarAway-DialoGPT-HanSolo": [
    "model.safetensors"
  ],
  "postbot/bloom-1b1-emailgen": [
    "model.safetensors"
  ],
  "andrewkroening/GalaxyFarAway-DialoGPT-Vader": [
    "model.safetensors"
  ],
  "andrewkroening/GalaxyFarAway-DialoGPT-Yoda": [
    "model.safetensors"
  ],
  "pszemraj/gpt-neo-125M-magicprompt-SD": [
    "model.safetensors"
  ],
  "pszemraj/opt-350m-magicprompt-SD": [
    "model.safetensors"
  ],
  "pszemraj/tiny-gpt2-magicprompt": [
    "model.safetensors"
  ],
  "pszemraj/distilgpt2-magicprompt-SD": [
    "model.safetensors"
  ],
  "GItaf/PELM-JointGPT": [
    "model.safetensors"
  ],
  "model-attribution-challenge/bloom-560m": [
    "model.safetensors"
  ],
  "lcw99/gpt-neo-1.3B-ko": [
    "model.safetensors"
  ],
  "pszemraj/opt-350m-multiprompt": [
    "model.safetensors"
  ],
  "lcw99/gpt-neo-1.3B-ko-fp16": [
    "model.safetensors"
  ],
  "KoboldAI/OPT-350M-Erebus": [
    "model.safetensors"
  ],
  "pszemraj/distilgpt2-multiprompt": [
    "model.safetensors"
  ],
  "fav-kky/gpt2-small-cs": [
    "model.safetensors"
  ],
  "facebook/galactica-125m": [
    "model.safetensors"
  ],
  "Den4ikAI/rugpt3-QA": [
    "model.safetensors"
  ],
  "4eJIoBek/ruGPT3_small_nujdiki_stage1": [
    "model.safetensors"
  ],
  "4eJIoBek/ruGPT3_small_nujdiki_fithah": [
    "model.safetensors"
  ],
  "AleBurzio/distilgpt2_jje": [
    "model.safetensors"
  ],
  "EleutherAI/pythia-2.8b-v0": [
    "model.safetensors"
  ],
  "IDEA-CCNL/Yuyuan-GPT2-110M-SciFi-Chinese": [
    "model.safetensors"
  ],
  "dkagramanyan/horoscope_rugpt3small": [
    "model.safetensors"
  ],
  "power-greg/super-fast-llm": [
    "model.safetensors"
  ],
  "juancopi81/gpt2-finetuned-yannic-large": [
    "model.safetensors"
  ],
  "juancopi81/GPT-Y": [
    "model.safetensors"
  ],
  "EleutherAI/pythia-2.8b-deduped-v0": [
    "model.safetensors"
  ],
  "kpriyanshu256/gpt-ya2": [
    "model.safetensors"
  ],
  "ploymel/mbart-50-reduced-th-en": [
    "model.safetensors"
  ],
  "Den4ikAI/DLM_500m": [
    "model.safetensors"
  ],
  "nlp-waseda/gpt2-xl-japanese": [
    "model.safetensors"
  ],
  "crumb/bloom-560m-RLHF-SD2-prompter": [
    "model.safetensors"
  ],
  "crumb/bloom-560m-RLHF-SD2-prompter-aesthetic": [
    "model.safetensors"
  ],
  "Den4ikAI/DLM_CHITCHAT_700M": [
    "model.safetensors"
  ],
  "asifahmed/distillgpt2-BittensorTuned4": [
    "model.safetensors"
  ],
  "tum-nlp/german-gpt2_easy": [
    "model.safetensors"
  ],
  "FredZhang7/distilgpt2-stable-diffusion": [
    "model.safetensors"
  ],
  "microsoft/git-base": [
    "model.safetensors"
  ],
  "FredZhang7/distilgpt2-stable-diffusion-v2": [
    "model.safetensors"
  ],
  "IDEA-CCNL/Wenzhong2.0-GPT2-110M-BertTokenizer-chinese": [
    "model.safetensors"
  ],
  "giulio98/codegen-2B-mono-xlcost": [
    "model.safetensors"
  ],
  "luiz826/MichaelScottGenFinal": [
    "model.safetensors"
  ],
  "dh-unibe/luther-xl": [
    "model.safetensors"
  ],
  "dh-unibe/gpt2-larger-luther": [
    "model.safetensors"
  ],
  "AI-Sweden-Models/gpt-sw3-126m": [
    "model.safetensors"
  ],
  "AI-Sweden-Models/gpt-sw3-356m": [
    "model.safetensors"
  ],
  "AI-Sweden-Models/gpt-sw3-1.3b": [
    "model.safetensors"
  ],
  "AI-Sweden-Models/gpt-sw3-6.7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AI-Sweden-Models/gpt-sw3-20b": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "yshen99/ZhiGuoLiZheng-GPT2": [
    "model.safetensors"
  ],
  "quintic/finetune_lean_2b": [
    "model.safetensors"
  ],
  "BirdL/OLM-GPT2-Yannic": [
    "model.safetensors"
  ],
  "sophiadt/DialoGPT-medium-707": [
    "model.safetensors"
  ],
  "mrsteyk/openchatgpt-neo-125m": [
    "model.safetensors"
  ],
  "robowaifudev/megatron-gpt2-345m": [
    "model.safetensors"
  ],
  "sophiadt/DialoGPT-medium-reigen": [
    "model.safetensors"
  ],
  "mrsteyk/openchatgpt-neox-125m": [
    "model.safetensors"
  ],
  "breadlicker45/MuseNeo": [
    "model.safetensors"
  ],
  "PygmalionAI/pygmalion-1.3b": [
    "model.safetensors"
  ],
  "igorktech/rugpt3-joker-150k": [
    "model.safetensors"
  ],
  "alexandreteles/GPTChizuru": [
    "model.safetensors"
  ],
  "kmewhort/stable-diffusion-prompt-bolster": [
    "model.safetensors"
  ],
  "Delcos/cogni1": [
    "model.safetensors"
  ],
  "Delcos/cogni1m": [
    "model.safetensors"
  ],
  "TheHappyDrone/DialoGPT-medium-salesman": [
    "model.safetensors"
  ],
  "TheHappyDrone/DialoGPT-medium-Nexus-Nova": [
    "model.safetensors"
  ],
  "microsoft/git-base-vatex": [
    "model.safetensors"
  ],
  "microsoft/git-large-coco": [
    "model.safetensors"
  ],
  "microsoft/git-large-vqav2": [
    "model.safetensors"
  ],
  "TheHappyDrone/DialoGPT-medium-Nexus-Nova-turing-v2": [
    "model.safetensors"
  ],
  "akhooli/poetry2023": [
    "model.safetensors"
  ],
  "Tanrei/GPTSAN-japanese": [
    "model.safetensors"
  ],
  "sdadas/polish-gpt2-large": [
    "model.safetensors"
  ],
  "sdadas/polish-gpt2-xl": [
    "model.safetensors"
  ],
  "akhooli/ap2023": [
    "model.safetensors"
  ],
  "Ar4ikov/gpt2-stable-diffusion-prompt-generator": [
    "model.safetensors"
  ],
  "souljoy/gpt2-small-chinese-cluecorpussmall": [
    "model.safetensors"
  ],
  "Ar4ikov/gpt2-pt-stable-diffusion-prompt-generator": [
    "model.safetensors"
  ],
  "Ar4ikov/gpt2-pt-2-stable-diffusion-prompt-generator": [
    "model.safetensors"
  ],
  "Ar4ikov/gpt2-medium-stable-diffusion-prompt-generator": [
    "model.safetensors"
  ],
  "Ar4ikov/gpt2-medium-2-stable-diffusion-prompt-generator": [
    "model.safetensors"
  ],
  "Ar4ikov/gpt2-medium-650k-stable-diffusion-prompt-generator": [
    "model.safetensors"
  ],
  "gabrielaltay/pubtator-gpt-p287M-c128": [
    "model.safetensors"
  ],
  "lchaloupsky/czech-gpt2-oscar": [
    "model.safetensors"
  ],
  "lchaloupsky/czech-gpt2-medical": [
    "model.safetensors"
  ],
  "Ar4ikov/gpt2-650k-stable-diffusion-prompt-generator": [
    "model.safetensors"
  ],
  "procesaur/gpt2-srlat": [
    "model.safetensors"
  ],
  "procesaur/gpt2-srlat-sem": [
    "model.safetensors"
  ],
  "procesaur/gpt2-srlat-synt": [
    "model.safetensors"
  ],
  "Norod78/gpt-fluentui-flat-svg": [
    "model.safetensors"
  ],
  "sr5434/gptQuotes": [
    "model.safetensors"
  ],
  "Delcos/cogni6": [],
  "olivierdehaene/optimized-santacoder": [
    "model.safetensors"
  ],
  "emre/spanish-dialoGPT": [
    "model.safetensors"
  ],
  "Suchinthana/sinhala-gpt-neo": [
    "model.safetensors"
  ],
  "bigscience/bloom-7b1-petals": [
    "model.safetensors"
  ],
  "microsoft/git-large-r": [
    "model.safetensors"
  ],
  "Suchinthana/sinhala-gpt-neo-cc100": [
    "model.safetensors"
  ],
  "DarwinAnim8or/gpt-grug-125m": [
    "model.safetensors"
  ],
  "DarwinAnim8or/GPT-DMV-125m": [
    "model.safetensors"
  ],
  "DarwinAnim8or/GPT-Greentext-125m": [
    "model.safetensors"
  ],
  "pszemraj/distilgpt2-HC3": [
    "model.safetensors"
  ],
  "crumb/pico-gpt-j-6.7m": [
    "model.safetensors"
  ],
  "artificialguybr/textcaps-teste2": [
    "model.safetensors"
  ],
  "OctaviusI/convogpt-2.7B-mirror": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "DarwinAnim8or/GPT-Greentext-355m": [
    "model.safetensors"
  ],
  "postbot/pythia-160m-hq-emails": [
    "model.safetensors"
  ],
  "Peeepy/Evie": [
    "model.safetensors"
  ],
  "arun-shankar/GPT-2-covid-news-articles": [
    "model.safetensors"
  ],
  "Fuwaguwa/DialoGPT-Medium-AzurLaneMusashi-v8": [
    "model.safetensors"
  ],
  "s3nh/DialoGPT-large-Rick": [
    "model.safetensors"
  ],
  "s3nh/DialoGPT-large-Morty": [
    "model.safetensors"
  ],
  "gmongaras/gpt-anime-sub-1.3B": [
    "model.safetensors"
  ],
  "concedo/Pythia-70M-ChatSalad": [
    "model.safetensors"
  ],
  "s3nh/DialoGPT-small-morty": [
    "model.safetensors"
  ],
  "Givinghawk/GPT-Morty": [
    "model.safetensors"
  ],
  "Crataco/Pythia-160M-Deduped-Adventure": [
    "model.safetensors"
  ],
  "s3nh/DialoGPT-small-harry-potter-goblet-of-fire": [
    "model.safetensors"
  ],
  "s3nh/DialoGPT-small-hermione-granger-goblet-of-fire": [
    "model.safetensors"
  ],
  "s3nh/DialoGPT-small-woody-toy-story": [
    "model.safetensors"
  ],
  "Writer/palmyra-small": [
    "model.safetensors"
  ],
  "thefrigidliquidation/pythia-410m-lightnovels": [
    "model.safetensors"
  ],
  "Vaibhav-rm/GPT2-Shri-v1": [
    "model.safetensors"
  ],
  "sayakpaul/git-base-pokemon": [
    "model.safetensors"
  ],
  "EleutherAI/pythia-160m": [
    "model.safetensors"
  ],
  "DarwinAnim8or/GPT-Grug-355m": [
    "model.safetensors"
  ],
  "EleutherAI/pythia-160m-deduped": [
    "model.safetensors"
  ],
  "FredZhang7/anime-anything-promptgen-v2": [
    "model.safetensors"
  ],
  "EleutherAI/pythia-1.4b": [
    "model.safetensors"
  ],
  "EleutherAI/pythia-2.8b-deduped": [
    "model.safetensors"
  ],
  "EleutherAI/pythia-2.8b": [
    "model.safetensors"
  ],
  "EleutherAI/pythia-70m-deduped": [
    "model.safetensors"
  ],
  "EleutherAI/pythia-410m": [
    "model.safetensors"
  ],
  "EleutherAI/pythia-410m-deduped": [
    "model.safetensors"
  ],
  "EleutherAI/pythia-1b-deduped": [
    "model.safetensors"
  ],
  "postbot/emailgen-pythia-410m-deduped": [
    "model.safetensors"
  ],
  "EleutherAI/pythia-160m-seed1": [
    "model.safetensors"
  ],
  "EleutherAI/pythia-160m-seed2": [
    "model.safetensors"
  ],
  "EleutherAI/pythia-160m-seed3": [
    "model.safetensors"
  ],
  "vietgpt-archive/gpt2-150M": [
    "model.safetensors"
  ],
  "vietgpt-archive/gpt-neo-125M": [
    "model.safetensors"
  ],
  "evilfreelancer/dostoevsky_doesnt_write_it_gpt2": [
    "model.safetensors"
  ],
  "Beltenebros/DialoGPT-small-PerionOfGaul": [
    "model.safetensors"
  ],
  "Intel/fid_flan_t5_base_nq": [
    "model.safetensors"
  ],
  "Intel/fid_t5_large_nq": [
    "model.safetensors"
  ],
  "Suchinthana/sinhala-gpt-neo-siwiki": [
    "model.safetensors"
  ],
  "0Tick/e621TagAutocomplete": [
    "model.safetensors"
  ],
  "HiTZ/gpt2-eus-euscrawl": [
    "model.safetensors"
  ],
  "SRDdev/ScriptForge": [
    "model.safetensors"
  ],
  "0Tick/danbooruTagAutocomplete": [
    "model.safetensors"
  ],
  "mahmoudNG/wikitext-ds": [
    "model.safetensors"
  ],
  "AI-Sweden-Models/gpt-sw3-40b": [
    "model-00001-of-00017.safetensors",
    "model-00002-of-00017.safetensors",
    "model-00003-of-00017.safetensors",
    "model-00004-of-00017.safetensors",
    "model-00005-of-00017.safetensors",
    "model-00006-of-00017.safetensors",
    "model-00007-of-00017.safetensors",
    "model-00008-of-00017.safetensors",
    "model-00009-of-00017.safetensors",
    "model-00010-of-00017.safetensors",
    "model-00011-of-00017.safetensors",
    "model-00012-of-00017.safetensors",
    "model-00013-of-00017.safetensors",
    "model-00014-of-00017.safetensors",
    "model-00015-of-00017.safetensors",
    "model-00016-of-00017.safetensors",
    "model-00017-of-00017.safetensors"
  ],
  "David042/DialoGPT-LucasBot": [
    "model.safetensors"
  ],
  "Hobospider132/DialoGPT-Mahiru-Proto": [
    "model.safetensors"
  ],
  "BreadAi/gpt-Youtube": [
    "model.safetensors"
  ],
  "mykor/gpt2-ko": [
    "model.safetensors"
  ],
  "alpindale/pygm-350m-experimental": [
    "model.safetensors"
  ],
  "Joshwabail/gpt2_finetuned_wolfram": [
    "model.safetensors"
  ],
  "okazaki-lab/japanese-gpt2-medium-unidic": [
    "model.safetensors"
  ],
  "SRDdev/ScriptForge-small": [
    "model.safetensors"
  ],
  "Isotonic/gpt-human-assistant": [
    "model.safetensors"
  ],
  "DarwinAnim8or/GPT-NoSleep-355m": [
    "model.safetensors"
  ],
  "SummerSigh/GPT2-Instruct-SFT": [
    "model.safetensors"
  ],
  "kennethhendricks/DialoGPT-medium-PowPowGaming": [
    "model.safetensors"
  ],
  "SummerSigh/GPTNeo350M-Instruct-SFT": [
    "model.safetensors"
  ],
  "Leomas/DialoGPT-medium-Leomas": [
    "model.safetensors"
  ],
  "EleutherAI/pythia-intervention-410m-deduped": [
    "model.safetensors"
  ],
  "SummerSigh/GPTNeo350M-Instruct-Safety-SFT": [
    "model.safetensors"
  ],
  "RJZauner/distilgpt2_eli5_causal_model": [
    "model.safetensors"
  ],
  "SummerSigh/Pythia410m-Instruct-SFT": [
    "model.safetensors"
  ],
  "sr5434/chatbot": [
    "model.safetensors"
  ],
  "Upword/gpt-neox-20b-embeddings": [
    "model-00001-of-00046.safetensors",
    "model-00002-of-00046.safetensors",
    "model-00003-of-00046.safetensors",
    "model-00004-of-00046.safetensors",
    "model-00005-of-00046.safetensors",
    "model-00006-of-00046.safetensors",
    "model-00007-of-00046.safetensors",
    "model-00008-of-00046.safetensors",
    "model-00009-of-00046.safetensors",
    "model-00010-of-00046.safetensors",
    "model-00011-of-00046.safetensors",
    "model-00012-of-00046.safetensors",
    "model-00013-of-00046.safetensors",
    "model-00014-of-00046.safetensors",
    "model-00015-of-00046.safetensors",
    "model-00016-of-00046.safetensors",
    "model-00017-of-00046.safetensors",
    "model-00018-of-00046.safetensors",
    "model-00019-of-00046.safetensors",
    "model-00020-of-00046.safetensors",
    "model-00021-of-00046.safetensors",
    "model-00022-of-00046.safetensors",
    "model-00023-of-00046.safetensors",
    "model-00024-of-00046.safetensors",
    "model-00025-of-00046.safetensors",
    "model-00026-of-00046.safetensors",
    "model-00027-of-00046.safetensors",
    "model-00028-of-00046.safetensors",
    "model-00029-of-00046.safetensors",
    "model-00030-of-00046.safetensors",
    "model-00031-of-00046.safetensors",
    "model-00032-of-00046.safetensors",
    "model-00033-of-00046.safetensors",
    "model-00034-of-00046.safetensors",
    "model-00035-of-00046.safetensors",
    "model-00036-of-00046.safetensors",
    "model-00037-of-00046.safetensors",
    "model-00038-of-00046.safetensors",
    "model-00039-of-00046.safetensors",
    "model-00040-of-00046.safetensors",
    "model-00041-of-00046.safetensors",
    "model-00042-of-00046.safetensors",
    "model-00043-of-00046.safetensors",
    "model-00044-of-00046.safetensors",
    "model-00045-of-00046.safetensors",
    "model-00046-of-00046.safetensors"
  ],
  "Zeda/DialoGPT-Medium-ZedaBot": [
    "model.safetensors"
  ],
  "thefrigidliquidation/pythia-1b-lightnovels": [
    "model.safetensors"
  ],
  "soBeauty/distilbert-base-uncased-Auto_Train": [
    "model.safetensors"
  ],
  "DeathReaper0965/gpt2-large-code-generator": [
    "model.safetensors"
  ],
  "BreadAi/StoryPy": [
    "model.safetensors"
  ],
  "igorktech/sc-gpt-upf": [
    "model.safetensors"
  ],
  "jslin09/bloom-560m-finetuned-fraud": [
    "model.safetensors"
  ],
  "imperialwool/ai-dungeon-medium-rus": [
    "model.safetensors"
  ],
  "FahriBilici/crypto_model_gpt2": [
    "model.safetensors"
  ],
  "EleutherAI/pythia-1b": [
    "model.safetensors"
  ],
  "JeffreyLau/SikuGPT2": [
    "model.safetensors"
  ],
  "imperialwool/ai-dungeon-large-en": [
    "model.safetensors"
  ],
  "kennethhendricks/DialoGPT-medium-jared-hendricks-gen1": [
    "model.safetensors"
  ],
  "toloka/gpt2-large-supervised-prompt-writing": [
    "model.safetensors"
  ],
  "LordDanielDE/DialoGPT-medium-Hina": [
    "model.safetensors"
  ],
  "femboysLover/rugpt3_medium_otvetmailru": [
    "model.safetensors"
  ],
  "Pavarissy/mentalgpt-v0.0.1": [
    "model.safetensors"
  ],
  "Fan2/gpt2-confluence": [
    "model.safetensors"
  ],
  "Mogwhy/DialoGPT-medium-Arrobot": [
    "model.safetensors"
  ],
  "beomi/KoAlpaca-Polyglot-5.8B": [
    "model-00001-of-00013.safetensors",
    "model-00002-of-00013.safetensors",
    "model-00003-of-00013.safetensors",
    "model-00004-of-00013.safetensors",
    "model-00005-of-00013.safetensors",
    "model-00006-of-00013.safetensors",
    "model-00007-of-00013.safetensors",
    "model-00008-of-00013.safetensors",
    "model-00009-of-00013.safetensors",
    "model-00010-of-00013.safetensors",
    "model-00011-of-00013.safetensors",
    "model-00012-of-00013.safetensors",
    "model-00013-of-00013.safetensors"
  ],
  "anforsm/GPT-Echo-82m": [
    "model.safetensors"
  ],
  "BigSalmon/InformalToFormalLincoln95Paraphrase": [
    "model.safetensors"
  ],
  "YukioKoito/DialoGPT-small-ozua": [
    "model.safetensors"
  ],
  "YukioKoito/DialoGPT-small-doog": [
    "model.safetensors"
  ],
  "SRDdev/ScriptForge-medium": [
    "model.safetensors"
  ],
  "Yarflam/gptRoleplay": [
    "model.safetensors"
  ],
  "Kongfha/PhraAphaiManee-LM": [
    "model.safetensors"
  ],
  "coldfir3/oscar-pt-large": [
    "model.safetensors"
  ],
  "AlexWortega/instruct_rugptlarge": [
    "model.safetensors"
  ],
  "jncarlo/monica-v0.1.0": [
    "model.safetensors"
  ],
  "softrime/distilgpt2-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "BreadAi/MuseCan-1-2": [
    "model.safetensors"
  ],
  "MarkK/GPT-Sponge": [
    "model.safetensors"
  ],
  "Patil/Stable-Diffusion-prompt-generator": [
    "model.safetensors"
  ],
  "Bingsu/llama-190m-arch": [
    "model.safetensors"
  ],
  "TabbyML/NeoX-70M": [
    "model.safetensors"
  ],
  "XBOT-RK/distilgpt2-wiki-qa": [
    "model.safetensors"
  ],
  "NbAiLab/nb-alpaca-lora-7b": [
    "adapter_model.safetensors"
  ],
  "Xmaster6y/gpt2-mul": [
    "model.safetensors"
  ],
  "benkimz/agbrain": [
    "model.safetensors"
  ],
  "ybelkada/bloom-1b7-8bit": [
    "model.safetensors"
  ],
  "Corianas/111m": [
    "model.safetensors"
  ],
  "Corianas/256m": [
    "model.safetensors"
  ],
  "Corianas/1.3b": [
    "model.safetensors"
  ],
  "Corianas/590m": [
    "model.safetensors"
  ],
  "OccamRazor/pythia-160m-deduped-gptq-4bit": [
    "model.safetensors"
  ],
  "GerbilLab/GerbilBlender-A-32m": [
    "model.safetensors"
  ],
  "Corianas/Quokka_2.7b": [
    "model.safetensors"
  ],
  "Corianas/256_5epoch": [
    "model.safetensors"
  ],
  "jonfd/gpt2-igc-is": [
    "model.safetensors"
  ],
  "Ar4ikov/PromptGPTv2": [
    "model.safetensors"
  ],
  "GerbilLab/GerbilBlender-D-6.7m": [
    "model.safetensors"
  ],
  "GerbilLab/GerbilBlender-A-77m": [
    "model.safetensors"
  ],
  "GerbilLab/GerbilBlender-B-star-77m": [
    "model.safetensors"
  ],
  "malteos/gpt2-uk": [
    "model.safetensors"
  ],
  "cactusfriend/nightmare-invokeai-prompts": [
    "model.safetensors"
  ],
  "DarwinAnim8or/NoSleepPromptGen": [
    "model.safetensors"
  ],
  "refringence/ad-gpt2-finetuned-dch1": [
    "model.safetensors"
  ],
  "totallynotbrent/brotGPT": [],
  "huggyllama/llama-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "huggyllama/llama-13b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "totallynotbrent/brotAIplus": [
    "model.safetensors"
  ],
  "huggyllama/llama-30b": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "huggyllama/llama-65b": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "wybxc/new-yiri": [
    "model.safetensors"
  ],
  "naxautify/gpt2-4k": [
    "model.safetensors"
  ],
  "Corianas/Quokka_256m": [
    "model.safetensors"
  ],
  "Corianas/Quokka_111m": [
    "model.safetensors"
  ],
  "totallynotbrent/brotGPTbeta": [
    "model.safetensors"
  ],
  "totallynotbrent/aaronGPTalpha": [
    "model.safetensors"
  ],
  "lxe/Cerebras-GPT-1.3B-Alpaca-SP": [
    "model.safetensors"
  ],
  "Neko-Institute-of-Science/LLaMA-7B-HF": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Neko-Institute-of-Science/LLaMA-13B-HF": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Neko-Institute-of-Science/LLaMA-30B-HF": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "Neko-Institute-of-Science/LLaMA-65B-HF": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "bigcode/gpt_bigcode-santacoder": [
    "model.safetensors"
  ],
  "GerbilLab/IPythia-70m": [
    "model.safetensors"
  ],
  "totallynotbrent/brotGPTplus": [],
  "NihalSrivastava/advertisement-description-generator": [
    "model.safetensors"
  ],
  "naxautify/gpt2-medium-4k-pile": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "Corianas/Quokka_1.3b": [
    "model.safetensors"
  ],
  "Corianas/Quokka_590m": [
    "model.safetensors"
  ],
  "vicgalle/gpt2-alpaca": [
    "model.safetensors"
  ],
  "TheBloke/koala-7B-GPTQ": [
    "model.safetensors"
  ],
  "vicgalle/gpt2-open-instruct-v1": [
    "model.safetensors"
  ],
  "auhide/chef-gpt-base": [
    "model.safetensors"
  ],
  "vicgalle/gpt2-alpaca-gpt4": [
    "model.safetensors"
  ],
  "TheBloke/koala-13B-GPTQ": [
    "model.safetensors"
  ],
  "RTT-FI/RTT-NLP-125M": [
    "model.safetensors"
  ],
  "toloka/gpt2-large-rl-prompt-writing": [
    "model.safetensors"
  ],
  "beomi/kollama-7b": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "houck2040/geo-physics-test": [
    "model.safetensors"
  ],
  "totallynotbrent/aaronGPTplus": [
    "model.safetensors"
  ],
  "TheBloke/vicuna-7B-v0-GPTQ": [
    "model.safetensors"
  ],
  "MrD05/Kaido-350m": [
    "model.safetensors"
  ],
  "MrD05/kaido-1.3b": [
    "model.safetensors"
  ],
  "MrD05/pyg6b": [],
  "auhide/gpt2-small-bgwiki": [
    "model.safetensors"
  ],
  "SebastianSchramm/Cerebras-GPT-111M-instruction": [
    "model.safetensors"
  ],
  "floriangardin/model": [
    "model.safetensors"
  ],
  "inu-ai/alpaca-guanaco-japanese-gpt-1b": [
    "model.safetensors"
  ],
  "peter-sk/gpt-neox-da": [
    "model.safetensors"
  ],
  "akoksal/LongForm-OPT-2.7B": [
    "model.safetensors"
  ],
  "inu-ai/dolly-japanese-gpt-1b": [
    "model.safetensors"
  ],
  "beomi/kollama-13b": [
    "model-00001-of-00028.safetensors",
    "model-00002-of-00028.safetensors",
    "model-00003-of-00028.safetensors",
    "model-00004-of-00028.safetensors",
    "model-00005-of-00028.safetensors",
    "model-00006-of-00028.safetensors",
    "model-00007-of-00028.safetensors",
    "model-00008-of-00028.safetensors",
    "model-00009-of-00028.safetensors",
    "model-00010-of-00028.safetensors",
    "model-00011-of-00028.safetensors",
    "model-00012-of-00028.safetensors",
    "model-00013-of-00028.safetensors",
    "model-00014-of-00028.safetensors",
    "model-00015-of-00028.safetensors",
    "model-00016-of-00028.safetensors",
    "model-00017-of-00028.safetensors",
    "model-00018-of-00028.safetensors",
    "model-00019-of-00028.safetensors",
    "model-00020-of-00028.safetensors",
    "model-00021-of-00028.safetensors",
    "model-00022-of-00028.safetensors",
    "model-00023-of-00028.safetensors",
    "model-00024-of-00028.safetensors",
    "model-00025-of-00028.safetensors",
    "model-00026-of-00028.safetensors",
    "model-00027-of-00028.safetensors",
    "model-00028-of-00028.safetensors"
  ],
  "zlsl/ru_startrek": [
    "model.safetensors"
  ],
  "zlsl/ru_warcraft": [
    "model.safetensors"
  ],
  "TheBloke/gpt4-alpaca-lora-30B-GPTQ": [
    "model.safetensors"
  ],
  "nonlinearshimada/gpt2": [
    "model.safetensors"
  ],
  "alexbuyan/yt_videos_comments": [
    "model.safetensors"
  ],
  "Avitas8485/Dialogpt-small-v1": [
    "model.safetensors"
  ],
  "RomeroRZ/gladiusprompt-vith-gpt2": [
    "model.safetensors"
  ],
  "spitfire4794/ben-ultra": [
    "model.safetensors"
  ],
  "VTSTech/Desktop-GPT-111m": [
    "model.safetensors"
  ],
  "TheBloke/gpt4-alpaca-lora-13B-GPTQ": [
    "model.safetensors"
  ],
  "PranomVignesh/gpt2-sonnet-generators": [
    "model.safetensors"
  ],
  "Darsh12/mcq_generation": [
    "model.safetensors"
  ],
  "beomi/KoAlpaca-Polyglot-12.8B": [
    "model-00001-of-00028.safetensors",
    "model-00002-of-00028.safetensors",
    "model-00003-of-00028.safetensors",
    "model-00004-of-00028.safetensors",
    "model-00005-of-00028.safetensors",
    "model-00006-of-00028.safetensors",
    "model-00007-of-00028.safetensors",
    "model-00008-of-00028.safetensors",
    "model-00009-of-00028.safetensors",
    "model-00010-of-00028.safetensors",
    "model-00011-of-00028.safetensors",
    "model-00012-of-00028.safetensors",
    "model-00013-of-00028.safetensors",
    "model-00014-of-00028.safetensors",
    "model-00015-of-00028.safetensors",
    "model-00016-of-00028.safetensors",
    "model-00017-of-00028.safetensors",
    "model-00018-of-00028.safetensors",
    "model-00019-of-00028.safetensors",
    "model-00020-of-00028.safetensors",
    "model-00021-of-00028.safetensors",
    "model-00022-of-00028.safetensors",
    "model-00023-of-00028.safetensors",
    "model-00024-of-00028.safetensors",
    "model-00025-of-00028.safetensors",
    "model-00026-of-00028.safetensors",
    "model-00027-of-00028.safetensors",
    "model-00028-of-00028.safetensors"
  ],
  "ku-nlp/gpt2-small-japanese-char": [
    "model.safetensors"
  ],
  "TheBloke/alpaca-lora-65B-GPTQ": [
    "model.safetensors"
  ],
  "Celestinian/SentimentGPT": [
    "model.safetensors"
  ],
  "niizam/gpt2-4chan-mini": [
    "model.safetensors"
  ],
  "vvsotnikov/stablelm-tuned-alpha-3b-16bit": [
    "model.safetensors"
  ],
  "MockingJ/chatbot": [
    "model.safetensors"
  ],
  "naxautify/pythia-1.4b-deduped-8k": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "nicholascao/chatbloom-1b7-sft": [
    "model.safetensors"
  ],
  "seanmor5/tiny-gpt-neox-test": [
    "model.safetensors"
  ],
  "houck2040/satire_llm": [
    "model.safetensors"
  ],
  "PixelPerfect/PixelPerfect_StableDiffusion_AutoCompleteModel": [
    "model.safetensors"
  ],
  "dagim/AmharicGPT": [
    "model.safetensors"
  ],
  "sr5434/InstructCodegen-350M-mono": [
    "model.safetensors"
  ],
  "TheBloke/medalpaca-13B-GPTQ": [
    "model.safetensors"
  ],
  "unionai/pythia-70m-deduped-alpaca-cleaned": [
    "model.safetensors"
  ],
  "Celestinian/PromptGPT": [
    "model.safetensors"
  ],
  "Den4ikAI/ebany_researcher": [
    "model.safetensors"
  ],
  "Avitas8485/Dialogpt-medium-finetuned": [
    "model.safetensors"
  ],
  "erfanzar/PGT-1B": [
    "model.safetensors"
  ],
  "erfanzar/PGT-1B-2EP": [
    "model.safetensors"
  ],
  "TheBloke/wizardLM-7B-GPTQ": [
    "model.safetensors"
  ],
  "ahj224/mymodel": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "thegoodfellas/tgf-gpt-117m-tunned": [
    "model.safetensors"
  ],
  "DarwinAnim8or/DailyChat-350M": [
    "model.safetensors"
  ],
  "AlexWortega/wortegaLM": [
    "model.safetensors"
  ],
  "Locutusque/gpt2-conversational-or-qa": [
    "model.safetensors"
  ],
  "lcw99/polyglot-ko-12.8b-chang-instruct-chat": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AI-Sweden-Models/gpt-sw3-126m-instruct": [
    "model.safetensors"
  ],
  "AI-Sweden-Models/gpt-sw3-356m-instruct": [
    "model.safetensors"
  ],
  "AI-Sweden-Models/gpt-sw3-1.3b-instruct": [
    "model.safetensors"
  ],
  "Lajonbot/GPT2-124M-Instruct-12500steps-polish": [
    "model.safetensors"
  ],
  "AI-Sweden-Models/gpt-sw3-6.7b-v2-instruct": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AI-Sweden-Models/gpt-sw3-6.7b-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AI-Sweden-Models/gpt-sw3-20b-instruct": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "unionai/pythia-1b-deduped-finetune-alpaca-cleaned": [
    "model.safetensors"
  ],
  "TheBloke/stable-vicuna-13B-GPTQ": [
    "model.safetensors"
  ],
  "emozilla/pythia-1.4b-deduped-rp-420m-4k": [
    "model.safetensors"
  ],
  "emozilla/pythia-1.4b-deduped-rp-280m-4k": [
    "model.safetensors"
  ],
  "Narrativaai/BioGPT-Large-finetuned-chatdoctor": [
    "model.safetensors"
  ],
  "TheBloke/OpenAssistant-SFT-7-Llama-30B-GPTQ": [
    "model.safetensors"
  ],
  "Neko-Institute-of-Science/pygmalion-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "crumb/gpt2023": [
    "model.safetensors"
  ],
  "Neko-Institute-of-Science/metharme-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TehVenom/Metharme-7b-Merged-Safetensors": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "TehVenom/Pygmalion-7b-Merged-Safetensors": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "BiaDd/DialoGPT-medium-Punko": [
    "model.safetensors"
  ],
  "Lajonbot/LaMini-GPT-774M-19000-steps-polish": [
    "model.safetensors"
  ],
  "userzyzz/piggySharded": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "Imablank/P1GM4L10N-7B-MERGED_WEIGHTS": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Imablank/Metharme-7B-MERGED_WEIGHTS": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "BreadAi/PM_modelV2": [
    "model.safetensors"
  ],
  "mrsteyk/memepp-llama-512v-6l-8h-256e": [
    "model.safetensors"
  ],
  "NewBreaker/gpt2": [
    "model.safetensors"
  ],
  "oyxy2019/Wenzhong-GPT2-110M-THUCNews": [
    "model.safetensors"
  ],
  "Lajonbot/pythia-1b-13000-steps-polish": [
    "model.safetensors"
  ],
  "KnutJaegersberg/megatron-GPT-2-345m-EvolInstruct": [
    "model.safetensors"
  ],
  "hermanshid/distilbert-id-law": [
    "model.safetensors"
  ],
  "TehVenom/Pygmalion-Vicuna-1.1-7b": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "askmyteapot/metharme": [
    "metharme-0.1percdamp-4bit-32g.safetensors",
    "metharme-0.1percdamp-4bit.safetensors",
    "metharme-10percdamp-4bit.safetensors",
    "metharme-1percdamp-4bit.safetensors",
    "metharme-4bit-32g.safetensors",
    "metharme-4bit.safetensors",
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "diabolic6045/tony_stark_chatbot": [
    "model.safetensors"
  ],
  "diabolic6045/harry_potter_chatbot": [
    "model.safetensors"
  ],
  "s3nh/DialoGPT-small-5000steps-polish": [
    "model.safetensors"
  ],
  "s3nh/DialoGPT-medium-4000steps-polish": [
    "model.safetensors"
  ],
  "crumb/distilpythia": [
    "model.safetensors"
  ],
  "nasheed/rl-grp-prj-gpt2-base-persuader": [
    "model.safetensors"
  ],
  "jerteh/gpt2-orao": [
    "model.safetensors"
  ],
  "Narsil/gpt3": [
    "model.safetensors"
  ],
  "TheBloke/wizard-vicuna-13B-GPTQ": [
    "model.safetensors"
  ],
  "Dampish/Dante_256M": [
    "model.safetensors"
  ],
  "TheBloke/WizardLM-7B-uncensored-GPTQ": [
    "model.safetensors"
  ],
  "Celestinian/Synthia-700M": [
    "model.safetensors"
  ],
  "s3nh/tiny-gpt2-instruct-polish": [
    "model.safetensors"
  ],
  "s3nh/gpt2-open-instruct-v1-polish": [
    "model.safetensors"
  ],
  "TheBloke/GPT4All-13B-snoozy-GPTQ": [
    "model.safetensors"
  ],
  "Vipitis/santacoder-finetuned-Shadertoys-fine": [
    "model.safetensors"
  ],
  "TheBloke/gpt4-x-vicuna-13B-GPTQ": [
    "model.safetensors"
  ],
  "Vipitis/santacoder-finetuned-Shadertoys": [
    "model.safetensors"
  ],
  "ce-lery/dolly-japanese-gpt-1b-clone": [
    "model.safetensors",
    "output/model.safetensors"
  ],
  "OccamRazor/mpt-7b-storywriter-4bit-128g": [
    "model.safetensors"
  ],
  "Celestinian/Synthia-1.5B": [
    "model.safetensors"
  ],
  "ByteWave/gpt2-turkish-uncased": [
    "model.safetensors"
  ],
  "4bit/mpt-7b-storywriter-4bit-128g": [
    "model.safetensors"
  ],
  "s3nh/DialoGPT-large-instruct-polish-3000-steps": [
    "model.safetensors"
  ],
  "universonic/llama-7b-8bit": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "dkalpakchi/SweCTRL-Mini": [
    "model.safetensors"
  ],
  "sephwalker3/piggy-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "DIAG-PSSeng/cicero-gpt2": [
    "model.safetensors"
  ],
  "p208p2002/bloomz-Alpaca-560M": [
    "model.safetensors"
  ],
  "HuggingFaceH4/starchat-alpha": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "sam2ai/odia-distil-gpt2": [
    "model.safetensors"
  ],
  "DarwinAnim8or/GPT-NoSleep-1.5b": [
    "model.safetensors"
  ],
  "DarwinAnim8or/GPT-Greentext-1.5b": [
    "model.safetensors"
  ],
  "TheBloke/h2ogpt-oasst1-512-30B-GPTQ": [
    "model.safetensors"
  ],
  "ewof/koishi-instruct-3b": [
    "model.safetensors"
  ],
  "TheBloke/dromedary-65B-lora-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/gpt4-alpaca-lora_mlp-65B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Wizard-Vicuna-13B-Uncensored-GPTQ": [
    "model.safetensors"
  ],
  "vitaliy-sharandin/wiseai": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ldilov/stablelm-tuned-alpha-7b-4bit-128g-descact-sym-true-sequential": [
    "model.safetensors"
  ],
  "AlexWortega/wortegaLM-1b": [
    "model.safetensors"
  ],
  "i2/cnn_gen_2epochs": [
    "model.safetensors"
  ],
  "psyche/kogpt": [
    "model.safetensors"
  ],
  "bigcode/tiny_starcoder_py": [
    "model.safetensors"
  ],
  "gray567/PModel": [
    "model.safetensors"
  ],
  "Tempstablediffusion/opt-125m_flow_001": [
    "model.safetensors"
  ],
  "TheBloke/wizard-mega-13B-GPTQ": [
    "model.safetensors"
  ],
  "loresiensis/distilgpt2-emailgen-phishing": [
    "model.safetensors"
  ],
  "Fredithefish/RedPajama-3B-Chat-SDPromptGenInstruct-merged": [
    "model.safetensors"
  ],
  "Locutusque/gpt2-medium-conversational": [
    "model.safetensors"
  ],
  "Fredithefish/RedPajama-INCITE-Chat-3B-Instruction-Tuning-with-GPT-4": [
    "model.safetensors"
  ],
  "Rachneet/gpt2-xl-alpaca": [
    "model.safetensors"
  ],
  "DarwinAnim8or/Pythia-Greentext-1.4b": [
    "model.safetensors"
  ],
  "rinna/japanese-gpt-neox-3.6b-instruction-sft": [
    "model.safetensors"
  ],
  "rinna/japanese-gpt-neox-3.6b": [
    "model.safetensors"
  ],
  "TheBloke/VicUnlocked-30B-LoRA-GPTQ": [
    "model.safetensors"
  ],
  "n0madic/ai-art-random-prompts": [
    "model.safetensors"
  ],
  "ikala/redpajama-3b-chat": [
    "model.safetensors"
  ],
  "IHaBiS/stabilityai_stablelm-base-alpha-7b_safetensors": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "ku-nlp/gpt2-medium-japanese-char": [
    "model.safetensors"
  ],
  "TheBloke/Wizard-Vicuna-7B-Uncensored-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Manticore-13B-GPTQ": [
    "model.safetensors"
  ],
  "TehVenom/Metharme-13b-8bit-GPTQ": [
    "model.safetensors"
  ],
  "TehVenom/Metharme-13b-4bit-GPTQ": [
    "model.safetensors"
  ],
  "TehVenom/Pygmalion-13b-8bit-GPTQ": [
    "model.safetensors"
  ],
  "khanhj/testgpt2chatbot": [
    "model.safetensors"
  ],
  "beomi/KoRWKV-1.5B": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/WizardLM-30B-Uncensored-GPTQ": [
    "model.safetensors"
  ],
  "openaccess-ai-collective/manticore-13b-chat-pyg": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "michaelfeil/codegen2-1B-gptj": [
    "model.safetensors"
  ],
  "michaelfeil/codegen2-3_7B-gptj": [
    "model.safetensors"
  ],
  "4bit/pyg-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "zjunlp/zhixi-13b-lora": [
    "adapter_model.safetensors"
  ],
  "WangZeJun/bloom-396m-chat": [
    "model.safetensors"
  ],
  "RahmaBS/git-base-pokemon": [
    "model.safetensors"
  ],
  "akoksal/LongForm-OPT-125M": [
    "model.safetensors"
  ],
  "TheBloke/airoboros-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/manticore-13b-chat-pyg-GPTQ": [
    "model.safetensors"
  ],
  "breadlicker45/discord-gpt2": [
    "model.safetensors"
  ],
  "TheBloke/Project-Baize-v2-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Project-Baize-v2-13B-GPTQ": [
    "model.safetensors"
  ],
  "openaccess-ai-collective/manticore-30b-chat-pyg-alpha": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "alpindale/pygmalion-instruct": [
    "model-00001-of-00039.safetensors",
    "model-00002-of-00039.safetensors",
    "model-00003-of-00039.safetensors",
    "model-00004-of-00039.safetensors",
    "model-00005-of-00039.safetensors",
    "model-00006-of-00039.safetensors",
    "model-00007-of-00039.safetensors",
    "model-00008-of-00039.safetensors",
    "model-00009-of-00039.safetensors",
    "model-00010-of-00039.safetensors",
    "model-00011-of-00039.safetensors",
    "model-00012-of-00039.safetensors",
    "model-00013-of-00039.safetensors",
    "model-00014-of-00039.safetensors",
    "model-00015-of-00039.safetensors",
    "model-00016-of-00039.safetensors",
    "model-00017-of-00039.safetensors",
    "model-00018-of-00039.safetensors",
    "model-00019-of-00039.safetensors",
    "model-00020-of-00039.safetensors",
    "model-00021-of-00039.safetensors",
    "model-00022-of-00039.safetensors",
    "model-00023-of-00039.safetensors",
    "model-00024-of-00039.safetensors",
    "model-00025-of-00039.safetensors",
    "model-00026-of-00039.safetensors",
    "model-00027-of-00039.safetensors",
    "model-00028-of-00039.safetensors",
    "model-00029-of-00039.safetensors",
    "model-00030-of-00039.safetensors",
    "model-00031-of-00039.safetensors",
    "model-00032-of-00039.safetensors",
    "model-00033-of-00039.safetensors",
    "model-00034-of-00039.safetensors",
    "model-00035-of-00039.safetensors",
    "model-00036-of-00039.safetensors",
    "model-00037-of-00039.safetensors",
    "model-00038-of-00039.safetensors",
    "model-00039-of-00039.safetensors"
  ],
  "IHaBiS/pygmalion-13b-safetensors": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "sadiqj/camlcoder": [
    "model.safetensors"
  ],
  "TheBloke/guanaco-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/guanaco-33B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/guanaco-65B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/guanaco-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Vigogne-Instruct-13B-GPTQ": [
    "model.safetensors"
  ],
  "beomi/KoRWKV-6B": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "JackFram/llama-160m": [
    "model.safetensors"
  ],
  "MayaPH/FinOPT-Washington": [
    "model.safetensors"
  ],
  "MayaPH/FinOPT-Lincoln": [
    "model.safetensors"
  ],
  "MayaPH/FinOPT-Franklin": [
    "model.safetensors"
  ],
  "Avitas8485/Dialogpt-medium-v2": [
    "model.safetensors"
  ],
  "TheBloke/Falcon-7B-Instruct-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/falcon-40b-instruct-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/WizardLM-13B-1.0-GPTQ": [
    "model.safetensors"
  ],
  "danielhanchen/open_llama_3b_600bt_preview": [
    "model.safetensors"
  ],
  "adityavelusamy/quest-v3": [
    "model.safetensors"
  ],
  "m33393/llama-65b-gptq-cuda-4bit-32g-safetensors": [
    "4bit-32g.safetensors"
  ],
  "adityavelusamy/autotrain-6v04-emwh-bq47-62263135046": [
    "model.safetensors"
  ],
  "TheBloke/gorilla-7B-GPTQ": [
    "model.safetensors"
  ],
  "rockerBOO/stablelm-tuned-alpha-3b-8bit": [
    "model.safetensors"
  ],
  "TheBloke/Samantha-7B-GPTQ": [
    "model.safetensors"
  ],
  "minhcrafters/DialoGPT-small-Fukuya": [
    "model.safetensors"
  ],
  "TheBloke/Samantha-13B-GPTQ": [
    "model.safetensors"
  ],
  "quintic/pythia-repair-char-based-2.8B-highlr-hf-2000step": [
    "model.safetensors"
  ],
  "TheBloke/samantha-33B-GPTQ": [
    "model.safetensors"
  ],
  "quintic/gpt2-large": [
    "model.safetensors"
  ],
  "stanford-crfm/levanter-backpack-1b": [
    "model.safetensors"
  ],
  "dfurman/Falcon-7B-Chat-v0.1": [
    "adapter_model.safetensors"
  ],
  "dfurman/Falcon-40B-Chat-v0.1": [
    "adapter_model.safetensors"
  ],
  "rinna/japanese-gpt-neox-3.6b-instruction-sft-v2": [
    "model.safetensors"
  ],
  "rinna/japanese-gpt-neox-3.6b-instruction-ppo": [
    "model.safetensors"
  ],
  "TheBloke/Wizard-Vicuna-30B-Uncensored-GPTQ": [
    "model.safetensors"
  ],
  "Lajonbot/pythia-160m-53500-self-instruct-polish": [
    "model.safetensors"
  ],
  "Lajonbot/pythia-410m-21k-steps-self-instruct-polish": [
    "model.safetensors"
  ],
  "BlueSunflower/gpt2-medium-chess": [
    "model.safetensors"
  ],
  "TheBloke/samantha-falcon-7B-GPTQ": [
    "model.safetensors"
  ],
  "beomi/polyglot-ko-12.8b-safetensors-8bit": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "ivanzhouyq/levanter-backpack-1b-100k": [
    "model.safetensors"
  ],
  "beomi/polyglot-ko-12.8b-safetensors": [
    "model-00001-of-00028.safetensors",
    "model-00002-of-00028.safetensors",
    "model-00003-of-00028.safetensors",
    "model-00004-of-00028.safetensors",
    "model-00005-of-00028.safetensors",
    "model-00006-of-00028.safetensors",
    "model-00007-of-00028.safetensors",
    "model-00008-of-00028.safetensors",
    "model-00009-of-00028.safetensors",
    "model-00010-of-00028.safetensors",
    "model-00011-of-00028.safetensors",
    "model-00012-of-00028.safetensors",
    "model-00013-of-00028.safetensors",
    "model-00014-of-00028.safetensors",
    "model-00015-of-00028.safetensors",
    "model-00016-of-00028.safetensors",
    "model-00017-of-00028.safetensors",
    "model-00018-of-00028.safetensors",
    "model-00019-of-00028.safetensors",
    "model-00020-of-00028.safetensors",
    "model-00021-of-00028.safetensors",
    "model-00022-of-00028.safetensors",
    "model-00023-of-00028.safetensors",
    "model-00024-of-00028.safetensors",
    "model-00025-of-00028.safetensors",
    "model-00026-of-00028.safetensors",
    "model-00027-of-00028.safetensors",
    "model-00028-of-00028.safetensors"
  ],
  "TheBloke/hippogriff-30b-chat-GPTQ": [
    "model.safetensors"
  ],
  "p208p2002/gpt2-large-babi": [
    "model.safetensors"
  ],
  "s3nh/pythia-410m-70k-steps-self-instruct-polish": [
    "model.safetensors"
  ],
  "TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/WizardLM-Uncensored-Falcon-7B-GPTQ": [
    "model.safetensors"
  ],
  "ebisuke/liz-nojaloli-nxja-ja": [
    "model.safetensors"
  ],
  "WangZeJun/bloom-820m-chat": [
    "model.safetensors"
  ],
  "cosimoiaia/Loquace-410m": [
    "model.safetensors"
  ],
  "s3nh/pythia-410m-91k-steps-self-instruct-polish": [
    "model.safetensors"
  ],
  "beomi/KoAlpaca-KoRWKV-6B": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "s3nh/pythia-410m-103k-steps-self-instruct-polish": [
    "model.safetensors"
  ],
  "nomic-ai/gpt4all-falcon": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "breadlicker45/gpt-neo-small": [
    "model.safetensors"
  ],
  "TabbyML/SantaCoder-1B": [
    "model.safetensors"
  ],
  "sadiqj/camlcoder-dev": [
    "model.safetensors"
  ],
  "PygmalionAI/metharme-1.3b": [
    "model.safetensors"
  ],
  "caprizone6/BioGPT-Large-PubMedQA-finetuned-KIDS2023": [
    "model.safetensors"
  ],
  "TheBloke/Karen_theEditor_13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/PMC_LLAMA-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/based-30B-GPTQ": [
    "model.safetensors"
  ],
  "alibidaran/medical_transcription_generator": [
    "model.safetensors"
  ],
  "TheBloke/WizardLM-Uncensored-Falcon-40B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Nous-Hermes-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/airoboros-13b-gpt4-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/based-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/based-13b-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/airoboros-7b-gpt4-GPTQ": [
    "model.safetensors"
  ],
  "s3nh/pythia-1.4b-deduped-10k-steps-self-instruct-polish": [
    "model.safetensors"
  ],
  "TheBloke/llama-deus-7b-v3-GPTQ": [
    "model.safetensors"
  ],
  "dwojcik/gpt2-large-fine-tuned-context-256": [
    "model.safetensors"
  ],
  "flozi00/falcon-7b-sft-mix-2000-4-bits-autogptq": [
    "model.safetensors"
  ],
  "TheBloke/Planner-7B-GPTQ": [
    "model.safetensors"
  ],
  "datatab/gpt2-serbian-base": [
    "model.safetensors"
  ],
  "Kongfha/KlonSuphap-LM": [
    "model.safetensors"
  ],
  "TheBloke/Selfee-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/WizardLM-30B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/chronos-33b-GPTQ": [
    "model.safetensors"
  ],
  "Ssarion/gpt2-multi-news": [
    "model.safetensors"
  ],
  "s3nh/pythia-1.4b-deduped-53k-steps-self-instruct-polish": [
    "model.safetensors"
  ],
  "HuggingFaceH4/starchat-beta": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/chronos-wizardlm-uc-scot-st-13B-GPTQ": [
    "model.safetensors"
  ],
  "Fredithefish/ReasonixPajama-3B-HF": [
    "model.safetensors"
  ],
  "TheBloke/CAMEL-13B-Combined-Data-GPTQ": [
    "model.safetensors"
  ],
  "MolagBal/mio-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/CAMEL-13B-Role-Playing-Data-GPTQ": [
    "model.safetensors"
  ],
  "nicholasKluge/Aira-2-124M": [
    "model.safetensors"
  ],
  "emrecanacikgoz/opt-125m-MedMCQA-radiology": [
    "model.safetensors"
  ],
  "nicholasKluge/Aira-2-355M": [
    "model.safetensors"
  ],
  "nicholasKluge/Aira-2-774M": [
    "model.safetensors"
  ],
  "nicholasKluge/Aira-2-portuguese-560M": [
    "model.safetensors"
  ],
  "alibaba-pai/pai-bloom-1b1-text2prompt-sd": [
    "model.safetensors"
  ],
  "TheBloke/selfee-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Vicuna-13B-CoT-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Vicuna-7B-CoT-GPTQ": [
    "model.safetensors"
  ],
  "piratos/ct2fast-starchat-beta": [],
  "Finnish-NLP/llama-7b-finnish": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/starcoder-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/starcoderplus-GPTQ": [
    "model.safetensors"
  ],
  "flozi00/OpenAssistant-SFT-7-Llama-30B-4-bits-autogptq": [
    "model.safetensors"
  ],
  "TheBloke/minotaur-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/starchat-beta-GPTQ": [
    "model.safetensors"
  ],
  "leondz/artgpt2tox": [
    "model.safetensors"
  ],
  "vilsonrodrigues/falcon-7b-instruct-sharded": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "euclaise/gpt-neox-122m-minipile-digits": [
    "model.safetensors"
  ],
  "zlsl/ru_warhammer40k": [
    "model.safetensors"
  ],
  "TheBloke/open-llama-7b-open-instruct-GPTQ": [
    "model.safetensors"
  ],
  "flozi00/OpenAssistant-falcon-40B-4-bits-autogptq": [
    "model.safetensors"
  ],
  "TheBloke/samantha-1.1-llama-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/airoboros-13B-1.1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/tulu-30B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/samantha-1.1-llama-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/tulu-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/tulu-7B-GPTQ": [
    "model.safetensors"
  ],
  "nicholasKluge/Aira-2-portuguese-124M": [
    "model.safetensors"
  ],
  "TheBloke/samantha-1.1-llama-33B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/airoboros-33b-gpt4-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/fin-llama-33B-GPTQ": [
    "model.safetensors"
  ],
  "houck2040/rice_mba": [
    "model.safetensors"
  ],
  "CobraMamba/mamba-gpt-3b": [
    "model.safetensors"
  ],
  "Binaryy/gpt2_travel_test": [
    "model.safetensors"
  ],
  "Doge22/DialoGPT-medium-max": [
    "model.safetensors"
  ],
  "Finnish-NLP/llama-3b-finnish": [
    "model.safetensors"
  ],
  "stefan-it/secret-gpt2": [
    "model.safetensors"
  ],
  "yswill/llama-13b-hf": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/chronos-hermes-13B-GPTQ": [
    "model.safetensors"
  ],
  "ljcnju/gpt2forattack": [
    "model.safetensors"
  ],
  "TFLai/gpt2-instruct-turkish-cased": [
    "model.safetensors"
  ],
  "TheBloke/minotaur-13B-fixed-GPTQ": [
    "model.safetensors"
  ],
  "huggingface/falcon-40b-gptq": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/airoboros-33B-gpt4-1.2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/airoboros-65B-gpt4-1.2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/WizardCoder-15B-1.0-GPTQ": [
    "model.safetensors"
  ],
  "paragonnov/copaca-1.3B": [
    "model.safetensors"
  ],
  "Narsil/starcoder-gptq-testing": [
    "model.safetensors"
  ],
  "breadlicker45/MuseRizz": [
    "model.safetensors"
  ],
  "Narsil/starcoder-gptq": [
    "model.safetensors"
  ],
  "javirandor/passgpt-10characters": [
    "model.safetensors"
  ],
  "Arc53/DocsGPT-7B": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "HaiderSultanArc/UnaniGPT": [
    "model.safetensors"
  ],
  "vilsonrodrigues/falcon-7b-sharded": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "Locutusque/gpt2-large-conversational": [
    "model.safetensors"
  ],
  "cateto/korean-gpt-neox-125M": [
    "model.safetensors"
  ],
  "WangZeJun/bloom-3b-moss-chat": [
    "model.safetensors"
  ],
  "l3cube-pune/mr-gpt": [
    "model.safetensors"
  ],
  "Suppi123/Bert-Base-Uncased-Text-Style-Transfer-Using-Examples": [
    "model.safetensors"
  ],
  "Suppi123/GPT-NEO-2.7B-Text-Style-Transfer-Using-Examples": [
    "model.safetensors"
  ],
  "TheBloke/airoboros-7B-gpt4-1.2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/airoboros-13B-gpt4-1.2-GPTQ": [
    "model.safetensors"
  ],
  "busywhistling/WizardCoder-15B-V1.0_safetensors": [
    "model-00001-of-00028.safetensors",
    "model-00002-of-00028.safetensors",
    "model-00003-of-00028.safetensors",
    "model-00004-of-00028.safetensors",
    "model-00005-of-00028.safetensors",
    "model-00006-of-00028.safetensors",
    "model-00007-of-00028.safetensors",
    "model-00008-of-00028.safetensors",
    "model-00009-of-00028.safetensors",
    "model-00010-of-00028.safetensors",
    "model-00011-of-00028.safetensors",
    "model-00012-of-00028.safetensors",
    "model-00013-of-00028.safetensors",
    "model-00014-of-00028.safetensors",
    "model-00015-of-00028.safetensors",
    "model-00016-of-00028.safetensors",
    "model-00017-of-00028.safetensors",
    "model-00018-of-00028.safetensors",
    "model-00019-of-00028.safetensors",
    "model-00020-of-00028.safetensors",
    "model-00021-of-00028.safetensors",
    "model-00022-of-00028.safetensors",
    "model-00023-of-00028.safetensors",
    "model-00024-of-00028.safetensors",
    "model-00025-of-00028.safetensors",
    "model-00026-of-00028.safetensors",
    "model-00027-of-00028.safetensors",
    "model-00028-of-00028.safetensors"
  ],
  "zlsl/l_warhammer3": [
    "model.safetensors"
  ],
  "zlsl/m_physics": [
    "model.safetensors"
  ],
  "zlsl/m_cosmos": [
    "model.safetensors"
  ],
  "TheBloke/robin-33B-v2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/robin-7B-v2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/robin-13B-v2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/robin-65B-v2-GPTQ": [
    "model.safetensors"
  ],
  "GeorgiaTechResearchInstitute/galactica-30b-evol-instruct-70k": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "vilm/vietcuna-3b": [
    "model.safetensors"
  ],
  "SRDdev/ScriptForge_Plus": [
    "model.safetensors"
  ],
  "dfurman/LLaMA-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "dfurman/LLaMA-13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "KennethTM/gpt2-small-danish": [
    "model.safetensors"
  ],
  "TheBloke/galactica-30B-evol-instruct-70K-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/CAMEL-33B-Combined-Data-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/minotaur-15B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/WizardLM-7B-V1.0-Uncensored-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/BigTranslate-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/vicuna-7B-v1.3-GPTQ": [
    "model.safetensors"
  ],
  "anujsahani01/codegen_finetune": [
    "model.safetensors"
  ],
  "TheBloke/baichuan-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/cassandra-6.9B-GPTQ": [
    "model.safetensors"
  ],
  "crumb/bespoke-gpt-124m": [
    "model.safetensors"
  ],
  "xzuyn/GPT-2-Stable-Diffusion-2.008M-Prompts-6.86M": [
    "model.safetensors"
  ],
  "minani/GPT-vietnamese": [
    "model.safetensors"
  ],
  "Wazzzabeee/PoliteBloomz": [
    "model.safetensors"
  ],
  "syf2023/gpt2": [
    "model.safetensors"
  ],
  "garage-bAInd/Platypus-30B": [
    "model-00001-of-00023.safetensors",
    "model-00002-of-00023.safetensors",
    "model-00003-of-00023.safetensors",
    "model-00004-of-00023.safetensors",
    "model-00005-of-00023.safetensors",
    "model-00006-of-00023.safetensors",
    "model-00007-of-00023.safetensors",
    "model-00008-of-00023.safetensors",
    "model-00009-of-00023.safetensors",
    "model-00010-of-00023.safetensors",
    "model-00011-of-00023.safetensors",
    "model-00012-of-00023.safetensors",
    "model-00013-of-00023.safetensors",
    "model-00014-of-00023.safetensors",
    "model-00015-of-00023.safetensors",
    "model-00016-of-00023.safetensors",
    "model-00017-of-00023.safetensors",
    "model-00018-of-00023.safetensors",
    "model-00019-of-00023.safetensors",
    "model-00020-of-00023.safetensors",
    "model-00021-of-00023.safetensors",
    "model-00022-of-00023.safetensors",
    "model-00023-of-00023.safetensors"
  ],
  "emozilla/open_llama-3b-2k-xpos-ckpt1000": [
    "model.safetensors"
  ],
  "TheBloke/WizardLM-13B-V1.0-Uncensored-GPTQ": [
    "model.safetensors"
  ],
  "KennethTM/gpt2-small-danish-review-response": [
    "model.safetensors"
  ],
  "TheBloke/airoboros-7B-gpt4-1.3-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/baichuan-vicuna-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/open-llama-13b-open-instruct-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/airoboros-13B-gpt4-1.3-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/airoboros-33B-gpt4-1.3-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/airoboros-65B-gpt4-1.3-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/baichuan-llama-7B-GPTQ": [
    "model.safetensors"
  ],
  "autopilot-ai/Indic-sentence-completion": [
    "model.safetensors"
  ],
  "xzuyn/GPT2-Stable-Diffusion-1.487M-Prompts-Deduped-6.86M": [
    "model.safetensors"
  ],
  "Tinny-Robot/NCAIR-ChatBot": [
    "model.safetensors"
  ],
  "Rajaganapathy/distilgpt2_model": [
    "model.safetensors"
  ],
  "TheBloke/airoboros-7B-gpt4-1.4-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/airoboros-13B-gpt4-1.4-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Flan-OpenLlama-7B-GPTQ": [
    "model.safetensors"
  ],
  "papahawk/keya-560m": [
    "model.safetensors"
  ],
  "mio/danbooru-gpt2": [
    "model.safetensors"
  ],
  "nicholasKluge/Aira-2-1B5": [
    "model.safetensors"
  ],
  "kraitans21/test_pythia": [
    "model.safetensors"
  ],
  "Andrew5057/gpt-backstory-generator": [
    "model.safetensors"
  ],
  "Joshwabail/gpt-2-large-sft": [
    "model.safetensors"
  ],
  "TheBloke/h2ogpt-gm-oasst1-en-2048-falcon-40b-v2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/WizardLM-33B-V1.0-Uncensored-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/orca_mini_13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/orca_mini_7B-GPTQ": [
    "model.safetensors"
  ],
  "jiyuanq/falcon-40b-instruct-gptq-128g-act": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/vicuna-13b-v1.3.0-GPTQ": [
    "model.safetensors"
  ],
  "nnpy/opt-350m-instruct": [
    "model.safetensors"
  ],
  "felixdae/cs324-length-control": [
    "model.safetensors"
  ],
  "Narsil/amall-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Guanaco-33B-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/WizardLM-33B-V1-0-Uncensored-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "cactusfriend/nightmare-promptgen-XL": [
    "model.safetensors"
  ],
  "IssamL/darijabertgenad": [
    "model.safetensors"
  ],
  "TheBloke/Tulu-30B-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/airoboros-33B-gpt4-1.4-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/chronos-33b-superhot-8k-GPTQ": [
    "model.safetensors"
  ],
  "nicholasKluge/Aira-2-portuguese-1B7": [
    "model.safetensors"
  ],
  "TheBloke/Wizard-Vicuna-30B-Superhot-8K-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Vicuna-13B-1-3-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "Ichigo2899/WIZVIC-7b-TGI-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/WizardLM-13B-V1-0-Uncensored-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/guanaco-13B-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Nous-Hermes-13B-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Manticore-13B-Chat-Pyg-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Manticore-13B-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Minotaur-13B-fixed-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "Ichigo2899/Airoboros-13b-8k-TGI-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Robin-13B-v2-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Samantha-13B-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Tulu-13B-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Wizard-Vicuna-13B-Uncensored-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "xzuyn/GPT2-RPGPT-8.48M": [
    "model.safetensors"
  ],
  "udxyz/HarryPotterBot": [
    "model.safetensors"
  ],
  "TheBloke/airoboros-13b-gpt4-1.4-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/CAMEL-13B-Role-Playing-Data-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Chronos-Hermes-13B-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/CAMEL-13B-Combined-Data-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/GPT4All-13B-Snoozy-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Samantha-33B-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Chronos-13B-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Pygmalion-13B-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "breadlicker45/dough-instruct-base-001": [
    "model.safetensors"
  ],
  "usmiva/gpt-web-bg": [
    "model.safetensors"
  ],
  "sahil2801/glaive_math_1b_1": [
    "model.safetensors"
  ],
  "vuiseng9/ov-gpt2-fp32-no-cache": [
    "model.safetensors"
  ],
  "Norod78/TinyStories-3M-val-Hebrew": [
    "model.safetensors"
  ],
  "garage-bAInd/GPlatty-30B": [
    "model-00001-of-00023.safetensors",
    "model-00002-of-00023.safetensors",
    "model-00003-of-00023.safetensors",
    "model-00004-of-00023.safetensors",
    "model-00005-of-00023.safetensors",
    "model-00006-of-00023.safetensors",
    "model-00007-of-00023.safetensors",
    "model-00008-of-00023.safetensors",
    "model-00009-of-00023.safetensors",
    "model-00010-of-00023.safetensors",
    "model-00011-of-00023.safetensors",
    "model-00012-of-00023.safetensors",
    "model-00013-of-00023.safetensors",
    "model-00014-of-00023.safetensors",
    "model-00015-of-00023.safetensors",
    "model-00016-of-00023.safetensors",
    "model-00017-of-00023.safetensors",
    "model-00018-of-00023.safetensors",
    "model-00019-of-00023.safetensors",
    "model-00020-of-00023.safetensors",
    "model-00021-of-00023.safetensors",
    "model-00022-of-00023.safetensors",
    "model-00023-of-00023.safetensors"
  ],
  "garage-bAInd/SuperPlatty-30B": [
    "model-00001-of-00023.safetensors",
    "model-00002-of-00023.safetensors",
    "model-00003-of-00023.safetensors",
    "model-00004-of-00023.safetensors",
    "model-00005-of-00023.safetensors",
    "model-00006-of-00023.safetensors",
    "model-00007-of-00023.safetensors",
    "model-00008-of-00023.safetensors",
    "model-00009-of-00023.safetensors",
    "model-00010-of-00023.safetensors",
    "model-00011-of-00023.safetensors",
    "model-00012-of-00023.safetensors",
    "model-00013-of-00023.safetensors",
    "model-00014-of-00023.safetensors",
    "model-00015-of-00023.safetensors",
    "model-00016-of-00023.safetensors",
    "model-00017-of-00023.safetensors",
    "model-00018-of-00023.safetensors",
    "model-00019-of-00023.safetensors",
    "model-00020-of-00023.safetensors",
    "model-00021-of-00023.safetensors",
    "model-00022-of-00023.safetensors",
    "model-00023-of-00023.safetensors"
  ],
  "TheBloke/wizard-vicuna-13B-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/airoboros-33B-gpt4-1-4-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "wyklq/falcon-40b-gptq": [
    "gptq_model-4bit-128g.safetensors"
  ],
  "hegbert/my_awesome_eli5_clm-model": [
    "model.safetensors"
  ],
  "TheBloke/Manticore-13B-Chat-Pyg-Guanaco-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/GPlatty-30B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Platypus-30B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/llama-30b-supercot-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "lxyuan/distilgpt2-finetuned-finance": [
    "model.safetensors"
  ],
  "turkbloom/turkbloom": [
    "model.safetensors"
  ],
  "TheBloke/Platypus-30B-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/GPlatty-30B-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/airoboros-65B-gpt4-1.4-GPTQ": [
    "model.safetensors"
  ],
  "osiria/diablo-italian-base-1.3b": [
    "model.safetensors"
  ],
  "TheBloke/UltraLM-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/h2ogpt-research-oasst1-llama-65B-GPTQ": [
    "model.safetensors"
  ],
  "Abzu/mpt-30b-instruct-q8": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/LongChat-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/LongChat-7B-GPTQ": [
    "model.safetensors"
  ],
  "syzymon/long_llama_3b": [
    "model.safetensors"
  ],
  "TheBloke/Chinese-Alpaca-33B-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/vicuna-33B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Vicuna-33B-1-3-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "Ichigo2899/Vicuna-13B-1-3-SuperHOT-8K-fp16-TGI-GPTQ": [
    "model.safetensors"
  ],
  "davidvblumenthal/1.4B-GPT-Verite": [
    "model.safetensors"
  ],
  "iambestfeed/open_llama_3b_4bit_128g": [
    "model.safetensors"
  ],
  "TheBloke/Redmond-Hermes-Coder-GPTQ": [
    "model.safetensors"
  ],
  "juancopi81/lmd-8bars-2048-epochs10": [
    "model.safetensors"
  ],
  "anujsahani01/finetuned_codegen": [
    "model.safetensors"
  ],
  "BramVanroy/falcon-7b-ft-alpaca-cleaned-dutch": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "clam004/gpt-neo-125m-context-consistent-v3": [
    "model.safetensors"
  ],
  "TheBloke/SuperPlatty-30B-GPTQ": [
    "model.safetensors"
  ],
  "bhenrym14/airoboros-33b-gpt4-1.4.1-PI-8192-fp16": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "clam004/gpt-neo-125m-v4": [
    "model.safetensors"
  ],
  "minhcrafters/DialoGPT-small-mindwandering": [
    "model.safetensors"
  ],
  "TheBloke/orca_mini_v2_7B-GPTQ": [
    "model.safetensors"
  ],
  "BramVanroy/falcon-7b-ft-alpaca-dolly-dutch": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Unspoiled-Egg/DialoGPT-small-TheoVon": [
    "model.safetensors"
  ],
  "kraitans21/pythia_1B_th_old_token": [
    "model.safetensors"
  ],
  "Pitchboy/falcon-7b-facts": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "minhcrafters/DialoGPT-medium-Zephirel": [
    "model.safetensors"
  ],
  "LaconicAI/falcon-40b-instruct-gptq": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "zlsl/en_l_warhammer_fantasy": [
    "model.safetensors"
  ],
  "zlsl/en_l_wh40k_full": [
    "model.safetensors"
  ],
  "migueldeguzmandev/modFDTGPT2xl": [
    "model.safetensors"
  ],
  "projecte-aina/aguila-7b": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "SaffalPoosh/falcon_7B_instruct_safetensors": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "papahawk/gpt2-1.5b": [
    "model.safetensors"
  ],
  "HuggingFaceM4/idefics-80b": [
    "model-00001-of-00017.safetensors",
    "model-00002-of-00017.safetensors",
    "model-00003-of-00017.safetensors",
    "model-00004-of-00017.safetensors",
    "model-00005-of-00017.safetensors",
    "model-00006-of-00017.safetensors",
    "model-00007-of-00017.safetensors",
    "model-00008-of-00017.safetensors",
    "model-00009-of-00017.safetensors",
    "model-00010-of-00017.safetensors",
    "model-00011-of-00017.safetensors",
    "model-00012-of-00017.safetensors",
    "model-00013-of-00017.safetensors",
    "model-00014-of-00017.safetensors",
    "model-00015-of-00017.safetensors",
    "model-00016-of-00017.safetensors",
    "model-00017-of-00017.safetensors"
  ],
  "juancopi81/lmd-8bars-2048-epochs20_v3": [
    "model.safetensors"
  ],
  "clam004/gpt-neo-125m-imdb": [
    "model.safetensors"
  ],
  "MicaniLabs/Stoa-13B-GPTQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/CAMEL-33B-Combined-Data-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "BramVanroy/falcon-40b-ft-alpaca-dolly-dutch": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "TheBloke/Airoboros-7B-GPT4-1-4-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Baize-v2-13B-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "nkpz/serena-safe-gptq": [
    "4bit--1g.act.order.safetensors"
  ],
  "jackoyoungblood/TinyStoriesTest": [
    "model.safetensors"
  ],
  "Abzu/mpt-7b-q8": [
    "model.safetensors"
  ],
  "TheBloke/Guanaco-7B-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "SaffalPoosh/falcon-7b_safetensors": [
    "model.safetensors"
  ],
  "TheBloke/Koala-7B-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Robin-7B-v2-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Baize-v2-7B-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Koala-13B-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Samantha-1-1-Llama-7B-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Selfee-13B-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Selfee-7B-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Tulu-7B-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Vicuna-7B-v1-3-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Vicuna-7B-CoT-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Wizard-Vicuna-7B-Uncensored-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/WizardLM-7B-V1-0-Uncensored-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/PMC_LLAMA-7B-10-Epoch-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "jackoyoungblood/TinyStoriesProject": [
    "model.safetensors"
  ],
  "happyduck/koal_5.8b": [
    "model-00001-of-00013.safetensors",
    "model-00002-of-00013.safetensors",
    "model-00003-of-00013.safetensors",
    "model-00004-of-00013.safetensors",
    "model-00005-of-00013.safetensors",
    "model-00006-of-00013.safetensors",
    "model-00007-of-00013.safetensors",
    "model-00008-of-00013.safetensors",
    "model-00009-of-00013.safetensors",
    "model-00010-of-00013.safetensors",
    "model-00011-of-00013.safetensors",
    "model-00012-of-00013.safetensors",
    "model-00013-of-00013.safetensors"
  ],
  "crumb/opentinystories-30m-base": [
    "model.safetensors"
  ],
  "Abzu/mpt-7b-instruct-q8": [
    "model.safetensors"
  ],
  "Abzu/mpt-7b-chat-q8": [
    "model.safetensors"
  ],
  "Abzu/mpt-7b-storywriter-q8": [
    "model.safetensors"
  ],
  "Abzu/mpt-30b-q8": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "Abzu/mpt-30b-chat-q8": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Pygmalion-7B-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/WizardLM-13B-V1.1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/WizardLM-13B-V1-1-SuperHOT-8K-GPTQ": [
    "model.safetensors"
  ],
  "crumb/opentinystories-68m-base": [
    "model.safetensors"
  ],
  "Maykeye/TinyLLama-v0": [
    "model.safetensors"
  ],
  "crumb/opentinystories-68m-complex": [
    "model.safetensors"
  ],
  "iambestfeed/llama_7b_4bit_16g_spqr": [
    "model.safetensors"
  ],
  "spitfire4794/dialogpt-small-rick": [
    "model.safetensors"
  ],
  "tschesky/PygmalionTest": [
    "model.safetensors"
  ],
  "flozi00/open_llama_7b-german-assistant": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Ichigo2899/WizardLM-13B-V1-0-Uncensored-SuperHOT-8K-TGI": [
    "model.safetensors"
  ],
  "TheBloke/orca_mini_v2_13b-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/GodziLLa-30B-GPTQ": [
    "model.safetensors"
  ],
  "nnpy/pythia-160m-chat": [
    "model.safetensors"
  ],
  "TheBloke/openchat_v2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/openchat_v2_w-GPTQ": [
    "model.safetensors"
  ],
  "spitfire4794/dialogpt-small-morty": [
    "model.safetensors"
  ],
  "muhtasham/TajGPT": [
    "model.safetensors"
  ],
  "TheBloke/WizardCoder-Guanaco-15B-V1.0-GPTQ": [
    "model.safetensors"
  ],
  "bhenrym14/airoboros-7b-gpt4-1.4.1-lxctx-PI-16384-fp16": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Chronoboros-33B-GPTQ": [
    "model.safetensors"
  ],
  "Henk717/airochronos-33B": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "SaylorTwift/gpt2_test": [
    "model.safetensors"
  ],
  "TheBloke/airochronos-33B-GPTQ": [
    "model.safetensors"
  ],
  "jpandeinge/DialoGPT-medium-Oshiwambo-Bot": [
    "model.safetensors"
  ],
  "KennethTM/gpt2-medium-danish": [
    "model.safetensors"
  ],
  "custads23/pygmalion-1.3b": [
    "model.safetensors"
  ],
  "squarelike/Gugugo-koen-1.3B-V0.9": [
    "model.safetensors"
  ],
  "TheBloke/open-llama-7B-v2-open-instruct-GPTQ": [
    "model.safetensors"
  ],
  "HuggingFaceM4/idefics-9b": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "aburnazy/opt-125m-alpaca-am-wiki": [
    "model.safetensors"
  ],
  "chrisdesa/compressed-redpajama-4bit": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "chrisdesa/compressed-redpajama-2bit": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "zlsl/l_wh40k_all": [
    "model.safetensors"
  ],
  "TheBloke/Starcoderplus-Guanaco-GPT4-15B-V1.0-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/OpenOrca-Preview1-13B-GPTQ": [
    "model.safetensors"
  ],
  "vlsp-2023-vllm/hoa-1b4": [
    "model.safetensors"
  ],
  "Shushant/thesis_nepaliGPT": [
    "model.safetensors"
  ],
  "bhenrym14/airoboros-33b-gpt4-1.4.1-lxctx-PI-16384-fp16": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "marouni/miniDolly": [
    "model.safetensors"
  ],
  "vilm/vietcuna-3b-v2": [
    "model.safetensors"
  ],
  "TheBloke/openchat_v2_openorca_preview-GPTQ": [
    "model.safetensors"
  ],
  "KnutJaegersberg/gpt-2-xl-EvolInstruct": [
    "model.safetensors"
  ],
  "TheBloke/h2ogpt-gm-oasst1-en-2048-falcon-7b-v3-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/WizardCoder-Guanaco-15B-V1.1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/LLaMa-65B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/LLaMa-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/LLaMa-30B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/LLaMa-7B-GPTQ": [
    "model.safetensors"
  ],
  "datatab/alpaca-serbian-3b-base": [
    "model.safetensors"
  ],
  "TheBloke/MythoLogic-13B-GPTQ": [
    "model.safetensors"
  ],
  "breadlicker45/MuseRWKV": [
    "model.safetensors"
  ],
  "RiversHaveWings/open_llama_7b_safetensors": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "breadlicker45/museRWKV-test": [
    "model.safetensors"
  ],
  "hemanth-kj/futurewei-test-1": [
    "adapter_model.safetensors",
    "last-checkpoint/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "squarelike/Gugugo-koen-1.3B-V0.95": [
    "model.safetensors"
  ],
  "TheBloke/Codegen25-7B-mono-GPTQ": [
    "model.safetensors"
  ],
  "w601sxs/b1ade-1b": [
    "model.safetensors"
  ],
  "Andron00e/YetAnother_Open-Llama-3B-LoRA-OpenOrca": [
    "model.safetensors"
  ],
  "assafm/cobalt-salmon": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Llama-2-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Llama-2-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Llama-2-7B-Chat-GPTQ": [
    "model.safetensors"
  ],
  "anonymous4chan/llama-2-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Llama-2-13B-chat-GPTQ": [
    "model.safetensors"
  ],
  "NousResearch/Llama-2-7b-hf": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ruggsea/gpt-ita-fdi_lega": [
    "model.safetensors"
  ],
  "NousResearch/Llama-2-13b-hf": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "gsaivinay/Llama-2-7b-Chat-GPTQ": [
    "model.safetensors"
  ],
  "anonymous4chan/llama-2-13b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "anonymous4chan/llama-2-70b": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "NousResearch/Llama-2-7b-chat-hf": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "NousResearch/Llama-2-70b-hf": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "Panchovix/LLaMA-2-70B-GPTQ-transformers4.32.0.dev0": [
    "llama-2-70b-4bit.safetensors"
  ],
  "TheBloke/Llama-2-70B-Chat-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Llama-2-70B-GPTQ": [
    "model.safetensors"
  ],
  "NousResearch/Llama-2-13b-chat-hf": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Llama-2-70B-fp16": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "TheBloke/Llama-2-70B-Chat-fp16": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "4bit/Llama-2-7b-chat-hf": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "4bit/Llama-2-13b-chat-hf": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TinyPixel/Llama-2-7B-bf16-sharded": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "NousResearch/Llama-2-70b-chat-hf": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "4bit/Llama-2-70b-chat-hf": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "Aharneish/gpt2-2": [
    "model.safetensors"
  ],
  "TheBloke/Redmond-Puffin-13B-GPTQ": [
    "model.safetensors"
  ],
  "EleutherAI/pythia-14m": [
    "model.safetensors"
  ],
  "EleutherAI/pythia-31m": [
    "model.safetensors"
  ],
  "Q-bert/ChessGPT": [
    "model.safetensors"
  ],
  "Peeepy/llama-2-13b-8bit": [
    "8bit.safetensors"
  ],
  "TheBloke/Luna-AI-Llama2-Uncensored-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/llama-2-7B-Guanaco-QLoRA-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/upstage-llama-30b-instruct-2048-GPTQ": [
    "model.safetensors"
  ],
  "beomi/llama-2-ko-7b": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "circulus/Llama-2-7b-instruct": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "tarax/Camelid-7B-Open": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/llama-2-13B-Guanaco-QLoRA-GPTQ": [
    "model.safetensors"
  ],
  "lomahony/eleuther-pythia70m-hh-sft": [
    "model.safetensors"
  ],
  "stabilityai/StableBeluga1-Delta": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "TheBloke/llama-2-13B-German-Assistant-v2-GPTQ": [
    "model.safetensors"
  ],
  "TheCraftySlayer/llama": [],
  "transmogrifier/pr-falcon-7b-instruct-8bit-Jul20": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/LLongMA-2-7B-GPTQ": [
    "model.safetensors"
  ],
  "line-corporation/japanese-large-lm-1.7b": [
    "model.safetensors"
  ],
  "line-corporation/japanese-large-lm-3.6b": [
    "model.safetensors"
  ],
  "Delcos/Llama-2-chat-st-ignr-unc": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Softechlb/Llama_2_13b_NEE": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "leegihan123/llama2chat7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/llama-2-70b-Guanaco-QLoRA-GPTQ": [
    "model.safetensors"
  ],
  "jerteh/gpt2-vrabac": [
    "model.safetensors"
  ],
  "TheBloke/30B-Epsilon-GPTQ": [
    "model.safetensors"
  ],
  "Andron00e/YetAnother_Open-Llama-3B-LoRA": [
    "model.safetensors"
  ],
  "guardrail/llama-2-7b-guanaco-instruct-sharded": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "lomahony/eleuther-pythia70m-hh-dpo": [
    "model.safetensors"
  ],
  "lomahony/eleuther-pythia160m-hh-sft": [
    "model.safetensors"
  ],
  "lomahony/eleuther-pythia410m-hh-dpo": [
    "model.safetensors"
  ],
  "TheBloke/13B-Ouroboros-GPTQ": [
    "model.safetensors"
  ],
  "eu-test/gpt2": [
    "model.safetensors"
  ],
  "Karzan/ckb-gpt2": [
    "model.safetensors"
  ],
  "TheBloke/13B-BlueMethod-GPTQ": [
    "model.safetensors"
  ],
  "monuminu/indo-instruct-llama2-13b": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "TheBloke/Upstage-Llama1-65B-Instruct-GPTQ": [
    "model.safetensors"
  ],
  "rahuldshetty/tiny-starcoder-instruct": [
    "model.safetensors"
  ],
  "TheBloke/Nous-Hermes-Llama2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/StableBeluga2-70B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/llama2_7b_chat_uncensored-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Vicuna-13B-v1.3-German-GPTQ": [
    "model.safetensors"
  ],
  "yodi/karina": [
    "model.safetensors"
  ],
  "hsultanbey/codegen350multi_finetuned": [
    "model.safetensors"
  ],
  "flozi00/Llama-2-7b-german-assistant-v1-4bit-autogptq": [
    "model.safetensors"
  ],
  "michelecafagna26/git-base-captioning-ft-hl-actions": [
    "model.safetensors"
  ],
  "michelecafagna26/git-base-captioning-ft-hl-scenes": [
    "model.safetensors"
  ],
  "michelecafagna26/git-base-captioning-ft-hl-rationales": [
    "model.safetensors"
  ],
  "Andron00e/Llama-Translation-Answering-v2": [
    "model.safetensors"
  ],
  "TheBloke/MythoBoros-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/llama2-7b-chat-codeCherryPop-qLoRA-GPTQ": [
    "model.safetensors"
  ],
  "aabidk/distilgpt2-sd": [
    "model.safetensors"
  ],
  "zaursamedov1/llama2-finetuned-NER": [],
  "ashercn97/code-llama-slay": [
    "adapter_model.safetensors"
  ],
  "heegyu/WizardVicuna-Uncensored-3B-0719": [
    "model.safetensors"
  ],
  "lamini/lamini_docs_3_steps": [
    "model.safetensors"
  ],
  "zohaib99k/llama-2-13b-chat-hf": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dfurman/Llama-2-13B-Instruct-v0.2": [
    "adapter_model.safetensors"
  ],
  "TheBloke/Dolphin-Llama-13B-GPTQ": [
    "model.safetensors"
  ],
  "mlabonne/llama-2-7b-miniguanaco": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rirv938/Wizard-Vicuna-30B-Uncensored-GPTQ-Act-Order-False": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "bigcode/octocoder": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "lamini/lamini_docs_finetuned": [
    "model.safetensors"
  ],
  "dfurman/Llama-2-70B-Instruct-v0.1": [
    "adapter_model.safetensors"
  ],
  "michelecafagna26/git-base-captioning-ft-hl-narratives": [
    "model.safetensors"
  ],
  "TheBloke/airoboros-l2-7b-gpt4-1.4.1-GPTQ": [
    "model.safetensors"
  ],
  "DasAluhut/l2cpy": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/airoboros-l2-13B-gpt4-1.4.1-GPTQ": [
    "model.safetensors"
  ],
  "assafm/electric-walrus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/airoboros-l2-70B-gpt4-1.4.1-GPTQ": [
    "model.safetensors"
  ],
  "flozi00/Llama-2-7b-german-assistant-v2-4bit-autogptq": [
    "model.safetensors"
  ],
  "HuggingFaceM4/idefics-9b-instruct": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/AlpacaCielo-13B-GPTQ": [
    "model.safetensors"
  ],
  "BramVanroy/falcon-7b-ft-mc4_nl_cleaned_tiny": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "HuggingFaceM4/idefics-80b-instruct": [
    "model-00001-of-00017.safetensors",
    "model-00002-of-00017.safetensors",
    "model-00003-of-00017.safetensors",
    "model-00004-of-00017.safetensors",
    "model-00005-of-00017.safetensors",
    "model-00006-of-00017.safetensors",
    "model-00007-of-00017.safetensors",
    "model-00008-of-00017.safetensors",
    "model-00009-of-00017.safetensors",
    "model-00010-of-00017.safetensors",
    "model-00011-of-00017.safetensors",
    "model-00012-of-00017.safetensors",
    "model-00013-of-00017.safetensors",
    "model-00014-of-00017.safetensors",
    "model-00015-of-00017.safetensors",
    "model-00016-of-00017.safetensors",
    "model-00017-of-00017.safetensors"
  ],
  "TheTravellingEngineer/llama2-7b-hf-guanaco": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Technotech/MagicPrompt-tinystories-33M-epoch10-merged": [
    "model.safetensors"
  ],
  "robertheessels/train6": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/OpenAssistant-Llama2-13B-Orca-8K-3319-GPTQ": [
    "model.safetensors"
  ],
  "beaugogh/pythia-1.4b-deduped-sharegpt": [
    "model.safetensors"
  ],
  "multimodalai/llama2-13b-bf16-edtech-6k-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Envoid/MindFlay-22B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Ahmed007/GPT2-Arabic_Poetry_generator": [
    "model.safetensors"
  ],
  "sundar-pichai/llama-2-13b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "NousResearch/Nous-Hermes-llama-2-7b": [
    "model.safetensors"
  ],
  "TitanML/ct2-int8-llama-2-7b-chat": [],
  "leoclement/Llama-2-7b-chat-hf": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ashercn97/awesome-prompts-merged": [
    "model.safetensors"
  ],
  "bhenrym14/airophin-13b-pntk-16k-fp16": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/WizardLM-13B-V1.2-GPTQ": [
    "model.safetensors"
  ],
  "juancopi81/lmd-8bars-2048-epochs30_v4": [
    "model.safetensors"
  ],
  "nkpz/llama2-22b-chat-wizard-uncensored": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "nkpz/llama2-22b-frankenwizard": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "allen-eric/llama2-7b-chat": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "0prodigy/axolotl": [
    "adapter_model.safetensors"
  ],
  "TheBloke/Llama-2-7B-Chat-fp16": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ybelkada/llama-7b-GPTQ-test": [
    "model.safetensors"
  ],
  "AR-javis/my_demo_repo": [
    "model.safetensors"
  ],
  "explosion-testing/llama2-kv-sharing": [
    "model.safetensors"
  ],
  "KnutJaegersberg/galactica-orca-wizardlm-1.3b": [
    "model.safetensors"
  ],
  "assafm/uppish-salmon": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "bofenghuang/vigogne-2-13b-instruct": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "SachinKaushik/llama-2-7b-instruct-maths-4bitshards": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "squarelike/Gugugo-koen-1.3B-V1.0": [
    "model.safetensors"
  ],
  "t-dai-con/gpt-fine-tuned-v2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "quantumaikr/QuantumLM-70B-hf": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "Ahmed007/gpt2-arabic-poet": [
    "model.safetensors"
  ],
  "stabilityai/StableBeluga-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "stabilityai/StableBeluga-13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "CobraMamba/mamba-gpt-3b-v2": [
    "model.safetensors"
  ],
  "annishaa/my_awesome_eli5_clm-model-2": [
    "model.safetensors"
  ],
  "Leogrin/eleuther-pythia1.4b-hh-sft": [
    "model.safetensors"
  ],
  "Fiery101/distilgpt2-finetuned-radar": [
    "model.safetensors"
  ],
  "TheBloke/Kimiko-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Nous-Hermes-Llama-2-7B-GPTQ": [
    "model.safetensors"
  ],
  "acrastt/RedPajama-INCITE-Chat-Instruct-3B-V1": [
    "model.safetensors"
  ],
  "HexHands/finishSTUDIO": [
    "model.safetensors"
  ],
  "TheBloke/Kimiko-7B-GPTQ": [
    "model.safetensors"
  ],
  "mosama/Llama-2-Medical-Merged-LoRA": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "nkpz/llama2-22b-chronos-alpaca-experiment1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "CobraMamba/mamba-gpt-3b-v3": [
    "model.safetensors"
  ],
  "MichelNivard/starcoderbase_3b_for_R_merged": [
    "model.safetensors"
  ],
  "KoboldAI/LLAMA2-13B-Holodeck-1": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "fmsys/pythia-2.8b-deduped-sentence_ordering": [
    "model.safetensors"
  ],
  "noamwies/llama-test-gqa-with-better-transformer": [
    "model.safetensors"
  ],
  "smangrul/full-finetune-starcoderbase-3b-deepspeed-colab": [
    "model.safetensors"
  ],
  "robertheessels/train7": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "eu-test/Llama-2-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "iamtarun/pycompetitive-codegen350M-qlora": [
    "model.safetensors"
  ],
  "Katonic/llama-2-7b": [],
  "TheBloke/StableBeluga-13B-GPTQ": [
    "model.safetensors"
  ],
  "Arjun-G-Ravi/GPT2-Alpaca": [
    "model.safetensors"
  ],
  "timinar/baby-llama-58m": [
    "model.safetensors"
  ],
  "TheBloke/MythoLogic-Mini-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/StableBeluga-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Vigogne-2-13B-Instruct-GPTQ": [
    "model.safetensors"
  ],
  "amazingvince/llama-2-16k-booksum": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "parvudan/model-test": [
    "final_merged_checkpoint/llama7b-4bit-128g.safetensors",
    "final_merged_checkpoint/model-00001-of-00002.safetensors",
    "final_merged_checkpoint/model-00002-of-00002.safetensors"
  ],
  "Technotech/sd-prompt-instruct-3b-epoch-0.4": [
    "model.safetensors"
  ],
  "TheBloke/Vigogne-2-7B-Instruct-GPTQ": [
    "model.safetensors"
  ],
  "assafm/llama-2-13b-trained-001": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "flozi00/Llama-2-13B-german-assistant-v3-4bit-autogptq": [
    "model.safetensors"
  ],
  "rah-1/Rahulio": [
    "model.safetensors"
  ],
  "rinna/bilingual-gpt-neox-4b": [
    "model.safetensors"
  ],
  "amrmnd/finance-12.8b-5e": [
    "model-00001-of-00028.safetensors",
    "model-00002-of-00028.safetensors",
    "model-00003-of-00028.safetensors",
    "model-00004-of-00028.safetensors",
    "model-00005-of-00028.safetensors",
    "model-00006-of-00028.safetensors",
    "model-00007-of-00028.safetensors",
    "model-00008-of-00028.safetensors",
    "model-00009-of-00028.safetensors",
    "model-00010-of-00028.safetensors",
    "model-00011-of-00028.safetensors",
    "model-00012-of-00028.safetensors",
    "model-00013-of-00028.safetensors",
    "model-00014-of-00028.safetensors",
    "model-00015-of-00028.safetensors",
    "model-00016-of-00028.safetensors",
    "model-00017-of-00028.safetensors",
    "model-00018-of-00028.safetensors",
    "model-00019-of-00028.safetensors",
    "model-00020-of-00028.safetensors",
    "model-00021-of-00028.safetensors",
    "model-00022-of-00028.safetensors",
    "model-00023-of-00028.safetensors",
    "model-00024-of-00028.safetensors",
    "model-00025-of-00028.safetensors",
    "model-00026-of-00028.safetensors",
    "model-00027-of-00028.safetensors",
    "model-00028-of-00028.safetensors"
  ],
  "rinna/bilingual-gpt-neox-4b-8k": [
    "model.safetensors"
  ],
  "TheBloke/Upstage-Llama-2-70B-instruct-v2-GPTQ": [
    "model.safetensors"
  ],
  "rinna/bilingual-gpt-neox-4b-instruction-sft": [
    "model.safetensors"
  ],
  "zlsl/l_soft_erotic": [
    "model.safetensors"
  ],
  "zlsl/l_soft_erotic_tm": [
    "model.safetensors"
  ],
  "Bingsu/my_rwkv_4_world_1.5B-v1-fixed-20230612-ctx4096": [
    "model.safetensors"
  ],
  "TheBloke/OpenChat_v3.2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/airoboros-33B-GPT4-m2.0-GPTQ": [
    "model.safetensors"
  ],
  "lemonteaa/exercise-openllama-3b-qlora-axolotl-checkpoint200-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/airoboros-l2-13b-gpt4-2.0-GPTQ": [
    "model.safetensors"
  ],
  "lemonteaa/testing-temp": [
    "model.safetensors"
  ],
  "Notespeak/AriadneAI-v1.0.2-fp16": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/airoboros-l2-13b-gpt4-m2.0-GPTQ": [
    "model.safetensors"
  ],
  "renahime/DialoGPT-medium-umineko": [
    "model.safetensors"
  ],
  "HexHands/finishABOUTME": [
    "model.safetensors"
  ],
  "TheBloke/airoboros-l2-7B-gpt4-2.0-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/airoboros-l2-7B-gpt4-m2.0-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/airoboros-33B-GPT4-2.0-GPTQ": [
    "model.safetensors"
  ],
  "Elliot4AI/Dugong-Llama2-7b-chinese": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sirabhop/llama-2-rbh-SQL-agent": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "yujiepan/starcoder-tiny-random": [
    "model.safetensors"
  ],
  "assafm/llama-2-13b-trained-002": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "RoversX/MJ-Beta3-Base-on-StableBeluga-7B-merged": [],
  "flozi00/openbuddy-llama2-13b-v8.1-fp16-4bit-autogptq": [
    "model.safetensors"
  ],
  "assafm/llama-2-13b-trained-odontil-002": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jakobkruse/codeparrot-ds": [
    "model.safetensors"
  ],
  "joecane/distilgpt2-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "assafm/llama-2-13b-trained-odontil-003": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/NewHope-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/CodeUp-Llama-2-13B-Chat-HF-GPTQ": [
    "model.safetensors"
  ],
  "Locutusque/gpt2-large-medical": [
    "model.safetensors"
  ],
  "yashgoenka/gorilla-llama-2-7B-QLoRA": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "TabbyML/StarCoder-1B": [
    "model.safetensors"
  ],
  "rinna/bilingual-gpt-neox-4b-instruction-ppo": [
    "model.safetensors"
  ],
  "assafm/llama-2-13b-trained-macnica-003": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheTravellingEngineer/llama2-7b-chat-hf-guanaco": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/OpenAssistant-Llama2-13B-Orca-v2-8K-3166-GPTQ": [
    "model.safetensors"
  ],
  "4bit/StableBeluga-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/airoboros-l2-70B-GPT4-2.0-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Hermes-LLongMA-2-13B-8K-GPTQ": [
    "model.safetensors"
  ],
  "flozi00/Llama-2-13b-german-assistant-v4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "flozi00/Llama-2-13b-german-assistant-v4-4bit-autogptq": [
    "model.safetensors"
  ],
  "sirmuelemos/pllm_data_syntax": [
    "checkpoint-1000/model.safetensors",
    "checkpoint-1500/model.safetensors",
    "checkpoint-500/model.safetensors"
  ],
  "TheBloke/Hermes-LLongMA-2-7B-8K-GPTQ": [
    "model.safetensors"
  ],
  "line-corporation/japanese-large-lm-3.6b-instruction-sft": [
    "model.safetensors"
  ],
  "Shad0ws/gpt2": [
    "model.safetensors"
  ],
  "Qwen/Qwen-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Qwen/Qwen-7B-Chat": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "TheBloke/vicuna-13B-v1.5-16K-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/vicuna-7B-v1.5-16K-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/OpenOrcaxOpenChat-Preview2-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/vicuna-7B-v1.5-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/vicuna-13B-v1.5-GPTQ": [
    "model.safetensors"
  ],
  "nkpz/llama2-22b-blocktriangular-alpaca": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Shanav12/jokes_model": [
    "model.safetensors"
  ],
  "TheBloke/qCammel-70-x-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/llama2_70b_chat_uncensored-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Airochronos-L2-13B-GPTQ": [
    "model.safetensors"
  ],
  "WeiNyn/Llama2-7b-hf": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "stabilityai/stablelm-base-alpha-7b-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "stabilityai/stablelm-base-alpha-3b-v2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "monuminu/indo-instruct-llama2-32k": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "TheBloke/Vigogne-2-7B-Chat-GPTQ": [
    "model.safetensors"
  ],
  "zlsl/l_soft_erotic_tm-16bit": [
    "model.safetensors"
  ],
  "TheBloke/MythoLogic-L2-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Chronohermes-Grad-L2-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Airoboros-L2-70B-GPT4-m2.0-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Chronoboros-Grad-L2-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/qCammel-13-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/13B-Legerdemain-L2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Airoboros-65B-GPT4-m2.0-GPTQ": [
    "model.safetensors"
  ],
  "garage-bAInd/Platypus2-70B": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "TheBloke/Chronolima-Airo-Grad-L2-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Airolima-Chronos-Grad-L2-13B-GPTQ": [
    "model.safetensors"
  ],
  "lgaalves/gpt2-dolly": [
    "model.safetensors"
  ],
  "garage-bAInd/Platypus2-70B-instruct": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "TheBloke/Airoboros-65B-GPT4-2.0-GPTQ": [
    "model.safetensors"
  ],
  "garage-bAInd/Platypus2-13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "garage-bAInd/Camel-Platypus2-13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "garage-bAInd/Stable-Platypus2-13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "gammatau/starcoder-1b-fit": [
    "model.safetensors"
  ],
  "vilm/vietcuna-7b-v3": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jploski/retnet-mini-shakespeare": [
    "model.safetensors"
  ],
  "TheBloke/HermesLimaRP-L2-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Chronos-Beluga-v2-13B-GPTQ": [
    "model.safetensors"
  ],
  "cipher982/report_builder": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Mursel/gpt2-turkish": [
    "model.safetensors"
  ],
  "TheBloke/Llama-2-70B-OASST-1-200-GPTQ": [
    "model.safetensors"
  ],
  "assafm/llama-2-13b-trained-cs-001": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "stockmark/gpt-neox-japanese-1.4b": [
    "model.safetensors"
  ],
  "TheBloke/Huginn-13B-GPTQ": [
    "model.safetensors"
  ],
  "assafm/llama-2-13b-trained-cs-001-02": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/WizardLM-1.0-Uncensored-Llama2-13B-GPTQ": [
    "model.safetensors"
  ],
  "quantumaikr/llama-2-70b-fb16-guanaco-1k": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "TheBloke/Dolphin-Llama2-7B-GPTQ": [
    "model.safetensors"
  ],
  "funstoryai/immersiveL-exp": [
    "model.safetensors"
  ],
  "TheBloke/Spring-Dragon-GPTQ": [
    "model.safetensors"
  ],
  "subham92/test-2": [
    "model.safetensors"
  ],
  "assafm/llama-2-7b-trained-cs-001": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Aharneish/gpt2-sailit1": [
    "model.safetensors"
  ],
  "stabilityai/stablecode-completion-alpha-3b-4k": [
    "model.safetensors"
  ],
  "Ahmed107/WizardCoder-15B-1.0-GPTQ-edited": [
    "model.safetensors"
  ],
  "ittailup/lallama-13b-alpha": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "nicbull/DialoGPT-medium-nic2": [
    "model.safetensors"
  ],
  "Aharneish/gpt2-sailit": [
    "model.safetensors"
  ],
  "TheTravellingEngineer/llama2-7b-chat-hf-v2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "duliadotio/dulia-13b-8k-alpha": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/MythoMix-L2-13B-GPTQ": [
    "model.safetensors"
  ],
  "Jorghi21/llama2-7b-4bit": [
    "model.safetensors"
  ],
  "TheBloke/stablecode-completion-alpha-3b-4k-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/stablecode-instruct-alpha-3b-GPTQ": [
    "model.safetensors"
  ],
  "mosama/llama2-rope-scaled": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "aka-nikko/ainz-ooal-gown": [
    "model.safetensors"
  ],
  "Jorghi21/llama7b-4bit-fixed": [
    "model.safetensors"
  ],
  "TheBloke/Firefly-Llama2-13B-v1.2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/WizardLM-70B-V1.0-GPTQ": [
    "model.safetensors"
  ],
  "h2oai/h2ogpt-4096-llama2-7b-chat": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "h2oai/h2ogpt-4096-llama2-13b-chat": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "h2oai/h2ogpt-4096-llama2-70b-chat": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "h2oai/h2ogpt-4096-llama2-70b": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "h2oai/h2ogpt-4096-llama2-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "h2oai/h2ogpt-4096-llama2-13b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/huginnv1.2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/AlpacaCielo2-7B-8K-GPTQ": [
    "model.safetensors"
  ],
  "jmparejaz/growthcadet_llam2": [],
  "garage-bAInd/Camel-Platypus2-70B": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "juancopi81/lmd-8bars-2048-epochs40_v4": [
    "model.safetensors"
  ],
  "nicbull/DialoGPT-medium-leric": [
    "model.safetensors"
  ],
  "BramVanroy/llama2-13b-ft-mc4_nl_cleaned_tiny": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TabbyML/StableCode-3B": [
    "model.safetensors"
  ],
  "TheTravellingEngineer/llama2-7b-chat-hf-v3": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheTravellingEngineer/llama2-7b-chat-hf-v4": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "4i-ai/Llama-2-7b-alpaca-es": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "zlsl/l_erotic_kink_chat": [
    "model.safetensors"
  ],
  "TheBloke/orca_mini_v3_7B-GPTQ": [
    "model.safetensors"
  ],
  "HWERI/pythia-1.4b-deduped-sharegpt": [
    "model.safetensors"
  ],
  "uoe-nlp/gpt-neo-125m_instruction-tuned_sni": [
    "model.safetensors"
  ],
  "TheBloke/Stable-Platypus2-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/orca_mini_v3_13B-GPTQ": [
    "model.safetensors"
  ],
  "MayaPH/GodziLLa2-70B": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "nuprl/MultiPLCoder-1b": [
    "model.safetensors"
  ],
  "TheBloke/Platypus2-13B-GPTQ": [
    "model.safetensors"
  ],
  "universeTBD/astrollama": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Camel-Platypus2-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Platypus2-70B-Instruct-GPTQ": [
    "model.safetensors"
  ],
  "weiren119/traditional_chinese_qlora_llama2_13b_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "quantumaikr/llama-2-70b-fb16-orca-chat-10k": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "TheBloke/Platypus2-70B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/MythoMax-L2-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Camel-Platypus2-70B-GPTQ": [
    "model.safetensors"
  ],
  "smangrul/starcoder15B-personal-copilot-merged": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "quantumaikr/llama-2-70b-fb16-korean": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "smangrul/starcoder7B-personal-copilot-merged": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Arc53/docsgpt-7b-falcon": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "radlab/polish-gpt2-small": [
    "model.safetensors"
  ],
  "RajuKandasamy/tamillama_tiny_30m": [
    "model.safetensors"
  ],
  "TheBloke/WizardMath-7B-V1.0-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/WizardMath-13B-V1.0-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/WizardMath-70B-V1.0-GPTQ": [
    "model.safetensors"
  ],
  "quantumaikr/llama-2-70b-fb16-orca-chat": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "TheBloke/Llama-2-13B-German-Assistant-v4-GPTQ": [
    "model.safetensors"
  ],
  "Trelis/Llama-2-7b-chat-hf-hosted-inference-8bit": [
    "model.safetensors"
  ],
  "TheBloke/OpenOrca-Platypus2-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/EverythingLM-13B-16K-GPTQ": [
    "model.safetensors"
  ],
  "petals-team/StableBeluga2": [
    "model_00001-of-00081.safetensors",
    "model_00002-of-00081.safetensors",
    "model_00003-of-00081.safetensors",
    "model_00004-of-00081.safetensors",
    "model_00005-of-00081.safetensors",
    "model_00006-of-00081.safetensors",
    "model_00007-of-00081.safetensors",
    "model_00008-of-00081.safetensors",
    "model_00009-of-00081.safetensors",
    "model_00010-of-00081.safetensors",
    "model_00011-of-00081.safetensors",
    "model_00012-of-00081.safetensors",
    "model_00013-of-00081.safetensors",
    "model_00014-of-00081.safetensors",
    "model_00015-of-00081.safetensors",
    "model_00016-of-00081.safetensors",
    "model_00017-of-00081.safetensors",
    "model_00018-of-00081.safetensors",
    "model_00019-of-00081.safetensors",
    "model_00020-of-00081.safetensors",
    "model_00021-of-00081.safetensors",
    "model_00022-of-00081.safetensors",
    "model_00023-of-00081.safetensors",
    "model_00024-of-00081.safetensors",
    "model_00025-of-00081.safetensors",
    "model_00026-of-00081.safetensors",
    "model_00027-of-00081.safetensors",
    "model_00028-of-00081.safetensors",
    "model_00029-of-00081.safetensors",
    "model_00030-of-00081.safetensors",
    "model_00031-of-00081.safetensors",
    "model_00032-of-00081.safetensors",
    "model_00033-of-00081.safetensors",
    "model_00034-of-00081.safetensors",
    "model_00035-of-00081.safetensors",
    "model_00036-of-00081.safetensors",
    "model_00037-of-00081.safetensors",
    "model_00038-of-00081.safetensors",
    "model_00039-of-00081.safetensors",
    "model_00040-of-00081.safetensors",
    "model_00041-of-00081.safetensors",
    "model_00042-of-00081.safetensors",
    "model_00043-of-00081.safetensors",
    "model_00044-of-00081.safetensors",
    "model_00045-of-00081.safetensors",
    "model_00046-of-00081.safetensors",
    "model_00047-of-00081.safetensors",
    "model_00048-of-00081.safetensors",
    "model_00049-of-00081.safetensors",
    "model_00050-of-00081.safetensors",
    "model_00051-of-00081.safetensors",
    "model_00052-of-00081.safetensors",
    "model_00053-of-00081.safetensors",
    "model_00054-of-00081.safetensors",
    "model_00055-of-00081.safetensors",
    "model_00056-of-00081.safetensors",
    "model_00057-of-00081.safetensors",
    "model_00058-of-00081.safetensors",
    "model_00059-of-00081.safetensors",
    "model_00060-of-00081.safetensors",
    "model_00061-of-00081.safetensors",
    "model_00062-of-00081.safetensors",
    "model_00063-of-00081.safetensors",
    "model_00064-of-00081.safetensors",
    "model_00065-of-00081.safetensors",
    "model_00066-of-00081.safetensors",
    "model_00067-of-00081.safetensors",
    "model_00068-of-00081.safetensors",
    "model_00069-of-00081.safetensors",
    "model_00070-of-00081.safetensors",
    "model_00071-of-00081.safetensors",
    "model_00072-of-00081.safetensors",
    "model_00073-of-00081.safetensors",
    "model_00074-of-00081.safetensors",
    "model_00075-of-00081.safetensors",
    "model_00076-of-00081.safetensors",
    "model_00077-of-00081.safetensors",
    "model_00078-of-00081.safetensors",
    "model_00079-of-00081.safetensors",
    "model_00080-of-00081.safetensors",
    "model_00081-of-00081.safetensors"
  ],
  "TheBloke/LlongOrca-7B-16K-GPTQ": [
    "model.safetensors"
  ],
  "fengtc/Llama-2-7b-chat-hf": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "dwlee/ds_base_alpha": [
    "model-00001-of-00028.safetensors",
    "model-00002-of-00028.safetensors",
    "model-00003-of-00028.safetensors",
    "model-00004-of-00028.safetensors",
    "model-00005-of-00028.safetensors",
    "model-00006-of-00028.safetensors",
    "model-00007-of-00028.safetensors",
    "model-00008-of-00028.safetensors",
    "model-00009-of-00028.safetensors",
    "model-00010-of-00028.safetensors",
    "model-00011-of-00028.safetensors",
    "model-00012-of-00028.safetensors",
    "model-00013-of-00028.safetensors",
    "model-00014-of-00028.safetensors",
    "model-00015-of-00028.safetensors",
    "model-00016-of-00028.safetensors",
    "model-00017-of-00028.safetensors",
    "model-00018-of-00028.safetensors",
    "model-00019-of-00028.safetensors",
    "model-00020-of-00028.safetensors",
    "model-00021-of-00028.safetensors",
    "model-00022-of-00028.safetensors",
    "model-00023-of-00028.safetensors",
    "model-00024-of-00028.safetensors",
    "model-00025-of-00028.safetensors",
    "model-00026-of-00028.safetensors",
    "model-00027-of-00028.safetensors",
    "model-00028-of-00028.safetensors"
  ],
  "TheBloke/Huginn-v3-13B-GPTQ": [
    "model.safetensors"
  ],
  "Arc53/docsgpt-40b-falcon": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "Arc53/docsgpt-14b": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "msb-roshan/molgpt": [
    "model.safetensors"
  ],
  "davzoku/cria-llama2-7b-v1.3": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "SachinKaushik/llama2-7b-chat-5g": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "vishnu-vs/llama-7bhf": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/LosslessMegaCoder-Llama2-7B-Mini-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/CodeUp-Alpha-13B-HF-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/llama2-22B-daydreamer-v2-GPTQ": [
    "model.safetensors"
  ],
  "bhenrym14/airophin-v2-13b-PI-8k-fp16": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "KoboldAI/LLaMA2-13B-Holomax": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/PULI-GPT-3SX-GPTQ": [
    "model.safetensors"
  ],
  "BramVanroy/Llama-2-13b-chat-dutch": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mzbac/llama2-13b-grammar-corrector": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/LosslessMegaCoder-Llama2-13B-Mini-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/GodziLLa2-70B-GPTQ": [
    "model.safetensors"
  ],
  "cenkersisman/gpt2-turkish-900m": [
    "model.safetensors"
  ],
  "MayaPH/opt-flan-iml-6.7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dickheadmorron12/andrewtate": [
    "model.safetensors"
  ],
  "acrastt/Marx-3B": [
    "model.safetensors"
  ],
  "TheBloke/Llama2-22B-Daydreamer-v3-GPTQ": [
    "model.safetensors"
  ],
  "sxx123/gpt2-medium": [
    "model.safetensors"
  ],
  "tifa-benchmark/llama2_tifa_question_generation": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "The-Face-Of-Goonery/Huginn-22b-Prototype": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Amal17/wikipedia-20230601.ace": [
    "model.safetensors"
  ],
  "TheBloke/Scarlett-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Scarlett-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/scarlett-33B-GPTQ": [
    "model.safetensors"
  ],
  "flozi00/Llama-2-13b-german-assistant-v5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Carl-Llama-2-13B-GPTQ": [
    "model.safetensors"
  ],
  "monuminu/indo-instruct-llama2-70b": [
    "model-00001-of-00081.safetensors",
    "model-00002-of-00081.safetensors",
    "model-00003-of-00081.safetensors",
    "model-00004-of-00081.safetensors",
    "model-00005-of-00081.safetensors",
    "model-00006-of-00081.safetensors",
    "model-00007-of-00081.safetensors",
    "model-00008-of-00081.safetensors",
    "model-00009-of-00081.safetensors",
    "model-00010-of-00081.safetensors",
    "model-00011-of-00081.safetensors",
    "model-00012-of-00081.safetensors",
    "model-00013-of-00081.safetensors",
    "model-00014-of-00081.safetensors",
    "model-00015-of-00081.safetensors",
    "model-00016-of-00081.safetensors",
    "model-00017-of-00081.safetensors",
    "model-00018-of-00081.safetensors",
    "model-00019-of-00081.safetensors",
    "model-00020-of-00081.safetensors",
    "model-00021-of-00081.safetensors",
    "model-00022-of-00081.safetensors",
    "model-00023-of-00081.safetensors",
    "model-00024-of-00081.safetensors",
    "model-00025-of-00081.safetensors",
    "model-00026-of-00081.safetensors",
    "model-00027-of-00081.safetensors",
    "model-00028-of-00081.safetensors",
    "model-00029-of-00081.safetensors",
    "model-00030-of-00081.safetensors",
    "model-00031-of-00081.safetensors",
    "model-00032-of-00081.safetensors",
    "model-00033-of-00081.safetensors",
    "model-00034-of-00081.safetensors",
    "model-00035-of-00081.safetensors",
    "model-00036-of-00081.safetensors",
    "model-00037-of-00081.safetensors",
    "model-00038-of-00081.safetensors",
    "model-00039-of-00081.safetensors",
    "model-00040-of-00081.safetensors",
    "model-00041-of-00081.safetensors",
    "model-00042-of-00081.safetensors",
    "model-00043-of-00081.safetensors",
    "model-00044-of-00081.safetensors",
    "model-00045-of-00081.safetensors",
    "model-00046-of-00081.safetensors",
    "model-00047-of-00081.safetensors",
    "model-00048-of-00081.safetensors",
    "model-00049-of-00081.safetensors",
    "model-00050-of-00081.safetensors",
    "model-00051-of-00081.safetensors",
    "model-00052-of-00081.safetensors",
    "model-00053-of-00081.safetensors",
    "model-00054-of-00081.safetensors",
    "model-00055-of-00081.safetensors",
    "model-00056-of-00081.safetensors",
    "model-00057-of-00081.safetensors",
    "model-00058-of-00081.safetensors",
    "model-00059-of-00081.safetensors",
    "model-00060-of-00081.safetensors",
    "model-00061-of-00081.safetensors",
    "model-00062-of-00081.safetensors",
    "model-00063-of-00081.safetensors",
    "model-00064-of-00081.safetensors",
    "model-00065-of-00081.safetensors",
    "model-00066-of-00081.safetensors",
    "model-00067-of-00081.safetensors",
    "model-00068-of-00081.safetensors",
    "model-00069-of-00081.safetensors",
    "model-00070-of-00081.safetensors",
    "model-00071-of-00081.safetensors",
    "model-00072-of-00081.safetensors",
    "model-00073-of-00081.safetensors",
    "model-00074-of-00081.safetensors",
    "model-00075-of-00081.safetensors",
    "model-00076-of-00081.safetensors",
    "model-00077-of-00081.safetensors",
    "model-00078-of-00081.safetensors",
    "model-00079-of-00081.safetensors",
    "model-00080-of-00081.safetensors",
    "model-00081-of-00081.safetensors"
  ],
  "TheBloke/Carl-33B-GPTQ": [
    "model.safetensors"
  ],
  "Deci/DeciCoder-1b": [
    "model.safetensors"
  ],
  "Cyrema/Llama-2-7b-Bogpit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "4bit/medllama2_7b_s": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "rajuptvs/bigscience_bloom-560m_sharded_8bit": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "arya555/vicuna-7b-v1.5-hf": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "gbenonvi/Llama-2-7b-chat-hf": [],
  "TheBloke/Carl-13B-GPTQ": [
    "model.safetensors"
  ],
  "rjmacarthy/codegen-350M-finetuned-react": [
    "model.safetensors"
  ],
  "unionai/Llama-2-7b-hf-8bit": [
    "flyte34wt1230/local_flytekit/810e18b454e773a781f5bff5b4bed050/models--meta-llama--Llama-2-7b-hf/.no_exist/6fdf2e60f86ff2481f2241aaee459f85b5b0bbb9/model.safetensors",
    "flyte34wt1230/local_flytekit/810e18b454e773a781f5bff5b4bed050/models--meta-llama--Llama-2-7b-hf/snapshots/6fdf2e60f86ff2481f2241aaee459f85b5b0bbb9/model-00001-of-00002.safetensors",
    "flyte34wt1230/local_flytekit/810e18b454e773a781f5bff5b4bed050/models--meta-llama--Llama-2-7b-hf/snapshots/6fdf2e60f86ff2481f2241aaee459f85b5b0bbb9/model-00002-of-00002.safetensors",
    "flytedcexo992/local_flytekit/4749e914390429bbda8d9d320f0d942d/models--meta-llama--Llama-2-7b-hf/.no_exist/6fdf2e60f86ff2481f2241aaee459f85b5b0bbb9/model.safetensors",
    "flytedcexo992/local_flytekit/4749e914390429bbda8d9d320f0d942d/models--meta-llama--Llama-2-7b-hf/snapshots/6fdf2e60f86ff2481f2241aaee459f85b5b0bbb9/model-00001-of-00002.safetensors",
    "flytedcexo992/local_flytekit/4749e914390429bbda8d9d320f0d942d/models--meta-llama--Llama-2-7b-hf/snapshots/6fdf2e60f86ff2481f2241aaee459f85b5b0bbb9/model-00002-of-00002.safetensors",
    "flyteuazoy2ub/local_flytekit/bff2ced49300febd3ad83fc5eb49de69/models--meta-llama--Llama-2-7b-hf/.no_exist/6fdf2e60f86ff2481f2241aaee459f85b5b0bbb9/model.safetensors",
    "flyteuazoy2ub/local_flytekit/bff2ced49300febd3ad83fc5eb49de69/models--meta-llama--Llama-2-7b-hf/snapshots/6fdf2e60f86ff2481f2241aaee459f85b5b0bbb9/model-00001-of-00002.safetensors",
    "flyteuazoy2ub/local_flytekit/bff2ced49300febd3ad83fc5eb49de69/models--meta-llama--Llama-2-7b-hf/snapshots/6fdf2e60f86ff2481f2241aaee459f85b5b0bbb9/model-00002-of-00002.safetensors"
  ],
  "TheBloke/orca_mini_v3_70B-GPTQ": [
    "model.safetensors"
  ],
  "acrastt/Puma-3B": [
    "model.safetensors"
  ],
  "andreaskoepf/falcon-40b-megacode2": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "diegomiranda/text-to-cypher": [
    "model.safetensors"
  ],
  "andreaskoepf/llama2-13b-orcabest": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "OpenAssistant/falcon-40b-megacode2-oasst": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "rombodawg/LosslessMegaCoder-Falcon-40b-mini": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "mzbac/llama2-13b-grammar-corrector-v1.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "chargoddard/platypus-2-22b-relora": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Cyrema/Llama-2-7b-Cesspit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Cyrema/Llama-2-7b-Slimpit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "RuterNorway/Llama-2-13b-chat-norwegian-LoRa": [
    "adapter_model.safetensors"
  ],
  "RuterNorway/Llama-2-13b-chat-norwegian-GPTQ": [
    "model.safetensors"
  ],
  "Voicelab/trurl-2-7b-8bit": [
    "model.safetensors"
  ],
  "TheBloke/Llama2-13B-MegaCode2-OASST-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Octocoder-GPTQ": [
    "model.safetensors"
  ],
  "vwxyzjn/starcoderbase-triviaqa": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "TheBloke/Zarablend-L2-7B-GPTQ": [
    "model.safetensors"
  ],
  "acrastt/Griffin-3B": [
    "model.safetensors"
  ],
  "Saurabh16100/MedLLM-1-1-New": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "heegyu/polyglot-ko-1.3b-chat": [
    "model.safetensors"
  ],
  "kimsan0622/gpt2-medium": [
    "model.safetensors"
  ],
  "andreaskoepf/llama2-13b-megacode3-16000": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "xzuyn/GPT-2-Small-Stripped": [
    "pytorch_model.safetensors"
  ],
  "xzuyn/GPT-2-XL-Stripped": [
    "pytorch_model.safetensors"
  ],
  "czurita/mpt-7b-8k-instruct-sharded-bf16-2GB": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "hungeni/LLama2-7B-OAssis1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "hungeni/LLama2-7B-AmrutaDB": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TaylorAI/Flash-Llama-13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "optimacare/llama_training_test": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "PRAJWAL23/python_code_generator": [
    "model.safetensors"
  ],
  "UncleanCode/anacondia-70m": [
    "model.safetensors"
  ],
  "marciogualtieri/funnybot-joke-generator-model-dad-jokes": [
    "model.safetensors"
  ],
  "Qwen/Qwen-7B-Chat-Int4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "marciogualtieri/funnybot-joke-generator-model-question-answer-jokes": [
    "model.safetensors"
  ],
  "czurita/nsql-llama-2-7B-sharded-bf16-2GB": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "TheBloke/LlongOrca-13B-16K-GPTQ": [
    "model.safetensors"
  ],
  "4bit/japanese-stablelm-instruct-alpha-7b-s": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "4bit/japanese-stablelm-base-alpha-7b-s": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "heegyu/polyglot-ko-3.8b-chat": [
    "model.safetensors"
  ],
  "chargoddard/Chronorctypus-Limarobormes-13b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Locutusque/gpt2-xl-conversational": [
    "model.safetensors"
  ],
  "dahara1/weblab-10b-instruction-sft-GPTQ": [
    "finetune_sample/model.safetensors",
    "gptq_model-4bit-128g.safetensors",
    "model.safetensors"
  ],
  "TheBloke/Samantha-1.1-70B-GPTQ": [
    "model.safetensors"
  ],
  "quantumaikr/KoreanLM-1.5b": [
    "model.safetensors"
  ],
  "quantumaikr/KoreanLM-3B": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Llama-2-7B-32K-Instruct-GPTQ": [
    "model.safetensors"
  ],
  "uukuguy/speechless-hermes-coig-lite-13b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TFLai/JokeGPT-en": [
    "model.safetensors"
  ],
  "flozi00/Llama-2-13b-german-assistant-v6": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "flozi00/Llama-2-13b-german-assistant-v6-4bit-autogptq": [
    "model.safetensors"
  ],
  "MemerMemetan/better-japanese-weblab-10b-instruct": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/L2-MythoMax22b-Instruct-Falseblock-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Llama2-22B-GPLATTY-GPTQ": [
    "model.safetensors"
  ],
  "serenaz/Llama-2-7b-hf-lora-medical-meadow": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mesolitica/llama-7b-hf-2048-fpf": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "garage-bAInd/Platypus2-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "serenaz/Llama-2-7b-hf-medical-meadow": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "SheenCloud/sheen-7b-chat": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/EverythingLM-13b-V2-16K-GPTQ": [
    "model.safetensors"
  ],
  "huashiyiqike/testmodel": [
    "model.safetensors"
  ],
  "4i-ai/Llama-2-13b-alpaca-es": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "TheBloke/Llama2-28B-Air03-GPTQ": [
    "model.safetensors"
  ],
  "rohanbalkondekar/yes-bank": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "flozi00/Llama-2-7b-german-assistant-v3": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mesolitica/llama-13b-hf-2048-fpf": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Chronorctypus-Limarobormes-13b-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Griffin-3B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Marx-3b-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Puma-3b-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Synthia-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Synthia-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Zarablend-MX-L2-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Trurl-2-13B-GPTQ": [
    "model.safetensors"
  ],
  "Karzan/gpt2-walamakan": [
    "model.safetensors"
  ],
  "philschmid/330aa24bbb": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Trurl-2-7B-GPTQ": [
    "model.safetensors"
  ],
  "anushehchaudry/llama-2-tiny-random": [
    "model.safetensors"
  ],
  "Trelis/Llama-2-7b-chat-hf-function-calling-v2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "rohanbalkondekar/bank-exp-2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "philschmid/f9749f03ca": [
    "checkpoint-2000/model-00001-of-00002.safetensors",
    "checkpoint-2000/model-00002-of-00002.safetensors",
    "checkpoint-2100/model-00001-of-00002.safetensors",
    "checkpoint-2100/model-00002-of-00002.safetensors",
    "checkpoint-2200/model-00001-of-00002.safetensors",
    "checkpoint-2200/model-00002-of-00002.safetensors",
    "checkpoint-2300/model-00001-of-00002.safetensors",
    "checkpoint-2300/model-00002-of-00002.safetensors"
  ],
  "Sakshi1307/llama-2-7b-Sakshi": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "acrastt/Marx-3B-V2": [
    "model.safetensors"
  ],
  "halo-69/distilgpt2-finetuned-finance": [
    "model.safetensors"
  ],
  "chargoddard/MelangeA-70b": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "chargoddard/MelangeB-70b": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "chargoddard/MelangeC-70b": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "vodkaslime/test-repo-stablecode": [
    "model.safetensors"
  ],
  "Wissam42/llama-test": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "truefoundry/pygmalion-6b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "flozi00/Llama-2-7b-german-assistant-v3-4bit-autogptq": [
    "model.safetensors"
  ],
  "Fredithefish/Guanaco-3B-Uncensored": [
    "model.safetensors"
  ],
  "vwxyzjn/starcoderbase-triviaqa1": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "SHJ622/falcon_7b_ecommerce_ai_chatbot": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Devden/Llama2": [
    "model.safetensors"
  ],
  "KoboldAI/LLaMA2-13B-Holomax-GPTQ": [
    "model.safetensors"
  ],
  "IHaBiS/MythoMax-13b-upstage-65b-instruct-FalseBlock": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "msaad02/llama2_7b_brockportgpt": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/PuddleJumper-13B-GPTQ": [
    "model.safetensors"
  ],
  "flozi00/Llama-2-13b-german-assistant-v5-4bit-autogptq": [
    "model.safetensors"
  ],
  "rtlabs/StableCode-3B": [
    "model.safetensors"
  ],
  "HeshamHaroon/falcon-rw-1b-4bit": [
    "model.safetensors"
  ],
  "atharvapawar/securix_Llama-2-7B-Chat-GGML": [
    "model.safetensors"
  ],
  "TheBloke/Nous-Hermes-Llama2-70B-GPTQ": [
    "model.safetensors"
  ],
  "zlsl/ruGPT-3.5-13B-erotic-kink-chat-lora": [
    "adapter_model.safetensors"
  ],
  "overenginar/open-llama-7b-oasst": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Nous-Puffin-70B-GPTQ": [
    "model.safetensors"
  ],
  "overenginar/falcon-7b-oasst": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "overenginar/gpt2-oasst": [
    "model.safetensors"
  ],
  "atharvapawar/Securix_GPT_Neo": [
    "model.safetensors"
  ],
  "ashukumar27/llama2-finetuned-marketing": [
    "adapter_model.safetensors",
    "checkpoint-10/adapter_model.safetensors"
  ],
  "TheBloke/CodeLlama-13B-fp16": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/CodeLlama-13B-Instruct-fp16": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/CodeLlama-13B-Python-fp16": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "codellama/CodeLlama-7b-hf": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "codellama/CodeLlama-7b-Python-hf": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "codellama/CodeLlama-13b-hf": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "codellama/CodeLlama-13b-Python-hf": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "codellama/CodeLlama-7b-Instruct-hf": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "codellama/CodeLlama-13b-Instruct-hf": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "h2oai/h2ogpt-16k-codellama-13b-instruct": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/CodeLlama-7B-Instruct-fp16": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/CodeLlama-7B-Python-fp16": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "codellama/CodeLlama-34b-hf": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "TheBloke/CodeLlama-7B-fp16": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "h2oai/h2ogpt-16k-codellama-13b-python": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "h2oai/h2ogpt-16k-codellama-13b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "h2oai/h2ogpt-16k-codellama-34b": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "h2oai/h2ogpt-16k-codellama-34b-python": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "h2oai/h2ogpt-16k-codellama-34b-instruct": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "codellama/CodeLlama-34b-Python-hf": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "codellama/CodeLlama-34b-Instruct-hf": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "h2oai/h2ogpt-16k-codellama-7b-instruct": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "h2oai/h2ogpt-16k-codellama-7b-python": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "h2oai/h2ogpt-16k-codellama-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/CodeLlama-7B-Instruct-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/CodeLlama-34B-Python-fp16": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "TheBloke/CodeLlama-34B-Instruct-fp16": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "TheBloke/CodeLlama-34B-fp16": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "unionai/Llama-2-7b-hf-wikipedia": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors",
    "model.safetensors"
  ],
  "TheBloke/CodeLlama-7B-Python-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/CodeLlama-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/CodeLlama-13B-Instruct-GPTQ": [
    "model.safetensors"
  ],
  "dhmeltzer/llama-7b-SFT_eli5_wiki65k_1024_r_64_alpha_16_merged": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "dhmeltzer/llama-7b-SFT_ds_wiki65k_1024_r_64_alpha_16_merged": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "dhmeltzer/llama-7b-SFT_ds_eli5_1024_r_64_alpha_16_merged": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/CodeLlama-13B-Python-GPTQ": [
    "model.safetensors"
  ],
  "heegyu/WizardVicuna-open-llama-3b-v2": [
    "model.safetensors"
  ],
  "TheBloke/CodeLlama-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/CodeLlama-34B-Instruct-GPTQ": [
    "model.safetensors"
  ],
  "Jeppo/Llama-2-13B-chat": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/CodeLlama-34B-Python-GPTQ": [
    "model.safetensors"
  ],
  "crodri/falcon_aguila_meteocat": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/CodeLlama-34B-GPTQ": [
    "model.safetensors"
  ],
  "TabbyML/CodeLlama-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FinchResearch/GTamaraw-1b": [
    "model.safetensors"
  ],
  "PocketDoc/Dans-CreepingSenseOfDoom-13b-gptq-4bit-32g-ao": [
    "Dans-CreepingSenseOfDoom-gptq-4bit-32g-ao.safetensors"
  ],
  "TheBloke/Samantha-1.11-70B-GPTQ": [
    "model.safetensors"
  ],
  "unionai/Llama-2-7b-hf-wikipedia-8bit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mlabonne/dummy-CodeLlama-7b-hf": [
    "model.safetensors"
  ],
  "TheBloke/Samantha-1.11-CodeLlama-34B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Llama2-70B-OASST-SFT-v10-GPTQ": [
    "model.safetensors"
  ],
  "acrastt/OmegLLaMA-3B": [
    "model.safetensors"
  ],
  "NousResearch/CodeLlama-13b-Instruct-hf-flash": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "NousResearch/CodeLlama-7b-Instruct-hf-flash": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FinchResearch/GTamaraw2-1b": [
    "model.safetensors"
  ],
  "SebastianSchramm/Cerebras-GPT-111M-instruction-GPTQ-4bit-128g-actorder_True": [
    "model.safetensors"
  ],
  "Mediocreatmybest/Phind-CodeLlama-34B-Python-v1_8bit_nf4": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Phind-CodeLlama-34B-v1-GPTQ": [
    "model.safetensors"
  ],
  "Mediocreatmybest/Phind-CodeLlama-34B-Python-v1_8bit_fp4": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "SebastianSchramm/UniNER-7B-all-GPTQ-4bit-128g-actorder_True": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "OpenAssistant/codellama-13b-oasst-sft-v10": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "jed351/gpt2-rthk": [
    "model.safetensors"
  ],
  "TheBloke/WizardCoder-Python-34B-V1.0-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Zarafusionex-1.1-L2-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Synthia-70B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Phind-CodeLlama-34B-Python-v1-GPTQ": [
    "model.safetensors"
  ],
  "FinchResearch/GTamaraw3-1b": [
    "model.safetensors"
  ],
  "TheBloke/Genz-70b-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Llama-2-70B-Orca-200k-GPTQ": [
    "model.safetensors"
  ],
  "Karzan/gpt2-walamakan-2": [
    "model.safetensors"
  ],
  "fbellame/llama2-pdf-to-quizz-13b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Airoboros-c34B-2.1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Airoboros-L2-70B-2.1-GPTQ": [
    "model.safetensors"
  ],
  "chargoddard/llama-2-34b-uncode": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "TheBloke/Huginn-22B-Prototype-GPTQ": [
    "model.safetensors"
  ],
  "SebastianSchramm/UniNER-7B-type-GPTQ-4bit-128g-actorder_True": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "SebastianSchramm/UniNER-7B-definition-GPTQ-4bit-128g-actorder_True": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "SebastianSchramm/UniNER-7B-type-sup-GPTQ-4bit-128g-actorder_True": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "shuvom/pythia-70m-FT-Lamini-420": [
    "model.safetensors"
  ],
  "TheBloke/CodeLlama-13B-oasst-sft-v10-GPTQ": [
    "model.safetensors"
  ],
  "RobbeD/OpenLlama-Platypus-3B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/WizardCoder-Python-13B-V1.0-GPTQ": [
    "model.safetensors"
  ],
  "Weyaxi/OpenOrca-Platypus2-13B-QLoRA-0.80-epoch": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "L-R/LLmRa-355M": [
    "model.safetensors"
  ],
  "Weyaxi/OrcaMini-Platypus2-13B-QLoRA-0.80-epoch": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Weyaxi/Stable-Platypus2-13B-QLoRA-0.80-epoch": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Weyaxi/Nous-Hermes-Platypus2-13B-QLoRA-0.80-epoch": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Fredithefish/Guanaco-3B-Uncensored-v2": [
    "model.safetensors"
  ],
  "Weyaxi/Limarp-Platypus2-13B-QLoRA-0.80-epoch": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Weyaxi/MythoMix-Platypus2-13B-QLoRA-0.80-epoch": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Weyaxi/PuddleJumper-Platypus2-13B-QLoRA-0.80-epoch": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "GtQuik702/OPT-350M-Erebus-wikitext2": [
    "model.safetensors"
  ],
  "nomsgadded/clm": [
    "model.safetensors"
  ],
  "Isotonic/gpt2-context_generator": [
    "model.safetensors"
  ],
  "Aharneish/gpt2-spiritual": [
    "model.safetensors"
  ],
  "JennnDexter/clm": [
    "model.safetensors"
  ],
  "TabbyML/CodeLlama-13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FlagAlpha/Atom-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Mediocreatmybest/WizardCoder-Python-13B-V1.0_8bit_nf4": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "schauppi/WizardCoder-1.0-34B": [
    "model.safetensors"
  ],
  "Sao10K/Medusa-13b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "axiomepic/harmon": [
    "model.safetensors"
  ],
  "TheBloke/Phind-CodeLlama-34B-v2-GPTQ": [
    "model.safetensors"
  ],
  "4bit/Chinese-Llama-2-7b-4bit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "lvwerra/starcoderbase-gsm8k": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "monsoon-nlp/mGPT-quantized": [
    "model.safetensors"
  ],
  "FinchResearch/Manish-1b": [
    "model.safetensors"
  ],
  "FinchResearch/Gurkha-copilot-1b": [
    "model.safetensors"
  ],
  "synapsoft/Llama-2-7b-hf-flan2022-1.2M": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "hrfoukin75/mythomax_finetuned": [
    "model.safetensors"
  ],
  "kaitchup/Llama-2-7b-gptq-2bit": [
    "model.safetensors"
  ],
  "TheBloke/Samantha-1.11-13B-GPTQ": [
    "model.safetensors"
  ],
  "Sao10K/Mythical-Destroyer-L2-13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/MythoMax-Kimiko-Mix-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Lemur-70B-Chat-v1-GPTQ": [
    "model.safetensors"
  ],
  "4bit/ELYZA-japanese-Llama-2-7b-instruct": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "smallcloudai/Refact-1_6B-fim": [
    "model.safetensors"
  ],
  "TheBloke/Mythical-Destroyer-L2-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Airoboros-L2-13B-2.1-GPTQ": [
    "model.safetensors"
  ],
  "Sao10K/Mythical-Destroyer-V2-L2-13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "KimJY/LogicLMv2Sharded": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "TheBloke/model_007-70B-GPTQ": [
    "model.safetensors"
  ],
  "KennethTM/gpt2-medium-danish-review-response": [
    "model.safetensors"
  ],
  "TheBloke/Airoboros-L2-7B-2.1-GPTQ": [
    "model.safetensors"
  ],
  "Weyaxi/Luban-Platypus2-13B-QLora-0.80-epoch": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jason-lee08/my_model": [
    "model.safetensors"
  ],
  "TFMC/ELYZA-japanese-Llama-2-7b-instruct-GPTQ-4bit-64g": [
    "model.safetensors"
  ],
  "Benson/llama-2-7b-miniguanaco-chat-hf": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mesolitica/llama-7b-hf-16384-fpf": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "tianyil1/denas-llama2": [
    "model.safetensors"
  ],
  "Weyaxi/Ensemble5-Platypus2-13B-QLora-0.80-epoch": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dahara1/ELYZA-japanese-Llama-2-7b-fast-instruct-GPTQ": [
    "gptq_model-4bit-128g.safetensors",
    "model.safetensors"
  ],
  "TheBloke/Mythical-Destroyer-V2-L2-13B-GPTQ": [
    "model.safetensors"
  ],
  "Weyaxi/Airboros2.1-Platypus2-13B-QLora-0.80-epoch": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Weyaxi/MythicalDestroyerV2-Platypus2-13B-QLora-0.80-epoch": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "IkariDev/Athena-v1": [
    "model-00001-of-00013.safetensors",
    "model-00002-of-00013.safetensors",
    "model-00003-of-00013.safetensors",
    "model-00004-of-00013.safetensors",
    "model-00005-of-00013.safetensors",
    "model-00006-of-00013.safetensors",
    "model-00007-of-00013.safetensors",
    "model-00008-of-00013.safetensors",
    "model-00009-of-00013.safetensors",
    "model-00010-of-00013.safetensors",
    "model-00011-of-00013.safetensors",
    "model-00012-of-00013.safetensors",
    "model-00013-of-00013.safetensors"
  ],
  "Weyaxi/Athena-Platypus2-13B-QLora-0.80-epoch": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Sarvagha/falcon-7b-instruct-sharded": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "TheBloke/Huginn-13B-v4.5-GPTQ": [
    "model.safetensors"
  ],
  "Sarvagha/Text2SQL_prompting": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "Weyaxi/OpenOrcaPlatypus2-Platypus2-13B-QLora-0.80-epoch": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "TheBloke/Huginn-13B-v4-GPTQ": [
    "model.safetensors"
  ],
  "JoSw-14/LoKuS-13B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "mesolitica/llama-13b-hf-16384-fpf": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Athena-v1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Luban-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Kimiko-v2-13B-GPTQ": [
    "model.safetensors"
  ],
  "mbien/gpt-neo-pl-125m": [
    "model.safetensors"
  ],
  "lgaalves/llama-2-7b-hf_open-platypus": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/fiction.live-Kimiko-V2-70B-GPTQ": [
    "model.safetensors"
  ],
  "filipealmeida/open-llama-3b-v2-pii-transform": [
    "model.safetensors"
  ],
  "Qwen/Qwen-VL-Chat-Int4": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "JulesBelveze/pygmalion-2.7b-safetensors": [
    "model.safetensors"
  ],
  "yujiepan/llama-2-tiny-3layers-random": [
    "model.safetensors"
  ],
  "flozi00/codellama-34b-german-assistant-v1": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "flozi00/codellama-34b-german-assistant-v1-4bit-autogptq": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/MythoMax-L2-Kimiko-v2-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Airoboros-L2-70B-2.1-Creative-GPTQ": [
    "model.safetensors"
  ],
  "Karan-PayU/LLAMA-Finetuned": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "squarelike/Gugugo-koja-1.3B-V0.95": [
    "model.safetensors"
  ],
  "winglian/chat-34b": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "genaiquest/codegen-350M-nl-fine-tuned": [
    "model.safetensors"
  ],
  "bhenrym14/airoboros-l2-13b-2.1-PI-16k-fp16": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jessiedu314/gpt2-finetuned1-merchantname": [
    "model.safetensors"
  ],
  "Undi95/UndiMix-v1-13b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lgaalves/falcon-7b_guanaco": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/llama-2-13B-chat-limarp-v2-merged-GPTQ": [
    "model.safetensors"
  ],
  "lgaalves/gpt2_open-platypus": [
    "model.safetensors"
  ],
  "ValiantLabs/ShiningValiant": [
    "model-00001-of-00061.safetensors",
    "model-00002-of-00061.safetensors",
    "model-00003-of-00061.safetensors",
    "model-00004-of-00061.safetensors",
    "model-00005-of-00061.safetensors",
    "model-00006-of-00061.safetensors",
    "model-00007-of-00061.safetensors",
    "model-00008-of-00061.safetensors",
    "model-00009-of-00061.safetensors",
    "model-00010-of-00061.safetensors",
    "model-00011-of-00061.safetensors",
    "model-00012-of-00061.safetensors",
    "model-00013-of-00061.safetensors",
    "model-00014-of-00061.safetensors",
    "model-00015-of-00061.safetensors",
    "model-00016-of-00061.safetensors",
    "model-00017-of-00061.safetensors",
    "model-00018-of-00061.safetensors",
    "model-00019-of-00061.safetensors",
    "model-00020-of-00061.safetensors",
    "model-00021-of-00061.safetensors",
    "model-00022-of-00061.safetensors",
    "model-00023-of-00061.safetensors",
    "model-00024-of-00061.safetensors",
    "model-00025-of-00061.safetensors",
    "model-00026-of-00061.safetensors",
    "model-00027-of-00061.safetensors",
    "model-00028-of-00061.safetensors",
    "model-00029-of-00061.safetensors",
    "model-00030-of-00061.safetensors",
    "model-00031-of-00061.safetensors",
    "model-00032-of-00061.safetensors",
    "model-00033-of-00061.safetensors",
    "model-00034-of-00061.safetensors",
    "model-00035-of-00061.safetensors",
    "model-00036-of-00061.safetensors",
    "model-00037-of-00061.safetensors",
    "model-00038-of-00061.safetensors",
    "model-00039-of-00061.safetensors",
    "model-00040-of-00061.safetensors",
    "model-00041-of-00061.safetensors",
    "model-00042-of-00061.safetensors",
    "model-00043-of-00061.safetensors",
    "model-00044-of-00061.safetensors",
    "model-00045-of-00061.safetensors",
    "model-00046-of-00061.safetensors",
    "model-00047-of-00061.safetensors",
    "model-00048-of-00061.safetensors",
    "model-00049-of-00061.safetensors",
    "model-00050-of-00061.safetensors",
    "model-00051-of-00061.safetensors",
    "model-00052-of-00061.safetensors",
    "model-00053-of-00061.safetensors",
    "model-00054-of-00061.safetensors",
    "model-00055-of-00061.safetensors",
    "model-00056-of-00061.safetensors",
    "model-00057-of-00061.safetensors",
    "model-00058-of-00061.safetensors",
    "model-00059-of-00061.safetensors",
    "model-00060-of-00061.safetensors",
    "model-00061-of-00061.safetensors"
  ],
  "TheBloke/LoKuS-13B-GPTQ": [
    "model.safetensors"
  ],
  "NadavShaked/d_nikud23": [
    "model.safetensors"
  ],
  "KimJY/LGLMv3": [
    "model-00001-of-00028.safetensors",
    "model-00002-of-00028.safetensors",
    "model-00003-of-00028.safetensors",
    "model-00004-of-00028.safetensors",
    "model-00005-of-00028.safetensors",
    "model-00006-of-00028.safetensors",
    "model-00007-of-00028.safetensors",
    "model-00008-of-00028.safetensors",
    "model-00009-of-00028.safetensors",
    "model-00010-of-00028.safetensors",
    "model-00011-of-00028.safetensors",
    "model-00012-of-00028.safetensors",
    "model-00013-of-00028.safetensors",
    "model-00014-of-00028.safetensors",
    "model-00015-of-00028.safetensors",
    "model-00016-of-00028.safetensors",
    "model-00017-of-00028.safetensors",
    "model-00018-of-00028.safetensors",
    "model-00019-of-00028.safetensors",
    "model-00020-of-00028.safetensors",
    "model-00021-of-00028.safetensors",
    "model-00022-of-00028.safetensors",
    "model-00023-of-00028.safetensors",
    "model-00024-of-00028.safetensors",
    "model-00025-of-00028.safetensors",
    "model-00026-of-00028.safetensors",
    "model-00027-of-00028.safetensors",
    "model-00028-of-00028.safetensors"
  ],
  "player1537/Dolphinette": [
    "model.safetensors"
  ],
  "Saiteja/quantized_llama_7b": [
    "model.safetensors"
  ],
  "lgaalves/gpt2_platypus-dolly-guanaco": [
    "model.safetensors"
  ],
  "lgaalves/gpt2_guanaco-dolly-platypus": [
    "model.safetensors"
  ],
  "TheBloke/Synthia-70B-v1.1-GPTQ": [
    "model.safetensors"
  ],
  "shauray/Llava-Llama-2-7B-hf": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Undi95/UndiMix-v2-13b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "uukuguy/speechless-llama2-luban-orca-platypus-13b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Yarn-Llama-2-7B-64K-GPTQ": [
    "model.safetensors"
  ],
  "swaroopajit/git-base-fashion": [
    "model.safetensors"
  ],
  "TinyLlama/TinyLlama-1.1B-step-50K-105b": [
    "model.safetensors"
  ],
  "abhinavkulkarni/codellama-CodeLlama-13b-Instruct-hf-w4-g128-awq": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Sarvagha/new_model": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "TheBloke/Yarn-Llama-2-13B-128K-GPTQ": [
    "model.safetensors"
  ],
  "Mikivis/xuanxuan": [
    "model.safetensors"
  ],
  "TheBloke/Yarn-Llama-2-7B-128K-GPTQ": [
    "model.safetensors"
  ],
  "monuminu/llama-2-70b-miniguanaco": [
    "model-00001-of-00081.safetensors",
    "model-00002-of-00081.safetensors",
    "model-00003-of-00081.safetensors",
    "model-00004-of-00081.safetensors",
    "model-00005-of-00081.safetensors",
    "model-00006-of-00081.safetensors",
    "model-00007-of-00081.safetensors",
    "model-00008-of-00081.safetensors",
    "model-00009-of-00081.safetensors",
    "model-00010-of-00081.safetensors",
    "model-00011-of-00081.safetensors",
    "model-00012-of-00081.safetensors",
    "model-00013-of-00081.safetensors",
    "model-00014-of-00081.safetensors",
    "model-00015-of-00081.safetensors",
    "model-00016-of-00081.safetensors",
    "model-00017-of-00081.safetensors",
    "model-00018-of-00081.safetensors",
    "model-00019-of-00081.safetensors",
    "model-00020-of-00081.safetensors",
    "model-00021-of-00081.safetensors",
    "model-00022-of-00081.safetensors",
    "model-00023-of-00081.safetensors",
    "model-00024-of-00081.safetensors",
    "model-00025-of-00081.safetensors",
    "model-00026-of-00081.safetensors",
    "model-00027-of-00081.safetensors",
    "model-00028-of-00081.safetensors",
    "model-00029-of-00081.safetensors",
    "model-00030-of-00081.safetensors",
    "model-00031-of-00081.safetensors",
    "model-00032-of-00081.safetensors",
    "model-00033-of-00081.safetensors",
    "model-00034-of-00081.safetensors",
    "model-00035-of-00081.safetensors",
    "model-00036-of-00081.safetensors",
    "model-00037-of-00081.safetensors",
    "model-00038-of-00081.safetensors",
    "model-00039-of-00081.safetensors",
    "model-00040-of-00081.safetensors",
    "model-00041-of-00081.safetensors",
    "model-00042-of-00081.safetensors",
    "model-00043-of-00081.safetensors",
    "model-00044-of-00081.safetensors",
    "model-00045-of-00081.safetensors",
    "model-00046-of-00081.safetensors",
    "model-00047-of-00081.safetensors",
    "model-00048-of-00081.safetensors",
    "model-00049-of-00081.safetensors",
    "model-00050-of-00081.safetensors",
    "model-00051-of-00081.safetensors",
    "model-00052-of-00081.safetensors",
    "model-00053-of-00081.safetensors",
    "model-00054-of-00081.safetensors",
    "model-00055-of-00081.safetensors",
    "model-00056-of-00081.safetensors",
    "model-00057-of-00081.safetensors",
    "model-00058-of-00081.safetensors",
    "model-00059-of-00081.safetensors",
    "model-00060-of-00081.safetensors",
    "model-00061-of-00081.safetensors",
    "model-00062-of-00081.safetensors",
    "model-00063-of-00081.safetensors",
    "model-00064-of-00081.safetensors",
    "model-00065-of-00081.safetensors",
    "model-00066-of-00081.safetensors",
    "model-00067-of-00081.safetensors",
    "model-00068-of-00081.safetensors",
    "model-00069-of-00081.safetensors",
    "model-00070-of-00081.safetensors",
    "model-00071-of-00081.safetensors",
    "model-00072-of-00081.safetensors",
    "model-00073-of-00081.safetensors",
    "model-00074-of-00081.safetensors",
    "model-00075-of-00081.safetensors",
    "model-00076-of-00081.safetensors",
    "model-00077-of-00081.safetensors",
    "model-00078-of-00081.safetensors",
    "model-00079-of-00081.safetensors",
    "model-00080-of-00081.safetensors",
    "model-00081-of-00081.safetensors"
  ],
  "eth-easl/pythia_2.8b_deduped-task065_timetravel_consistent_sentence_classification": [
    "model.safetensors"
  ],
  "iashchak/ruGPT-3.5-13B-gptq-4bits": [
    "model.safetensors"
  ],
  "premai-io/CodeLlama-34b-Instruct-hf": [
    "model_00001-of-00049.safetensors",
    "model_00002-of-00049.safetensors",
    "model_00003-of-00049.safetensors",
    "model_00004-of-00049.safetensors",
    "model_00005-of-00049.safetensors",
    "model_00006-of-00049.safetensors",
    "model_00007-of-00049.safetensors",
    "model_00008-of-00049.safetensors",
    "model_00009-of-00049.safetensors",
    "model_00010-of-00049.safetensors",
    "model_00011-of-00049.safetensors",
    "model_00012-of-00049.safetensors",
    "model_00013-of-00049.safetensors",
    "model_00014-of-00049.safetensors",
    "model_00015-of-00049.safetensors",
    "model_00016-of-00049.safetensors",
    "model_00017-of-00049.safetensors",
    "model_00018-of-00049.safetensors",
    "model_00019-of-00049.safetensors",
    "model_00020-of-00049.safetensors",
    "model_00021-of-00049.safetensors",
    "model_00022-of-00049.safetensors",
    "model_00023-of-00049.safetensors",
    "model_00024-of-00049.safetensors",
    "model_00025-of-00049.safetensors",
    "model_00026-of-00049.safetensors",
    "model_00027-of-00049.safetensors",
    "model_00028-of-00049.safetensors",
    "model_00029-of-00049.safetensors",
    "model_00030-of-00049.safetensors",
    "model_00031-of-00049.safetensors",
    "model_00032-of-00049.safetensors",
    "model_00033-of-00049.safetensors",
    "model_00034-of-00049.safetensors",
    "model_00035-of-00049.safetensors",
    "model_00036-of-00049.safetensors",
    "model_00037-of-00049.safetensors",
    "model_00038-of-00049.safetensors",
    "model_00039-of-00049.safetensors",
    "model_00040-of-00049.safetensors",
    "model_00041-of-00049.safetensors",
    "model_00042-of-00049.safetensors",
    "model_00043-of-00049.safetensors",
    "model_00044-of-00049.safetensors",
    "model_00045-of-00049.safetensors",
    "model_00046-of-00049.safetensors",
    "model_00047-of-00049.safetensors",
    "model_00048-of-00049.safetensors",
    "model_00049-of-00049.safetensors"
  ],
  "Undi95/ReMM-L2-13B-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Mira-LeafTown/GPT-2-Chinese-AnimeThesaurus": [
    "model.safetensors"
  ],
  "uukuguy/speechless-llama2-hermes-orca-platypus-13b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Yarn-Llama-2-13B-64K-GPTQ": [
    "model.safetensors"
  ],
  "DiegoVSulz/capivarinha-portugues-7b-lv2-gptq-128-4bit": [
    "model.safetensors"
  ],
  "uukuguy/speechless-llama2-hermes-orca-platypus-wizardlm-13b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Airoboros-33B-2.1-GPTQ": [
    "model.safetensors"
  ],
  "mihirtw/med-train-llama": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Devio/test-22B": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "TheBloke/Stheno-Inverted-L2-13B-GPTQ": [
    "model.safetensors"
  ],
  "Devio/test2": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "TheBloke/Stheno-L2-13B-GPTQ": [
    "model.safetensors"
  ],
  "acrastt/Bean-3B": [
    "model.safetensors"
  ],
  "TheBloke/UndiMix-v1-13B-GPTQ": [
    "model.safetensors"
  ],
  "bhenrym14/airoboros-l2-13b-2.1-YaRN-64k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "uukuguy/speechless-llama2-13b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/UndiMix-v2-13B-GPTQ": [
    "model.safetensors"
  ],
  "elliotthwang/Elliott-LLaMa-GPTQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "vicky7901/my_LLaMA-2-model": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Speechless-Llama2-Hermes-Orca-Platypus-WizardLM-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Speechless-Llama2-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Asclepius-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/OpenBuddy-Llama2-13B-v11.1-GPTQ": [
    "model.safetensors"
  ],
  "elliotthwangmsa/elliottmsa_QPT": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Devio/test-3b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "pszemraj/mega-ar-small-4096-wikitext-103-raw-v1": [
    "model.safetensors"
  ],
  "chukypedro/llama-2-13b-chat-leadelo_cosine_model_4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "quantumaikr/llama-2-70B-instruct": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "quantumaikr/KoreanLM-llama-2-7B-finetuned": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "msong/codeparrot-ds-accelerate": [
    "model.safetensors"
  ],
  "quantumaikr/KoreanLM-7B-GPTQ-4bit": [
    "model.safetensors"
  ],
  "petals-team/falcon-rw-1b": [
    "model.safetensors"
  ],
  "Sakonii/distilgpt2-nepali-qa": [
    "model.safetensors"
  ],
  "team-lucid/mptk-1b": [
    "model.safetensors"
  ],
  "chukypedro/Llama-2-13b-Chat-GPTQ": [
    "model.safetensors"
  ],
  "uukuguy/speechless-codellama-orca-platypus-13b-0.10e": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Envoid/Yousei-22B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "diabolic6045/itineraries_Generator": [
    "model.safetensors"
  ],
  "42dot/42dot_LLM-PLM-1.3B": [
    "model.safetensors"
  ],
  "synapsoft/Llama-2-7b-chat-hf-flan2022-1.2M": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "42dot/42dot_LLM-SFT-1.3B": [
    "model.safetensors"
  ],
  "Mikivis/gpt2-large-lora-sft": [
    "model.safetensors"
  ],
  "uukuguy/speechless-codellama-orca-airoboros-13b-0.10e": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FinchResearch/SiLM-3b-v2": [
    "model.safetensors"
  ],
  "rohanbalkondekar/asia-bank-chat-support-64e-llama-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "kaitchup/OPT-1.3B-SFT-DSChatLoRA": [
    "model.safetensors"
  ],
  "Weyaxi/Nova-13B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Weyaxi/SpeechlessV1-Nova-13B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Weyaxi/EnsembleV5-Nova-13B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Weyaxi/Orca-Nova-13B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "PygmalionAI/pygmalion-2-13b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "PygmalionAI/pygmalion-2-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/openchat_v3.2_super-GPTQ": [
    "model.safetensors"
  ],
  "jessiedu314/gpt2-medium-finetuned1-merchantname": [
    "model.safetensors"
  ],
  "dhmeltzer/llama-7b-SFT-qlora-eli5-wiki_DPO_ds_RM_contrast_1024_r_64_alpha_16_merged": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "dhmeltzer/llama-7b-SFT-qlora-eli5-wiki_DPO_ds_RM_top_2_1024_r_64_alpha_16_merged": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "quantumaikr/llama-2-70B-chat": [
    "model-00001-of-00049.safetensors",
    "model-00002-of-00049.safetensors",
    "model-00003-of-00049.safetensors",
    "model-00004-of-00049.safetensors",
    "model-00005-of-00049.safetensors",
    "model-00006-of-00049.safetensors",
    "model-00007-of-00049.safetensors",
    "model-00008-of-00049.safetensors",
    "model-00009-of-00049.safetensors",
    "model-00010-of-00049.safetensors",
    "model-00011-of-00049.safetensors",
    "model-00012-of-00049.safetensors",
    "model-00013-of-00049.safetensors",
    "model-00014-of-00049.safetensors",
    "model-00015-of-00049.safetensors",
    "model-00016-of-00049.safetensors",
    "model-00017-of-00049.safetensors",
    "model-00018-of-00049.safetensors",
    "model-00019-of-00049.safetensors",
    "model-00020-of-00049.safetensors",
    "model-00021-of-00049.safetensors",
    "model-00022-of-00049.safetensors",
    "model-00023-of-00049.safetensors",
    "model-00024-of-00049.safetensors",
    "model-00025-of-00049.safetensors",
    "model-00026-of-00049.safetensors",
    "model-00027-of-00049.safetensors",
    "model-00028-of-00049.safetensors",
    "model-00029-of-00049.safetensors",
    "model-00030-of-00049.safetensors",
    "model-00031-of-00049.safetensors",
    "model-00032-of-00049.safetensors",
    "model-00033-of-00049.safetensors",
    "model-00034-of-00049.safetensors",
    "model-00035-of-00049.safetensors",
    "model-00036-of-00049.safetensors",
    "model-00037-of-00049.safetensors",
    "model-00038-of-00049.safetensors",
    "model-00039-of-00049.safetensors",
    "model-00040-of-00049.safetensors",
    "model-00041-of-00049.safetensors",
    "model-00042-of-00049.safetensors",
    "model-00043-of-00049.safetensors",
    "model-00044-of-00049.safetensors",
    "model-00045-of-00049.safetensors",
    "model-00046-of-00049.safetensors",
    "model-00047-of-00049.safetensors",
    "model-00048-of-00049.safetensors",
    "model-00049-of-00049.safetensors"
  ],
  "CobraMamba/mamba-gpt-3b-v4": [
    "model.safetensors"
  ],
  "TheBloke/ReMM-SLERP-L2-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/OpenBuddy-Llama2-70b-v10.1-GPTQ": [
    "model.safetensors"
  ],
  "pankaj-munde/llama-2-13b-chat-gptq": [
    "model.safetensors"
  ],
  "PygmalionAI/mythalion-13b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "L-R/LLmRa-1.3B": [
    "model.safetensors"
  ],
  "KnutJaegersberg/megatron-gpt2-345m-evol_instruct_v2": [
    "model.safetensors"
  ],
  "alexgk/git-large-coco": [
    "model.safetensors"
  ],
  "flytech/devchat-llama-7b": [
    "adapter_model.safetensors",
    "last-checkpoint/adapter_model.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/WizardLM-1.0-Uncensored-CodeLlama-34B-GPTQ": [
    "model.safetensors"
  ],
  "Weyaxi/Nova-13B-50-step": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "lgaalves/gpt2_camel_physics-platypus": [
    "model.safetensors"
  ],
  "TheBloke/Pygmalion-2-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Pygmalion-2-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Mythalion-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Chronos-70B-v2-GPTQ": [
    "model.safetensors"
  ],
  "Masterjp123/MythicalMax": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "elliotthwang/Chinese-LLaMa-GPTQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "vasimakram01/dawah_llama2_working_repo": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "alibaba-pai/pai-bloom-1b1-text2prompt-sd-v2": [
    "model.safetensors"
  ],
  "Mikivis/gpt2-large-lora-sft1": [
    "model.safetensors"
  ],
  "Undi95/ReMM-Lion-13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Mikivis/gpt2-large-lora-sft2": [
    "model.safetensors"
  ],
  "papasega/distilbertGPTgeneratedFluency": [
    "model.safetensors"
  ],
  "papasega/distilbertGPTgeneratedFluency1000": [
    "model.safetensors"
  ],
  "TheBloke/Synthia-70B-v1.2-GPTQ": [
    "model.safetensors"
  ],
  "LogitsAI/Llama-2-7b-chat-hf": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Falcon-180B-Chat-GPTQ": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "lgaalves/llama-2-13b-chat-platypus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Sao10K/Medusa-1.1-L2-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "flytech/open-llama-3b-v2-4bit": [
    "model.safetensors"
  ],
  "4bit/Qwen-VL-Chat-Int4": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "ahnyeonchan/OpenOrca-AYT-13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "quantumaikr/falcon-180B-chat-instruct": [
    "model-00001-of-00041.safetensors",
    "model-00002-of-00041.safetensors",
    "model-00003-of-00041.safetensors",
    "model-00004-of-00041.safetensors",
    "model-00005-of-00041.safetensors",
    "model-00006-of-00041.safetensors",
    "model-00007-of-00041.safetensors",
    "model-00008-of-00041.safetensors",
    "model-00009-of-00041.safetensors",
    "model-00010-of-00041.safetensors",
    "model-00011-of-00041.safetensors",
    "model-00012-of-00041.safetensors",
    "model-00013-of-00041.safetensors",
    "model-00014-of-00041.safetensors",
    "model-00015-of-00041.safetensors",
    "model-00016-of-00041.safetensors",
    "model-00017-of-00041.safetensors",
    "model-00018-of-00041.safetensors",
    "model-00019-of-00041.safetensors",
    "model-00020-of-00041.safetensors",
    "model-00021-of-00041.safetensors",
    "model-00022-of-00041.safetensors",
    "model-00023-of-00041.safetensors",
    "model-00024-of-00041.safetensors",
    "model-00025-of-00041.safetensors",
    "model-00026-of-00041.safetensors",
    "model-00027-of-00041.safetensors",
    "model-00028-of-00041.safetensors",
    "model-00029-of-00041.safetensors",
    "model-00030-of-00041.safetensors",
    "model-00031-of-00041.safetensors",
    "model-00032-of-00041.safetensors",
    "model-00033-of-00041.safetensors",
    "model-00034-of-00041.safetensors",
    "model-00035-of-00041.safetensors",
    "model-00036-of-00041.safetensors",
    "model-00037-of-00041.safetensors",
    "model-00038-of-00041.safetensors",
    "model-00039-of-00041.safetensors",
    "model-00040-of-00041.safetensors",
    "model-00041-of-00041.safetensors"
  ],
  "tum-nlp/IDMGSP-GPT-2-INTRODUCTION": [
    "model.safetensors"
  ],
  "tum-nlp/IDMGSP-GPT-2-ABSTRACT": [
    "model.safetensors"
  ],
  "posicube/Llama2-chat-AYT-13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "daedalus314/Griffin-3B-GPTQ": [
    "model.safetensors"
  ],
  "mahimairaja/tweet-summarization-llama-2-finetuned": [
    "adapter_model.safetensors"
  ],
  "TheBloke/YuLan-Chat-2-13B-GPTQ": [
    "model.safetensors"
  ],
  "The-Face-Of-Goonery/Huginn-19b-prototype": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/13B-Thorns-L2-GPTQ": [
    "model.safetensors"
  ],
  "Sao10K/Stheno-Mix-L2-20B": [
    "model-1.safetensors",
    "model-2.safetensors",
    "model-3.safetensors",
    "model-4.safetensors",
    "model-5.safetensors"
  ],
  "quantumaikr/falcon-180B-wizard_alpaca_dolly_orca": [
    "model-00001-of-00041.safetensors",
    "model-00002-of-00041.safetensors",
    "model-00003-of-00041.safetensors",
    "model-00004-of-00041.safetensors",
    "model-00005-of-00041.safetensors",
    "model-00006-of-00041.safetensors",
    "model-00007-of-00041.safetensors",
    "model-00008-of-00041.safetensors",
    "model-00009-of-00041.safetensors",
    "model-00010-of-00041.safetensors",
    "model-00011-of-00041.safetensors",
    "model-00012-of-00041.safetensors",
    "model-00013-of-00041.safetensors",
    "model-00014-of-00041.safetensors",
    "model-00015-of-00041.safetensors",
    "model-00016-of-00041.safetensors",
    "model-00017-of-00041.safetensors",
    "model-00018-of-00041.safetensors",
    "model-00019-of-00041.safetensors",
    "model-00020-of-00041.safetensors",
    "model-00021-of-00041.safetensors",
    "model-00022-of-00041.safetensors",
    "model-00023-of-00041.safetensors",
    "model-00024-of-00041.safetensors",
    "model-00025-of-00041.safetensors",
    "model-00026-of-00041.safetensors",
    "model-00027-of-00041.safetensors",
    "model-00028-of-00041.safetensors",
    "model-00029-of-00041.safetensors",
    "model-00030-of-00041.safetensors",
    "model-00031-of-00041.safetensors",
    "model-00032-of-00041.safetensors",
    "model-00033-of-00041.safetensors",
    "model-00034-of-00041.safetensors",
    "model-00035-of-00041.safetensors",
    "model-00036-of-00041.safetensors",
    "model-00037-of-00041.safetensors",
    "model-00038-of-00041.safetensors",
    "model-00039-of-00041.safetensors",
    "model-00040-of-00041.safetensors",
    "model-00041-of-00041.safetensors"
  ],
  "Undi95/UndiMix-v3-13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LemTenku/model": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "andreipb/gpt2-poetry-model-crpo": [
    "model.safetensors"
  ],
  "TheBloke/Baichuan2-13B-Chat-GPTQ": [
    "model.safetensors"
  ],
  "sarankup-newgen/llama2-70b-email-trained-delivered": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "BarraHome/Llama-2-7b-GPTQ-Pacemaker": [
    "model.safetensors"
  ],
  "Brouz/Slerpeno": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "royallab/Pygmalion-2-13b-SuperCOT": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jangmin/gptq-llama2-7b-chat-hf-food-order-understanding-30K": [
    "model.safetensors"
  ],
  "Arjun-G-Ravi/chat-GPT2": [
    "model.safetensors"
  ],
  "flytech/togetherchat-dev-7b": [
    "adapter_model.safetensors",
    "last-checkpoint/adapter_model.safetensors"
  ],
  "quantumaikr/falcon-180B-WizardLM_Orca": [
    "model-00001-of-00041.safetensors",
    "model-00002-of-00041.safetensors",
    "model-00003-of-00041.safetensors",
    "model-00004-of-00041.safetensors",
    "model-00005-of-00041.safetensors",
    "model-00006-of-00041.safetensors",
    "model-00007-of-00041.safetensors",
    "model-00008-of-00041.safetensors",
    "model-00009-of-00041.safetensors",
    "model-00010-of-00041.safetensors",
    "model-00011-of-00041.safetensors",
    "model-00012-of-00041.safetensors",
    "model-00013-of-00041.safetensors",
    "model-00014-of-00041.safetensors",
    "model-00015-of-00041.safetensors",
    "model-00016-of-00041.safetensors",
    "model-00017-of-00041.safetensors",
    "model-00018-of-00041.safetensors",
    "model-00019-of-00041.safetensors",
    "model-00020-of-00041.safetensors",
    "model-00021-of-00041.safetensors",
    "model-00022-of-00041.safetensors",
    "model-00023-of-00041.safetensors",
    "model-00024-of-00041.safetensors",
    "model-00025-of-00041.safetensors",
    "model-00026-of-00041.safetensors",
    "model-00027-of-00041.safetensors",
    "model-00028-of-00041.safetensors",
    "model-00029-of-00041.safetensors",
    "model-00030-of-00041.safetensors",
    "model-00031-of-00041.safetensors",
    "model-00032-of-00041.safetensors",
    "model-00033-of-00041.safetensors",
    "model-00034-of-00041.safetensors",
    "model-00035-of-00041.safetensors",
    "model-00036-of-00041.safetensors",
    "model-00037-of-00041.safetensors",
    "model-00038-of-00041.safetensors",
    "model-00039-of-00041.safetensors",
    "model-00040-of-00041.safetensors",
    "model-00041-of-00041.safetensors"
  ],
  "yunhuan929/falcon_180b": [
    "model-00001-of-00081.safetensors",
    "model-00002-of-00081.safetensors",
    "model-00003-of-00081.safetensors",
    "model-00004-of-00081.safetensors",
    "model-00005-of-00081.safetensors",
    "model-00006-of-00081.safetensors",
    "model-00007-of-00081.safetensors",
    "model-00008-of-00081.safetensors",
    "model-00009-of-00081.safetensors",
    "model-00010-of-00081.safetensors",
    "model-00011-of-00081.safetensors",
    "model-00012-of-00081.safetensors",
    "model-00013-of-00081.safetensors",
    "model-00014-of-00081.safetensors",
    "model-00015-of-00081.safetensors",
    "model-00016-of-00081.safetensors",
    "model-00017-of-00081.safetensors",
    "model-00018-of-00081.safetensors",
    "model-00019-of-00081.safetensors",
    "model-00020-of-00081.safetensors",
    "model-00021-of-00081.safetensors",
    "model-00022-of-00081.safetensors",
    "model-00023-of-00081.safetensors",
    "model-00024-of-00081.safetensors",
    "model-00025-of-00081.safetensors",
    "model-00026-of-00081.safetensors",
    "model-00027-of-00081.safetensors",
    "model-00028-of-00081.safetensors",
    "model-00029-of-00081.safetensors",
    "model-00030-of-00081.safetensors",
    "model-00031-of-00081.safetensors",
    "model-00032-of-00081.safetensors",
    "model-00033-of-00081.safetensors",
    "model-00034-of-00081.safetensors",
    "model-00035-of-00081.safetensors",
    "model-00036-of-00081.safetensors",
    "model-00037-of-00081.safetensors",
    "model-00038-of-00081.safetensors",
    "model-00039-of-00081.safetensors",
    "model-00040-of-00081.safetensors",
    "model-00041-of-00081.safetensors",
    "model-00042-of-00081.safetensors",
    "model-00043-of-00081.safetensors",
    "model-00044-of-00081.safetensors",
    "model-00045-of-00081.safetensors",
    "model-00046-of-00081.safetensors",
    "model-00047-of-00081.safetensors",
    "model-00048-of-00081.safetensors",
    "model-00049-of-00081.safetensors",
    "model-00050-of-00081.safetensors",
    "model-00051-of-00081.safetensors",
    "model-00052-of-00081.safetensors",
    "model-00053-of-00081.safetensors",
    "model-00054-of-00081.safetensors",
    "model-00055-of-00081.safetensors",
    "model-00056-of-00081.safetensors",
    "model-00057-of-00081.safetensors",
    "model-00058-of-00081.safetensors",
    "model-00059-of-00081.safetensors",
    "model-00060-of-00081.safetensors",
    "model-00061-of-00081.safetensors",
    "model-00062-of-00081.safetensors",
    "model-00063-of-00081.safetensors",
    "model-00064-of-00081.safetensors",
    "model-00065-of-00081.safetensors",
    "model-00066-of-00081.safetensors",
    "model-00067-of-00081.safetensors",
    "model-00068-of-00081.safetensors",
    "model-00069-of-00081.safetensors",
    "model-00070-of-00081.safetensors",
    "model-00071-of-00081.safetensors",
    "model-00072-of-00081.safetensors",
    "model-00073-of-00081.safetensors",
    "model-00074-of-00081.safetensors",
    "model-00075-of-00081.safetensors",
    "model-00076-of-00081.safetensors",
    "model-00077-of-00081.safetensors",
    "model-00078-of-00081.safetensors",
    "model-00079-of-00081.safetensors",
    "model-00080-of-00081.safetensors",
    "model-00081-of-00081.safetensors"
  ],
  "gokul8967/Sofi-gptq": [
    "model.safetensors"
  ],
  "chargoddard/llama-2-26b-trenchcoat-stack": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LAYEK-143/LLAMA": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "TheBloke/Llama-2-PeanutButter_v19_R8-7B-GPTQ": [
    "model.safetensors"
  ],
  "chargoddard/llama-2-16b-nastychat": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Guanaco-7B-Uncensored-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Guanaco-13B-Uncensored-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Airoboros-L2-13B-2_1-YaRN-64K-GPTQ": [
    "model.safetensors"
  ],
  "FunkEngine/SchweinZwei-13b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rirv938/wizard-vicuna-13b-uncensored-w4-g128-awq-v2": [
    "model.safetensors"
  ],
  "flozi00/Llama-2-13b-german-assistant-v7": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dcbv/charluv-mythalion-13b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "abacusai/Giraffe-v2-70b-32k": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "Brouz/REMM-PYG-0.65-SLERP": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "nmitchko/i2b2-querybuilder-34b-merged": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "TheBloke/Guanaco-3B-Uncensored-v2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/COTHuginn-4.5-19B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Spicyboros-7B-2.2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Falcon-180B-GPTQ": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "flozi00/Llama-2-13b-german-assistant-v7-4bit-autogptq": [
    "model.safetensors"
  ],
  "Undi95/MLewdBoros-L2-13B": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Undi95/ReMM-v2-L2-13B": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "TheBloke/Uni-TianYan-70B-GPTQ": [
    "model.safetensors"
  ],
  "ibm/MoLM-350M-4B": [
    "model.safetensors"
  ],
  "LemTenku/model2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Undi95/ReMM-v2-L2-13B-VARIANT": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "TheBloke/ORCA_LLaMA_70B_QLoRA-GPTQ": [
    "model.safetensors"
  ],
  "flytech/togetherchat-dev-7b-v2": [
    "adapter_model.safetensors",
    "last-checkpoint/adapter_model.safetensors"
  ],
  "flytech/gpt-j-6b-devchat": [
    "adapter_model.safetensors",
    "last-checkpoint/adapter_model.safetensors"
  ],
  "pszemraj/mega-ar-small-4096-sw_minipile": [
    "model.safetensors"
  ],
  "TheBloke/Spicyboros-13B-2.2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Pygmalion-2-13B-SuperCOT-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Tulpar-7B-v0-GPTQ": [
    "model.safetensors"
  ],
  "AhmedElDokmak/opt-125m-gptq-4bit": [
    "model.safetensors"
  ],
  "Sao10K/JanniesBasedLigma-L2-13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "WGNW/Llama-2-ko-7b-Chat-auto-gptq-4bit": [
    "model.safetensors"
  ],
  "gmongaras/Wizard_7B_Reddit_Political_2019_8bit": [
    "model.safetensors"
  ],
  "Undi95/Unholy-v1-10L-13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "NewstaR/OpenStar-1b": [
    "model.safetensors"
  ],
  "Undi95/Unholy-v1-12L-13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/MLewdBoros-L2-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/ReMM-v2-L2-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Llama-2-13B-Ensemble-v5-GPTQ": [
    "model.safetensors"
  ],
  "dfurman/Llama-2-7B-Instruct-v0.1": [
    "adapter_model.safetensors"
  ],
  "nguyenthanhdo/pygmalion-tuned-v2": [],
  "pszemraj/mega-ar-large-2048-simplewiki": [
    "model.safetensors"
  ],
  "The-Face-Of-Goonery/Huginn-16B-Prototype": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "dhmeltzer/Llama-2-7b-hf-eli5-cleaned-1024_qlora_merged": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "dhmeltzer/Llama-2-7b-hf-eli5-cleaned-wiki65k-1024_qlora_merged": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "dfurman/Falcon-180B-Instruct-v0.1": [
    "adapter_model.safetensors"
  ],
  "TheBloke/Nous-Hermes-13B-Code-GPTQ": [
    "model.safetensors"
  ],
  "qwopqwop/test-awq": [
    "model.safetensors"
  ],
  "Faradaylab/ARIA-70B-V3": [
    "model-00001-of-00081.safetensors",
    "model-00002-of-00081.safetensors",
    "model-00003-of-00081.safetensors",
    "model-00004-of-00081.safetensors",
    "model-00005-of-00081.safetensors",
    "model-00006-of-00081.safetensors",
    "model-00007-of-00081.safetensors",
    "model-00008-of-00081.safetensors",
    "model-00009-of-00081.safetensors",
    "model-00010-of-00081.safetensors",
    "model-00011-of-00081.safetensors",
    "model-00012-of-00081.safetensors",
    "model-00013-of-00081.safetensors",
    "model-00014-of-00081.safetensors",
    "model-00015-of-00081.safetensors",
    "model-00016-of-00081.safetensors",
    "model-00017-of-00081.safetensors",
    "model-00018-of-00081.safetensors",
    "model-00019-of-00081.safetensors",
    "model-00020-of-00081.safetensors",
    "model-00021-of-00081.safetensors",
    "model-00022-of-00081.safetensors",
    "model-00023-of-00081.safetensors",
    "model-00024-of-00081.safetensors",
    "model-00025-of-00081.safetensors",
    "model-00026-of-00081.safetensors",
    "model-00027-of-00081.safetensors",
    "model-00028-of-00081.safetensors",
    "model-00029-of-00081.safetensors",
    "model-00030-of-00081.safetensors",
    "model-00031-of-00081.safetensors",
    "model-00032-of-00081.safetensors",
    "model-00033-of-00081.safetensors",
    "model-00034-of-00081.safetensors",
    "model-00035-of-00081.safetensors",
    "model-00036-of-00081.safetensors",
    "model-00037-of-00081.safetensors",
    "model-00038-of-00081.safetensors",
    "model-00039-of-00081.safetensors",
    "model-00040-of-00081.safetensors",
    "model-00041-of-00081.safetensors",
    "model-00042-of-00081.safetensors",
    "model-00043-of-00081.safetensors",
    "model-00044-of-00081.safetensors",
    "model-00045-of-00081.safetensors",
    "model-00046-of-00081.safetensors",
    "model-00047-of-00081.safetensors",
    "model-00048-of-00081.safetensors",
    "model-00049-of-00081.safetensors",
    "model-00050-of-00081.safetensors",
    "model-00051-of-00081.safetensors",
    "model-00052-of-00081.safetensors",
    "model-00053-of-00081.safetensors",
    "model-00054-of-00081.safetensors",
    "model-00055-of-00081.safetensors",
    "model-00056-of-00081.safetensors",
    "model-00057-of-00081.safetensors",
    "model-00058-of-00081.safetensors",
    "model-00059-of-00081.safetensors",
    "model-00060-of-00081.safetensors",
    "model-00061-of-00081.safetensors",
    "model-00062-of-00081.safetensors",
    "model-00063-of-00081.safetensors",
    "model-00064-of-00081.safetensors",
    "model-00065-of-00081.safetensors",
    "model-00066-of-00081.safetensors",
    "model-00067-of-00081.safetensors",
    "model-00068-of-00081.safetensors",
    "model-00069-of-00081.safetensors",
    "model-00070-of-00081.safetensors",
    "model-00071-of-00081.safetensors",
    "model-00072-of-00081.safetensors",
    "model-00073-of-00081.safetensors",
    "model-00074-of-00081.safetensors",
    "model-00075-of-00081.safetensors",
    "model-00076-of-00081.safetensors",
    "model-00077-of-00081.safetensors",
    "model-00078-of-00081.safetensors",
    "model-00079-of-00081.safetensors",
    "model-00080-of-00081.safetensors",
    "model-00081-of-00081.safetensors"
  ],
  "TheBloke/Unholy-v1-10l-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Unholy-v1-12L-13B-GPTQ": [
    "model.safetensors"
  ],
  "KoalaAI/OPT-1.3b-Chat": [
    "model.safetensors"
  ],
  "FlagAlpha/Atom-7B-Chat": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "DaertML/tiny_starcoder_py-GPTQ": [
    "model.safetensors"
  ],
  "DaertML/stablelm-base-alpha-3b-4bit-GPTQ": [
    "model.safetensors"
  ],
  "cmarkea/bloomz-7b1-mt-sft-chat": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "cmarkea/bloomz-3b-sft-chat": [
    "model.safetensors"
  ],
  "cmarkea/bloomz-560m-sft-chat": [
    "model.safetensors"
  ],
  "anhnv125/llama-op-v10": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "TheBloke/Spicyboros-70B-2.2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Marcoroni-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Marcoroni-7b-GPTQ": [
    "model.safetensors"
  ],
  "crumb/core1-base-464m-c4": [
    "model.safetensors"
  ],
  "TheBloke/Llama-2-70B-Ensemble-v5-GPTQ": [
    "model.safetensors"
  ],
  "elliotthwang/Elliott-Chinese-LLaMa-GPTQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "harborwater/open-llama-3b-v2-wizard-evol-instuct-v2-196k": [
    "model.safetensors"
  ],
  "pszemraj/pythia-31m-simplewiki-2048": [
    "model.safetensors"
  ],
  "HWERI/pythia-70m-deduped-cleansharegpt": [
    "model.safetensors"
  ],
  "TheBloke/Llama-2-13B-Chat-Dutch-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/JanniesBasedLigma-L2-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Sheep-Duck-Llama-2-70B-GPTQ": [
    "model.safetensors"
  ],
  "Undi95/ReMM-v2.1-L2-13B": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "lgaalves/xgen-7b-8k_dolly": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Airoboros-L2-7B-2.2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Airoboros-L2-13B-2.2-GPTQ": [
    "model.safetensors"
  ],
  "lgaalves/llama-2-13b-hf-platypus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Spicyboros-c34b-2.2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Llama-2-13B-Ensemble-v6-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Airoboros-L2-70b-2.2-GPTQ": [
    "model.safetensors"
  ],
  "chachamatcha/NoDrama-CodeLLama-QLoRa-Evol": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "mamachang/llama2-continue-train": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "typeof/phi-1_5_foreval": [
    "model.safetensors"
  ],
  "Panchovix/airoboros-l2-70b-gpt4-1.4.1-safetensors": [
    "pytorch_model-00001-of-00015.safetensors",
    "pytorch_model-00002-of-00015.safetensors",
    "pytorch_model-00003-of-00015.safetensors",
    "pytorch_model-00004-of-00015.safetensors",
    "pytorch_model-00005-of-00015.safetensors",
    "pytorch_model-00006-of-00015.safetensors",
    "pytorch_model-00007-of-00015.safetensors",
    "pytorch_model-00008-of-00015.safetensors",
    "pytorch_model-00009-of-00015.safetensors",
    "pytorch_model-00010-of-00015.safetensors",
    "pytorch_model-00011-of-00015.safetensors",
    "pytorch_model-00012-of-00015.safetensors",
    "pytorch_model-00013-of-00015.safetensors",
    "pytorch_model-00014-of-00015.safetensors",
    "pytorch_model-00015-of-00015.safetensors"
  ],
  "TheBloke/Euryale-L2-70B-GPTQ": [
    "model.safetensors"
  ],
  "Undi95/UndiMix-v4-13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ibm/MoLM-700M-4B": [
    "model.safetensors"
  ],
  "TheBloke/Euryale-Inverted-L2-70B-GPTQ": [
    "model.safetensors"
  ],
  "sauce1337/AppleSauce-L2-13b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mesolitica/llama-7b-hf-32768-fpf": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mesolitica/llama-13b-hf-32768-fpf": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "iamplus/Llama-2-7b-hf-ChatOrca": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sauce1337/BerrySauce-L2-13b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "BEBO-DBIndia/LLAMA_V58M": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Deci/DeciLM-6b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Deci/DeciLM-6b-instruct": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Weyaxi/Luban-Marcoroni-13B-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mlpipes-asabay/md-assistant": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "RJuro/llama-2-7b-chuk-test-gptq-4bit": [
    "model.safetensors"
  ],
  "TheBloke/Kuchiki-L2-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Llama2-Chat-AYT-13B-GPTQ": [
    "model.safetensors"
  ],
  "casperhansen/opt-125m-awq": [
    "model.safetensors"
  ],
  "chukypedro/llama-2-7b-chat-hf": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Llama-2-Coder-7B-GPTQ": [
    "model.safetensors"
  ],
  "Pawel1212/L2-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Weyaxi/Luban-Marcoroni-13B-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "teknium/Phi-Hermes-1.3B": [
    "model.safetensors"
  ],
  "Weyaxi/Luban-Marcoroni-13B-v3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "billbai0102/qwen-vl-int4": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "bibimbap/Qwen-VL-Chat-Int4": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "royallab/Pygmalion-2-13b-SuperCOT2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "gokul8967/sasuke_ch1-gptq": [
    "model.safetensors"
  ],
  "WGNW/llama-2-ko-7b-auto-gptq": [
    "model.safetensors"
  ],
  "Weyaxi/ChatAYT-Lora-Assamble-Marcoroni": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Weyaxi/ChatAYT-Lora-Assamble-Marcoroni-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/AppleSauce-L2-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/BerrySauce-L2-13B-GPTQ": [
    "model.safetensors"
  ],
  "ByteWave/prompt-generator": [
    "model.safetensors"
  ],
  "TheBloke/Pygmalion-2-13B-SuperCOT2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Llama-2-13B-LoRA-Assemble-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Llama-2-7B-LoRA-Assemble-GPTQ": [
    "model.safetensors"
  ],
  "Mithilss/Llama-2-7b-hf": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "kaitchup/OPT-350M-RM-DSChat": [
    "model.safetensors"
  ],
  "TheBloke/Marcoroni-70B-GPTQ": [
    "model.safetensors"
  ],
  "pszemraj/pythia-31m-simplepile-lite-2048-scratch-2e": [
    "model.safetensors"
  ],
  "Pawel1212/L2-13b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dhmeltzer/Llama-2-13b-hf-eli5-cleaned-1024_qlora_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "csdc-atl/Baichuan2-7B-Chat-GPTQ-Int4": [
    "model.safetensors"
  ],
  "dhmeltzer/Llama-2-13b-hf-eli5-cleaned-wiki65k-1024_qlora_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dhmeltzer/Llama-2-13b-hf-ds_wiki_1024_full_r_64_alpha_16_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dhmeltzer/Llama-2-13b-hf-ds_eli5_1024_r_64_alpha_16_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Chinese-Alpaca-2-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Chinese-Llama-2-13B-GPTQ": [
    "model.safetensors"
  ],
  "dhmeltzer/Llama-2-13b-hf-eli5-wiki-1024_r_64_alpha_16_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "bibimbap/Qwen-7B-Chat-Int4": [
    "model.safetensors"
  ],
  "TheBloke/Chinese-Alpaca-2-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Chinese-Llama-2-7B-GPTQ": [
    "model.safetensors"
  ],
  "Ansoi/birdstruct": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mamachang/llama-7b-sagemaker-feature-processing": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "TheBloke/CodeFuse-CodeLlama-34B-GPTQ": [
    "model.safetensors"
  ],
  "pszemraj/pythia-31m-goodwiki-deduped-2048-scratch": [
    "model.safetensors"
  ],
  "Parcurcik/joke_ai": [
    "model.safetensors"
  ],
  "pszemraj/pythia-31m-KI_v1-2048-scratch": [
    "model.safetensors"
  ],
  "pszemraj/pythia-31m-simplewiki-scratch-bf16": [
    "model.safetensors"
  ],
  "pszemraj/GPT-Neo-33M-simplewiki-2048-scratch": [
    "model.safetensors"
  ],
  "WGNW/kollama-13b-auto-gptq": [
    "model.safetensors"
  ],
  "JorritJ/spicyboros-c34b-2.2-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "danlou/persona-generator-llama-2-7b-qlora-merged": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "elliotthwang/Elliott-Chinese-LLaMa-GPTQ-V1.0": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Synthia-70B-v1.2b-GPTQ": [
    "model.safetensors"
  ],
  "pszemraj/BL-pythia-31m-simpleRW-lite-2048-scratch": [
    "model.safetensors"
  ],
  "ethzanalytics/pythia-31m": [
    "model.safetensors"
  ],
  "TheBloke/ChatAYT-Lora-Assamble-Marcoroni-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Luban-Marcoroni-13B-v3-GPTQ": [
    "model.safetensors"
  ],
  "patched-codes/patched-coder-34b": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "csdc-atl/Baichuan2-13B-Chat-GPTQ-Int4": [
    "model.safetensors"
  ],
  "typeof/phi-2-qlora-ft": [
    "model.safetensors"
  ],
  "Doctor-Shotgun/CalliopeDS-L2-13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TinyLlama/TinyLlama-1.1B-intermediate-step-240k-503b": [
    "model.safetensors"
  ],
  "royallab/Pygmalion-2-13b-SuperCOT-weighed": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/OpenOrca_Stx-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/CalliopeDS-L2-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Kuchiki-1.1-L2-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Airoboros-c34B-2.2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Synthia-34B-v1.2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Pygmalion-2-13B-SuperCOT-weighed-GPTQ": [
    "model.safetensors"
  ],
  "TinyLlama/TinyLlama-1.1B-Chat-v0.1": [
    "model.safetensors"
  ],
  "TheBloke/TigerBot-70B-Chat-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/WizardCoder-Python-7B-V1.0-GPTQ": [
    "model.safetensors"
  ],
  "dhmeltzer/Llama-2-13b-hf-eli5-wiki-1024_qlora_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lmganon123/Euryale-L2-70B-2.1BPW-exllama2": [
    "model.safetensors"
  ],
  "TheBloke/MLewd-L2-Chat-13B-GPTQ": [
    "model.safetensors"
  ],
  "Panchovix/Uni-TianYan-safetensors": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "TinyLlama/TinyLlama-1.1B-Chat-v0.2": [
    "model.safetensors"
  ],
  "wangmw11/llama-2-7b-python": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBlokeAI/Test-AWQ-13B-128": [
    "model.safetensors"
  ],
  "NewstaR/Porpoise-6b-instruct": [],
  "TheBloke/ReMM-v2.1-L2-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Magpie-13B-GPTQ": [
    "model.safetensors"
  ],
  "Panchovix/Marcoroni-70B-safetensors": [
    "pytorch_model-00001-of-00015.safetensors",
    "pytorch_model-00002-of-00015.safetensors",
    "pytorch_model-00003-of-00015.safetensors",
    "pytorch_model-00004-of-00015.safetensors",
    "pytorch_model-00005-of-00015.safetensors",
    "pytorch_model-00006-of-00015.safetensors",
    "pytorch_model-00007-of-00015.safetensors",
    "pytorch_model-00008-of-00015.safetensors",
    "pytorch_model-00009-of-00015.safetensors",
    "pytorch_model-00010-of-00015.safetensors",
    "pytorch_model-00011-of-00015.safetensors",
    "pytorch_model-00012-of-00015.safetensors",
    "pytorch_model-00013-of-00015.safetensors",
    "pytorch_model-00014-of-00015.safetensors",
    "pytorch_model-00015-of-00015.safetensors"
  ],
  "TheBloke/Llama-2-70B-LoRA-Assemble-v2-GPTQ": [
    "model.safetensors"
  ],
  "JackFram/llama-160m-base": [
    "model.safetensors"
  ],
  "hdeldar/llama-2-7b-persian-text-1k": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Undi95/MLewd-ReMM-L2-Chat-20B-Inverted": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Undi95/MLewd-ReMM-L2-Chat-20B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "p208p2002/llama-chinese-81M": [
    "model.safetensors"
  ],
  "mesolitica/llama-1b-hf-32768-fpf": [
    "model.safetensors"
  ],
  "TigerResearch/tigerbot-70b-chat-v2-4bit-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "wangrongsheng/Qwen-VL-Chat-Int4": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Panchovix/Synthia-70B-v1.2b-safetensors": [
    "pytorch_model-00001-of-00015.safetensors",
    "pytorch_model-00002-of-00015.safetensors",
    "pytorch_model-00003-of-00015.safetensors",
    "pytorch_model-00004-of-00015.safetensors",
    "pytorch_model-00005-of-00015.safetensors",
    "pytorch_model-00006-of-00015.safetensors",
    "pytorch_model-00007-of-00015.safetensors",
    "pytorch_model-00008-of-00015.safetensors",
    "pytorch_model-00009-of-00015.safetensors",
    "pytorch_model-00010-of-00015.safetensors",
    "pytorch_model-00011-of-00015.safetensors",
    "pytorch_model-00012-of-00015.safetensors",
    "pytorch_model-00013-of-00015.safetensors",
    "pytorch_model-00014-of-00015.safetensors",
    "pytorch_model-00015-of-00015.safetensors"
  ],
  "KnutJaegersberg/deacon-3b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mhenrichsen/context-aware-splitter-1b": [
    "model.safetensors"
  ],
  "lgaalves/gpt-2-xl_camel-ai-physics": [
    "model.safetensors"
  ],
  "Undi95/66Mytho33Pyg2-13B": [
    "model-00001-of-00013.safetensors",
    "model-00002-of-00013.safetensors",
    "model-00003-of-00013.safetensors",
    "model-00004-of-00013.safetensors",
    "model-00005-of-00013.safetensors",
    "model-00006-of-00013.safetensors",
    "model-00007-of-00013.safetensors",
    "model-00008-of-00013.safetensors",
    "model-00009-of-00013.safetensors",
    "model-00010-of-00013.safetensors",
    "model-00011-of-00013.safetensors",
    "model-00012-of-00013.safetensors",
    "model-00013-of-00013.safetensors"
  ],
  "TheBloke/Llama-2-7B-Chat-AWQ": [
    "model.safetensors"
  ],
  "flytech/Ruckus-7b-ALPHA": [
    "adapter_model.safetensors",
    "last-checkpoint/adapter_model.safetensors"
  ],
  "TheBloke/Llama-2-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Llama-2-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/CodeLlama-13B-Python-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/CodeLlama-13B-Instruct-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/CodeLlama-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Llama-2-13B-chat-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Llama-2-70B-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Llama-2-70B-Chat-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Luban-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/CodeLlama-34B-Instruct-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/CodeLlama-34B-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Marcoroni-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/CodeLlama-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/CodeLlama-7B-Instruct-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/CodeLlama-34B-Python-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Marcoroni-70B-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/CodeLlama-7B-Python-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Marcoroni-7b-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/WizardCoder-Python-7B-V1.0-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/WizardCoder-Python-34B-V1.0-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/WizardCoder-Python-13B-V1.0-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/WizardLM-13B-V1.2-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/WizardMath-7B-V1.0-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Camel-Platypus2-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/WizardMath-13B-V1.0-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Camel-Platypus2-70B-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Platypus2-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/WizardLM-70B-V1.0-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "mamachang/llama2-70b-2": [
    "model-00001-of-00081.safetensors",
    "model-00002-of-00081.safetensors",
    "model-00003-of-00081.safetensors",
    "model-00004-of-00081.safetensors",
    "model-00005-of-00081.safetensors",
    "model-00006-of-00081.safetensors",
    "model-00007-of-00081.safetensors",
    "model-00008-of-00081.safetensors",
    "model-00009-of-00081.safetensors",
    "model-00010-of-00081.safetensors",
    "model-00011-of-00081.safetensors",
    "model-00012-of-00081.safetensors",
    "model-00013-of-00081.safetensors",
    "model-00014-of-00081.safetensors",
    "model-00015-of-00081.safetensors",
    "model-00016-of-00081.safetensors",
    "model-00017-of-00081.safetensors",
    "model-00018-of-00081.safetensors",
    "model-00019-of-00081.safetensors",
    "model-00020-of-00081.safetensors",
    "model-00021-of-00081.safetensors",
    "model-00022-of-00081.safetensors",
    "model-00023-of-00081.safetensors",
    "model-00024-of-00081.safetensors",
    "model-00025-of-00081.safetensors",
    "model-00026-of-00081.safetensors",
    "model-00027-of-00081.safetensors",
    "model-00028-of-00081.safetensors",
    "model-00029-of-00081.safetensors",
    "model-00030-of-00081.safetensors",
    "model-00031-of-00081.safetensors",
    "model-00032-of-00081.safetensors",
    "model-00033-of-00081.safetensors",
    "model-00034-of-00081.safetensors",
    "model-00035-of-00081.safetensors",
    "model-00036-of-00081.safetensors",
    "model-00037-of-00081.safetensors",
    "model-00038-of-00081.safetensors",
    "model-00039-of-00081.safetensors",
    "model-00040-of-00081.safetensors",
    "model-00041-of-00081.safetensors",
    "model-00042-of-00081.safetensors",
    "model-00043-of-00081.safetensors",
    "model-00044-of-00081.safetensors",
    "model-00045-of-00081.safetensors",
    "model-00046-of-00081.safetensors",
    "model-00047-of-00081.safetensors",
    "model-00048-of-00081.safetensors",
    "model-00049-of-00081.safetensors",
    "model-00050-of-00081.safetensors",
    "model-00051-of-00081.safetensors",
    "model-00052-of-00081.safetensors",
    "model-00053-of-00081.safetensors",
    "model-00054-of-00081.safetensors",
    "model-00055-of-00081.safetensors",
    "model-00056-of-00081.safetensors",
    "model-00057-of-00081.safetensors",
    "model-00058-of-00081.safetensors",
    "model-00059-of-00081.safetensors",
    "model-00060-of-00081.safetensors",
    "model-00061-of-00081.safetensors",
    "model-00062-of-00081.safetensors",
    "model-00063-of-00081.safetensors",
    "model-00064-of-00081.safetensors",
    "model-00065-of-00081.safetensors",
    "model-00066-of-00081.safetensors",
    "model-00067-of-00081.safetensors",
    "model-00068-of-00081.safetensors",
    "model-00069-of-00081.safetensors",
    "model-00070-of-00081.safetensors",
    "model-00071-of-00081.safetensors",
    "model-00072-of-00081.safetensors",
    "model-00073-of-00081.safetensors",
    "model-00074-of-00081.safetensors",
    "model-00075-of-00081.safetensors",
    "model-00076-of-00081.safetensors",
    "model-00077-of-00081.safetensors",
    "model-00078-of-00081.safetensors",
    "model-00079-of-00081.safetensors",
    "model-00080-of-00081.safetensors",
    "model-00081-of-00081.safetensors"
  ],
  "TheBloke/WizardMath-70B-V1.0-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Platypus2-70B-Instruct-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Stable-Platypus2-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Platypus2-70B-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Carl-Llama-2-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/qCammel-13-AWQ": [
    "model.safetensors"
  ],
  "abhayesian/pythia-1.4-reversed": [
    "model.safetensors"
  ],
  "TheBloke/qCammel-70-x-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Airoboros-L2-13B-2_1-YaRN-64K-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Airoboros-c34B-2.1-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Airoboros-c34B-2.2-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Airoboros-L2-13B-2.1-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Airoboros-L2-13B-2.2-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/airoboros-l2-13b-gpt4-2.0-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/airoboros-l2-13b-gpt4-m2.0-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Airoboros-L2-70B-2.1-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Airoboros-L2-70B-2.1-Creative-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/airoboros-l2-70B-GPT4-2.0-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Airoboros-L2-70b-2.2-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Airoboros-L2-7B-2.1-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Airoboros-L2-7B-2.2-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Airoboros-L2-70B-GPT4-m2.0-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Spicyboros-13B-2.2-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Spicyboros-70B-2.2-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Spicyboros-7B-2.2-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Spicyboros-c34b-2.2-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Dolphin-Llama2-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Samantha-1.1-70B-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Samantha-1.11-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/WizardLM-1.0-Uncensored-CodeLlama-34B-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Samantha-1.11-CodeLlama-34B-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Samantha-1.11-70B-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/WizardLM-1.0-Uncensored-Llama2-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/vicuna-13B-v1.5-16K-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Chronos-70B-v2-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/vicuna-13B-v1.5-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/vicuna-7B-v1.5-16K-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/vicuna-7B-v1.5-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Vigogne-2-7B-Chat-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Vigogne-2-13B-Instruct-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Vigogne-2-7B-Instruct-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Magpie-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Llama-2-13B-Chat-Dutch-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Genz-70b-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/13B-Legerdemain-L2-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/13B-Thorns-L2-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Chronorctypus-Limarobormes-13b-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/CodeFuse-CodeLlama-34B-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Hermes-LLongMA-2-13B-8K-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Hermes-LLongMA-2-7B-8K-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/LLongMA-2-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/CodeUp-Alpha-13B-HF-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Llama-2-70B-Orca-200k-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/CodeUp-Llama-2-13B-Chat-HF-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/CalliopeDS-L2-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Chronohermes-Grad-L2-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/llama-2-13B-chat-limarp-v2-merged-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Nous-Hermes-Llama-2-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Nous-Hermes-Llama2-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/ORCA_LLaMA_70B_QLoRA-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Nous-Hermes-Llama2-70B-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Redmond-Puffin-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Nous-Puffin-70B-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/llama-2-13B-German-Assistant-v2-AWQ": [
    "model.safetensors"
  ],
  "aspctu/starcoder-16b-gptq-8bit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Llama-2-13B-German-Assistant-v4-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Guanaco-13B-Uncensored-AWQ": [
    "model.safetensors"
  ],
  "aspctu/starcoder-7b-gptq-8bit": [
    "model.safetensors"
  ],
  "TheBloke/Guanaco-7B-Uncensored-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/llama2_7b_chat_uncensored-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/MythoLogic-Mini-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/MythoLogic-L2-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/MythoMax-L2-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/MythoMix-L2-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Spring-Dragon-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Tulpar-7B-v0-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Athena-v1-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/LoKuS-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Llama-2-70B-OASST-1-200-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Airochronos-L2-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/llama2_70b_chat_uncensored-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Airolima-Chronos-Grad-L2-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Chronoboros-Grad-L2-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Chronolima-Airo-Grad-L2-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/OpenOrca_Stx-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/orca_mini_v3_13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/model_007-70B-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/orca_mini_v3_70B-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/orca_mini_v3_7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Mythalion-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Pygmalion-2-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Pygmalion-2-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Synthia-13B-AWQ": [
    "model.safetensors"
  ],
  "Yukang/Llama-2-13b-chat-longlora-32k-sft": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "TheBloke/GodziLLa2-70B-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Synthia-34B-v1.2-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Synthia-70B-v1.1-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Synthia-70B-v1.2-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Synthia-70B-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Synthia-70B-v1.2b-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Synthia-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/llama-2-13B-Guanaco-QLoRA-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/llama-2-7B-Guanaco-QLoRA-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/llama-2-70b-Guanaco-QLoRA-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Llama-2-Coder-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/llama2-22B-daydreamer-v2-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Llama2-22B-Daydreamer-v3-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Yarn-Llama-2-13B-128K-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Yarn-Llama-2-13B-64K-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Yarn-Llama-2-7B-128K-AWQ": [
    "model.safetensors"
  ],
  "p208p2002/llama-traditional-chinese-120M": [
    "model.safetensors"
  ],
  "TheBloke/Yarn-Llama-2-7B-64K-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Kimiko-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Kimiko-v2-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Llama-2-13B-LoRA-Assemble-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Kimiko-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Llama-2-7B-LoRA-Assemble-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/LlongOrca-7B-16K-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Llama-2-70B-LoRA-Assemble-v2-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/OpenOrca-Platypus2-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/OpenOrcaxOpenChat-Preview2-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/CodeLlama-13B-oasst-sft-v10-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Llama2-13B-MegaCode2-OASST-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/fiction.live-Kimiko-V2-70B-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Llama2-70B-OASST-SFT-v10-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/OpenBuddy-Llama2-13B-v11.1-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/openchat_v3.2_super-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/OpenBuddy-Llama2-70b-v10.1-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/OpenAssistant-Llama2-13B-Orca-8K-3319-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Lemur-70B-Chat-v1-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Llama-2-PeanutButter_v19_R8-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Phind-CodeLlama-34B-Python-v1-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Phind-CodeLlama-34B-v1-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Phind-CodeLlama-34B-v2-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Llama2-Chat-AYT-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Sheep-Duck-Llama-2-70B-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/LosslessMegaCoder-Llama2-13B-Mini-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/LosslessMegaCoder-Llama2-7B-Mini-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Pygmalion-2-13B-SuperCOT-weighed-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Pygmalion-2-13B-SuperCOT-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Pygmalion-2-13B-SuperCOT2-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Euryale-Inverted-L2-70B-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/JanniesBasedLigma-L2-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Euryale-L2-70B-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Mythical-Destroyer-L2-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Mythical-Destroyer-V2-L2-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Stheno-Inverted-L2-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Stheno-L2-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/AppleSauce-L2-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/BerrySauce-L2-13B-AWQ": [
    "model.safetensors"
  ],
  "Mahmoud22/quantized-finetuining-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/StableBeluga-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/StableBeluga-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/MythoMax-Kimiko-Mix-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Luna-AI-Llama2-Uncensored-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/StableBeluga2-70B-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/ChatAYT-Lora-Assamble-Marcoroni-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Luban-Marcoroni-13B-v3-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Chronos-Beluga-v2-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Huginn-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Huginn-13B-v4.5-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Huginn-13B-v4-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Huginn-v3-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Llama-2-7B-32K-Instruct-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/TigerBot-70B-Chat-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/llama2-7b-chat-codeCherryPop-qLoRA-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/AlpacaCielo-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/AlpacaCielo2-7B-8K-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/EverythingLM-13B-16K-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/EverythingLM-13b-V2-16K-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/PuddleJumper-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/MLewd-L2-Chat-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/MLewdBoros-L2-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/MythoMax-L2-Kimiko-v2-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Nous-Hermes-13B-Code-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/ReMM-SLERP-L2-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/ReMM-v2-L2-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/ReMM-v2.1-L2-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/UndiMix-v1-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/UndiMix-v2-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Unholy-v1-10l-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Unholy-v1-12L-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Uni-TianYan-70B-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Speechless-Llama2-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Speechless-Llama2-Hermes-Orca-Platypus-WizardLM-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Trurl-2-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Upstage-Llama-2-70B-instruct-v2-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Trurl-2-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Firefly-Llama2-13B-v1.2-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/YuLan-Chat-2-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/HermesLimaRP-L2-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Kuchiki-1.1-L2-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Kuchiki-L2-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Zarablend-L2-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Zarablend-MX-L2-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Zarafusionex-1.1-L2-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Chinese-Alpaca-2-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Chinese-Alpaca-2-13B-AWQ": [
    "model.safetensors"
  ],
  "Thireus/WizardLM-70B-V1.0-BF16": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "TheBloke/Chinese-Llama-2-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Chinese-Llama-2-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/huginnv1.2-AWQ": [
    "model.safetensors"
  ],
  "flytech/Ruckus-7b-v17": [
    "adapter_model.safetensors",
    "last-checkpoint/adapter_model.safetensors"
  ],
  "Undi95/MM-ReMM-L2-20B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "TheBloke/airoboros-l2-13B-gpt4-1.4.1-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/airoboros-l2-7b-gpt4-1.4.1-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/airoboros-l2-7B-gpt4-2.0-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/airoboros-l2-7B-gpt4-m2.0-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/airoboros-l2-70B-gpt4-1.4.1-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "BEE-spoke-data/phi-1bee5": [
    "model.safetensors"
  ],
  "PocketDoc/Dans-RetroRodeo-13b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/13B-BlueMethod-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/tulu-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/13B-Ouroboros-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/13B-Chimera-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/13B-HyperMantis-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/chronos-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/30B-Epsilon-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/30B-Lazarus-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "BEE-spoke-data/TinyLlama-1.1bee": [
    "model.safetensors"
  ],
  "TheBloke/chronos-33b-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/MythoBoros-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/MythoLogic-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/based-13b-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/based-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/based-30B-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Dolphin-Llama-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Wizard-Vicuna-13B-Uncensored-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Wizard-Vicuna-30B-Uncensored-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Uncensored-Frank-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Uncensored-Frank-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Wizard-Vicuna-7B-Uncensored-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/WizardLM-13B-Uncensored-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/WizardLM-13B-V1.0-Uncensored-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/WizardLM-30B-uncensored-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/WizardLM-7B-uncensored-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/WizardLM-33B-V1.0-Uncensored-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/WizardLM-7B-V1.0-Uncensored-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/SuperPlatty-30B-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/guanaco-33B-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/guanaco-65B-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Uncensored-Frank-13b-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Uncensored-Frank-13b-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/guanaco-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/upstage-llama-30b-instruct-2048-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Upstage-Llama1-65B-Instruct-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Uncensored-Frank-33b-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Uncensored-Frank-33b-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/WizardLM-13B-1.0-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/WizardLM-13B-V1.1-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Manticore-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/minotaur-13B-fixed-AWQ": [
    "model.safetensors"
  ],
  "flytech/Ruckus-13B-v20": [
    "adapter_model.safetensors",
    "last-checkpoint/adapter_model.safetensors"
  ],
  "TheBloke/wizard-mega-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/minotaur-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/llama-13b-supercot-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/chronos-hermes-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/chronos-wizardlm-uc-scot-st-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/CAMEL-13B-Combined-Data-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/CAMEL-13B-Role-Playing-Data-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/CAMEL-33B-Combined-Data-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/fin-llama-33B-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Karen_theEditor_13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/gorilla-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/llama-30b-supercot-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Chronoboros-33B-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/airochronos-33B-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/wizard-vicuna-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Vicuna-13B-CoT-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Vicuna-7B-CoT-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/FashionGPT-70B-V1.1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/FashionGPT-70B-V1.1-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/LLaMA-13b-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/medalpaca-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/GPlatty-30B-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Platypus-30B-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/LLaMA-30b-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/LLaMA-7b-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/VicUnlocked-30B-LoRA-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/hippogriff-30b-chat-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/LLaMA-65B-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/manticore-13b-chat-pyg-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/tulu-30B-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/tulu-7B-AWQ": [
    "model.safetensors"
  ],
  "Dev2410/GPT4ALL": [
    "adapter_model.safetensors"
  ],
  "KnutJaegersberg/deacon-13b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "RuterNorway/Llama-2-7b-chat-norwegian-LoRa": [
    "adapter_model.safetensors"
  ],
  "TheBloke/ARIA-70B-V2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/ARIA-70B-V2-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Falcon-180B-Chat-AWQ": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "mistralai/Mistral-7B-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "vilm/vulture-40b": [
    "model-00001-of-00022.safetensors",
    "model-00002-of-00022.safetensors",
    "model-00003-of-00022.safetensors",
    "model-00004-of-00022.safetensors",
    "model-00005-of-00022.safetensors",
    "model-00006-of-00022.safetensors",
    "model-00007-of-00022.safetensors",
    "model-00008-of-00022.safetensors",
    "model-00009-of-00022.safetensors",
    "model-00010-of-00022.safetensors",
    "model-00011-of-00022.safetensors",
    "model-00012-of-00022.safetensors",
    "model-00013-of-00022.safetensors",
    "model-00014-of-00022.safetensors",
    "model-00015-of-00022.safetensors",
    "model-00016-of-00022.safetensors",
    "model-00017-of-00022.safetensors",
    "model-00018-of-00022.safetensors",
    "model-00019-of-00022.safetensors",
    "model-00020-of-00022.safetensors",
    "model-00021-of-00022.safetensors",
    "model-00022-of-00022.safetensors"
  ],
  "mesolitica/llama-600m-hf-32768-fpf": [
    "model.safetensors"
  ],
  "flytech/Ruckus-13b-v20e10": [
    "adapter_model.safetensors"
  ],
  "flytech/Ruckus-13B-v20e9": [
    "adapter_model.safetensors"
  ],
  "flytech/Ruckus-13B-v20e8": [
    "adapter_model.safetensors"
  ],
  "TheBloke/StellarX-4B-V0.2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Xwin-LM-13B-V0.1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Xwin-LM-13B-V0.1-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/MAmmoTH-Coder-34B-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/MAmmoTH-Coder-34B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/MAmmoTH-70B-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/MAmmoTH-70B-GPTQ": [
    "model.safetensors"
  ],
  "whatdhack/gpt-neo-2.7B-sft-peft-oasst1history-merge": [
    "model.safetensors"
  ],
  "amirabdullah19852020/pythia-70m_utility_reward": [
    "model.safetensors"
  ],
  "Zagusan/Wikibot-3001": [
    "model.safetensors"
  ],
  "Thireus/WizardLM-70B-V1.0-BF16-4.0bpw-h6-exl2": [
    "Thireus_WizardLM-70B-V1.0-BF16-4.0bpw-h6-exl2-00001-of-00005.safetensors",
    "Thireus_WizardLM-70B-V1.0-BF16-4.0bpw-h6-exl2-00002-of-00005.safetensors",
    "Thireus_WizardLM-70B-V1.0-BF16-4.0bpw-h6-exl2-00003-of-00005.safetensors",
    "Thireus_WizardLM-70B-V1.0-BF16-4.0bpw-h6-exl2-00004-of-00005.safetensors",
    "Thireus_WizardLM-70B-V1.0-BF16-4.0bpw-h6-exl2-00005-of-00005.safetensors"
  ],
  "Thireus/WizardLM-70B-V1.0-BF16-5.0bpw-h6-exl2": [
    "Thireus_WizardLM-70B-V1.0-BF16-5.0bpw-h6-exl2-00001-of-00006.safetensors",
    "Thireus_WizardLM-70B-V1.0-BF16-5.0bpw-h6-exl2-00002-of-00006.safetensors",
    "Thireus_WizardLM-70B-V1.0-BF16-5.0bpw-h6-exl2-00003-of-00006.safetensors",
    "Thireus_WizardLM-70B-V1.0-BF16-5.0bpw-h6-exl2-00004-of-00006.safetensors",
    "Thireus_WizardLM-70B-V1.0-BF16-5.0bpw-h6-exl2-00005-of-00006.safetensors",
    "Thireus_WizardLM-70B-V1.0-BF16-5.0bpw-h6-exl2-00006-of-00006.safetensors"
  ],
  "UnstableLlama/Xwin-LM-7B-V0.1-8bpw-exl2": [
    "model.safetensors"
  ],
  "aegon-h/TinyLlama-1.1B": [
    "model.safetensors"
  ],
  "TheBloke/Inkbot-13B-4k-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Inkbot-13B-4k-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Xwin-LM-7B-V0.1-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Xwin-LM-7B-V0.1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Xwin-LM-70B-V0.1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Xwin-LM-70B-V0.1-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "Bhuvaneshwari/merged_model_13b_simple_21_09": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Tejasw1/votum-13b-v1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Panchovix/Marcoroni-70B-v1-safetensors": [
    "pytorch_model-00001-of-00015.safetensors",
    "pytorch_model-00002-of-00015.safetensors",
    "pytorch_model-00003-of-00015.safetensors",
    "pytorch_model-00004-of-00015.safetensors",
    "pytorch_model-00005-of-00015.safetensors",
    "pytorch_model-00006-of-00015.safetensors",
    "pytorch_model-00007-of-00015.safetensors",
    "pytorch_model-00008-of-00015.safetensors",
    "pytorch_model-00009-of-00015.safetensors",
    "pytorch_model-00010-of-00015.safetensors",
    "pytorch_model-00011-of-00015.safetensors",
    "pytorch_model-00012-of-00015.safetensors",
    "pytorch_model-00013-of-00015.safetensors",
    "pytorch_model-00014-of-00015.safetensors",
    "pytorch_model-00015-of-00015.safetensors"
  ],
  "Sao10K/Stheno-Mega-False-49B-L2": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "TheBlokeAI/jackfram_llama-68m-GPTQ": [
    "model.safetensors"
  ],
  "csdc-atl/internlm-chat-20b-GPTQ-Int4": [
    "model.safetensors"
  ],
  "jradchenko/DeciCoder-1b": [
    "model.safetensors"
  ],
  "Mahmoud22/llama-7B-chat-gptq": [
    "model.safetensors"
  ],
  "TheBloke/Buddy-7B-v0.2-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Buddy-7B-v0.2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Airoboros-L2-70b-2.2.1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Airoboros-L2-70b-2.2.1-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "Undi95/ReMM-v2.2-L2-13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "nuevamc/llama-2-7b-chat-nuevamc": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "Duxiaoman-DI/XuanYuan-70B": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "Duxiaoman-DI/XuanYuan-70B-Chat": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "Cartinoe5930/orca_mini_v3-13b-GPTQ": [
    "model.safetensors"
  ],
  "lenbrocki/Serena13bv2Q": [
    "model.safetensors"
  ],
  "Tejasw1/votum-13b-v1-gptq": [
    "model.safetensors"
  ],
  "MathLLM/MathCoder-L-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MathLLM/MathCoder-CL-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Thireus/WizardLM-70B-V1.0-FP32-4.0bpw-h6-exl2": [
    "Thireus_WizardLM-70B-V1.0-FP32-4.0bpw-h6-exl2-00001-of-00005.safetensors",
    "Thireus_WizardLM-70B-V1.0-FP32-4.0bpw-h6-exl2-00002-of-00005.safetensors",
    "Thireus_WizardLM-70B-V1.0-FP32-4.0bpw-h6-exl2-00003-of-00005.safetensors",
    "Thireus_WizardLM-70B-V1.0-FP32-4.0bpw-h6-exl2-00004-of-00005.safetensors",
    "Thireus_WizardLM-70B-V1.0-FP32-4.0bpw-h6-exl2-00005-of-00005.safetensors"
  ],
  "Thireus/WizardLM-70B-V1.0-FP32-5.0bpw-h6-exl2": [
    "Thireus_WizardLM-70B-V1.0-FP32-5.0bpw-h6-exl2-00001-of-00006.safetensors",
    "Thireus_WizardLM-70B-V1.0-FP32-5.0bpw-h6-exl2-00002-of-00006.safetensors",
    "Thireus_WizardLM-70B-V1.0-FP32-5.0bpw-h6-exl2-00003-of-00006.safetensors",
    "Thireus_WizardLM-70B-V1.0-FP32-5.0bpw-h6-exl2-00004-of-00006.safetensors",
    "Thireus_WizardLM-70B-V1.0-FP32-5.0bpw-h6-exl2-00005-of-00006.safetensors",
    "Thireus_WizardLM-70B-V1.0-FP32-5.0bpw-h6-exl2-00006-of-00006.safetensors"
  ],
  "Komposter43/saiga2_70b_lora-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "Komposter43/saiga2_70b_lora-GPTQ": [
    "model.safetensors"
  ],
  "Undi95/MXLewd-L2-20B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "UnstableLlama/Xwin-LM-7B-V0.1-4bpw-exl2": [
    "model.safetensors"
  ],
  "UnstableLlama/Xwin-LM-13B-V0.1-5bpw-exl2": [
    "model.safetensors"
  ],
  "UnstableLlama/Xwin-LM-13B-V0.1-4.65bpw-exl2": [
    "model.safetensors"
  ],
  "UnstableLlama/Xwin-LM-13B-V0.1-4bpw-exl2": [
    "model.safetensors"
  ],
  "chargoddard/storytime-13b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Undi95/MXLewdMini-L2-13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/MLewd-ReMM-L2-Chat-20B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/MLewd-ReMM-L2-Chat-20B-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/MLewd-ReMM-L2-Chat-20B-Inverted-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/MLewd-ReMM-L2-Chat-20B-Inverted-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/ALMA-7B-Pretrain-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/ALMA-7B-Pretrain-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/ALMA-13B-Pretrain-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/ALMA-13B-Pretrain-GPTQ": [
    "model.safetensors"
  ],
  "WGNW/llama-2-7b-ko-auto-gptq": [
    "model.safetensors"
  ],
  "mesolitica/llama-2b-hf-32768-fpf": [
    "model.safetensors"
  ],
  "boomerchan/Kiwi-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "IkariDev/Athena-v2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Pclanglais/Brahe": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/airoboros-c34b-2.2.1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/airoboros-c34b-2.2.1-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "PocketDoc/Dans-MysteryModel-13b": [
    "model-00001-of-00028.safetensors",
    "model-00002-of-00028.safetensors",
    "model-00003-of-00028.safetensors",
    "model-00004-of-00028.safetensors",
    "model-00005-of-00028.safetensors",
    "model-00006-of-00028.safetensors",
    "model-00007-of-00028.safetensors",
    "model-00008-of-00028.safetensors",
    "model-00009-of-00028.safetensors",
    "model-00010-of-00028.safetensors",
    "model-00011-of-00028.safetensors",
    "model-00012-of-00028.safetensors",
    "model-00013-of-00028.safetensors",
    "model-00014-of-00028.safetensors",
    "model-00015-of-00028.safetensors",
    "model-00016-of-00028.safetensors",
    "model-00017-of-00028.safetensors",
    "model-00018-of-00028.safetensors",
    "model-00019-of-00028.safetensors",
    "model-00020-of-00028.safetensors",
    "model-00021-of-00028.safetensors",
    "model-00022-of-00028.safetensors",
    "model-00023-of-00028.safetensors",
    "model-00024-of-00028.safetensors",
    "model-00025-of-00028.safetensors",
    "model-00026-of-00028.safetensors",
    "model-00027-of-00028.safetensors",
    "model-00028-of-00028.safetensors"
  ],
  "AzureBlack/Athena-v2-6.0bpw-6h-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "TheBloke/airoboros-l2-13B-2.2.1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/EverythingLM-13B-V3-16K-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/EverythingLM-13B-V3-16K-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/airoboros-l2-13B-2.2.1-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/airoboros-l2-7B-2.2.1-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/airoboros-l2-7B-2.2.1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/MAmmoTH-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/MAmmoTH-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/MAmmoTH-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/MAmmoTH-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Athena-v2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Athena-v2-AWQ": [
    "model.safetensors"
  ],
  "Panchovix/FashionGPT-70B-V1.1-safetensors": [
    "pytorch_model-00001-of-00015.safetensors",
    "pytorch_model-00002-of-00015.safetensors",
    "pytorch_model-00003-of-00015.safetensors",
    "pytorch_model-00004-of-00015.safetensors",
    "pytorch_model-00005-of-00015.safetensors",
    "pytorch_model-00006-of-00015.safetensors",
    "pytorch_model-00007-of-00015.safetensors",
    "pytorch_model-00008-of-00015.safetensors",
    "pytorch_model-00009-of-00015.safetensors",
    "pytorch_model-00010-of-00015.safetensors",
    "pytorch_model-00011-of-00015.safetensors",
    "pytorch_model-00012-of-00015.safetensors",
    "pytorch_model-00013-of-00015.safetensors",
    "pytorch_model-00014-of-00015.safetensors",
    "pytorch_model-00015-of-00015.safetensors"
  ],
  "TheBloke/PuddleJumper-13B-V2-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/PuddleJumper-13B-V2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/MXLewd-L2-20B-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/MXLewd-L2-20B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/storytime-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/storytime-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/MXLewdMini-L2-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/MXLewdMini-L2-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/MetaMath-13B-V1.0-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/MetaMath-13B-V1.0-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/MAmmoTH-Coder-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/MAmmoTH-Coder-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/MetaMath-70B-V1.0-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/MetaMath-70B-V1.0-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/MetaMath-7B-V1.0-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/MetaMath-7B-V1.0-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Synthia-13B-v1.2-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Synthia-13B-v1.2-GPTQ": [
    "model.safetensors"
  ],
  "Qwen/Qwen-14B-Chat-Int4": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Qwen/Qwen-14B-Chat": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "Qwen/Qwen-14B": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "TheBloke/Synthia-7B-v1.2-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Synthia-7B-v1.2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/openbuddy-coder-34b-v11-bf16-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/openbuddy-coder-34b-v11-bf16-GPTQ": [
    "model.safetensors"
  ],
  "Envoid/Cybil-13B": [
    "model-00001-of-00013.safetensors",
    "model-00002-of-00013.safetensors",
    "model-00003-of-00013.safetensors",
    "model-00004-of-00013.safetensors",
    "model-00005-of-00013.safetensors",
    "model-00006-of-00013.safetensors",
    "model-00007-of-00013.safetensors",
    "model-00008-of-00013.safetensors",
    "model-00009-of-00013.safetensors",
    "model-00010-of-00013.safetensors",
    "model-00011-of-00013.safetensors",
    "model-00012-of-00013.safetensors",
    "model-00013-of-00013.safetensors"
  ],
  "aleph65/J7B-exl2-8b": [
    "output.safetensors"
  ],
  "Locutusque/gpt2-conversational-retrain": [
    "model.safetensors"
  ],
  "aleph65/J13B-exl2-8b": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "WGNW/llama-2-7b-ko-auto-gptq-full": [
    "model.safetensors"
  ],
  "TheBloke/openbuddy-llama2-34b-v11.1-bf16-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/openbuddy-llama2-34b-v11.1-bf16-GPTQ": [
    "model.safetensors"
  ],
  "AzureBlack/MLewdBoros-LRPSGPT-2Char-13B-8bpw-6h-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Ansoi/birdstruct2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Pclanglais/Epstein": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "marblyso/DialoGPT-medium-collin": [
    "model.safetensors"
  ],
  "Undi95/U-Amethyst-20B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Weyaxi/2x-LoRA-Assemble-13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "xzyao/openllama-3b-chat": [
    "model.safetensors"
  ],
  "Panchovix/Xwin-LM-70B-V0.1-safetensors": [
    "pytorch_model-00001-of-00029.safetensors",
    "pytorch_model-00002-of-00029.safetensors",
    "pytorch_model-00003-of-00029.safetensors",
    "pytorch_model-00004-of-00029.safetensors",
    "pytorch_model-00005-of-00029.safetensors",
    "pytorch_model-00006-of-00029.safetensors",
    "pytorch_model-00007-of-00029.safetensors",
    "pytorch_model-00008-of-00029.safetensors",
    "pytorch_model-00009-of-00029.safetensors",
    "pytorch_model-00010-of-00029.safetensors",
    "pytorch_model-00011-of-00029.safetensors",
    "pytorch_model-00012-of-00029.safetensors",
    "pytorch_model-00013-of-00029.safetensors",
    "pytorch_model-00014-of-00029.safetensors",
    "pytorch_model-00015-of-00029.safetensors",
    "pytorch_model-00016-of-00029.safetensors",
    "pytorch_model-00017-of-00029.safetensors",
    "pytorch_model-00018-of-00029.safetensors",
    "pytorch_model-00019-of-00029.safetensors",
    "pytorch_model-00020-of-00029.safetensors",
    "pytorch_model-00021-of-00029.safetensors",
    "pytorch_model-00022-of-00029.safetensors",
    "pytorch_model-00023-of-00029.safetensors",
    "pytorch_model-00024-of-00029.safetensors",
    "pytorch_model-00025-of-00029.safetensors",
    "pytorch_model-00026-of-00029.safetensors",
    "pytorch_model-00027-of-00029.safetensors",
    "pytorch_model-00028-of-00029.safetensors",
    "pytorch_model-00029-of-00029.safetensors"
  ],
  "webpolis/zenos-gpt-j-6B-instruct-4bit": [
    "model.safetensors"
  ],
  "Locutusque/gpt2-large-conversational-retrain": [
    "model.safetensors"
  ],
  "4bit/Qwen-14B-Chat-Int4": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "AgentPublic/fabrique-reference-2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mmnga/Xwin-LM-7B-AWQ-calib-ja-100k": [
    "model.safetensors"
  ],
  "danlou/safespace-1.0-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "victor/CodeLlama-34b-Instruct-hf": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "pfnet/plamo-13b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "amazingvince/llama2_xs_233m_GQA-llama-1028-interleaved-deduped-v1-tb-interleaved-deduped-1028-0919": [
    "model.safetensors"
  ],
  "jphme/em_german_13b_v01": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jphme/em_german_13b_v01_gptq": [
    "model.safetensors"
  ],
  "jphme/em_german_7b_v01": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "lgaalves/gpt1": [
    "model.safetensors"
  ],
  "JNewber/my-str-lora": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/vicuna-33B-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Panchovix/Euryale-L2-70B-safetensors": [
    "pytorch_model-00001-of-00014.safetensors",
    "pytorch_model-00002-of-00014.safetensors",
    "pytorch_model-00003-of-00014.safetensors",
    "pytorch_model-00004-of-00014.safetensors",
    "pytorch_model-00005-of-00014.safetensors",
    "pytorch_model-00006-of-00014.safetensors",
    "pytorch_model-00007-of-00014.safetensors",
    "pytorch_model-00008-of-00014.safetensors",
    "pytorch_model-00009-of-00014.safetensors",
    "pytorch_model-00010-of-00014.safetensors",
    "pytorch_model-00011-of-00014.safetensors",
    "pytorch_model-00012-of-00014.safetensors",
    "pytorch_model-00013-of-00014.safetensors",
    "pytorch_model-00014-of-00014.safetensors"
  ],
  "Kooten/MXLewd-L2-20B-6bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Kooten/MLewd-ReMM-L2-Chat-20B-6bpw-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "aleph65/J70B-exl2-5b": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "AtAndDev/ShortKing-1.4b-v0.1": [
    "model.safetensors"
  ],
  "Sao10K/Zephyrus-L1-33B": [
    "model-00001-of-00061.safetensors",
    "model-00002-of-00061.safetensors",
    "model-00003-of-00061.safetensors",
    "model-00004-of-00061.safetensors",
    "model-00005-of-00061.safetensors",
    "model-00006-of-00061.safetensors",
    "model-00007-of-00061.safetensors",
    "model-00008-of-00061.safetensors",
    "model-00009-of-00061.safetensors",
    "model-00010-of-00061.safetensors",
    "model-00011-of-00061.safetensors",
    "model-00012-of-00061.safetensors",
    "model-00013-of-00061.safetensors",
    "model-00014-of-00061.safetensors",
    "model-00015-of-00061.safetensors",
    "model-00016-of-00061.safetensors",
    "model-00017-of-00061.safetensors",
    "model-00018-of-00061.safetensors",
    "model-00019-of-00061.safetensors",
    "model-00020-of-00061.safetensors",
    "model-00021-of-00061.safetensors",
    "model-00022-of-00061.safetensors",
    "model-00023-of-00061.safetensors",
    "model-00024-of-00061.safetensors",
    "model-00025-of-00061.safetensors",
    "model-00026-of-00061.safetensors",
    "model-00027-of-00061.safetensors",
    "model-00028-of-00061.safetensors",
    "model-00029-of-00061.safetensors",
    "model-00030-of-00061.safetensors",
    "model-00031-of-00061.safetensors",
    "model-00032-of-00061.safetensors",
    "model-00033-of-00061.safetensors",
    "model-00034-of-00061.safetensors",
    "model-00035-of-00061.safetensors",
    "model-00036-of-00061.safetensors",
    "model-00037-of-00061.safetensors",
    "model-00038-of-00061.safetensors",
    "model-00039-of-00061.safetensors",
    "model-00040-of-00061.safetensors",
    "model-00041-of-00061.safetensors",
    "model-00042-of-00061.safetensors",
    "model-00043-of-00061.safetensors",
    "model-00044-of-00061.safetensors",
    "model-00045-of-00061.safetensors",
    "model-00046-of-00061.safetensors",
    "model-00047-of-00061.safetensors",
    "model-00048-of-00061.safetensors",
    "model-00049-of-00061.safetensors",
    "model-00050-of-00061.safetensors",
    "model-00051-of-00061.safetensors",
    "model-00052-of-00061.safetensors",
    "model-00053-of-00061.safetensors",
    "model-00054-of-00061.safetensors",
    "model-00055-of-00061.safetensors",
    "model-00056-of-00061.safetensors",
    "model-00057-of-00061.safetensors",
    "model-00058-of-00061.safetensors",
    "model-00059-of-00061.safetensors",
    "model-00060-of-00061.safetensors",
    "model-00061-of-00061.safetensors"
  ],
  "flytech/Ruckus-13b-X": [
    "adapter_model.safetensors",
    "last-checkpoint/adapter_model.safetensors"
  ],
  "mesolitica/malaysian-llama2-7b-32k-instructions": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "stabilityai/japanese-stablelm-instruct-alpha-7b-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors",
    "model.fp16-00001-of-00002.safetensors",
    "model.fp16-00002-of-00002.safetensors"
  ],
  "line-corporation/japanese-large-lm-1.7b-instruction-sft-4bit-32g-actorder_False": [
    "model.safetensors"
  ],
  "line-corporation/japanese-large-lm-1.7b-instruction-sft-4bit-128g-actorder_False": [
    "model.safetensors"
  ],
  "line-corporation/japanese-large-lm-1.7b-instruction-sft-8bit-1g-actorder_True": [
    "model.safetensors"
  ],
  "line-corporation/japanese-large-lm-3.6b-instruction-sft-4bit-32g-actorder_False": [
    "model.safetensors"
  ],
  "line-corporation/japanese-large-lm-3.6b-instruction-sft-4bit-128g-actorder_False": [
    "model.safetensors"
  ],
  "line-corporation/japanese-large-lm-3.6b-instruction-sft-8bit-1g-actorder_True": [
    "model.safetensors"
  ],
  "mesolitica/malaysian-llama2-13b-32k-instructions": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "KennethTM/gpt-neo-1.3B-danish": [
    "model.safetensors"
  ],
  "mmnga/ELYZA-japanese-Llama-2-7b-fast-instruct-AWQ-calib-ja-100k": [
    "model.safetensors"
  ],
  "Kooten/U-Amethyst-20B-6bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Kooten/U-Amethyst-20B-3bpw-exl2": [
    "output.safetensors"
  ],
  "Monkeydddd/luf-10000": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "aleph65/J70B-exl2-5bit-wiki": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "Undi95/SynthiAthena-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Mintrz/Loobe-1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "flytech/Ruckus-7b-c2": [
    "adapter_model.safetensors"
  ],
  "flytech/Ruckus-7b-c3": [
    "adapter_model.safetensors"
  ],
  "flytech/Ruckus-13b-c1": [
    "adapter_model.safetensors"
  ],
  "flytech/Ruckus-13b-Y": [
    "adapter_model.safetensors",
    "last-checkpoint/adapter_model.safetensors"
  ],
  "Enno-Ai/ennodata-13b-8bit-raw-15epoch": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "LemTenku/s": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Frisson/LLZmRG": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "elinas/chronos007-70b": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "BrunoGR/EmotionalBot_LLaMA2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "AzureBlack/U-Amethyst-20B-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "maximuslee07/llama-2-7b-rockwell-final": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Mintrz/Loobe-2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Undi95/Emerhyst-20B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "YULU-BIKE/LLAMA_YULU": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "flytech/Ruckus-13b-AX": [
    "adapter_model.safetensors"
  ],
  "posicube/Llama-chat-AY-13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/law-LLM-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/law-LLM-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/sqlcoder-GPTQ": [
    "model.safetensors"
  ],
  "R136a1/Synthia-13B-v1.2-EXL2": [
    "output.safetensors"
  ],
  "kittn/mistral-7B-v0.1-hf": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Qwen-14B-Chat-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/U-Amethyst-20B-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/U-Amethyst-20B-GPTQ": [
    "model.safetensors"
  ],
  "jojo0217/ChatSKKU5.8B": [
    "model-00001-of-00013.safetensors",
    "model-00002-of-00013.safetensors",
    "model-00003-of-00013.safetensors",
    "model-00004-of-00013.safetensors",
    "model-00005-of-00013.safetensors",
    "model-00006-of-00013.safetensors",
    "model-00007-of-00013.safetensors",
    "model-00008-of-00013.safetensors",
    "model-00009-of-00013.safetensors",
    "model-00010-of-00013.safetensors",
    "model-00011-of-00013.safetensors",
    "model-00012-of-00013.safetensors",
    "model-00013-of-00013.safetensors"
  ],
  "Undi95/Emerhyst-13B": [
    "model-00001-of-00013.safetensors",
    "model-00002-of-00013.safetensors",
    "model-00003-of-00013.safetensors",
    "model-00004-of-00013.safetensors",
    "model-00005-of-00013.safetensors",
    "model-00006-of-00013.safetensors",
    "model-00007-of-00013.safetensors",
    "model-00008-of-00013.safetensors",
    "model-00009-of-00013.safetensors",
    "model-00010-of-00013.safetensors",
    "model-00011-of-00013.safetensors",
    "model-00012-of-00013.safetensors",
    "model-00013-of-00013.safetensors"
  ],
  "mistralai/Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "firelzrd/Xwin-LM-70B-V0.1-fp16-safetensors": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "TheBloke/Marcoroni-70B-v1-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Marcoroni-70B-v1-GPTQ": [
    "model.safetensors"
  ],
  "Sao10K/SthenoWriter-L2-13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Athena-v3-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Athena-v3-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/openbuddy-openllama-7B-v12-bf16-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/openbuddy-openllama-7B-v12-bf16-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Mistral-7B-v0.1-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Mistral-7B-Instruct-v0.1-AWQ": [
    "model.safetensors"
  ],
  "TheBlake/Llama-2-7b": [
    "model.safetensors"
  ],
  "Mintrz/Loobe-3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "flytech/Ruckus-13b-27": [
    "adapter_model.safetensors",
    "last-checkpoint/adapter_model.safetensors"
  ],
  "jphme/em_german_7b_v01_gptq": [
    "model.safetensors"
  ],
  "dfurman/Mistral-7B-Instruct-v0.1": [
    "adapter_model.safetensors"
  ],
  "AzureBlack/Emerhyst-20B-5.125bpw-6h-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Undi95/Mistral-PetroLimaRP-v3-12B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jin05102518/llama-2-ko-70b-awq": [
    "model-00001-of-00013.safetensors",
    "model-00002-of-00013.safetensors",
    "model-00003-of-00013.safetensors",
    "model-00004-of-00013.safetensors",
    "model-00005-of-00013.safetensors",
    "model-00006-of-00013.safetensors",
    "model-00007-of-00013.safetensors",
    "model-00008-of-00013.safetensors",
    "model-00009-of-00013.safetensors",
    "model-00010-of-00013.safetensors",
    "model-00011-of-00013.safetensors",
    "model-00012-of-00013.safetensors",
    "model-00013-of-00013.safetensors"
  ],
  "TheBloke/Emerhyst-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Emerhyst-13B-GPTQ": [
    "model.safetensors"
  ],
  "jphme/em_german_mistral_v01": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Emerhyst-20B-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Emerhyst-20B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/leo-hessianai-13B-chat-bilingual-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/leo-hessianai-13B-chat-bilingual-GPTQ": [
    "model.safetensors"
  ],
  "AzureBlack/Athena-v3-13b-5.25bpw-6h-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "TheBloke/leo-hessianai-13B-chat-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/leo-hessianai-13B-chat-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/leo-hessianai-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/leo-hessianai-13B-AWQ": [
    "model.safetensors"
  ],
  "TokenBender/ChameliRola": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/leo-hessianai-7B-chat-bilingual-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/leo-hessianai-7B-chat-bilingual-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/leo-hessianai-7B-chat-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/leo-hessianai-7B-chat-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/leo-hessianai-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/leo-hessianai-7B-GPTQ": [
    "model.safetensors"
  ],
  "winglian/Mistral-7B-v0.1": [
    "model-00001-of-00131.safetensors",
    "model-00002-of-00131.safetensors",
    "model-00003-of-00131.safetensors",
    "model-00004-of-00131.safetensors",
    "model-00005-of-00131.safetensors",
    "model-00006-of-00131.safetensors",
    "model-00007-of-00131.safetensors",
    "model-00008-of-00131.safetensors",
    "model-00009-of-00131.safetensors",
    "model-00010-of-00131.safetensors",
    "model-00011-of-00131.safetensors",
    "model-00012-of-00131.safetensors",
    "model-00013-of-00131.safetensors",
    "model-00014-of-00131.safetensors",
    "model-00015-of-00131.safetensors",
    "model-00016-of-00131.safetensors",
    "model-00017-of-00131.safetensors",
    "model-00018-of-00131.safetensors",
    "model-00019-of-00131.safetensors",
    "model-00020-of-00131.safetensors",
    "model-00021-of-00131.safetensors",
    "model-00022-of-00131.safetensors",
    "model-00023-of-00131.safetensors",
    "model-00024-of-00131.safetensors",
    "model-00025-of-00131.safetensors",
    "model-00026-of-00131.safetensors",
    "model-00027-of-00131.safetensors",
    "model-00028-of-00131.safetensors",
    "model-00029-of-00131.safetensors",
    "model-00030-of-00131.safetensors",
    "model-00031-of-00131.safetensors",
    "model-00032-of-00131.safetensors",
    "model-00033-of-00131.safetensors",
    "model-00034-of-00131.safetensors",
    "model-00035-of-00131.safetensors",
    "model-00036-of-00131.safetensors",
    "model-00037-of-00131.safetensors",
    "model-00038-of-00131.safetensors",
    "model-00039-of-00131.safetensors",
    "model-00040-of-00131.safetensors",
    "model-00041-of-00131.safetensors",
    "model-00042-of-00131.safetensors",
    "model-00043-of-00131.safetensors",
    "model-00044-of-00131.safetensors",
    "model-00045-of-00131.safetensors",
    "model-00046-of-00131.safetensors",
    "model-00047-of-00131.safetensors",
    "model-00048-of-00131.safetensors",
    "model-00049-of-00131.safetensors",
    "model-00050-of-00131.safetensors",
    "model-00051-of-00131.safetensors",
    "model-00052-of-00131.safetensors",
    "model-00053-of-00131.safetensors",
    "model-00054-of-00131.safetensors",
    "model-00055-of-00131.safetensors",
    "model-00056-of-00131.safetensors",
    "model-00057-of-00131.safetensors",
    "model-00058-of-00131.safetensors",
    "model-00059-of-00131.safetensors",
    "model-00060-of-00131.safetensors",
    "model-00061-of-00131.safetensors",
    "model-00062-of-00131.safetensors",
    "model-00063-of-00131.safetensors",
    "model-00064-of-00131.safetensors",
    "model-00065-of-00131.safetensors",
    "model-00066-of-00131.safetensors",
    "model-00067-of-00131.safetensors",
    "model-00068-of-00131.safetensors",
    "model-00069-of-00131.safetensors",
    "model-00070-of-00131.safetensors",
    "model-00071-of-00131.safetensors",
    "model-00072-of-00131.safetensors",
    "model-00073-of-00131.safetensors",
    "model-00074-of-00131.safetensors",
    "model-00075-of-00131.safetensors",
    "model-00076-of-00131.safetensors",
    "model-00077-of-00131.safetensors",
    "model-00078-of-00131.safetensors",
    "model-00079-of-00131.safetensors",
    "model-00080-of-00131.safetensors",
    "model-00081-of-00131.safetensors",
    "model-00082-of-00131.safetensors",
    "model-00083-of-00131.safetensors",
    "model-00084-of-00131.safetensors",
    "model-00085-of-00131.safetensors",
    "model-00086-of-00131.safetensors",
    "model-00087-of-00131.safetensors",
    "model-00088-of-00131.safetensors",
    "model-00089-of-00131.safetensors",
    "model-00090-of-00131.safetensors",
    "model-00091-of-00131.safetensors",
    "model-00092-of-00131.safetensors",
    "model-00093-of-00131.safetensors",
    "model-00094-of-00131.safetensors",
    "model-00095-of-00131.safetensors",
    "model-00096-of-00131.safetensors",
    "model-00097-of-00131.safetensors",
    "model-00098-of-00131.safetensors",
    "model-00099-of-00131.safetensors",
    "model-00100-of-00131.safetensors",
    "model-00101-of-00131.safetensors",
    "model-00102-of-00131.safetensors",
    "model-00103-of-00131.safetensors",
    "model-00104-of-00131.safetensors",
    "model-00105-of-00131.safetensors",
    "model-00106-of-00131.safetensors",
    "model-00107-of-00131.safetensors",
    "model-00108-of-00131.safetensors",
    "model-00109-of-00131.safetensors",
    "model-00110-of-00131.safetensors",
    "model-00111-of-00131.safetensors",
    "model-00112-of-00131.safetensors",
    "model-00113-of-00131.safetensors",
    "model-00114-of-00131.safetensors",
    "model-00115-of-00131.safetensors",
    "model-00116-of-00131.safetensors",
    "model-00117-of-00131.safetensors",
    "model-00118-of-00131.safetensors",
    "model-00119-of-00131.safetensors",
    "model-00120-of-00131.safetensors",
    "model-00121-of-00131.safetensors",
    "model-00122-of-00131.safetensors",
    "model-00123-of-00131.safetensors",
    "model-00124-of-00131.safetensors",
    "model-00125-of-00131.safetensors",
    "model-00126-of-00131.safetensors",
    "model-00127-of-00131.safetensors",
    "model-00128-of-00131.safetensors",
    "model-00129-of-00131.safetensors",
    "model-00130-of-00131.safetensors",
    "model-00131-of-00131.safetensors"
  ],
  "flytech/Ruckus-13b-29": [
    "adapter_model.safetensors",
    "last-checkpoint/adapter_model.safetensors"
  ],
  "jphme/em_german_7b_leo": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jphme/em_german_7b_leo_gptq": [
    "model.safetensors"
  ],
  "robgonsalves/gpt-j-8bit_deep_haiku": [
    "model.safetensors"
  ],
  "Doctor-Shotgun/CalliopeDS-v2-L2-13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Mistral-7B-Instruct-v0.1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Mistral-7B-v0.1-GPTQ": [
    "model.safetensors"
  ],
  "flozi00/Mistral-7B-german-assistant-v1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/NexusRaven-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/NexusRaven-13B-GPTQ": [
    "model.safetensors"
  ],
  "openerotica/CodeLlama-34b-GPTQ-ERP": [
    "gptq_model-4bit--1g.safetensors"
  ],
  "stabilityai/stablelm-3b-4e1t": [
    "model.safetensors"
  ],
  "Kooten/Emerhyst-20B-3bpw-exl2": [
    "output.safetensors"
  ],
  "Kooten/Emerhyst-20B-6bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Nemanja21/RedPajama-3B-Chromecast-Support": [
    "model.safetensors"
  ],
  "lodrick-the-lafted/Wandering-Minstrel-14B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Sao10K/BrainDerp": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Sao10K/BrainDerp2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "flytech/Ruckus-13b-30": [
    "adapter_model.safetensors"
  ],
  "Sao10K/BrainDerp3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Enno-Ai/ennodata-raw-pankajmathur-13b-peft": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "alpindale/mistral-7b-safetensors": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Synthia-7B-v1.3-AWQ": [
    "model.safetensors"
  ],
  "Frisson/MLG-pro": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Undi95/Mistral-RP-0.1-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "typeof/mistral-7b-og": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Brouz/MaximalSlerp": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "gradientputri/Megamix-A1-13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "gradientputri/MegaMix-S1-13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "gradientputri/MegaMix-T1-13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lodrick-the-lafted/Synthetic-Minstrel-14B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Heralax/MythoMakiseMerged-13b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors",
    "pytorch_files/model-00001-of-00006.safetensors",
    "pytorch_files/model-00002-of-00006.safetensors",
    "pytorch_files/model-00003-of-00006.safetensors",
    "pytorch_files/model-00004-of-00006.safetensors",
    "pytorch_files/model-00005-of-00006.safetensors",
    "pytorch_files/model-00006-of-00006.safetensors"
  ],
  "TheBloke/Synthia-7B-v1.3-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/samantha-mistral-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/samantha-mistral-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/samantha-mistral-instruct-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/samantha-mistral-instruct-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Pandalyst-7B-V1.1-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Pandalyst-7B-V1.1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Pandalyst_13B_V1.0-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Pandalyst_13B_V1.0-AWQ": [
    "model.safetensors"
  ],
  "WGNW/llama-2-7b-ko-auto-gptq-full-v2": [
    "model.safetensors"
  ],
  "TheBloke/Kimiko-Mistral-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Kimiko-Mistral-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Megamix-A1-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Megamix-A1-13B-AWQ": [
    "model.safetensors"
  ],
  "tempNameRepost15/pig_13B_rename": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/MegaMix-S1-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/MegaMix-S1-13B-AWQ": [
    "model.safetensors"
  ],
  "Doctor-Shotgun/pygmalion-2-supercot-limarpv3-gradient-13b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/MegaMix-T1-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/MegaMix-T1-13B-AWQ": [
    "model.safetensors"
  ],
  "AzureBlack/Platypus2-70B-instruct-4.1bpw-6h-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "harborwater/open-llama-3b-everythingLM-2048": [
    "model.safetensors"
  ],
  "tempNameRepost15/pig_7B_rename": [
    "model.safetensors"
  ],
  "vilm/vulture-180b": [
    "adapter_model.safetensors"
  ],
  "AtAndDev/ShortKing-3b-v0.2": [
    "model.safetensors"
  ],
  "TheBloke/sheep-duck-llama-2-70B-v1.1-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/sheep-duck-llama-2-70B-v1.1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/lince-zero-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/MythoMakiseMerged-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/MythoMakiseMerged-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/UltraRM-13B-AWQ": [
    "model.safetensors"
  ],
  "LemTenku/T": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/UltraLM-13B-v2.0-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/UltraLM-13B-v2.0-AWQ": [
    "model.safetensors"
  ],
  "kaitchup/phi-1_5-safetensors": [
    "model.safetensors"
  ],
  "AzureBlack/airoboros-l2-70b-2.2.1-5bpw-6h-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "TheBloke/em_german_13b_v01-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/em_german_13b_v01-AWQ": [
    "model.safetensors"
  ],
  "UnstableLlama/speechless-llama2-hermes-orca-platypus-wizardlm-13b-exl2": [
    "model.safetensors"
  ],
  "TheBloke/em_german_70b_v01-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/em_german_70b_v01-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "jondurbin/airoboros-l2-7b-3.0": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "jondurbin/airoboros-l2-13b-3.0": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "TheBloke/em_german_7b_v01-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/em_german_7b_v01-GPTQ": [
    "model.safetensors"
  ],
  "AzureBlack/Nous-Hermes-Llama2-70b-4.5bpw-6h-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "Nagharjun17/zoningLlama2-GPTQ": [
    "model.safetensors"
  ],
  "TinyLlama/TinyLlama-1.1B-intermediate-step-480k-1T": [
    "model.safetensors"
  ],
  "schnabear/llama-2-7b-hf-nf4-sft-guanaco-1k-sharded": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "BobaZooba/Shurale7B-v1": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "Kooten/Emerhyst-20B-4bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "TheBloke/Mistral-7B-OpenOrca-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Mistral-7B-OpenOrca-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Inkbot-13B-8k-0.2-AWQ": [
    "model.safetensors"
  ],
  "schnabear/llama-2-7b-hf-nf4-dq-sft-guanaco-1k-sharded": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "TheBloke/Inkbot-13B-8k-0.2-GPTQ": [
    "model.safetensors"
  ],
  "bhenrym14/mistral-7b-platypus-fp16": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Nous-Capybara-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Nous-Capybara-7B-AWQ": [
    "model.safetensors"
  ],
  "Doctor-Shotgun/mythalion-supercot-limarpv3-gradient-13b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/dolphin-2.0-mistral-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/dolphin-2.0-mistral-7B-GPTQ": [
    "model.safetensors"
  ],
  "posicube/Llama2-chat-AYB-13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "BobaZooba/Shurale7B-v1-GPTQ": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Sashkanik13/safetensors_rugpt3small": [
    "model.safetensors"
  ],
  "lcw99/llama2-ko-chang-instruct-chat": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LemTenku/next": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lizpreciatior/lzlv_70b_fp16_hf": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "jondurbin/airoboros-3b-3p0": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "jondurbin/airoboros-m-7b-3.0": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Monkeydddd/guitar": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/TinyLlama-1.1B-Chat-v0.3-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/TinyLlama-1.1B-Chat-v0.3-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/TinyLlama-1.1B-python-v0.1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/TinyLlama-1.1B-python-v0.1-AWQ": [
    "model.safetensors"
  ],
  "chaofuyang/llama-2-13b-chat-gptq-4bit-128g": [
    "model.safetensors"
  ],
  "aiplanet/panda-coder-13B": [
    "model.safetensors"
  ],
  "Trelis/TinyLlama-1.1B-Chat-v0.3-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/em_german_mistral_v01-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/em_german_mistral_v01-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/TinyLlama-1.1B-intermediate-step-480k-1T-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/TinyLlama-1.1B-intermediate-step-480k-1T-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/airoboros-mistral2.2-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/airoboros-mistral2.2-7B-GPTQ": [
    "model.safetensors"
  ],
  "PocketDoc/Dans-TotSirocco-7b": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "PocketDoc/Dans-AdventurousWinds-7b": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/CodeFuse-13B-GPTQ": [
    "model.safetensors"
  ],
  "Weyaxi/2x-LoRA-Assemble-Platypus2-13B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "TheBloke/Dans-AdventurousWinds-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Dans-AdventurousWinds-7B-GPTQ": [
    "model.safetensors"
  ],
  "Weyaxi/2x-LoRA-Assemble-Nova-13B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Weyaxi/Chat-AYB-Nova-13B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Weyaxi/Chat-AYB-Platypus2-13B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Weyaxi/GenAI-Nova-13B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "TheBloke/Dans-TotSirocco-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Dans-TotSirocco-7B-GPTQ": [
    "model.safetensors"
  ],
  "Weyaxi/GenAI-Platypus2-13B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "usvsnsp/pythia-410m-ppo": [
    "model.safetensors"
  ],
  "TheBloke/Mistralic-7B-1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Mistralic-7B-1-AWQ": [
    "model.safetensors"
  ],
  "usvsnsp/pythia-160m-ppo": [
    "model.safetensors"
  ],
  "usvsnsp/pythia-70m-ppo": [
    "model.safetensors"
  ],
  "youssefoud/Genz-70b-AWQ-split": [],
  "smallcloudai/starcoderbase-1b": [
    "model.safetensors"
  ],
  "kaitchup/Llama-2-7b-awq-4bit": [
    "model.safetensors"
  ],
  "TheBloke/Llama-2-7B-vietnamese-20k-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Llama-2-7B-vietnamese-20k-GPTQ": [
    "model.safetensors"
  ],
  "alexsherstinsky/Mistral-7B-v0.1-sharded": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "jangmin/merged-llama2-7b-chat-hf-food-order-understanding-30K": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "flozi00/Mistral-7B-german-assistant-v2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Amethyst-13B-Mistral-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Amethyst-13B-Mistral-GPTQ": [
    "model.safetensors"
  ],
  "Ammad1Ali/alex-gptq-4bit": [
    "model.safetensors"
  ],
  "vwxyzjn/train_policy_accelerate__sentiment_offline_5k.json__seed1__1696447674": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate__sentiment_offline_5k.json__seed1": [
    "model.safetensors"
  ],
  "Weyaxi/Nebula-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Azurro/APT2-1B-Base": [
    "model.safetensors"
  ],
  "Weyaxi/OpenOrca-Nebula-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_tf_adam_gpt2__sentiment_offline_5k.json__seed5": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_tf_adam_gpt2__sentiment_offline_5k.json__seed3": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_tf_adam_gpt2__sentiment_offline_5k.json__seed2": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_tf_adam_gpt2__sentiment_offline_5k.json__seed4": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_tf_adam_gpt2__sentiment_offline_5k.json__seed1": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_tf_adam_gpt2__sentiment_offline_5k.json__seed7": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_tf_adam_gpt2__sentiment_offline_5k.json__seed6": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_tf_adam_gpt2__sentiment_offline_5k.json__seed8": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_tf_adam_gpt2__sentiment_offline_5k.json__seed9": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_tf_adam_gpt2__sentiment_offline_5k.json__seed10": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_tf_adam_gpt2__descriptiveness_offline_5k.json__seed1": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_tf_adam_gpt2__descriptiveness_offline_5k.json__seed2": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_tf_adam_gpt2__descriptiveness_offline_5k.json__seed5": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_tf_adam_gpt2__descriptiveness_offline_5k.json__seed3": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_tf_adam_gpt2__descriptiveness_offline_5k.json__seed6": [
    "model.safetensors"
  ],
  "haqishen/perform-test": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_pt_adam_gpt2__descriptiveness_offline_5k.json__seed2": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_pt_adam_gpt2__descriptiveness_offline_5k.json__seed4": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_pt_adam_gpt2__descriptiveness_offline_5k.json__seed3": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_pt_adam_gpt2__descriptiveness_offline_5k.json__seed1": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_tf_adam_gpt2__descriptiveness_offline_5k.json__seed8": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_tf_adam_gpt2__descriptiveness_offline_5k.json__seed7": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_tf_adam_gpt2__descriptiveness_offline_5k.json__seed10": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_tf_adam_gpt2__descriptiveness_offline_5k.json__seed9": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_pt_adam_gpt2__descriptiveness_offline_5k.json__seed5": [
    "model.safetensors"
  ],
  "haqishen/baseline": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_tf_adam_gpt2_grad_accu__descriptiveness_offline_5k.json__seed1": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_tf_adam_gpt2_grad_accu__descriptiveness_offline_5k.json__seed2": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_tf_adam_gpt2_grad_accu__descriptiveness_offline_5k.json__seed3": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_tf_adam_gpt2_grad_accu__descriptiveness_offline_5k.json__seed5": [
    "model.safetensors"
  ],
  "nps798/phi-1_5-qlora-alpaca-instruction": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "basilepp19/bloom-1b7_it": [
    "model.safetensors"
  ],
  "Weyaxi/Dolphin-Nebula-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Weyaxi/Samantha-Nebula-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_tf_adam_cerebras_gpt_111M__descriptiveness_offline_5k.json__seed5": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_tf_adam_cerebras_gpt_111M__descriptiveness_offline_5k.json__seed1": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_tf_adam_cerebras_gpt_111M__descriptiveness_offline_5k.json__seed3": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_tf_adam_cerebras_gpt_111M__descriptiveness_offline_5k.json__seed4": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_tf_adam_cerebras_gpt_111M__descriptiveness_offline_5k.json__seed2": [
    "model.safetensors"
  ],
  "grimpep/0b2": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_tf_adam_pythia-160m__descriptiveness_offline_5k.json__seed3": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_tf_adam_pythia-160m__descriptiveness_offline_5k.json__seed4": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_tf_adam_pythia-160m__descriptiveness_offline_5k.json__seed2": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_tf_adam_pythia-160m__descriptiveness_offline_5k.json__seed1": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_tf_adam_pythia-160m__descriptiveness_offline_5k.json__seed5": [
    "model.safetensors"
  ],
  "grimpep/0h2b": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "TheBloke/CollectiveCognition-v1.1-Mistral-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/CollectiveCognition-v1.1-Mistral-7B-AWQ": [
    "model.safetensors"
  ],
  "WisdomShell/CodeShell-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "NurtureAI/llama-2-7b-int4-gptq-python": [
    "model.safetensors"
  ],
  "h2oai/h2ogpt-4096-llama2-70b-chat-4bit": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_pt_adam_gpt2_xl_grad_accu__descriptiveness_offline_5k.json__seed3": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_tf_adam_gpt2_xl_grad_accu__descriptiveness_offline_5k.json__seed4": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_pt_adam_gpt2_xl_grad_accu__descriptiveness_offline_5k.json__seed2": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_tf_adam_gpt2_xl_grad_accu__descriptiveness_offline_5k.json__seed1": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_pt_adam_gpt2_xl_grad_accu__descriptiveness_offline_5k.json__seed4": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_tf_adam_gpt2_xl_grad_accu__descriptiveness_offline_5k.json__seed2": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_tf_adam_gpt2_xl_grad_accu__descriptiveness_offline_5k.json__seed5": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_pt_adam_gpt2_xl_grad_accu__descriptiveness_offline_5k.json__seed5": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_tf_adam_gpt2_xl_grad_accu__descriptiveness_offline_5k.json__seed3": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_pt_adam_gpt2_xl_grad_accu__descriptiveness_offline_5k.json__seed1": [
    "model.safetensors"
  ],
  "TheBloke/airoboros-l2-7B-3.0-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/airoboros-l2-13B-3.0-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/airoboros-l2-13B-3.0-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/airoboros-l2-7B-3.0-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/airoboros-m-7B-3.0-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/airoboros-m-7B-3.0-AWQ": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_pt_adam_gpt2__sentiment_offline_5k.json__seed1": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_pt_adam_gpt2__sentiment_offline_5k.json__seed3": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_pt_adam_gpt2__sentiment_offline_5k.json__seed4": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_pt_adam_gpt2__sentiment_offline_5k.json__seed2": [
    "model.safetensors"
  ],
  "TheBloke/llama-2-7B-Arguments-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/llama-2-7B-Arguments-GPTQ": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_pt_adam_gpt2__sentiment_offline_5k.json__seed5": [
    "model.safetensors"
  ],
  "Undi95/PsyMedRP-v1-20B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "myzens/XGLM_TR_FineTune_alpha-original": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_pt_adam_gpt2_xl_grad_accu__sentiment_offline_5k.json__seed4": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_pt_adam_gpt2_xl_grad_accu__sentiment_offline_5k.json__seed2": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_pt_adam_gpt2_xl_grad_accu__sentiment_offline_5k.json__seed5": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_pt_adam_gpt2_xl_grad_accu__sentiment_offline_5k.json__seed3": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_tf_adam_gpt2_xl_grad_accu__sentiment_offline_5k.json__seed2": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_tf_adam_gpt2_xl_grad_accu__sentiment_offline_5k.json__seed5": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_tf_adam_gpt2_xl_grad_accu__sentiment_offline_5k.json__seed4": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_tf_adam_gpt2_xl_grad_accu__sentiment_offline_5k.json__seed3": [
    "model.safetensors"
  ],
  "lm-human-preference-details/train_policy_accelerate_tf_adam_gpt2_xl_grad_accu__sentiment_offline_5k.json__seed1": [
    "model.safetensors"
  ],
  "chargoddard/duplicitous-mammal-13b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jingamz/llama2ec2": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "chargoddard/duplicitous-slurpbeast-13b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "zlsl/l_erotic_chat_v2": [
    "model.safetensors"
  ],
  "yentinglin/Taiwan-LLM-7B-v2.0-base": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "flozi00/Mistral-7B-german-assistant-v2-4bit-autogptq": [
    "model.safetensors"
  ],
  "nico-che/gpt2": [
    "model.safetensors"
  ],
  "NucleusAI/nucleus-22B-token-500B": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "mrsteyk/Mistral-7B-claude-chat-AWQ": [
    "model.safetensors"
  ],
  "TinyLlama/TinyLlama-1.1B-Chat-v0.3": [
    "model.safetensors"
  ],
  "Kooten/PsyMedRP-v1-20B-4bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Kooten/PsyMedRP-v1-20B-3bpw-h8-exl2": [
    "output.safetensors"
  ],
  "Kooten/PsyMedRP-v1-20B-6bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/airoboros-m-7b-3.0-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/airoboros-m-7b-3.0-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/airoboros-m-7b-3.0-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/airoboros-m-7b-3.0-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/airoboros-m-7b-3.0-8.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "TheBloke/UndiMix-v4-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/UndiMix-v4-13B-GPTQ": [
    "model.safetensors"
  ],
  "harborwater/wizard-orca-3b": [
    "model.safetensors"
  ],
  "openerotica/Qwen-7b-GPTQ-ERP": [
    "model.safetensors"
  ],
  "jangmin/awq-llama2-7b-chat-hf-food-order-understanding-30K": [
    "model.safetensors"
  ],
  "gokul8967/Llama-13b-TonyStark": [
    "model-00002-of-00003.safetensors"
  ],
  "gokul8967/Llama-13b-Loki": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jingamz/finetuningllama2": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "jphme/em_german_leo_mistral": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Yukang/LongAlpaca-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jslin09/LLaMA2_LegalInquryBot": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Undi95/MistralMegaOrca-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "phanerozoic/PirateTalk-13b-v1-GPTQ-4bit": [
    "model.safetensors"
  ],
  "jingamz/llama2chatcn": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "TheBloke/Mistral-Trismegistus-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Mistral-Trismegistus-7B-AWQ": [
    "model.safetensors"
  ],
  "jingamz/llama2jingamz": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "KaleDivergence/WeniGPT-L-70-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "IkariDev/Athena-v4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Yukang/LongAlpaca-13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "khaimaitien/qa-expert-7B-V1.0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "cenkersisman/gpt2-turkish-128-token": [
    "model.safetensors"
  ],
  "THUDM/agentlm-13b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jingamz/llama2jingamz6": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "THUDM/agentlm-70b": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "waldie/Athena-v4-8bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Weyaxi/CollectiveCognition-v1.1-Nebula-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Weyaxi/TekniumAiroboros-Nebula-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jingamz/llama2ec2cn": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "TheBloke/sheep-duck-llama-2-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/sheep-duck-llama-2-13B-GPTQ": [
    "model.safetensors"
  ],
  "Mxode/Pythia-70m-Synonym-Sentence-Converter": [
    "model.safetensors"
  ],
  "TheBloke/Llama2-chat-AYB-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Llama2-chat-AYB-13B-GPTQ": [
    "model.safetensors"
  ],
  "Undi95/Mistral-11B-Airoboros-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Athena-v4-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Athena-v4-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/PsyMedRP-v1-20B-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/PsyMedRP-v1-20B-GPTQ": [
    "model.safetensors"
  ],
  "Sao10K/ReMantik-L2-70B": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "elliotthwang/elliott_Llama-2-7b-hf": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Yukang/LongAlpaca-70B": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "KnutJaegersberg/Deacon-20B": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "lcw99/llama2-ko-7b-chang-base": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "shoppal/shoppal-v0.1": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "kkboy1/gpt2-trained": [
    "model.safetensors"
  ],
  "HuggingFaceH4/zephyr-7b-alpha": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "waldie/Mistral-11B-Airoboros-RP-v1-8bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "TheBloke/Ziya-Coding-34B-v1.0-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Ziya-Coding-34B-v1.0-GPTQ": [
    "model.safetensors"
  ],
  "Trelis/Llama-2-7b-chat-hf-6k": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Mediocreatmybest/Mistral-7B-OpenOrca_8bit_nf4": [
    "model.safetensors"
  ],
  "Undi95/Mistral-11B-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "flytech/Ruckus-PyAssi-13b": [
    "adapter_model.safetensors",
    "last-checkpoint/adapter_model.safetensors"
  ],
  "4bit/Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jeff31415/TinyLlama-1.1B-1T-OpenOrca": [
    "model.safetensors"
  ],
  "Undi95/Mistral-11B-CC-Air": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "4bit/llava-v1.5-7b-s": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "PAIXAI/Astrid-13B-Chat": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "PAIXAI/Astrid-3B": [
    "model.safetensors"
  ],
  "Panchovix/llama-2-70b-Guanaco-QLoRA-fp16-safetensors": [
    "pytorch_model-00001-of-00015.safetensors",
    "pytorch_model-00002-of-00015.safetensors",
    "pytorch_model-00003-of-00015.safetensors",
    "pytorch_model-00004-of-00015.safetensors",
    "pytorch_model-00005-of-00015.safetensors",
    "pytorch_model-00006-of-00015.safetensors",
    "pytorch_model-00007-of-00015.safetensors",
    "pytorch_model-00008-of-00015.safetensors",
    "pytorch_model-00009-of-00015.safetensors",
    "pytorch_model-00010-of-00015.safetensors",
    "pytorch_model-00011-of-00015.safetensors",
    "pytorch_model-00012-of-00015.safetensors",
    "pytorch_model-00013-of-00015.safetensors",
    "pytorch_model-00014-of-00015.safetensors",
    "pytorch_model-00015-of-00015.safetensors"
  ],
  "PAIXAI/Astrid-Mistral-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaxZabarka/qlora-out-3-quantized": [
    "model.safetensors"
  ],
  "PAIXAI/Astrid-7b-Instruct": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "promptora11/llama": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Natooz/Maestro-TSD-bpe20k": [
    "model.safetensors"
  ],
  "Natooz/Maestro-REMI-bpe20k": [
    "model.safetensors"
  ],
  "Stevross/Astrid-7B-Assistant-CPU": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "PAIXAI/Astrid-7B-LLama-Med": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/em_german_leo_mistral-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/em_german_leo_mistral-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/sqlcoder2-GPTQ": [
    "model.safetensors"
  ],
  "waldie/Mistral-Pygmalion-7b-4bpw-h6-exl2": [
    "output.safetensors"
  ],
  "waldie/Mistral-Pygmalion-7b-8bpw-h8-exl2": [
    "output.safetensors"
  ],
  "kubernetes-bad/Mistral-11B-CC-Air-RP-8.0bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "grimulkan/llama2_70b_longlora_fp16_32k_ROPE8": [
    "model-00001-of-00018.safetensors",
    "model-00002-of-00018.safetensors",
    "model-00003-of-00018.safetensors",
    "model-00004-of-00018.safetensors",
    "model-00005-of-00018.safetensors",
    "model-00006-of-00018.safetensors",
    "model-00007-of-00018.safetensors",
    "model-00008-of-00018.safetensors",
    "model-00009-of-00018.safetensors",
    "model-00010-of-00018.safetensors",
    "model-00011-of-00018.safetensors",
    "model-00012-of-00018.safetensors",
    "model-00013-of-00018.safetensors",
    "model-00014-of-00018.safetensors",
    "model-00015-of-00018.safetensors",
    "model-00016-of-00018.safetensors",
    "model-00017-of-00018.safetensors",
    "model-00018-of-00018.safetensors"
  ],
  "unaidedelf87777/wizard-mistral-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "lgaalves/mistral-7b-platypus1k": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "IHaBiS/Synatra-V0.1-7B-Instruct-4.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "IHaBiS/Undi95_Mistral-11B-TestBench3-4.0bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "IHaBiS/Undi95_Mistral-11B-TestBench3-6.0bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "CatLikeIceCream/LLAMA2_JOB_POSTING": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "nicholasKluge/Aira-2-1B1": [
    "model.safetensors"
  ],
  "TheBloke/Tinyllama-2-1b-miniguanaco-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Tinyllama-2-1b-miniguanaco-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/zephyr-7B-alpha-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/zephyr-7B-alpha-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/TinyLlama-1.1B-1T-OpenOrca-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/TinyLlama-1.1B-1T-OpenOrca-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/tinyllama-1.1b-chat-v0.3_platypus-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/tinyllama-1.1b-chat-v0.3_platypus-GPTQ": [
    "model.safetensors"
  ],
  "royallab/ZephRP-m7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/UndiMix-v3-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/UndiMix-v3-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/dolphin-2.1-mistral-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/dolphin-2.1-mistral-7B-AWQ": [
    "model.safetensors"
  ],
  "Weyaxi/SlimOpenOrca-Mistral-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Heralax/MistralMakise-Merged-13b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/jackalope-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/jackalope-7B-GPTQ": [
    "model.safetensors"
  ],
  "Qwen/Qwen-7B-Chat-Int8": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Weyaxi/Dolphin2.1-OpenOrca-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "zlsl/m_erotic_chat": [
    "model.safetensors"
  ],
  "Weyaxi/OpenOrca-Zephyr-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "zlsl/s_erotic_chat": [
    "model.safetensors"
  ],
  "Weyaxi/SlimOpenOrca-Mistral-7B-v2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "isek-ai/LightNovel-Intro-RetNet-400M": [
    "model.safetensors"
  ],
  "Undi95/Mistral-11B-OmniMix9": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lgaalves/gpt2-xl_lima": [
    "model.safetensors"
  ],
  "DLI-Lab/DOCTOR": [
    "model.safetensors"
  ],
  "Undi95/Mistral-11B-OmniMix": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "VAGOsolutions/SauerkrautLM-3b-v1": [
    "model.safetensors"
  ],
  "Vezora/Mistral-Narwhal-7b": [
    "Safe-Tensor-Version/model-00001-of-00002.safetensors",
    "Safe-Tensor-Version/model-00002-of-00002.safetensors"
  ],
  "mnoukhov/pythia410m-tldr-sft": [
    "model.safetensors"
  ],
  "TheBloke/ZephRP-m7b-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/ZephRP-m7b-AWQ": [
    "model.safetensors"
  ],
  "willnguyen/lacda-2-7B-chat-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "IHaBiS/Synatra-7B-Instruct-v0.2-4.125bpw-h8-exl2": [
    "output.safetensors"
  ],
  "IHaBiS/Synatra-7B-Instruct-v0.2-8bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "IHaBiS/Synatra-7B-Instruct-v0.2-6bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "harborwater/open-llama-3b-everything-v2": [
    "model.safetensors"
  ],
  "TheBloke/samantha-1.2-mistral-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/samantha-1.2-mistral-7B-GPTQ": [
    "model.safetensors"
  ],
  "Qwen/Qwen-14B-Chat-Int8": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "TheBloke/chronos007-70B-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/chronos007-70B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/FashionGPT-70B-v1.2-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/FashionGPT-70B-v1.2-GPTQ": [
    "model.safetensors"
  ],
  "NeverSleep/Mistral-11B-OmniMix-bf16": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mesolitica/mistral-7b-4096-fpf": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaxZabarka/main-bot-7b-test-quantized": [
    "model.safetensors"
  ],
  "krevas/LDCC-Instruct-Llama-2-ko-13B-v4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "vwxyzjn/train_sft_accelerate_summarize__tldr__seed1400__1697168329": [
    "model.safetensors"
  ],
  "vwxyzjn/train_sft_accelerate_summarize__tldr__seed1401__1697168334": [
    "model.safetensors"
  ],
  "vwxyzjn/train_sft_accelerate_summarize__tldr__seed1402__1697168345": [
    "model.safetensors"
  ],
  "vwxyzjn/train_sft_accelerate_summarize__tldr__seed1404__1697168449": [
    "model.safetensors"
  ],
  "vwxyzjn/train_sft_accelerate_summarize__tldr__seed1403__1697168471": [
    "model.safetensors"
  ],
  "vwxyzjn/train_sft_accelerate_summarize__tldr__seed1302__1697169015": [
    "model.safetensors"
  ],
  "vwxyzjn/train_sft_accelerate_summarize__tldr__seed1301__1697169023": [
    "model.safetensors"
  ],
  "vwxyzjn/train_sft_accelerate_summarize__tldr__seed1304__1697169024": [
    "model.safetensors"
  ],
  "vwxyzjn/train_sft_accelerate_summarize__tldr__seed1303__1697169064": [
    "model.safetensors"
  ],
  "vwxyzjn/train_sft_accelerate_summarize__tldr__seed1300__1697169266": [
    "model.safetensors"
  ],
  "vwxyzjn/train_sft_accelerate_summarize__tldr__seed1201__1697170415": [
    "model.safetensors"
  ],
  "vwxyzjn/train_sft_accelerate_summarize__tldr__seed1200__1697170464": [
    "model.safetensors"
  ],
  "vwxyzjn/train_sft_accelerate_summarize__tldr__seed1202__1697170473": [
    "model.safetensors"
  ],
  "vwxyzjn/train_sft_accelerate_summarize__tldr__seed1204__1697170542": [
    "model.safetensors"
  ],
  "vwxyzjn/train_sft_accelerate_summarize__tldr__seed1203__1697170797": [
    "model.safetensors"
  ],
  "uukuguy/speechless-mistral-dolphin-orca-platypus-samantha-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "IHaBiS/Mistral-11B-OmniMix-bf16-4.125bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "TheBloke/speechless-code-mistral-7B-v1.0-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/speechless-code-mistral-7B-v1.0-GPTQ": [
    "model.safetensors"
  ],
  "Vishal24/brand_mapping": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "yentinglin/Taiwan-LLM-13B-v2.0-base": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/CollectiveCognition-v1-Mistral-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/CollectiveCognition-v1-Mistral-7B-GPTQ": [
    "model.safetensors"
  ],
  "IHaBiS/Mistral-11B-OmniMix-bf16-6bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "TheBloke/speechless-codellama-34b-v2.0-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/speechless-tora-code-7B-v1.0-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/speechless-tora-code-7B-v1.0-GPTQ": [
    "model.safetensors"
  ],
  "nitinbhayana/Llama-2-7b-chat-hf-review-phrases-sentiments-v2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "IHaBiS/Mistral-11B-OmniMix-bf16-8bpw-h8-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "IHaBiS/PsyMedRP-v1-13B-6bpw-h8-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "IHaBiS/PsyMedRP-v1-13B-4.125bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Severian/ANIMA-Phi-Neptune-Mistral-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/speechless-codellama-34b-v2.0-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Severian/ANIMA-Phi-Neptune-Mistral-7B-AWQ": [
    "model.safetensors"
  ],
  "IHaBiS/PetrolLM-CollectiveCognition-4.125bpw-h8-exl2": [
    "output.safetensors"
  ],
  "IHaBiS/PetrolLM-CollectiveCognition-6bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "typeof/idefics-9b": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "typeof/Mistral-7B-v0.1-GPTQ": [
    "model.safetensors"
  ],
  "NeverSleep/Mistral-11B-AirOmniMix": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/OpenHermes-2-Mistral-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/OpenHermes-2-Mistral-7B-GPTQ": [
    "model.safetensors"
  ],
  "surathisin/nvso-model-test-1": [],
  "anakin87/zephyr-7b-alpha-sharded": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "NeverSleep/Mistral-11B-SynthIAirOmniMix": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/ShiningValiant-1.2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/ShiningValiant-1.2-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/SauerkrautLM-13B-v1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/SauerkrautLM-13B-v1-AWQ": [
    "model.safetensors"
  ],
  "AchyuthGamer/OpenGPT-7b-0.1": [
    "model.safetensors"
  ],
  "TheBloke/ALMA-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/ALMA-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/ALMA-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/ALMA-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/tora-13B-v1.0-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/tora-13B-v1.0-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/tora-70B-v1.0-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/tora-70B-v1.0-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/SauerkrautLM-7B-v1-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/SauerkrautLM-7B-v1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/SauerkrautLM-3B-v1-GPTQ": [
    "model.safetensors"
  ],
  "Undi95/Xwin-MLewd-13B-V0.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/SauerkrautLM-7B-v1-mistral-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/SauerkrautLM-7B-v1-mistral-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/genz-13B-v2-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/genz-13B-v2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/tora-7B-v1.0-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/tora-7B-v1.0-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Mistral-11B-CC-Air-RP-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Mistral-11B-CC-Air-RP-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/tora-code-13B-v1.0-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/tora-code-13B-v1.0-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/tora-code-34b-v1.0-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/tora-code-34b-v1.0-GPTQ": [
    "model.safetensors"
  ],
  "uukuguy/speechless-mistral-six-in-one-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Xwin-LM-13B-v0.2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Xwin-LM-13B-v0.2-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/tora-code-7B-v1.0-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/tora-code-7B-v1.0-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/StellarBright-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/StellarBright-GPTQ": [
    "model.safetensors"
  ],
  "LoneStriker/Mistral-11B-CC-Air-8.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/Mistral-11B-CC-Air-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Mistral-11B-CC-Air-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Mistral-11B-CC-Air-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Mistral-11B-CC-Air-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "PocketDoc/Dans-AdventurousWinds-Mk2-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Xwin-MLewd-13B-v0.2-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Xwin-MLewd-13B-v0.2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/airoboros-l2-13B-3.1-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/airoboros-l2-13B-3.1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/LongAlpaca-70B-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/LongAlpaca-70B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/llava-v1.5-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/llava-v1.5-13B-GPTQ": [
    "model.safetensors"
  ],
  "BobaZooba/WGPT-LoRA": [
    "adapter_model.safetensors",
    "last-checkpoint/adapter_model.safetensors"
  ],
  "IHaBiS/Synatra-11B-Testbench-8bpw-h8-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "blueapple8259/TinyStories-Alpaca": [
    "model.safetensors"
  ],
  "IHaBiS/Synatra-11B-Testbench-6.125bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "IHaBiS/Synatra-11B-Testbench-4.125bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "BobaZooba/WGPT": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "team-lucid/llama-ko-1b": [
    "model.safetensors"
  ],
  "TheBloke/SynthIA-7B-v1.5-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/SynthIA-7B-v1.5-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Airoboros-M-7B-3.1-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Airoboros-M-7B-3.1-GPTQ": [
    "model.safetensors"
  ],
  "IHaBiS/Mistral-11B-SynthIAirOmniMix-8bpw-h8-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/airoboros-m-7b-3.1-8.0bpw-h6-exl2": [
    "cal_data.safetensors",
    "input_states.safetensors",
    "output.safetensors"
  ],
  "TheBloke/Mistral-11B-OmniMix-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Mistral-11B-OmniMix-AWQ": [
    "model.safetensors"
  ],
  "IHaBiS/Mistral-11B-SynthIAirOmniMix-6.125bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "IHaBiS/Mistral-11B-SynthIAirOmniMix-4.125bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/airoboros-m-7b-3.1-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/airoboros-m-7b-3.1-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/airoboros-m-7b-3.1-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/airoboros-m-7b-3.1-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "MB7977/Llama-Chat-70b-5.0bpw-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "zeio/wit": [
    "model.safetensors"
  ],
  "maywell/Synatra-11B-Tb2M_SM": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "whatdhack/Llama-2-7b-chat-hf-oasst1-ft-sg": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "stabilityai/japanese-stablelm-3b-4e1t-base": [
    "model.safetensors"
  ],
  "demo-leaderboard/gpt2-demo": [
    "model.safetensors"
  ],
  "crodri/falcon_aguila_meteocatv2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "WGNW/psymon-KoLlama2-7b-auto-gptq-4bit": [
    "model.safetensors"
  ],
  "stabilityai/japanese-stablelm-3b-4e1t-instruct": [
    "model.safetensors"
  ],
  "stabilityai/japanese-stablelm-base-gamma-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "THUDM/agentlm-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "stabilityai/japanese-stablelm-instruct-gamma-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/openbuddy-mistral-7B-v13-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/openbuddy-mistral-7B-v13-GPTQ": [
    "model.safetensors"
  ],
  "maywell/Synatra_TbST02M_IN01": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "maywell/Synatra_TbIN01M_ST02": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/openbuddy-llama2-70B-v13-base-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/openbuddy-llama2-70B-v13-base-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/openbuddy-mistral-7B-v13-base-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/openbuddy-mistral-7B-v13-base-GPTQ": [
    "model.safetensors"
  ],
  "TheArchitectX/Mistral1": [
    "model.safetensors"
  ],
  "TheBloke/Airoboros-L2-70B-3.1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Airoboros-L2-70B-3.1-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "Nondzu/Mistral-7B-code-16k-qlora": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Hudhayfah/TestRepo": [
    "model.safetensors"
  ],
  "TheBloke/Leo-Mistral-Hessianai-7B-Chat-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Leo-Mistral-Hessianai-7B-Chat-GPTQ": [
    "model.safetensors"
  ],
  "LoneStriker/airoboros-l2-70b-3.1-2.4bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "waraichinc/llama2-13b-finetuned": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "LoneStriker/airoboros-l2-70b-3.1-2.6bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "notpushkin/zephyr-chat": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "LoneStriker/airoboros-l2-70b-3.1-3.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "LoneStriker/airoboros-l2-70b-3.1-4.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "LoneStriker/airoboros-l2-70b-3.1-5.0bpw-h6-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "LoneStriker/airoboros-l2-70b-3.1-6.0bpw-h6-exl2": [
    "output-00001-of-00007.safetensors",
    "output-00002-of-00007.safetensors",
    "output-00003-of-00007.safetensors",
    "output-00004-of-00007.safetensors",
    "output-00005-of-00007.safetensors",
    "output-00006-of-00007.safetensors",
    "output-00007-of-00007.safetensors"
  ],
  "LoneStriker/airoboros-l2-70b-3.1-2.3bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "jmoney54378256438905/jondurbin_airoboros-l2-13b-3.1-5.25bpw": [
    "output.safetensors"
  ],
  "LoneStriker/airoboros-l2-70b-3.1-4.65bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "AzureBlack/airoboros-l2-70b-2.2.1-3bpw-6h-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "krevas/LDCC-Instruct-Llama-2-ko-13B-v4.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "krevas/LDCC-Instruct-Llama-2-ko-13B-v7": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Sao10K/HACM7-Mistral-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Sao10K/R17AST-Mistral-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "chargoddard/jade-scramble": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "chargoddard/stormy-village": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mangeshdiyewar/llama-7b-chat-v1.5-awq": [
    "model.safetensors"
  ],
  "jondurbin/airoboros-3b-3p11": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Mistral-7B-Code-16K-qlora-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Mistral-7B-Code-16K-qlora-GPTQ": [
    "model.safetensors"
  ],
  "sarahlintang/mistral-indo-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Airoboros-M-7B-3.1.1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Airoboros-M-7B-3.1.1-AWQ": [
    "model.safetensors"
  ],
  "shoppal/shoppal-v0.1-sf": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "TheBloke/Pandalyst-7B-v1.2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Pandalyst-7B-v1.2-AWQ": [
    "model.safetensors"
  ],
  "cenkersisman/chatbot-gpt2-turkish-128-token": [
    "model.safetensors"
  ],
  "PericlesSavio/llama2-13b-chat-hf-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/airoboros-m-7b-3.1.1-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/airoboros-m-7b-3.1.1-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/airoboros-m-7b-3.1.1-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/airoboros-m-7b-3.1.1-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/airoboros-m-7b-3.1.1-8.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "TheBloke/Thespis-13B-v0.3-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Thespis-13B-v0.3-GPTQ": [
    "model.safetensors"
  ],
  "jondurbin/airoboros-l2-13b-3.1.1": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "TheBloke/Mistral-7B-Phibrarian-32K-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Mistral-7B-Phibrarian-32K-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/llemma_7b-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/llemma_7b-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/llemma_34b-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/llemma_34b-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheArchitectX/SHLa1": [
    "model.safetensors"
  ],
  "TheArchitectX/SHLa2": [
    "model.safetensors"
  ],
  "adept/fuyu-8b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mdouglas/guanamyra-small": [
    "model.safetensors"
  ],
  "rider61/gpt2-wikitext2": [
    "model.safetensors"
  ],
  "krevas/LDCC-Instruct-Llama-2-ko-13B-v4.1.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "haqishen/ds-2gpu": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "waldie/airoboros-l2-13b-3.1.1-8bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "TheBloke/Dans-AdventurousWinds-Mk2-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Dans-AdventurousWinds-Mk2-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Euryale-1.3-L2-70B-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Euryale-1.3-L2-70B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/rpguild-chatml-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/rpguild-chatml-13B-GPTQ": [
    "model.safetensors"
  ],
  "mangeshdiyewar/zephyr-7b-alpha-awq": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "PericlesSavio/Llama-2-7b-chat-hf-finetuned": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "waldie/Dans-AdventurousWinds-Mk2-7b-8bpw-h8-exl2": [
    "output.safetensors"
  ],
  "TheBloke/Airoboros-L2-13B-3.1.1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Airoboros-L2-13B-3.1.1-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Xwin-LM-7B-V0.2-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Xwin-LM-7B-V0.2-GPTQ": [
    "model.safetensors"
  ],
  "waldie/Euryale-1.3-L2-70B-2.18bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "Chat-Error/Summit": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/PsyMedRP-v1-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/PsyMedRP-v1-13B-AWQ": [
    "model.safetensors"
  ],
  "igig98/ppo_test": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AgentPublic/albert-light": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LemTenku/7BMR": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Dans-AdventurousWinds-Mk2-7b-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Dans-AdventurousWinds-Mk2-7b-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Dans-AdventurousWinds-Mk2-7b-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Dans-AdventurousWinds-Mk2-7b-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Dans-AdventurousWinds-Mk2-7b-8.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "TheBloke/SlimOpenOrca-Mistral-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/SlimOpenOrca-Mistral-7B-AWQ": [
    "model.safetensors"
  ],
  "IHaBiS/StellarBright-2.55bpw-h8-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "ashwincv0112/codellama-python7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "AzureBlack/Euryale-1.3-L2-70B-4.6bpw-6h-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "LumiOpen/Poro-34B": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "zhangchuheng123/llama2-alpaca-sft-2epoch": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "waldie/Athena-v4-3bpw-h6-exl2": [
    "output.safetensors"
  ],
  "TheBloke/MistralLite-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/MistralLite-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Mistral-Pygmalion-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Mistral-Pygmalion-7B-AWQ": [
    "model.safetensors"
  ],
  "latimar/Phind-Codellama-34B-v2-megacode-exl2": [
    "2.55/output-00001-of-00002.safetensors",
    "2.55/output-00002-of-00002.safetensors",
    "2.8/output-00001-of-00002.safetensors",
    "2.8/output-00002-of-00002.safetensors",
    "3.0/output-00001-of-00002.safetensors",
    "3.0/output-00002-of-00002.safetensors",
    "4.625/output-00001-of-00003.safetensors",
    "4.625/output-00002-of-00003.safetensors",
    "4.625/output-00003-of-00003.safetensors",
    "4.8/output-00001-of-00003.safetensors",
    "4.8/output-00002-of-00003.safetensors",
    "4.8/output-00003-of-00003.safetensors"
  ],
  "Btechproject/git-base-pokemon": [
    "model.safetensors"
  ],
  "nakhyeon/llama-2-ko-qlora4": [
    "adapter_model.safetensors"
  ],
  "waldie/Athena-v4-6bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "jondurbin/airoboros-m-7b-3.1.2": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "ybelkada/fuyu-8b-sharded": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "TheBloke/Airoboros-M-7B-3.1.2-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Airoboros-M-7B-3.1.2-GPTQ": [
    "model.safetensors"
  ],
  "LoneStriker/airoboros-m-7b-3.1.2-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/airoboros-m-7b-3.1.2-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/airoboros-m-7b-3.1.2-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/airoboros-m-7b-3.1.2-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/airoboros-m-7b-3.1.2-8.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "KoboldAI/LLaMA2-13B-Tiefighter-GPTQ": [
    "model.safetensors"
  ],
  "waldie/LLaMA2-13B-Tiefighter-8bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "h2oai/h2ogpt-32k-codellama-34b-instruct": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "aloobun/TinyAiroboros-2.2.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "AzureBlack/Athena-v1-13b-5bpw-6h-exl2": [
    "output.safetensors"
  ],
  "AzureBlack/Xwin-MLewd-13B-V0.2-5bpw-6h-exl2": [
    "output.safetensors"
  ],
  "oobabooga/CodeBooga-34B-v0.1": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "krevas/LDCC-Instruct-Llama-2-ko-13B-v4.1.12": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "flozi00/Mistral-7B-german-assistant-v3": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "krevas/LDCC-Instruct-Llama-2-ko-13B-v4.1.8": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AzureBlack/Thespis-13b-v0.3-5bpw-6h-exl2": [
    "output.safetensors"
  ],
  "BEE-spoke-data/verysmol_llama-v11-KIx2": [
    "model.safetensors"
  ],
  "kuenlong/ft-test-01": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "kuenlong/ft-test-02": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jojo0217/SFT_12.8B_mk2_v2": [
    "model-00001-of-00028.safetensors",
    "model-00002-of-00028.safetensors",
    "model-00003-of-00028.safetensors",
    "model-00004-of-00028.safetensors",
    "model-00005-of-00028.safetensors",
    "model-00006-of-00028.safetensors",
    "model-00007-of-00028.safetensors",
    "model-00008-of-00028.safetensors",
    "model-00009-of-00028.safetensors",
    "model-00010-of-00028.safetensors",
    "model-00011-of-00028.safetensors",
    "model-00012-of-00028.safetensors",
    "model-00013-of-00028.safetensors",
    "model-00014-of-00028.safetensors",
    "model-00015-of-00028.safetensors",
    "model-00016-of-00028.safetensors",
    "model-00017-of-00028.safetensors",
    "model-00018-of-00028.safetensors",
    "model-00019-of-00028.safetensors",
    "model-00020-of-00028.safetensors",
    "model-00021-of-00028.safetensors",
    "model-00022-of-00028.safetensors",
    "model-00023-of-00028.safetensors",
    "model-00024-of-00028.safetensors",
    "model-00025-of-00028.safetensors",
    "model-00026-of-00028.safetensors",
    "model-00027-of-00028.safetensors",
    "model-00028-of-00028.safetensors"
  ],
  "jondurbin/airoboros-c34b-3.1.2": [
    "model-00001-of-00018.safetensors",
    "model-00002-of-00018.safetensors",
    "model-00003-of-00018.safetensors",
    "model-00004-of-00018.safetensors",
    "model-00005-of-00018.safetensors",
    "model-00006-of-00018.safetensors",
    "model-00007-of-00018.safetensors",
    "model-00008-of-00018.safetensors",
    "model-00009-of-00018.safetensors",
    "model-00010-of-00018.safetensors",
    "model-00011-of-00018.safetensors",
    "model-00012-of-00018.safetensors",
    "model-00013-of-00018.safetensors",
    "model-00014-of-00018.safetensors",
    "model-00015-of-00018.safetensors",
    "model-00016-of-00018.safetensors",
    "model-00017-of-00018.safetensors",
    "model-00018-of-00018.safetensors"
  ],
  "TheBloke/Arithmo-Mistral-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Arithmo-Mistral-7B-AWQ": [
    "model.safetensors"
  ],
  "NousResearch/Nous-Capybara-3B-V1.9": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mo137/Amethyst-13B-Mistral-8bpw-hb8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/airoboros-c34b-3.1.2-3.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/airoboros-c34b-3.1.2-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/airoboros-c34b-3.1.2-5.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "mo137/Amethyst-13B-Mistral-2.2bpw-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/airoboros-c34b-3.1.2-6.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "mo137/Amethyst-13B-Mistral-3bpw-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/airoboros-c34b-3.1.2-8.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "mo137/Amethyst-13B-Mistral-6bpw-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "jmoney54378256438905/jondurbin_airoboros-c34b-3.1.2-5.25bpw": [
    "output.safetensors"
  ],
  "jmoney54378256438905/jondurbin_airoboros-c34b-3.1.2-4.65bpw": [
    "output.safetensors"
  ],
  "TheBloke/agentlm-70B-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/agentlm-70B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/agentlm-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/agentlm-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/CodeBooga-34B-v0.1-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/CodeBooga-34B-v0.1-GPTQ": [
    "model.safetensors"
  ],
  "MB7977/LongAlpaca-70B-32K-4.25bpw-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "CyberRift/sidekick": [
    "model.safetensors"
  ],
  "TheBloke/vicuna-33B-coder-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/vicuna-33B-coder-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/agentlm-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/agentlm-7B-AWQ": [
    "model.safetensors"
  ],
  "krevas/LDCC-Instruct-Llama-2-ko-13B-v4.1.14": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/MistralMakise-Merged-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/MistralMakise-Merged-13B-GPTQ": [
    "model.safetensors"
  ],
  "stockmark/stockmark-13b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jondurbin/airoboros-l2-70b-3.1.2": [
    "model-00001-of-00036.safetensors",
    "model-00002-of-00036.safetensors",
    "model-00003-of-00036.safetensors",
    "model-00004-of-00036.safetensors",
    "model-00005-of-00036.safetensors",
    "model-00006-of-00036.safetensors",
    "model-00007-of-00036.safetensors",
    "model-00008-of-00036.safetensors",
    "model-00009-of-00036.safetensors",
    "model-00010-of-00036.safetensors",
    "model-00011-of-00036.safetensors",
    "model-00012-of-00036.safetensors",
    "model-00013-of-00036.safetensors",
    "model-00014-of-00036.safetensors",
    "model-00015-of-00036.safetensors",
    "model-00016-of-00036.safetensors",
    "model-00017-of-00036.safetensors",
    "model-00018-of-00036.safetensors",
    "model-00019-of-00036.safetensors",
    "model-00020-of-00036.safetensors",
    "model-00021-of-00036.safetensors",
    "model-00022-of-00036.safetensors",
    "model-00023-of-00036.safetensors",
    "model-00024-of-00036.safetensors",
    "model-00025-of-00036.safetensors",
    "model-00026-of-00036.safetensors",
    "model-00027-of-00036.safetensors",
    "model-00028-of-00036.safetensors",
    "model-00029-of-00036.safetensors",
    "model-00030-of-00036.safetensors",
    "model-00031-of-00036.safetensors",
    "model-00032-of-00036.safetensors",
    "model-00033-of-00036.safetensors",
    "model-00034-of-00036.safetensors",
    "model-00035-of-00036.safetensors",
    "model-00036-of-00036.safetensors"
  ],
  "TheBloke/MLewdBoros-LRPSGPT-2Char-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/MLewdBoros-LRPSGPT-2Char-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Airoboros-L2-70B-3.1.2-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Airoboros-L2-70B-3.1.2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Airoboros-c34B-3.1.2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Airoboros-c34B-3.1.2-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/airoboros-l2-70b-3.1.2-2.4bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "Sao10K/Stheno-1.10-L2-13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Sao10K/SthenoWriter2.1-L2-13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/airoboros-l2-70b-3.1.2-4.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "LoneStriker/airoboros-l2-70b-3.1.2-4.65bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "Rexe/Faradaylab-aria-mistral-merge": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/airoboros-l2-70b-3.1.2-5.0bpw-h6-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "LoneStriker/airoboros-l2-70b-3.1.2-3.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "vwxyzjn/train_sft_accelerate_summarize__tldr__seed1__1697905371": [
    "model.safetensors"
  ],
  "vwxyzjn/train_sft_accelerate_summarize__tldr__seed1__1697905931": [
    "model.safetensors"
  ],
  "protocol139/distilgpt2-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "LoneStriker/airoboros-l2-70b-3.1.2-2.6bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/airoboros-l2-70b-3.1.2-6.0bpw-h6-exl2": [
    "output-00001-of-00007.safetensors",
    "output-00002-of-00007.safetensors",
    "output-00003-of-00007.safetensors",
    "output-00004-of-00007.safetensors",
    "output-00005-of-00007.safetensors",
    "output-00006-of-00007.safetensors",
    "output-00007-of-00007.safetensors"
  ],
  "MaxZabarka/classifier-7b-quantized": [
    "model.safetensors"
  ],
  "LemTenku/egi": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaxZabarka/classifier-7b-v3-quantized": [
    "model.safetensors"
  ],
  "JNewber/flute": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaxZabarka/classifier-7b-v4-quantized": [
    "model.safetensors"
  ],
  "MaxZabarka/classifier-7b-v5-quantized": [
    "model.safetensors"
  ],
  "NeverSleep/Echidna-13b-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaxZabarka/classifier-7b-v6-quantized": [
    "model.safetensors"
  ],
  "Jacobhe/llama2-wwf": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "NeverSleep/HornyEchidna-13b-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mesolitica/malaysian-mistral-191M-4096": [
    "model.safetensors"
  ],
  "TheBloke/LLaMA2-13B-Tiefighter-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/LLaMA2-13B-Tiefighter-GPTQ": [
    "model.safetensors"
  ],
  "GAIR/autoj-13b-GPTQ-4bits": [
    "model.safetensors"
  ],
  "Setiaku/p2tr1-13b-l2-fp16": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AzureBlack/PsyMedRP-v1-20B-8bpw-8h-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "AzureBlack/HornyEchidna-13b-v0.1-8bpw-8h-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "AzureBlack/NeverSleep_Echidna-13b-v0.1-8bpw-8h-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "TheBloke/CausalLM-14B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/CausalLM-14B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/CausalLM-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/CausalLM-7B-GPTQ": [
    "model.safetensors"
  ],
  "AzureBlack/Thespis-13b-v0.4-8bpw-8h-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "TheBloke/Thespis-13B-v0.4-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Thespis-13B-v0.4-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Mistral-7B-SciPhi-32k-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Mistral-7B-SciPhi-32k-AWQ": [
    "model.safetensors"
  ],
  "MaxZabarka/classifier-70b-v7-quantized-rename": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/SynthIA-7B-v2.0-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/SynthIA-7B-v2.0-AWQ": [
    "model.safetensors"
  ],
  "Kooten/Echidna-13b-v0.1-8bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Kooten/HornyEchidna-13b-v0.1-8bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LogitsAI/Llama-2-70b-chat-hf": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "Kooten/Echidna-13b-v0.1-3bpw-h8-exl2": [
    "output.safetensors"
  ],
  "AgentPublic/fabrique-reference-2.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaxZabarka/classifier-7b-v8-quantized": [
    "model.safetensors"
  ],
  "quissuiven/llama-2-7b-bysjobdesc-v3": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "mesolitica/malaysian-mistral-349M-4096": [
    "model.safetensors"
  ],
  "Kooten/HornyEchidna-13b-v0.1-3bpw-h8-exl2": [
    "output.safetensors"
  ],
  "sachith-surge/open-llama-v2-lamini-orca-evol-qlora-checkpoint-safetensors": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mo137/Amethyst-13B-Mistral-2.7bpw-exl2": [
    "output.safetensors"
  ],
  "mo137/Amethyst-13B-Mistral-2.5bpw-exl2": [
    "output.safetensors"
  ],
  "mo137/Amethyst-13B-Mistral-4bpw-exl2": [
    "output.safetensors"
  ],
  "dinoelT/llama2-7b-german-extraction-v1-awq": [
    "model.safetensors"
  ],
  "Safurai/Safurai-Csharp-34B-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "waraichinc/llama2-13b-chat-finetuned": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "Pclanglais/BraheTime": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mrm8488/mistral-7b-ft-AgentInstruct": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaxZabarka/classifier-7b-v9-quantized": [
    "model.safetensors"
  ],
  "yashsharma0906/Llama-2-7b-SHP-SFT": [
    "adapter_model.safetensors"
  ],
  "imiraoui/OpenHermes-2.5-Mistral-7B-sharded": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "jeff31415/TinyLlama-1.1B-1.5T-OpenOrca-Alpha": [
    "model.safetensors"
  ],
  "aisingapore/sealion3b": [
    "model.safetensors"
  ],
  "cldersaienril/Instameta-Mistral-v0.1-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Setiaku/l2-13b-thespurral-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Sao10K/Stheno-1.11v2-13B-L2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "asprenger/meta-llama-Llama-2-7b-chat-hf-gemm-w4-g128-awq": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ybelkada/test-mistral-7b-v0.1-awq": [
    "model.safetensors"
  ],
  "Weni/WeniGPT-L-70-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "youssed/llm-hub": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/HornyEchidna-13B-v0.1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/HornyEchidna-13B-v0.1-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Vigostral-7B-Chat-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Vigostral-7B-Chat-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Augmental-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Augmental-13B-GPTQ": [
    "model.safetensors"
  ],
  "LoneStriker/ShiningValiant-2.4bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/ShiningValiant-4.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "LoneStriker/ShiningValiant-4.65bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "AzureBlack/Nete-13B-ALPHA-8bpw-8h-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/ShiningValiant-5.0bpw-h6-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "AzureBlack/Augmental-13b-8bpw-8h-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/ShiningValiant-3.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "Doctor-Shotgun/Euryale-1.3-limarpv3-L2-70B": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "LoneStriker/ShiningValiant-2.6bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/ShiningValiant-6.0bpw-h6-exl2": [
    "output-00001-of-00007.safetensors",
    "output-00002-of-00007.safetensors",
    "output-00003-of-00007.safetensors",
    "output-00004-of-00007.safetensors",
    "output-00005-of-00007.safetensors",
    "output-00006-of-00007.safetensors",
    "output-00007-of-00007.safetensors"
  ],
  "jmoney54378256438905/Doctor-Shotgun_mythospice-limarp-70b-5.25bpw": [
    "output.safetensors"
  ],
  "Nondzu/Mistral-7B-codealpaca-lora": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mickume/harry_potter_tiny_mistral_7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "k3sh4v/Llama-2-7b-chat-hf-NoAccelerate-sharded-f16-500MB": [
    "model-00001-of-00028.safetensors",
    "model-00002-of-00028.safetensors",
    "model-00003-of-00028.safetensors",
    "model-00004-of-00028.safetensors",
    "model-00005-of-00028.safetensors",
    "model-00006-of-00028.safetensors",
    "model-00007-of-00028.safetensors",
    "model-00008-of-00028.safetensors",
    "model-00009-of-00028.safetensors",
    "model-00010-of-00028.safetensors",
    "model-00011-of-00028.safetensors",
    "model-00012-of-00028.safetensors",
    "model-00013-of-00028.safetensors",
    "model-00014-of-00028.safetensors",
    "model-00015-of-00028.safetensors",
    "model-00016-of-00028.safetensors",
    "model-00017-of-00028.safetensors",
    "model-00018-of-00028.safetensors",
    "model-00019-of-00028.safetensors",
    "model-00020-of-00028.safetensors",
    "model-00021-of-00028.safetensors",
    "model-00022-of-00028.safetensors",
    "model-00023-of-00028.safetensors",
    "model-00024-of-00028.safetensors",
    "model-00025-of-00028.safetensors",
    "model-00026-of-00028.safetensors",
    "model-00027-of-00028.safetensors",
    "model-00028-of-00028.safetensors"
  ],
  "ohashi56225/antor-full_bert_nlu-no_noise": [
    "model.safetensors"
  ],
  "nakhyeonn/llama-2-ko-qlora-prompt_1024": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mickume/alt_potterverse_mistral_7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jmoney54378256438905/lizpreciatior_lzlv_70b_exl2-5.25bpw": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "kittn/prometheus-13b-v1.0": [
    "model.bf16-00001-of-00013.safetensors",
    "model.bf16-00002-of-00013.safetensors",
    "model.bf16-00003-of-00013.safetensors",
    "model.bf16-00004-of-00013.safetensors",
    "model.bf16-00005-of-00013.safetensors",
    "model.bf16-00006-of-00013.safetensors",
    "model.bf16-00007-of-00013.safetensors",
    "model.bf16-00008-of-00013.safetensors",
    "model.bf16-00009-of-00013.safetensors",
    "model.bf16-00010-of-00013.safetensors",
    "model.bf16-00011-of-00013.safetensors",
    "model.bf16-00012-of-00013.safetensors",
    "model.bf16-00013-of-00013.safetensors",
    "model.fp16-00001-of-00013.safetensors",
    "model.fp16-00002-of-00013.safetensors",
    "model.fp16-00003-of-00013.safetensors",
    "model.fp16-00004-of-00013.safetensors",
    "model.fp16-00005-of-00013.safetensors",
    "model.fp16-00006-of-00013.safetensors",
    "model.fp16-00007-of-00013.safetensors",
    "model.fp16-00008-of-00013.safetensors",
    "model.fp16-00009-of-00013.safetensors",
    "model.fp16-00010-of-00013.safetensors",
    "model.fp16-00011-of-00013.safetensors",
    "model.fp16-00012-of-00013.safetensors",
    "model.fp16-00013-of-00013.safetensors"
  ],
  "nicholasKluge/Aira-OPT-125M": [
    "model.safetensors"
  ],
  "krevas/LDCC-Instruct-Llama-2-ko-13B-v4.2.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "marcsun13/Llama-2-13B-AWQ": [
    "model.safetensors"
  ],
  "jondurbin/airoboros-180b-2.2.1": [
    "model-00001-of-00107.safetensors",
    "model-00002-of-00107.safetensors",
    "model-00003-of-00107.safetensors",
    "model-00004-of-00107.safetensors",
    "model-00005-of-00107.safetensors",
    "model-00006-of-00107.safetensors",
    "model-00007-of-00107.safetensors",
    "model-00008-of-00107.safetensors",
    "model-00009-of-00107.safetensors",
    "model-00010-of-00107.safetensors",
    "model-00011-of-00107.safetensors",
    "model-00012-of-00107.safetensors",
    "model-00013-of-00107.safetensors",
    "model-00014-of-00107.safetensors",
    "model-00015-of-00107.safetensors",
    "model-00016-of-00107.safetensors",
    "model-00017-of-00107.safetensors",
    "model-00018-of-00107.safetensors",
    "model-00019-of-00107.safetensors",
    "model-00020-of-00107.safetensors",
    "model-00021-of-00107.safetensors",
    "model-00022-of-00107.safetensors",
    "model-00023-of-00107.safetensors",
    "model-00024-of-00107.safetensors",
    "model-00025-of-00107.safetensors",
    "model-00026-of-00107.safetensors",
    "model-00027-of-00107.safetensors",
    "model-00028-of-00107.safetensors",
    "model-00029-of-00107.safetensors",
    "model-00030-of-00107.safetensors",
    "model-00031-of-00107.safetensors",
    "model-00032-of-00107.safetensors",
    "model-00033-of-00107.safetensors",
    "model-00034-of-00107.safetensors",
    "model-00035-of-00107.safetensors",
    "model-00036-of-00107.safetensors",
    "model-00037-of-00107.safetensors",
    "model-00038-of-00107.safetensors",
    "model-00039-of-00107.safetensors",
    "model-00040-of-00107.safetensors",
    "model-00041-of-00107.safetensors",
    "model-00042-of-00107.safetensors",
    "model-00043-of-00107.safetensors",
    "model-00044-of-00107.safetensors",
    "model-00045-of-00107.safetensors",
    "model-00046-of-00107.safetensors",
    "model-00047-of-00107.safetensors",
    "model-00048-of-00107.safetensors",
    "model-00049-of-00107.safetensors",
    "model-00050-of-00107.safetensors",
    "model-00051-of-00107.safetensors",
    "model-00052-of-00107.safetensors",
    "model-00053-of-00107.safetensors",
    "model-00054-of-00107.safetensors",
    "model-00055-of-00107.safetensors",
    "model-00056-of-00107.safetensors",
    "model-00057-of-00107.safetensors",
    "model-00058-of-00107.safetensors",
    "model-00059-of-00107.safetensors",
    "model-00060-of-00107.safetensors",
    "model-00061-of-00107.safetensors",
    "model-00062-of-00107.safetensors",
    "model-00063-of-00107.safetensors",
    "model-00064-of-00107.safetensors",
    "model-00065-of-00107.safetensors",
    "model-00066-of-00107.safetensors",
    "model-00067-of-00107.safetensors",
    "model-00068-of-00107.safetensors",
    "model-00069-of-00107.safetensors",
    "model-00070-of-00107.safetensors",
    "model-00071-of-00107.safetensors",
    "model-00072-of-00107.safetensors",
    "model-00073-of-00107.safetensors",
    "model-00074-of-00107.safetensors",
    "model-00075-of-00107.safetensors",
    "model-00076-of-00107.safetensors",
    "model-00077-of-00107.safetensors",
    "model-00078-of-00107.safetensors",
    "model-00079-of-00107.safetensors",
    "model-00080-of-00107.safetensors",
    "model-00081-of-00107.safetensors",
    "model-00082-of-00107.safetensors",
    "model-00083-of-00107.safetensors",
    "model-00084-of-00107.safetensors",
    "model-00085-of-00107.safetensors",
    "model-00086-of-00107.safetensors",
    "model-00087-of-00107.safetensors",
    "model-00088-of-00107.safetensors",
    "model-00089-of-00107.safetensors",
    "model-00090-of-00107.safetensors",
    "model-00091-of-00107.safetensors",
    "model-00092-of-00107.safetensors",
    "model-00093-of-00107.safetensors",
    "model-00094-of-00107.safetensors",
    "model-00095-of-00107.safetensors",
    "model-00096-of-00107.safetensors",
    "model-00097-of-00107.safetensors",
    "model-00098-of-00107.safetensors",
    "model-00099-of-00107.safetensors",
    "model-00100-of-00107.safetensors",
    "model-00101-of-00107.safetensors",
    "model-00102-of-00107.safetensors",
    "model-00103-of-00107.safetensors",
    "model-00104-of-00107.safetensors",
    "model-00105-of-00107.safetensors",
    "model-00106-of-00107.safetensors",
    "model-00107-of-00107.safetensors"
  ],
  "AzureBlack/dolphin-2.1-70b-4.6bpw-8h-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "ahmedelhlwgy99/dolphin-2.1-mistral-7b-safetensors": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "GusPuffy/Mythomax-L2-13B-8bit-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "abhayzala/vpeval-program-generation-llama-2-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "josem7/SQL-SURI-13B-v0.2_AWQ": [
    "model.safetensors"
  ],
  "gradientai/gradient-tinystories-15m": [
    "model.safetensors"
  ],
  "MeoChrist/YA": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Dolphin-2.1-70B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Dolphin-2.1-70B-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "ahmedelhlwgy99/jais-13b-chat-safetensors": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "josem7/SCHEMA_LINK-SURI-13B-v0.2_AWQ": [
    "model.safetensors"
  ],
  "MaxZabarka/classifier-7b-v10-quantized": [
    "model.safetensors"
  ],
  "TheBloke/Cat-13B-0.5-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Cat-13B-0.5-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/lzlv_70B-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/lzlv_70B-GPTQ": [
    "model.safetensors"
  ],
  "Bsbell21/GenerAd-AI": [
    "adapter_model.safetensors"
  ],
  "pfnet/plamo-13b-instruct": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/SynthIA-70B-v1.5-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/SynthIA-70B-v1.5-GPTQ": [
    "model.safetensors"
  ],
  "promptora11/zeyphyr": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "mostafaamiri/persian_llama_7b": [
    "base_model/model-00001-of-00002.safetensors",
    "base_model/model-00002-of-00002.safetensors"
  ],
  "pfnet/plamo-13b-instruct-nc": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "flozi00/Mistral-7B-german-assistant-v4": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Doctor-Shotgun/lzlv-limarpv3-l2-70b": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "BEE-spoke-data/smol_llama-101M-GQA": [
    "model.safetensors"
  ],
  "flozi00/Mistral-7B-german-assistant-v4-4bit-autogptq": [
    "model.safetensors"
  ],
  "BEE-spoke-data/smol_llama-81M-tied": [
    "model.safetensors"
  ],
  "MaxZabarka/classifier-7b-v11-quantized": [
    "model.safetensors"
  ],
  "szymonrucinski/Krakowiak-7B-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "zyh3826/llama2-13b-ft-openllm-leaderboard-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/lzlv_70b_fp16_hf-2.4bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/lzlv_70b_fp16_hf-4.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "krevas/LDCC-Instruct-Llama-2-ko-13B-v4.2.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/lzlv_70b_fp16_hf-4.65bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "HuggingFaceH4/zephyr-7b-beta": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "jondurbin/airoboros-l2-c70b-3.1.2": [
    "model-00001-of-00036.safetensors",
    "model-00002-of-00036.safetensors",
    "model-00003-of-00036.safetensors",
    "model-00004-of-00036.safetensors",
    "model-00005-of-00036.safetensors",
    "model-00006-of-00036.safetensors",
    "model-00007-of-00036.safetensors",
    "model-00008-of-00036.safetensors",
    "model-00009-of-00036.safetensors",
    "model-00010-of-00036.safetensors",
    "model-00011-of-00036.safetensors",
    "model-00012-of-00036.safetensors",
    "model-00013-of-00036.safetensors",
    "model-00014-of-00036.safetensors",
    "model-00015-of-00036.safetensors",
    "model-00016-of-00036.safetensors",
    "model-00017-of-00036.safetensors",
    "model-00018-of-00036.safetensors",
    "model-00019-of-00036.safetensors",
    "model-00020-of-00036.safetensors",
    "model-00021-of-00036.safetensors",
    "model-00022-of-00036.safetensors",
    "model-00023-of-00036.safetensors",
    "model-00024-of-00036.safetensors",
    "model-00025-of-00036.safetensors",
    "model-00026-of-00036.safetensors",
    "model-00027-of-00036.safetensors",
    "model-00028-of-00036.safetensors",
    "model-00029-of-00036.safetensors",
    "model-00030-of-00036.safetensors",
    "model-00031-of-00036.safetensors",
    "model-00032-of-00036.safetensors",
    "model-00033-of-00036.safetensors",
    "model-00034-of-00036.safetensors",
    "model-00035-of-00036.safetensors",
    "model-00036-of-00036.safetensors"
  ],
  "LoneStriker/lzlv_70b_fp16_hf-5.0bpw-h6-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "mmnga/stockmark-13b-AWQ-calib-ja": [
    "model.safetensors"
  ],
  "LoneStriker/lzlv_70b_fp16_hf-3.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "Eitanli/llama2-recipe-summary-final_merged_checkpoint": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/lzlv_70b_fp16_hf-2.6bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/lzlv_70b_fp16_hf-6.0bpw-h6-exl2": [
    "output-00001-of-00007.safetensors",
    "output-00002-of-00007.safetensors",
    "output-00003-of-00007.safetensors",
    "output-00004-of-00007.safetensors",
    "output-00005-of-00007.safetensors",
    "output-00006-of-00007.safetensors",
    "output-00007-of-00007.safetensors"
  ],
  "ycchen/qwen-14b-4bit": [
    "model.safetensors"
  ],
  "IlyasMoutawwakil/vicuna-7b-v1.5-awq-gemm": [
    "model.safetensors"
  ],
  "mickume/alt_manga_mistral_7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mmnga/japanese-stablelm-instruct-gamma-7b-AWQ-calib-ja-1k": [
    "model.safetensors"
  ],
  "RossAscends/Mistral7B_Dolphin2.1_LIMARP0.5_4bpw_exl2": [
    "output.safetensors"
  ],
  "Siddharthvij10/MistralSharded2": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Macky3/stack-llama-2-sft": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ZL92/my_awesome_eli5_clm-model": [
    "model.safetensors"
  ],
  "gradientai/gradient-tinystories-20m": [
    "model.safetensors"
  ],
  "AzureBlack/Nete-13B-8bpw-8h-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "AzureBlack/NeverSleep_Echidna-13b-v0.2-8bpw-8h-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "typeof/tiny-llama-1b-py": [
    "model.safetensors"
  ],
  "LoneStriker/airoboros-l2-c70b-3.1.2-2.4bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/airoboros-l2-c70b-3.1.2-4.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "FPHam/Free_Sydney_V2_13b_HF": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/airoboros-l2-c70b-3.1.2-4.65bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "LoneStriker/airoboros-l2-c70b-3.1.2-5.0bpw-h6-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "LoneStriker/airoboros-l2-c70b-3.1.2-3.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "mickume/alt_dnd_mistral_7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/airoboros-l2-c70b-3.1.2-2.6bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/airoboros-l2-c70b-3.1.2-6.0bpw-h6-exl2": [
    "output-00001-of-00007.safetensors",
    "output-00002-of-00007.safetensors",
    "output-00003-of-00007.safetensors",
    "output-00004-of-00007.safetensors",
    "output-00005-of-00007.safetensors",
    "output-00006-of-00007.safetensors",
    "output-00007-of-00007.safetensors"
  ],
  "L-R/LLmRa-1.3B_V2": [
    "model.safetensors"
  ],
  "jondurbin/airoboros-33b-3.1.2": [
    "model-00001-of-00017.safetensors",
    "model-00002-of-00017.safetensors",
    "model-00003-of-00017.safetensors",
    "model-00004-of-00017.safetensors",
    "model-00005-of-00017.safetensors",
    "model-00006-of-00017.safetensors",
    "model-00007-of-00017.safetensors",
    "model-00008-of-00017.safetensors",
    "model-00009-of-00017.safetensors",
    "model-00010-of-00017.safetensors",
    "model-00011-of-00017.safetensors",
    "model-00012-of-00017.safetensors",
    "model-00013-of-00017.safetensors",
    "model-00014-of-00017.safetensors",
    "model-00015-of-00017.safetensors",
    "model-00016-of-00017.safetensors",
    "model-00017-of-00017.safetensors"
  ],
  "sanghwa-na/llama2-13b.kor": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "waldie/Nete-13B-5bpw-h6-exl2": [
    "output.safetensors"
  ],
  "TheBloke/zephyr-7B-beta-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/zephyr-7B-beta-AWQ": [
    "model.safetensors"
  ],
  "waldie/MLewdBoros-LRPSGPT-2Char-13B-5bpw-h6-exl2": [
    "output.safetensors"
  ],
  "mmnga/japanese-stablelm-base-gamma-7b-AWQ-calib-ja-1k": [
    "model.safetensors"
  ],
  "LoneStriker/zephyr-7b-beta-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/zephyr-7b-beta-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/zephyr-7b-beta-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/zephyr-7b-beta-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/zephyr-7b-beta-8.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "RossAscends/Mistral_7B_Dolphin2.1_LIMA0.5_fp16": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "typeof/mistral-3.3B": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "iashchak/phi-v1.5-instructor": [
    "model.safetensors"
  ],
  "LoneStriker/CodeBooga-34B-v0.1-3.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/CodeBooga-34B-v0.1-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/CodeBooga-34B-v0.1-5.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "TheBloke/Nete-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Nete-13B-GPTQ": [
    "model.safetensors"
  ],
  "BEE-spoke-data/smol_llama-101M-GQA-python": [
    "model.safetensors"
  ],
  "LoneStriker/CodeBooga-34B-v0.1-8.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "TheBloke/AshhLimaRP-Mistral-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/AshhLimaRP-Mistral-7B-AWQ": [
    "model.safetensors"
  ],
  "jmoney54378256438905/jondurbin_airoboros-33b-3.1.2-5.25bpw": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "Undi95/Lewd-Sydney-20B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "TheBloke/MistRP-Airoboros-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/MistRP-Airoboros-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/med42-70B-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/med42-70B-GPTQ": [
    "model.safetensors"
  ],
  "Panchovix/airoboros-l2-70b-gpt4-1.4.1-limarpv3-qlora": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "jmoney54378256438905/jondurbin_airoboros-33b-3.1.2-4.65bpw": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "evolusion-ai/Evo-70B-v1": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "ShivamPanwar/finqallama": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "krevas/LDCC-Instruct-Llama-2-ko-13B-v4.2.3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "krevas/LDCC-Instruct-Llama-2-ko-13B-v4.2.4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Lewd-Sydney-20B-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Lewd-Sydney-20B-GPTQ": [
    "model.safetensors"
  ],
  "squarelike/Gugugo-koen-7B-V1.1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Gale-medium-init-3B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Gale-medium-init-3B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Echidna-13B-v0.2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Echidna-13B-v0.2-AWQ": [
    "model.safetensors"
  ],
  "neovalle/H4rmoniousBreeze": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/openbuddy-mistral-7B-v13.1-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/openbuddy-mistral-7B-v13.1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Mistral_7B_Dolphin2.1_LIMA0.5-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Mistral_7B_Dolphin2.1_LIMA0.5-GPTQ": [
    "model.safetensors"
  ],
  "nakhyeonn/llama-2-ko-qlora-prompt_1024_new_2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "AzureBlack/Echidna-13b-v0.3-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "TheBloke/Mistral-7B-codealpaca-lora-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Mistral-7B-codealpaca-lora-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/SauerkrautLM-70B-v1-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/SauerkrautLM-70B-v1-GPTQ": [
    "model.safetensors"
  ],
  "Brandoko/CodeLlama-13b-Recharts-v2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "AzureBlack/Lewd-Sydney-20B-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Doctor-Shotgun/airoboros-limarpv3-l2-70b-2.2.1": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "TheBloke/Echidna-13B-v0.3-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Echidna-13B-v0.3-AWQ": [
    "model.safetensors"
  ],
  "LoneStriker/airoboros-l2-70b-3.1.2-5.25bpw-h6-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "LoneStriker/Mistral-7B-codealpaca-lora-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Mistral-7B-codealpaca-lora-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Mistral_7B_Dolphin2.1_LIMA0.5_fp16-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "waldie/Free_Sydney_V2_13b_HF-5bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Mistral-7B-codealpaca-lora-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Mistral_7B_Dolphin2.1_LIMA0.5_fp16-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Mistral-7B-codealpaca-lora-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Mistral_7B_Dolphin2.1_LIMA0.5_fp16-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Mistral-7B-codealpaca-lora-8.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/airoboros-l2-70b-3.1.2-5.50bpw-h6-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "TheBloke/japanese-stablelm-instruct-gamma-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/japanese-stablelm-instruct-gamma-7B-AWQ": [
    "model.safetensors"
  ],
  "LoneStriker/Mistral_7B_Dolphin2.1_LIMA0.5_fp16-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Mistral_7B_Dolphin2.1_LIMA0.5_fp16-8.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/stabilityai_japanese-stablelm-instruct-gamma-7b-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/stabilityai_japanese-stablelm-instruct-gamma-7b-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "mlabonne/zephyr-7b-beta-4.0bpw-exl2": [
    "cal_data.safetensors",
    "input_states.safetensors",
    "output.safetensors"
  ],
  "TheBloke/stockmark-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/stockmark-13B-GPTQ": [
    "model.safetensors"
  ],
  "LoneStriker/stabilityai_japanese-stablelm-instruct-gamma-7b-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/stabilityai_japanese-stablelm-instruct-gamma-7b-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "waldie/Lewd-Sydney-20B-4bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/stabilityai_japanese-stablelm-instruct-gamma-7b-8.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "TheBloke/Mistral-7B-Claude-Chat-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Mistral-7B-Claude-Chat-AWQ": [
    "model.safetensors"
  ],
  "nicholasKluge/Aira-OPT-1B3": [
    "model.safetensors"
  ],
  "sanghwa-na/mistrallite.kor": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "IkariDev/Athnete-13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "vwxyzjn/train_sft_accelerate_summarize__tldr__seed1__1698542727": [
    "model.safetensors"
  ],
  "Heralax/Augmental-13b-v1.50_A": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Heralax/Augmental-13b-v1.50_B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Kooten/Lewd-Sydney-20B-6bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Kooten/Lewd-Sydney-20B-4bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Kooten/Lewd-Sydney-20B-3bpw-h8-exl2": [
    "output.safetensors"
  ],
  "TheBloke/Mistral-ClaudeLimaRP-v3-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Mistral-ClaudeLimaRP-v3-7B-AWQ": [
    "model.safetensors"
  ],
  "deepseek-ai/deepseek-coder-6.7b-instruct": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "cideon00/bkai-villama2-sft": [
    "adapter_model.safetensors",
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "RomanAdi1234/Test-Code": [
    "adapter_model.safetensors"
  ],
  "TheBloke/Augmental-13B-v1.50_A-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Augmental-13B-v1.50_A-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Augmental-13B-v1.50_B-AWQ": [
    "model.safetensors"
  ],
  "iashchak/openbuddy-mistral-7b-v13-base-igor-link-dialogues": [
    "model.safetensors"
  ],
  "TheBloke/Athnete-13B-AWQ": [
    "model.safetensors"
  ],
  "igig98/ppo2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Augmental-13B-v1.50_B-GPTQ": [
    "model.safetensors"
  ],
  "AlvinxLukilah/TextGenerationV2": [
    "model.safetensors"
  ],
  "IHaBiS/Synatra-7B-v0.3-RP-exl2": [
    "output.safetensors"
  ],
  "TheBloke/Nous-Capybara-7B-v1.9-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Athnete-13B-GPTQ": [
    "model.safetensors"
  ],
  "DanilKapustin/llama-2-7b-miniguanaco": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Nous-Capybara-7B-v1.9-GPTQ": [
    "model.safetensors"
  ],
  "IHaBiS/Synatra-7B-v0.3-base-exl2": [
    "output.safetensors"
  ],
  "NeverSleep/Nethena-20B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "TheBloke/Nous-Capybara-3B-v1.9-GPTQ": [
    "model.safetensors"
  ],
  "daekeun-ml/Llama-2-ko-instruct-13B": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "TheBloke/AquilaChat2-34B-GPTQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/AquilaChat2-34B-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "DanilKapustin/llama-2-13b-bank-learned": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "AzureBlack/Athnete-13B-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "TheBloke/AquilaChat2-34B-16K-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/AquilaChat2-34B-16K-GPTQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "NeverSleep/Nethena-13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Airoboros-180B-2.2.1-AWQ": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "teknium/OpenHermes-2.5-Mistral-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "shilongdai/mistral-sum-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Free_Sydney_V2_13B-AWQ": [
    "model.safetensors"
  ],
  "LoneStriker/Augmental-13b-v1.50_B-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "TheBloke/SciPhi-Mistral-7B-32k-AWQ": [
    "model.safetensors"
  ],
  "krevas/LDCC-Instruct-Llama-2-ko-13B-v4.2.6": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Augmental-13b-v1.50_B-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Augmental-13b-v1.50_B-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Augmental-13b-v1.50_B-6.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Kooten/Athnete-13B-3bpw-h8-exl2": [
    "output.safetensors"
  ],
  "Kooten/Athnete-13B-4bpw-h8-exl2": [
    "output.safetensors"
  ],
  "Kooten/Athnete-13B-8bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/Augmental-13b-v1.50_B-8.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "webbigdata/ALMA-7B-Ja-V2-GPTQ-Ja-En": [
    "model.safetensors"
  ],
  "TheBloke/Free_Sydney_V2_13B-GPTQ": [
    "model.safetensors"
  ],
  "jfarland/linkedin-influencers": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/SciPhi-Mistral-7B-32k-GPTQ": [
    "model.safetensors"
  ],
  "mesolitica/mistral-7b-32768-fpf": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "devhyun88/kullama2-7b-platypus-kogpt4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sanghwa-na/llama2-13b.kor.v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "aisingapore/sealion7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "stabilityai/japanese-stablelm-base-beta-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "stabilityai/japanese-stablelm-base-beta-70b": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "stabilityai/japanese-stablelm-instruct-beta-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "stabilityai/japanese-stablelm-instruct-beta-70b": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "stabilityai/japanese-stablelm-base-ja_vocab-beta-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "stabilityai/japanese-stablelm-instruct-ja_vocab-beta-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "asprenger/meta-llama-Llama-2-13b-chat-hf-gemm-w4-g128-awq": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Akins-3B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Marx-3B-v3-GPTQ": [
    "model.safetensors"
  ],
  "Henk717/echidna-tiefigther-25": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "RaftDS/llama-2-13b-bank-learned": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "rinna/youri-7b-chat": [
    "model.safetensors"
  ],
  "rinna/youri-7b-instruction": [
    "model.safetensors"
  ],
  "KT-AI/midm-bitext-S-7B-inst-v1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Kooten/Nethena-13B-8bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Kooten/Nethena-13B-4bpw-h8-exl2": [
    "output.safetensors"
  ],
  "Kooten/Nethena-13B-3bpw-h8-exl2": [
    "output.safetensors"
  ],
  "nicholasKluge/Aira-OPT-350M": [
    "model.safetensors"
  ],
  "neovalle/H4rmoniousBreezeDPO": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "josem7/Schema-link-SURI-13B-v0.3": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Kooten/Nethena-20B-4bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "AlbelTec/phi-1_5-finetuned-sql": [
    "adapter_model.safetensors"
  ],
  "Kooten/Nethena-20B-3bpw-h8-exl2": [
    "output.safetensors"
  ],
  "Kooten/Nethena-20B-6bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "chunfengw/gpt2-finetuned": [
    "model.safetensors"
  ],
  "TheBloke/Thespis-13B-v0.5-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Nethena-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Nethena-20B-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Thespis-13B-v0.5-GPTQ": [
    "model.safetensors"
  ],
  "josem7/SCHEMA_LINK-SURI-13B-v0.3_AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Nethena-13B-GPTQ": [
    "model.safetensors"
  ],
  "iashchak/phi-v1.5-igor-link-dialogues": [
    "model.safetensors"
  ],
  "waldie/Nethena-20B-4bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "TheBloke/Nethena-20B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Uncensored-Jordan-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Uncensored-Jordan-33B-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Uncensored-Jordan-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Uncensored-Jordan-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Uncensored-Jordan-33B-GPTQ": [
    "model.safetensors"
  ],
  "M00D/mix-merged": [
    "model.safetensors"
  ],
  "TheBloke/Uncensored-Jordan-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/dolphin-2.2.1-mistral-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/dolphin-2.2.1-mistral-7B-GPTQ": [
    "model.safetensors"
  ],
  "uncensorie/xairowin-70b": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "Undi95/Nethena-MLewd-Xwin-23B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "sgarbi/gpt-nq-prompt-generator": [
    "model.safetensors"
  ],
  "sohohuk/test1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "AdnanRiaz107/santacoder-finetuned-the-stack-bash": [
    "model.safetensors"
  ],
  "daekeun-ml/Llama-2-ko-DPO-13B": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "upro/pygmalion-2-13b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mariavilla/phi-1_5-finetuned-gsm8k": [
    "adapter_model.safetensors"
  ],
  "Kooten/Nethena-MLewd-Xwin-23B-6bpw-h8-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "Kooten/Nethena-MLewd-Xwin-23B-5.6bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "IHaBiS/Nethena-MLewd-Xwin-23B-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "TheBloke/Nethena-MLewd-Xwin-23B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Nethena-MLewd-Xwin-23B-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Kooten/Nethena-MLewd-Xwin-23B-3.7bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "squarelike/Gugugo-koen-7B-V1.1-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/MetaMath-Mistral-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/MetaMath-Mistral-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Xwin-MLewd-7B-V0.2-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Xwin-MLewd-7B-V0.2-GPTQ": [
    "model.safetensors"
  ],
  "waldie/lzlv-limarpv3-l2-70b-2.4bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "Isaak-Carter/JOSIE-7B-v40_Llama_Base": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AzureBlack/Dawn-v0.1-70B-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "nelson2424/distilroberta-base-finetuned-cot": [
    "model.safetensors"
  ],
  "uncensorie/stairolzlv-70b": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "TheBloke/Skywork-13B-base-GPTQ": [
    "model.safetensors"
  ],
  "yonatano/contam-1.4b": [
    "model.safetensors"
  ],
  "krevas/LDCC-Instruct-Llama-2-ko-13B-v4.2.8": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "uncensorie/stairolz-70b": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "Norquinal/Mistral-7B-storywriter": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "gangkongkong/llama-2-ko-7b-gangkk-alpaca-cosin-all-epoch1-merge": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ValiantLabs/ShiningValiantXS": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "derek-thomas/jais-13b-chat-hf": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "01-ai/Yi-34B": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "cyberagent/calm2-7b-chat": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "lcw99/zephykor-ko-7b-chang": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "01-ai/Yi-6B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Amethyst-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Amethyst-13B-AWQ": [
    "model.safetensors"
  ],
  "gangkongkong/llama-2-koen-13b-gangkk-alpaca-cosine-all-epoch3-merge": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "matatonic/Xwin-LM-70B-V0.1-exl2-4.800b": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "ivanmatiasmongi/distilgpt2-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "Trelis/falcon-7b-chat-commercial-use-4k": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/vietnamese-llama2-7B-40GB-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/vietnamese-llama2-7B-40GB-AWQ": [
    "model.safetensors"
  ],
  "iashchak/Mistral-7B-v0.1": [
    "model.safetensors"
  ],
  "jfarland/another-test-model": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Trelis/falcon-7b-4k-chat-commercial-use": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "CyberRift/sidekick-mitre": [
    "model.safetensors"
  ],
  "TheBloke/SciPhi-Self-RAG-Mistral-7B-32k-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/SciPhi-Self-RAG-Mistral-7B-32k-GPTQ": [
    "model.safetensors"
  ],
  "mrm8488/limstral-7B-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Fraternitas/base_model_llama2-13b-chat": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Undi95/Utopia-13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/openbuddy-llama2-70B-v13.2-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/openbuddy-llama2-70B-v13.2-GPTQ": [
    "model.safetensors"
  ],
  "devhyun88/kullama2-7b-ko-PGO": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "p208p2002/llama-keyword-generator-zh2zh-120M": [
    "model.safetensors"
  ],
  "AzureBlack/Nethena-MLewd-Xwin-23B-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "shubhamgantayat/gpt2-medium-custom": [
    "model.safetensors"
  ],
  "Shishir1807/merged-llama-7b-chat-hf-med": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "yichunkuo/stablelm-3b-4e1t-gptq": [
    "model.safetensors"
  ],
  "sanghwa-na/llama2-13b.kor.v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Kooten/Utopia-13B-8bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Kooten/Utopia-13B-4bpw-h8-exl2": [
    "output.safetensors"
  ],
  "Kooten/Utopia-13B-3bpw-h8-exl2": [
    "output.safetensors"
  ],
  "Herocat/opt-350m-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "TheBloke/basilisk-7B-v0.2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/basilisk-7B-v0.2-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/japanese-stablelm-instruct-beta-70B-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/japanese-stablelm-instruct-beta-70B-GPTQ": [
    "model.safetensors"
  ],
  "ramdhanfirdaus/falcon-1b-finetuned-aings-chat-1": [
    "adapter_model.safetensors",
    "last-checkpoint/adapter_model.safetensors",
    "model.safetensors"
  ],
  "TheBloke/openchat_3.5-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Yarn-Mistral-7B-64k-AWQ": [
    "model.safetensors"
  ],
  "BAH-ML-ASC/Zephyr-7b-chat": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "taozi555/Euryale-2.65": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "TheBloke/Yarn-Mistral-7B-128k-AWQ": [
    "model.safetensors"
  ],
  "pyro-glitch/NEMO_AI_Compainon_v0.5": [
    "model.safetensors"
  ],
  "trl-internal-testing/tiny-random-GPTNeoXForCausalLM-safetensors": [
    "model.safetensors"
  ],
  "trl-internal-testing/tiny-random-GPTNeoXForCausalLM-safetensors-sharded": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors",
    "model.safetensors"
  ],
  "Lornng/Llama2-7b-merged-qlora-cpgQA-text-gen-final": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/openchat_3.5-GPTQ": [
    "model.safetensors"
  ],
  "hedtorresca/bertin-gpt-j-6B-es-finetuned-informativo-1000": [
    "adapter_model.safetensors"
  ],
  "Danroy/mazingira-gpt": [
    "model.safetensors"
  ],
  "TheBloke/OpenHermes-2.5-Mistral-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/OpenHermes-2.5-Mistral-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Yarn-Mistral-7B-128k-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Yarn-Mistral-7B-64k-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Thespis-Mistral-7B-v0.5-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Thespis-Mistral-7B-v0.5-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Utopia-13B-AWQ": [
    "model.safetensors"
  ],
  "Herocat/opt-125m-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "TheBloke/japanese-stablelm-instruct-beta-7B-AWQ": [
    "model.safetensors"
  ],
  "surcyf/5EZGRiRtTuxipeSq1vgwZgkwu4kdj7Lh1U6Yu7ZerRMQkE19": [
    "model.safetensors"
  ],
  "mesolitica/malaysian-mistral-7b-32k-instructions": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mesolitica/mistral-1.1b-32768-fpf": [
    "model.safetensors"
  ],
  "YahyAxis/DiabloGPT-small-Tetouane": [
    "model.safetensors"
  ],
  "Benson/Llama-2-13b-chat-hf": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "bachbouch/phi-1_5-finetuned-gsm8k": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Vezora/Mistral-14b-Merge-Base": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "kaizerBox/retnet-xsum": [
    "model.safetensors"
  ],
  "harryng4869/codellama-2-7b-mini": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "shubhamgantayat/bigscience-bloom-1b1-custom": [
    "model.safetensors"
  ],
  "crodri/aguila_falcon_instrucat": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ramdhanfirdaus/falcon-1b-finetuned-aings-chat-2": [
    "adapter_model.safetensors",
    "last-checkpoint/adapter_model.safetensors",
    "model.safetensors"
  ],
  "Jukaboo/Checkpoint_65_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mikesoylu/nano_asst": [
    "model.safetensors"
  ],
  "girrajjangid/opt-1.3b-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/japanese-stablelm-instruct-beta-7B-GPTQ": [
    "model.safetensors"
  ],
  "Vezora/Mistral-29b-Merge-Base": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ramdhanfirdaus/falcon-1b-finetuned-aings-chat-3": [
    "adapter_model.safetensors",
    "last-checkpoint/adapter_model.safetensors",
    "model.safetensors"
  ],
  "waldie/basilisk-7b-v0.2-8bpw-h8-exl2": [
    "output.safetensors"
  ],
  "gangkongkong/llama-2-koen-13b-gangkk-kullm-v2-cosine-all-2000step-merge": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "TheBloke/Utopia-13B-GPTQ": [
    "model.safetensors"
  ],
  "ramdhanfirdaus/falcon-1b-finetuned-aings-instructed-non-delimiter-1": [
    "adapter_model.safetensors",
    "last-checkpoint/adapter_model.safetensors",
    "model.safetensors"
  ],
  "tartuNLP/llammas-prelim": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "emekaboris/zephyr_8_bit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "projecte-aina/FLOR-1.3B": [
    "model.safetensors"
  ],
  "ramdhanfirdaus/falcon-1b-finetuned-aings-instructed-non-delimiter-2": [
    "adapter_model.safetensors",
    "last-checkpoint/adapter_model.safetensors",
    "model.safetensors"
  ],
  "ramdhanfirdaus/falcon-1b-finetuned-aings-instructed-non-delimiter-3": [
    "adapter_model.safetensors",
    "last-checkpoint/adapter_model.safetensors",
    "model.safetensors"
  ],
  "LongSafari/hyenadna-small-32k-seqlen-hf": [
    "model.safetensors"
  ],
  "LongSafari/hyenadna-medium-160k-seqlen-hf": [
    "model.safetensors"
  ],
  "LongSafari/hyenadna-medium-450k-seqlen-hf": [
    "model.safetensors"
  ],
  "LongSafari/hyenadna-large-1m-seqlen-hf": [
    "model.safetensors"
  ],
  "LongSafari/hyenadna-tiny-16k-seqlen-d128-hf": [
    "model.safetensors"
  ],
  "LongSafari/hyenadna-tiny-1k-seqlen-d256-hf": [
    "model.safetensors"
  ],
  "Praveen76/QLoRA-LlAMA-finetuned-for-E-commerceData": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "taozi555/Euryale-2.4": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "gradjitta/mistral-7b-ultrachat100k-merged-AWQ": [
    "model.safetensors"
  ],
  "sebastiantrbl/GPT2-input-response-pair": [
    "model.safetensors"
  ],
  "taozi555/Euryale-2.5": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "flamingFlamingo99/distilgpt2-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "Undi95/Toppy-M-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mogaio/pr_1.5b_500": [
    "model.safetensors"
  ],
  "LuisBlancheMirakl/finetuned_productcat": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LongSafari/hyenadna-tiny-1k-seqlen-hf": [
    "model.safetensors"
  ],
  "LoneStriker/Utopia-13B-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Utopia-13B-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Utopia-13B-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Utopia-13B-6.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/Utopia-13B-8.0bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Rology/Patien-communication": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Joetib/pythia-finetuned-5-steps": [
    "model.safetensors"
  ],
  "mb-nf/nf-l2-7b-squad2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mlabonne/zephyr-7b-beta-5.0bpw-exl2": [
    "cal_data.safetensors",
    "input_states.safetensors",
    "output.safetensors"
  ],
  "Joetib/pythia-finetuned-with-context-5-steps": [
    "model.safetensors"
  ],
  "taozi555/mythalion-4.25": [
    "output.safetensors"
  ],
  "taozi555/mythalion-4.0": [
    "output.safetensors"
  ],
  "Sakshi1307/llama-2-7b-finetuned-local": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "bachbouch/phi-1_5-finetuned-hr": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "RiversHaveWings/Mistral-7B-v0.1-safetensors": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "Joetib/pythia-410m-finetuned-1000-steps-qa": [
    "model.safetensors"
  ],
  "Sakshi1307/llama-2-7b-finetuned-local2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "robertsw/airoboros-13b-gpt4-1.2-AWQ": [
    "model.safetensors"
  ],
  "uncensorie/chronob-70b": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "uncensorie/chronob-slerp-70b": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "uncensorie/chronob-slerp-base-chrono-70b": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "robertsw/airoboros-65b-gpt4-1.4-AWQ": [
    "model.safetensors"
  ],
  "uncensorie/chronob-1.4-lin-70b": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "robertsw/airoboros-65b-gpt4-1.4-AWQ2": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "RayBernard/llama2cosmic": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Hieu-Pham/Llama2-7B-IA3-cooking-text-gen-prompting-merged": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "himuken/everythinglm-dnd-1ep": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ramdhanfirdaus/falcon-7b-finetuned-aings-instructed-delimiter-2": [
    "adapter_model.safetensors",
    "last-checkpoint/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ramdhanfirdaus/falcon-7b-finetuned-aings-instructed-delimiter-3": [
    "adapter_model.safetensors",
    "last-checkpoint/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ramdhanfirdaus/falcon-7b-finetuned-aings-instructed-delimiter-1": [
    "adapter_model.safetensors",
    "last-checkpoint/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mb-nf/l2-7b-squad1_1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TinyLlama/TinyLlama-1.1B-intermediate-step-715k-1.5T": [
    "model.safetensors"
  ],
  "nakhyeon/polyglot-ko-12b-qlora": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Aarenwong/Llama-2-7b-chat-hf-fine-tuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kyujinpy/Korean-OpenOrca-v3": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "wangyiyang/llama2-wangyy": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ramdhanfirdaus/falcon-1b-finetuned-aings-instructed-delimiter-4": [
    "adapter_model.safetensors",
    "last-checkpoint/adapter_model.safetensors",
    "model.safetensors"
  ],
  "ramdhanfirdaus/falcon-1b-finetuned-aings-instructed-non-delimiter-4": [
    "adapter_model.safetensors",
    "last-checkpoint/adapter_model.safetensors",
    "model.safetensors"
  ],
  "Corianas/tiny-llama-miniguanaco-1.5T": [
    "model.safetensors"
  ],
  "Herman555/dolphin-2.2.1-AshhLimaRP-Mistral-7B-GGUF": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rahat01/llama2-fine-tuned-dolly-15k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "actionpace/Llama-2-7b-hf-alpaca-gpt4-qlora1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "zackhlk/llama2test": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "neph1/bellman-7b-mistral-instruct": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rukaiyaaaah/fine-tuned": [
    "model.safetensors"
  ],
  "samadpls/querypls-prompt2sql": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "AzureBlack/ReMM-S-Kimiko-v2-13B-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "qeternity/Llama2-70b-2.5bpw-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "waldie/Naberius-7B-8bpw-h8-exl2": [
    "output.safetensors"
  ],
  "waldie/dolphin-2.2.1-AshhLimaRP-Mistral-7B-8bpw-h8-exl2": [
    "output.safetensors"
  ],
  "mariiaponom/test_colab": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AzureBlack/llava-v1.5-13b-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "TheBloke/Yi-34B-GPTQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Naberius-7B-AWQ": [
    "model.safetensors"
  ],
  "FPHam/Free_Sydney_V2_Mistral_7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Arotte/dragon-v0.1": [
    "model.safetensors"
  ],
  "qeternity/Llama2-70b-2.55bpw-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "tjake/llama2-7b-hf-jlama-Q4_0": [
    "model.safetensors"
  ],
  "MegatronJeremy/DialoGPT-small-van": [
    "model.safetensors"
  ],
  "btt-mining-coalation/mistral_7b_val_4_11_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "uncensorie/chronob-1-1-70b": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "TheBloke/deepseek-coder-33B-instruct-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MegatronJeremy/DialoGPT-small-van-2": [
    "model.safetensors"
  ],
  "Kooten/Toppy-M-7B-8bpw-h8-exl2": [
    "output.safetensors"
  ],
  "kaizerBox/retnet-summarization": [
    "model.safetensors"
  ],
  "qeternity/OpenHermes-2.5-Mistral-7B-6bpw-exl2": [
    "output.safetensors"
  ],
  "Undi95/UtopiaXL-13B": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Undi95/LimaRP-UtopiaXL-13B-v3-lora": [
    "checkpoint-1912/adapter_model.safetensors",
    "checkpoint-956/adapter_model.safetensors"
  ],
  "TheBloke/Naberius-7B-GPTQ": [
    "model.safetensors"
  ],
  "msanthum/distilgpt2-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "qeternity/Llama2-70b-5bpw-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "AzureBlack/UtopiaXL-13B-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "TheBloke/deepseek-coder-1.3b-instruct-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/deepseek-coder-1.3b-base-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/deepseek-coder-33B-base-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/deepseek-coder-6.7B-instruct-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/deepseek-coder-1.3b-base-GPTQ": [
    "model.safetensors"
  ],
  "FPHam/Autolycus-Mistral_7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/deepseek-coder-1.3b-instruct-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/deepseek-coder-6.7B-base-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/deepseek-coder-33B-base-GPTQ": [
    "model.safetensors"
  ],
  "LoneStriker/Toppy-M-7B-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Toppy-M-7B-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Toppy-M-7B-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Toppy-M-7B-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Toppy-M-7B-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "stockmark/stockmark-13b-instruct": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/deepseek-coder-33B-instruct-GPTQ": [
    "model.safetensors"
  ],
  "philTheThill/SentimentRoberta-Base": [
    "model.safetensors"
  ],
  "Herman555/OpenHermes-2.5-AshhLimaRP-Mistral-7B-GGUF": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "GamerGod2k/DialoGPT-medium-johnnyboy123": [
    "model.safetensors"
  ],
  "waldie/ORCA_LLaMA_70B_QLoRA-2.4bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "Sober-Clever/codeparrot-ds": [
    "model.safetensors"
  ],
  "TheBloke/deepseek-coder-6.7B-base-GPTQ": [
    "model.safetensors"
  ],
  "g-ronimo/Mistral-Bourdain": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Sapiensia/llama-2-7b-guanaco-instruct-sharded-test-0": [
    "adapter_model.safetensors",
    "checkpoint-3/adapter_model.safetensors"
  ],
  "TheBloke/deepseek-coder-6.7B-instruct-GPTQ": [
    "model.safetensors"
  ],
  "BEE-spoke-data/mega-ar-126m-v12-python-apps-4096": [
    "model.safetensors"
  ],
  "RachitD15673/mistral-finetuned-7B-instruct-manual": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "gbiddy/DestroymanGPT-small": [
    "model.safetensors"
  ],
  "TheBloke/deepseek-coder-5.7bmqa-base-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/deepseek-coder-5.7bmqa-base-AWQ": [
    "model.safetensors"
  ],
  "Mibei/DialoGPT-medium-neku": [
    "model.safetensors"
  ],
  "ashk72/llama_new": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Pipper/test_sol_model": [
    "model.safetensors"
  ],
  "Sao10K/Hesperus-v1-13B-L2-fp16": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "dinhhung1508/toan-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/calm2-7B-chat-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/calm2-7B-chat-GPTQ": [
    "model.safetensors"
  ],
  "LoneStriker/Yi-34B-3.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "alpindale/goliath-120b": [
    "model-00001-of-00024.safetensors",
    "model-00002-of-00024.safetensors",
    "model-00003-of-00024.safetensors",
    "model-00004-of-00024.safetensors",
    "model-00005-of-00024.safetensors",
    "model-00006-of-00024.safetensors",
    "model-00007-of-00024.safetensors",
    "model-00008-of-00024.safetensors",
    "model-00009-of-00024.safetensors",
    "model-00010-of-00024.safetensors",
    "model-00011-of-00024.safetensors",
    "model-00012-of-00024.safetensors",
    "model-00013-of-00024.safetensors",
    "model-00014-of-00024.safetensors",
    "model-00015-of-00024.safetensors",
    "model-00016-of-00024.safetensors",
    "model-00017-of-00024.safetensors",
    "model-00018-of-00024.safetensors",
    "model-00019-of-00024.safetensors",
    "model-00020-of-00024.safetensors",
    "model-00021-of-00024.safetensors",
    "model-00022-of-00024.safetensors",
    "model-00023-of-00024.safetensors",
    "model-00024-of-00024.safetensors"
  ],
  "LoneStriker/Yi-34B-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "Kooten/UtopiaXL-13B-8bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Kooten/UtopiaXL-13B-4bpw-h8-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Yi-34B-5.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "DecisionOptimizationSystem/DeepFeatLLMZephyr7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "jebcarter/Psyfighter-13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Kooten/UtopiaXL-13B-3bpw-h8-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Yi-34B-6.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "Sao10K/Euryale-1.4-L2-70B": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "jirin/Llama-2-13b-fingpt2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "casperhansen/mistral-7b-instruct-awq-gemv": [
    "model.safetensors"
  ],
  "louislian2341/codeparrot-ds": [
    "model.safetensors"
  ],
  "LoneStriker/Yi-34B-8.0bpw-h8-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "marblyso/DialoGPT-medium-yonny": [
    "model.safetensors"
  ],
  "Pclanglais/MonadGPT": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "panpas161/gpt2-wikitext2": [
    "model.safetensors"
  ],
  "KingZack/futurama-model": [
    "model.safetensors"
  ],
  "TheBloke/Hermes-Trismegistus-Mistral-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Hermes-Trismegistus-Mistral-7B-GPTQ": [
    "model.safetensors"
  ],
  "thanhnew2001/llama-2-7b-taipy1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "KingZack/future-futurama-maker": [
    "model.safetensors"
  ],
  "chargoddard/Yi-34B-Llama": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "Tural/stanford_alpaca": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "EduardoPacheco/gpt2-clip-guided": [
    "model.safetensors"
  ],
  "01-ai/Yi-34B-200K": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "01-ai/Yi-6B-200K": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Masterjp123/Setiaku_l2-13b-thespurral-m2.2_CLONE": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Tensoic/Tiny-Llama-openhermes-1.1B-step-715k-1.5T": [
    "model.safetensors"
  ],
  "tjake/llama2-7b-chat-hf-jlama-Q4": [
    "model.safetensors"
  ],
  "Czardas/llama2-fine-tuned-dolly-15k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "aisingapore/sealion7b-instruct-nc": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "llm-blender/PairRM": [
    "model.safetensors"
  ],
  "pranjalj/test": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "TheBloke/UtopiaXL-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/UtopiaXL-13B-GPTQ": [
    "model.safetensors"
  ],
  "michaelbenayoun/llama-2-tiny-4layers-random": [
    "model.safetensors"
  ],
  "k0x3k/my_eli5_clm-model": [
    "model.safetensors"
  ],
  "TheBloke/echidna-tiefigther-25-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/echidna-tiefigther-25-GPTQ": [
    "model.safetensors"
  ],
  "AgentPublic/Faust": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Hexoteric-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Hexoteric-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/japanese-stablelm-base-beta-70B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/japanese-stablelm-base-beta-70B-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "pankajemplay/llama-2-7b-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "0xOracle/mistral-7b-fraud-test-finetuned": [
    "diffusion_pytorch_model.safetensors"
  ],
  "pranjalj/codellama13b-8bit-1105-2000-length-legacy-format-no-chathistory_epoch_0": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "pranjalj/codellama13b-8bit-1105-2000-increased-rank-pj_epoch_0": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "tmae/llm-jp-13b-instruct-full-jaster-dolly-oasst-v1.0-safetensors": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "pranjalj/codellama13b-8bit-1105-2000-increased-rank-pj_epoch_1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "win10/Aphrodite-20b": [
    "model-00001-of-00054.safetensors",
    "model-00002-of-00054.safetensors",
    "model-00003-of-00054.safetensors",
    "model-00004-of-00054.safetensors",
    "model-00005-of-00054.safetensors",
    "model-00006-of-00054.safetensors",
    "model-00007-of-00054.safetensors",
    "model-00008-of-00054.safetensors",
    "model-00009-of-00054.safetensors",
    "model-00010-of-00054.safetensors",
    "model-00011-of-00054.safetensors",
    "model-00012-of-00054.safetensors",
    "model-00013-of-00054.safetensors",
    "model-00014-of-00054.safetensors",
    "model-00015-of-00054.safetensors",
    "model-00016-of-00054.safetensors",
    "model-00017-of-00054.safetensors",
    "model-00018-of-00054.safetensors",
    "model-00019-of-00054.safetensors",
    "model-00020-of-00054.safetensors",
    "model-00021-of-00054.safetensors",
    "model-00022-of-00054.safetensors",
    "model-00023-of-00054.safetensors",
    "model-00024-of-00054.safetensors",
    "model-00025-of-00054.safetensors",
    "model-00026-of-00054.safetensors",
    "model-00027-of-00054.safetensors",
    "model-00028-of-00054.safetensors",
    "model-00029-of-00054.safetensors",
    "model-00030-of-00054.safetensors",
    "model-00031-of-00054.safetensors",
    "model-00032-of-00054.safetensors",
    "model-00033-of-00054.safetensors",
    "model-00034-of-00054.safetensors",
    "model-00035-of-00054.safetensors",
    "model-00036-of-00054.safetensors",
    "model-00037-of-00054.safetensors",
    "model-00038-of-00054.safetensors",
    "model-00039-of-00054.safetensors",
    "model-00040-of-00054.safetensors",
    "model-00041-of-00054.safetensors",
    "model-00042-of-00054.safetensors",
    "model-00043-of-00054.safetensors",
    "model-00044-of-00054.safetensors",
    "model-00045-of-00054.safetensors",
    "model-00047-of-00054.safetensors",
    "model-00048-of-00054.safetensors",
    "model-00049-of-00054.safetensors",
    "model-00050-of-00054.safetensors",
    "model-00051-of-00054.safetensors",
    "model-00052-of-00054.safetensors",
    "model-00053-of-00054.safetensors",
    "model-00054-of-00054.safetensors"
  ],
  "TheBloke/openbuddy-zephyr-7B-v14.1-AWQ": [
    "model.safetensors"
  ],
  "Undi95/Dawn-v2-70B": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "rjiang121/llama-2-7b-chat-guanaco": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rizkyjun/bloom-1b-finetuned-aings-non-delimiter": [
    "model.safetensors"
  ],
  "rizkyjun/bloom-1b-finetuned-aings-non-delimiter-3": [
    "model.safetensors"
  ],
  "rizkyjun/bloom-1b-finetuned-aings-non-delimiter-4": [
    "model.safetensors"
  ],
  "rizkyjun/bloom-1b-finetuned-aings-non-delimiter-2": [
    "model.safetensors"
  ],
  "pranjalj/codellama13b-8bit-1105-2000-pj-without-checkpoint": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "mrm8488/Mistral-7B-v0.1-inst": [
    "model-00001-of-00003.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00003.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "mtc/LeoLM-leo-mistral-hessianai-7b-classification-with-explanation-neftune-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/openbuddy-zephyr-7B-v14.1-GPTQ": [
    "model.safetensors"
  ],
  "ybelkada/opt-125m-awq": [
    "model.safetensors"
  ],
  "TheBloke/Barcenas-Mistral-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Barcenas-Mistral-7B-GPTQ": [
    "model.safetensors"
  ],
  "Laszer/LatexCopilot": [
    "model.safetensors"
  ],
  "bkwalsh/distilgpt2-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "Winmodel/llama-2-7b-miniguanaco": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "0ppxnhximxr/CodeAI": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors",
    "model.safetensors"
  ],
  "developerchaithu/RickBot": [
    "model.safetensors"
  ],
  "typeof/amall": [
    "model.safetensors"
  ],
  "0ppxnhximxr/CodeAI-small": [
    "model.safetensors"
  ],
  "KnutJaegersberg/Deacon-34B": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "casperhansen/yi-6b-awq": [
    "model.safetensors"
  ],
  "Czardas/llama2-fine-tuned-perplexity-3k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "anurag-208/Llama2-7B-Dolly": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "brianbailey18/og_football_model_merged": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "eclipsemint/kollama2-7b-v0.3": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Keynote-Technology/KAI-7B-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "centroIA/zephyr-Merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "UtopiaLtd/pie-llama-13b": [
    "model.safetensors"
  ],
  "larryvrh/Yi-34B-200K-Llamafied": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "FelixChao/Mistral-7b-Chem-TW-v2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "teslalord/falcon-7b-instruct-lora": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "willpowers/distilgpt2-wikidata-QA": [
    "model.safetensors"
  ],
  "louislian2341/codeparrot-ds-accelerate": [
    "model.safetensors"
  ],
  "E-Hospital/open-orca-platypus-2-lora-medical": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "migtissera/Tess-XL-v1.0": [
    "model-00001-of-00050.safetensors",
    "model-00002-of-00050.safetensors",
    "model-00003-of-00050.safetensors",
    "model-00004-of-00050.safetensors",
    "model-00005-of-00050.safetensors",
    "model-00006-of-00050.safetensors",
    "model-00007-of-00050.safetensors",
    "model-00008-of-00050.safetensors",
    "model-00009-of-00050.safetensors",
    "model-00010-of-00050.safetensors",
    "model-00011-of-00050.safetensors",
    "model-00012-of-00050.safetensors",
    "model-00013-of-00050.safetensors",
    "model-00014-of-00050.safetensors",
    "model-00015-of-00050.safetensors",
    "model-00016-of-00050.safetensors",
    "model-00017-of-00050.safetensors",
    "model-00018-of-00050.safetensors",
    "model-00019-of-00050.safetensors",
    "model-00020-of-00050.safetensors",
    "model-00021-of-00050.safetensors",
    "model-00022-of-00050.safetensors",
    "model-00023-of-00050.safetensors",
    "model-00024-of-00050.safetensors",
    "model-00025-of-00050.safetensors",
    "model-00026-of-00050.safetensors",
    "model-00027-of-00050.safetensors",
    "model-00028-of-00050.safetensors",
    "model-00029-of-00050.safetensors",
    "model-00030-of-00050.safetensors",
    "model-00031-of-00050.safetensors",
    "model-00032-of-00050.safetensors",
    "model-00033-of-00050.safetensors",
    "model-00034-of-00050.safetensors",
    "model-00035-of-00050.safetensors",
    "model-00036-of-00050.safetensors",
    "model-00037-of-00050.safetensors",
    "model-00038-of-00050.safetensors",
    "model-00039-of-00050.safetensors",
    "model-00040-of-00050.safetensors",
    "model-00041-of-00050.safetensors",
    "model-00042-of-00050.safetensors",
    "model-00043-of-00050.safetensors",
    "model-00044-of-00050.safetensors",
    "model-00045-of-00050.safetensors",
    "model-00046-of-00050.safetensors",
    "model-00047-of-00050.safetensors",
    "model-00048-of-00050.safetensors",
    "model-00049-of-00050.safetensors",
    "model-00050-of-00050.safetensors"
  ],
  "firef1i/finbasic": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "nayohan/polyglot-ko-12.8b-Inst": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "Jungtek/llama2-fine-tuned-samchully_qa": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Manoj120/base-model": [
    "model.safetensors"
  ],
  "Manoj120/reward-model": [
    "model.safetensors"
  ],
  "miittnnss/lstm-textgen-pets": [
    "model.safetensors"
  ],
  "mangeshdiyewar/Llama-2-7b-chat-hf-fine-tuned_translation": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Manoj120/ppo-final-model": [
    "model.safetensors"
  ],
  "LoneStriker/Yi-6B-200K-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Yi-6B-200K-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Yi-6B-200K-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Yi-6B-200K-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "GHOFRANEE/mistral7b_ocr_to_json_v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Yi-6B-200K-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "RANITBAG/scratch": [
    "model.safetensors"
  ],
  "sumitsahayktk/mistral_7b-instruct_sharded-medquad_v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AdnanRiaz107/CodeBert-finetuned-the-stack-bash": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "elyza/ELYZA-japanese-CodeLlama-7b-instruct": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/TinyLlama-1.1B-intermediate-step-715k-1.5T-GPTQ": [
    "model.safetensors"
  ],
  "elyza/ELYZA-japanese-CodeLlama-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/TinyLlama-1.1B-intermediate-step-715k-1.5T-AWQ": [
    "model.safetensors"
  ],
  "mtc/ehartford-dolphin-2.2.1-mistral-7b-classification-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Toppy-M-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Toppy-M-7B-GPTQ": [
    "model.safetensors"
  ],
  "AdnanRiaz107/huggingfaceCodeBerta-finetuned-the-stack-bash": [
    "model.safetensors"
  ],
  "khanhnto/khanhnto": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "GouthamVignesh/falcon-arxiv-summary-1B": [
    "model.safetensors"
  ],
  "TheBloke/vigogne-2-70B-chat-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/vigogne-2-70B-chat-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "GouthamVignesh/falcon-arxiv-7b-longdoc-summary": [
    "model.safetensors"
  ],
  "cgato/Thespis-13b-v0.6": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "mtc/ehartford-dolphin-2.2.1-mistral-7b-classification-with-explanation-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "monsterapi/zephyr-7b-alpha_metamathqa": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AdnanRiaz107/huggingfacecodebert-base-mlm-finetuned-the-stack-bash": [
    "model.safetensors"
  ],
  "nalmeida/mistral-cucumber": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "GouthamVignesh/falcon-1b-arxiv": [
    "model.safetensors"
  ],
  "Himanshumaxwell/DialoGPT-small-harrypotter": [
    "model.safetensors"
  ],
  "Fraternitas/base_model_llama2-7b-chat": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "dharlendra/DialoGPT-small-Cartman01": [
    "model.safetensors"
  ],
  "Himanshumaxwell/DialoGPT-small-harrypotter3": [
    "model.safetensors"
  ],
  "AlvinxLukilah/UpdatedTextGen": [
    "model.safetensors"
  ],
  "yonatano/Contam-Large": [
    "model.safetensors"
  ],
  "joyfine/vicuna-7b-fine-tuning_SST_25": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mickume/wow_mistral_7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "yonatano/Contam-Medium": [
    "model.safetensors"
  ],
  "yonatano/Contam-Small": [
    "model.safetensors"
  ],
  "yonatano/Contam-1.4b-dupcount-higher": [
    "model.safetensors"
  ],
  "yonatano/Contam-1.4b-dupcount-lower": [
    "model.safetensors"
  ],
  "TheBloke/Dawn-v2-70B-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Dawn-v2-70B-GPTQ": [
    "model.safetensors"
  ],
  "lemonteaa/mergekit-test-1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "KnutJaegersberg/Deacon-34B-qlora": [
    "adapter_model.safetensors"
  ],
  "RossAscends/Toppy-7B-5bpw-exl2": [
    "output.safetensors"
  ],
  "yanismiraoui/Yi-6B-sharded": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "czham/DialoGPT-small-harrypotter": [
    "model.safetensors"
  ],
  "yanismiraoui/Yarn-Mistral-7b-128k-sharded": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "nalmeida/Zephyr-Cucumber-Instruct": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "yanismiraoui/openchat_3.5-sharded": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "mogaio/pr_1.5b_600_1": [
    "model.safetensors"
  ],
  "sebastiandizon/magpie": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "yanismiraoui/Yi-6B-200K-sharded": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "mogaio/pr_1.5b_600_2": [
    "model.safetensors"
  ],
  "mogaio/pr_1.5b_600_3": [
    "model.safetensors"
  ],
  "yanismiraoui/fuyu-8b-sharded": [
    "model-00001-of-00013.safetensors",
    "model-00002-of-00013.safetensors",
    "model-00003-of-00013.safetensors",
    "model-00004-of-00013.safetensors",
    "model-00005-of-00013.safetensors",
    "model-00006-of-00013.safetensors",
    "model-00007-of-00013.safetensors",
    "model-00008-of-00013.safetensors",
    "model-00009-of-00013.safetensors",
    "model-00010-of-00013.safetensors",
    "model-00011-of-00013.safetensors",
    "model-00012-of-00013.safetensors",
    "model-00013-of-00013.safetensors"
  ],
  "UtopiaLtd/pie-llama-7b": [
    "model.safetensors"
  ],
  "support-pvelocity/Llama-2-7B-instruct-text2sql": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "yanismiraoui/Mistral-7B-OpenOrca-sharded": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "yanismiraoui/dolphin-2.2.1-mistral-7b-sharded": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "rcherukuri14/autotrain-merged-multiple-choice": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "joyfine/vicuna-7b-fine-tuning_SST_20": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "akahana/harry-potter-gpt2": [
    "model.safetensors"
  ],
  "devhyun88/ku-mistral-7b-PGO-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "adonlee/LLaMA_2_13B_SFT_v1.5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "NurtureAI/openchat_3.5-16k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Sombressoul/Yi-34B-200K-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TinyPixel/stablelm-base-alpha-3b-v2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "DeepMount00/Mistral-Ita-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "thanhnew2001/starcoder-7b-taipy2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "khanhnto/khanhexp": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Nanbeige/Nanbeige-16B-Chat": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "Nanbeige/Nanbeige-16B-Base": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "binqiangliu/myLlama2Model": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "neneongkorea/remon-polyglot-1.3b-qlora": [
    "adapter_model.safetensors"
  ],
  "jbochi/madlad400-8b-lm": [
    "model-00000-of-00007.safetensors",
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "fenrirgochad/Llama-2-13b-chat-hf-sharded-bf16-3GB": [
    "model.safetensors"
  ],
  "openerotica/basilisk-7b-v0.2-EXL2-4.85-bpw": [
    "output.safetensors"
  ],
  "openerotica/basilisk-7b-v0.2-EXL2-6-bpw": [
    "output.safetensors"
  ],
  "openerotica/basilisk-7b-v0.2-EXL2-8-bpw": [
    "output.safetensors"
  ],
  "TheBloke/Thespis-13B-v0.6-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Thespis-13B-v0.6-GPTQ": [
    "model.safetensors"
  ],
  "fenrirgochad/Llama-2-13b-chat-hf-sharded-bf16-4GB": [
    "model.safetensors"
  ],
  "Gopikrishna/distilgpt2-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "LeoLM/leo-hessianai-70b": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "TheBloke/Psyfighter-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Psyfighter-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/LLaMA2-13B-TiefighterLR-AWQ": [
    "model.safetensors"
  ],
  "g-ronimo/llama-fridman": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jacobhoffmann/testmodel": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/LLaMA2-13B-TiefighterLR-GPTQ": [
    "model.safetensors"
  ],
  "NobodyExistsOnTheInternet/Yi-34B-GiftedConvo-merged": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "fenrirgochad/Llama-2-7b-chat-hf-sharded-bf16-5GB-sharded-bf16-4GB": [
    "model.safetensors"
  ],
  "TheBloke/dolphin-2.2-70B-GPTQ": [
    "model.safetensors"
  ],
  "GabSo/santacoder-finetuned-robot3": [
    "model.safetensors"
  ],
  "waldie/mythospice-limarp-70b-2.4bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "Superflows/Superflows-1": [
    "adapter_model.safetensors"
  ],
  "lewtun/zephyr-7b-sft": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "isek-ai/SDPrompt-RetNet-300M": [
    "model.safetensors"
  ],
  "Jungtek/llama2-fine-tuned-apr-v2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "lomahony/pythia-2.8b-helpful-sft": [
    "model.safetensors"
  ],
  "Keynote-Technology/KAI-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "waldie/Trion-M-7b-8bpw-h8-exl2": [
    "output.safetensors"
  ],
  "stabilityai/codellama13b_instruct_260k_synthesis": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "harpreetsahota/DeciLM-6B-qlora-blog-post": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "GabSo/santacoder-finetuned-robot4": [
    "model.safetensors"
  ],
  "NurtureAI/openchat_3.5-16k-4bit-gptq": [
    "model.safetensors"
  ],
  "Azurro/APT3-500M-Base": [
    "model.safetensors"
  ],
  "geroldcsendes/sft-hh-rlhf": [
    "model.safetensors"
  ],
  "jacobhoffmann/Mistral-7B-TestGen-Dart_v0.5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "waldie/Yi-34B-GiftedConvo-merged-4bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "yetanotherhif/jmg_mistral_7b_code": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "E-Hospital/open-orca-platypus-2-lora-latest": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "unionai/llm-model-llama2-demo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lcw99/llama2-ko-chang-13b-instruct-chat": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jerrykur/distilgpt2-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "Undi95/Dawn-v2-70B-2.55bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "NurtureAI/openchat_3.5-16k-awq": [
    "model.safetensors"
  ],
  "maritaca-ai/sabia-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "unionai/llm-llama2-finetuning-demo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AzureBlack/Dawn-v2-70B-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "lewtun/zephyr-7b-dpo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "grimpep/m": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "poedator/opt-125m-bnb-4bit": [
    "model.safetensors"
  ],
  "baseball46245/Mistral-7B-v0.1-sharded": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "TheBloke/Yi-34B-GiftedConvo-merged-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Yi-34B-GiftedConvo-merged-GPTQ": [
    "model.safetensors"
  ],
  "Keynote-Technology/TinyKAI-1B-v0.1": [
    "model.safetensors"
  ],
  "TheBloke/KAI-7B-beta-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/KAI-7B-beta-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/KAI-7B-Instruct-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/opus-v0-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/opus-v0-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/KAI-7B-Instruct-GPTQ": [
    "model.safetensors"
  ],
  "keylazy/Llama-2-7b-chat-hf-ark": [
    "model.safetensors"
  ],
  "ShiveringSpine/Euryale-1.4-L2-70B-5.0bpw-h6-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "tokxun/demo-1109": [
    "model.safetensors"
  ],
  "rizkyjun/bloom-1b-finetuned-aings-delimiter-2": [
    "model.safetensors"
  ],
  "mtc/LeoLM-leo-mistral-hessianai-7b-classification-with-explanation-3-epochs-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rizkyjun/bloom-1b-finetuned-aings-delimiter-4": [
    "model.safetensors"
  ],
  "rizkyjun/bloom-1b-finetuned-aings-delimiter-3": [
    "model.safetensors"
  ],
  "rizkyjun/bloom-1b-finetuned-aings-delimiter-1": [
    "model.safetensors"
  ],
  "ndubey/codellama2-finetuned-codex": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sue3489/test0_llama2-fine-tuned-dolly-15k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "phatjk/vietcuna-3b-v2-AWQ": [
    "model.safetensors"
  ],
  "IHaBiS/Synatra-7B-v0.3-dpo-exl2": [
    "output.safetensors"
  ],
  "tqgminh/Llama-2-7b-chat-hf-8bit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Manoj120/final-base-model": [
    "model.safetensors"
  ],
  "nghiadanh26/distilgpt2-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "crodri/aguila_falcon_InstruCATPlus": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "nero1342/MetaMath-Mistral-7B-sharded": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "czham/DialoGPT-small-dob": [
    "model.safetensors"
  ],
  "mhenrichsen/hestenettetLM": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "michaelbenayoun/mistral-tiny-4layers-8kv-heads-random": [
    "model.safetensors"
  ],
  "LouisVanLangendonck/llama-2-7b-network-traffic-generation_v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "opsci/92izai": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "desarrolloasesoreslocales/finetuning_mistral_merged3": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "jcolab5/Llama-2-7b-chat-hf-fine-tuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "alignment-handbook/zephyr-7b-sft-full": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "zuu/phi-1_5-finetuned-sql-injection": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/goliath-120b-AWQ": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "TheBloke/goliath-120b-GPTQ": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "mesolitica/tinyllama-1.1b-4096-fpf": [
    "model.safetensors"
  ],
  "npvinHnivqn/phi-1_5-finetuned-gsm8k": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "lewtun/zephyr-7b-dpo-full": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "bradmin/sft_trl_200": [
    "model.safetensors"
  ],
  "Sombressoul/Yi-6B-200K-AWQ": [
    "model.safetensors"
  ],
  "LoneStriker/Yi-34B-GiftedConvo-merged-3.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/Yi-34B-GiftedConvo-merged-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "joyfine/vicuna-7b-fine-tuning_Finance_20": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Yi-34B-GiftedConvo-merged-5.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Yi-34B-GiftedConvo-merged-6.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "hamayun7333/opt-125m-gptq-4bit": [
    "model.safetensors"
  ],
  "LoneStriker/Yi-34B-GiftedConvo-merged-8.0bpw-h8-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "TheBloke/Dolphin2.1-OpenOrca-7B-AWQ": [
    "model.safetensors"
  ],
  "erfanzar/LinguaMatic-Tiny": [
    "model.safetensors"
  ],
  "erfanzar/LinguaMatic": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "TheBloke/MonadGPT-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/MonadGPT-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/dolphin-2.2-70B-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Dolphin2.1-OpenOrca-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Trion-M-7B-AWQ": [
    "model.safetensors"
  ],
  "Doctor-Shotgun/SynthIA-v1.5-limarpv3-70B": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "TheBloke/Trion-M-7B-GPTQ": [
    "model.safetensors"
  ],
  "preetk21/my_awesome_eli5_clm-model": [
    "model.safetensors"
  ],
  "GPIPLD/PT1_Deploy": [
    "checkpoint-3500/model.safetensors",
    "model.safetensors"
  ],
  "Keynote-Technology/TinyKAI-3B-v0.1": [
    "model.safetensors"
  ],
  "Brandoko/CodeLlama-34b-Recharts-v2-adapter": [
    "adapter_model.safetensors"
  ],
  "kangkbl/DialoGPT-medium-chizuru": [
    "model.safetensors"
  ],
  "samgebra/DialoGPT-small": [
    "model.safetensors"
  ],
  "Brandoko/CodeLlama-34b-Recharts-v2": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "Kekelilii/llama-2-7b-chat-morpheme": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "prnv19/MetaMathMistral7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "firef1i/finbasic-llama2-13b": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "PiyushLavaniya/Llama2_Banker": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "lectura/TinyLlama-120M-news-counsel-lr1e-5": [
    "checkpoint-105/model.safetensors",
    "checkpoint-113/model.safetensors",
    "checkpoint-121/model.safetensors",
    "checkpoint-130/model.safetensors",
    "checkpoint-138/model.safetensors",
    "checkpoint-146/model.safetensors",
    "checkpoint-154/model.safetensors",
    "checkpoint-16/model.safetensors",
    "checkpoint-162/model.safetensors",
    "checkpoint-170/model.safetensors",
    "checkpoint-178/model.safetensors",
    "checkpoint-24/model.safetensors",
    "checkpoint-32/model.safetensors",
    "checkpoint-40/model.safetensors",
    "checkpoint-48/model.safetensors",
    "checkpoint-56/model.safetensors",
    "checkpoint-65/model.safetensors",
    "checkpoint-73/model.safetensors",
    "checkpoint-8/model.safetensors",
    "checkpoint-81/model.safetensors",
    "checkpoint-89/model.safetensors",
    "checkpoint-97/model.safetensors",
    "model.safetensors"
  ],
  "Jungtek/mistral-fine-tuned-samchully": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sue3489/test1_llama2-fine-tuned-dolly-15k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TinyPixel/llama-2-ft": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "TheBloke/dolphin-2.2.1-AshhLimaRP-Mistral-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/dolphin-2.2.1-AshhLimaRP-Mistral-7B-AWQ": [
    "model.safetensors"
  ],
  "kangkbl/DialoGPT-large-chizuru": [
    "model.safetensors"
  ],
  "bongchoi/MoMo-70B-V1.0": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "bongchoi/MoMo-70B-V1.1": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-babylm-no_aann-all-det-removal-1e-3": [
    "model.safetensors"
  ],
  "alignment-handbook/zephyr-7b-dpo-full": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FPHam/Generate_Question_Mistral_7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "RJuro/kanelsnegl-v0.1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "blueapple8259/ANHSY_0.1": [
    "model.safetensors"
  ],
  "TheBloke/claude2-alpaca-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/claude2-alpaca-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/claude2-alpaca-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/claude2-alpaca-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Yi-6B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Yi-6B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Yi-34B-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "lIlBrother/llama2-merge-v0.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lIlBrother/llama2-merge-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "PTU-AI-CLUB/UnoLineGPT": [
    "model.safetensors"
  ],
  "nainakader/QAModel": [
    "model.safetensors"
  ],
  "simonycl/data_selection_Llama-2-7b-hf-sharegpt_lora_step_2000": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "abneraigc/llama2finetune_demo": [
    "adapter_model.safetensors",
    "checkpoint-4/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "abneraigc/Llama-2-7b-chat-hf-finetune_v1": [
    "adapter_model.safetensors",
    "checkpoint-4/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Spleonard1/my_awesome_eli5_clm-model": [
    "model.safetensors"
  ],
  "Spleonard1/my_awesome_eli5_clm_model": [
    "model.safetensors"
  ],
  "dreamgen/opus-v0-7b-awq": [
    "model.safetensors"
  ],
  "Sakshi1307/llama-2-7b-finetuned-sutton-credit3": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "KalbeDigitalLab/alpara-7b-peft": [
    "adapter_model.safetensors"
  ],
  "TheBloke/prometheus-13B-v1.0-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/prometheus-13B-v1.0-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Yi-34B-200K-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/prometheus-7B-v1.0-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/prometheus-7B-v1.0-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Yi-34B-200K-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Yi-6B-200K-AWQ": [
    "model.safetensors"
  ],
  "KnutJaegersberg/Deacon-34B-200k": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "Loewolf/GPT_1": [
    "model.safetensors"
  ],
  "lixinran0809/my-model2": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "jiuhai/zephyr-7b-dpo-lora": [
    "adapter_model.safetensors"
  ],
  "TheBloke/Yi-6B-200K-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/openchat_3.5-16k-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/openchat_3.5-16k-GPTQ": [
    "model.safetensors"
  ],
  "Doctor-Shotgun/airoboros-2.2.1-y34b": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "lIlBrother/llama2-merge-v0.3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Doctor-Shotgun/airoboros-2.2.1-limarpv3-y34b": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "blueapple8259/ANHSY_test": [
    "model.safetensors"
  ],
  "KnutJaegersberg/Deacon-34B-200k-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mjphayes/distilgpt2-lfqa": [
    "model.safetensors"
  ],
  "AetiusBaltimore/DialoGPT-medium-Gabumon": [
    "model.safetensors"
  ],
  "jojo0217/test_1.3b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "larryvrh/Yi-6B-200K-Llamafied": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/openchat_3.5-16k-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/openchat_3.5-16k-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/openchat_3.5-16k-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "minhcrafters/gpt2-ai-challenge": [
    "model.safetensors"
  ],
  "LoneStriker/openchat_3.5-16k-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "joyfine/vicuna-7b-fine-tuning_QA_SST_20": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mzbac/CodeLlama-34b-guanaco-awq": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/openchat_3.5-16k-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "TinyPixel/stablelm-ft": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "khanhj/bkai-vi-llama2-7b-40GB-batrianx-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-babylm-no_aann-all-det-removal-3e-3": [
    "model.safetensors"
  ],
  "1TuanPham/Instruct-vietnamese-llama2-7b-bkai": [
    "model-00001-of-00016.safetensors",
    "model-00002-of-00016.safetensors",
    "model-00003-of-00016.safetensors",
    "model-00004-of-00016.safetensors",
    "model-00005-of-00016.safetensors",
    "model-00006-of-00016.safetensors",
    "model-00007-of-00016.safetensors",
    "model-00008-of-00016.safetensors",
    "model-00009-of-00016.safetensors",
    "model-00010-of-00016.safetensors",
    "model-00011-of-00016.safetensors",
    "model-00012-of-00016.safetensors",
    "model-00013-of-00016.safetensors",
    "model-00014-of-00016.safetensors",
    "model-00015-of-00016.safetensors",
    "model-00016-of-00016.safetensors"
  ],
  "LoneStriker/airoboros-2.2.1-y34b-3.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/airoboros-2.2.1-y34b-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "SeanZhan2014/distilgpt2-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "LoneStriker/airoboros-2.2.1-y34b-5.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "Neutrophil/DialoGPT-medium-severussnape": [
    "model.safetensors"
  ],
  "communityai/apt-chat-yi-6b-sft-full": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Dummy3021/llama_fine_tuned": [
    "model.safetensors"
  ],
  "TheBloke/cat-v1.0-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/cat-v1.0-13B-GPTQ": [
    "model.safetensors"
  ],
  "dreamgen/opus-v0-70b-awq": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "Loewolf/GPT_1.2": [
    "model.safetensors"
  ],
  "gizmo-ai/split-up-llama-7b-awq-with-config": [
    "model.safetensors"
  ],
  "benchang1110/GPT2-finetune": [
    "model.safetensors"
  ],
  "leonvanbokhorst/Llama-2-7b-chat-hf-fine-tuned-V1b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "DaertML/LLaMA-Turrera-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "gizmo-ai/split-up-llama-7b-GPTQ-4bit": [
    "model.safetensors"
  ],
  "Loewolf/GPT_1.5": [
    "model.safetensors"
  ],
  "LoneStriker/airoboros-2.2.1-y34b-6.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "DaertML/Aristotle-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Jaredquek/EdTech2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "DaertML/Plato-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/airoboros-2.2.1-y34b-8.0bpw-h8-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "GeneZC/MiniMA-3B": [
    "model.safetensors"
  ],
  "NeerajG03/llama2-7b-rsrch-fintune": [
    "model.safetensors"
  ],
  "leonvanbokhorst/Llama-2-7b-chat-hf-fine-tuned-V1c": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "OneJz/tomato-8b": [],
  "GeneZC/MiniChat-3B": [
    "model.safetensors"
  ],
  "rizkyjun/bloom-7b-finetuned-aings-1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SebastianSchramm/tinyllama-1.1B-intermediate-step-715k-1.5T-sft-lora": [
    "adapter_model.safetensors"
  ],
  "TheBloke/Yi-34B-200K-Llamafied-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Yi-34B-200K-Llamafied-GPTQ": [
    "model.safetensors"
  ],
  "blueapple8259/ANHSY_test2": [
    "model.safetensors"
  ],
  "borkh/pythia-70m-sft-0": [
    "model.safetensors"
  ],
  "erfanvaredi/zephyr-7b-customer-support-finetuned0": [
    "adapter_model.safetensors",
    "checkpoint-434/adapter_model.safetensors"
  ],
  "actionpace/EvolCodeLlama-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "gizmo-ai/q-and-a-llama-7b-GPTQ-4bit": [
    "model.safetensors"
  ],
  "Prompt48/Mistral-7B-v0.1-fine-tuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "pandarosso/it-llma-chatbot": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "gizmo-ai/incorrect-answers-llama-7b-GPTQ-4bit": [
    "model.safetensors"
  ],
  "sebastiandizon/magpie-2-7b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "joyfine/vicuna-7b-fine-tuning_QA_Finance_5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Weyaxi/Nebula-v2-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ataerdemm/Blyne-nonmerged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "iashchak/saiga_mistral_7b_lora-merged": [
    "model.safetensors"
  ],
  "Mlxa/wizard-1": [
    "model.safetensors"
  ],
  "joyfine/vicuna-7b-fine-tuning_QA_Finance_20": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "waldie/airoboros-2.2.1-limarpv3-y34b-4bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "TourDeFedya/git-base-phone-cases": [
    "model.safetensors"
  ],
  "TheBloke/Mistral-7B-OpenOrca-oasst_top1_2023-08-25-v1-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Mistral-7B-OpenOrca-oasst_top1_2023-08-25-v1-GPTQ": [
    "model.safetensors"
  ],
  "iblai/ibl-tutoring-chat-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Advaith28/Linear_pruned_RedPajama3B": [
    "model.safetensors"
  ],
  "tim9510019/Mistral-7B-Economic_zephyr_231105": [
    "adapter_model.safetensors"
  ],
  "AzureBlack/Augmental-Unholy-13b-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Neutrophil/DialoGPT-medium-dracomalfoy": [
    "model.safetensors"
  ],
  "pkarypis/zephyr-7b-sft-full": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "chargoddard/recent-basement": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "bugs152/merged-large-v3-finetuned": [
    "model.safetensors"
  ],
  "TinyPixel/stablelm-ft2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "borkh/pythia-70m-sft-function-calling": [
    "model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-babylm-no_aann-all-det-removal-1e-4": [
    "model.safetensors"
  ],
  "mjphayes/distilgpt2-finetuned-textbook_dataset": [
    "model.safetensors"
  ],
  "Prompt48/Mistral-7B-Instruct-v0.1-fine-tuned-V1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TinyPixel/stablelm-ft3": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Weyaxi/Platypus-Nebula-v2-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "thanhnew2001/starcoder-7b-taipy5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Weyaxi/SynthIA-v1.3-Nebula-v2-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Weyaxi/Dolphin-2.0-Nebula-v2-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Weyaxi/Dans-TotSirocco-Nebula-v2-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hakurei/mommygpt-3B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Weyaxi/OpenHermes-2.5-Nebula-v2-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Weyaxi/OpenHermes-2-Nebula-v2-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SebastianSchramm/tinyllama-1.1B-intermediate-step-715k-1.5T-sft-lora-merged": [
    "model.safetensors"
  ],
  "Heralax/Augmental-ReMM-13b-Merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SebastianSchramm/tinyllama-1.1B-intermediate-step-715k-1.5T-dpo-lora": [
    "adapter_model.safetensors"
  ],
  "Weyaxi/zephyr-alpha-Nebula-v2-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Weyaxi/Mistralic-1-Nebula-v2-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Weyaxi/zephyr-beta-Nebula-v2-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "bonobono612/codeparrot": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Augmental-ReMM-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Augmental-ReMM-13B-GPTQ": [
    "model.safetensors"
  ],
  "bonobono612/codeparrot-small": [
    "model.safetensors"
  ],
  "rathi2023/Zephyr-finetuned-MergedAdapter1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rizkyjun/bloom-1b-finetuned-aings-chat-1": [
    "model.safetensors"
  ],
  "rizkyjun/bloom-1b-finetuned-aings-chat-2": [
    "model.safetensors"
  ],
  "rizkyjun/bloom-1b-finetuned-aings-chat-3": [
    "model.safetensors"
  ],
  "AzureBlack/Augmental-ReMM-13b-Merged-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "blueapple8259/ANHSY_half_0.2": [
    "model.safetensors"
  ],
  "winglian/mistral-11b-128k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "1TuanPham/MetaMath-Mistral-7B-900MB-sharded": [
    "model-00001-of-00017.safetensors",
    "model-00002-of-00017.safetensors",
    "model-00003-of-00017.safetensors",
    "model-00004-of-00017.safetensors",
    "model-00005-of-00017.safetensors",
    "model-00006-of-00017.safetensors",
    "model-00007-of-00017.safetensors",
    "model-00008-of-00017.safetensors",
    "model-00009-of-00017.safetensors",
    "model-00010-of-00017.safetensors",
    "model-00011-of-00017.safetensors",
    "model-00012-of-00017.safetensors",
    "model-00013-of-00017.safetensors",
    "model-00014-of-00017.safetensors",
    "model-00015-of-00017.safetensors",
    "model-00016-of-00017.safetensors",
    "model-00017-of-00017.safetensors"
  ],
  "vivym/llava-baichuan2-7b": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "waldie/U-Amethyst-20B-4bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "DILAB-HYU/koquality-polyglot-12.8b": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "actionpace/Kimiko-v2-13B-mergetest": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ColleenMacklin/gpt-neo-125M-couples_therapist_full_renamed": [
    "model.safetensors"
  ],
  "AzureBlack/TimeCrystal-l2-13B-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002-001.safetensors"
  ],
  "TinyPixel/lima-3b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "actionpace/limarp-llama2-mergetest": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ailments/gpt-neo-125M-couples_therapist_full_renamed": [
    "model.safetensors"
  ],
  "PhantHive/bigbrain": [
    "adapter_model.safetensors"
  ],
  "actionpace/limarp-llama2-v2-mergetest": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "actionpace/LimaRP-Llama2-13B-v3-EXPERIMENT-mergetest": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "lionelchg/zephyr-7b-sft-lora": [
    "adapter_model.safetensors"
  ],
  "LoneStriker/Thespis-13b-v0.6-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Thespis-13b-v0.6-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Thespis-13b-v0.6-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "actionpace/Llama2-13B-no_robots-alpaca-lora-mergetest": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/Thespis-13b-v0.6-6.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/Thespis-13b-v0.6-8.0bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "actionpace/Chronos-Hermes-2-Storywriter-mergetest": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "TheBloke/Noromaid-13B-v0.1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Noromaid-13B-v0.1-AWQ": [
    "model.safetensors"
  ],
  "notzero/deepseek_sharded": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "allenai/tulu-2-dpo-70b": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "kaizerBox/retnet-summarization_small": [
    "model.safetensors"
  ],
  "mesolitica/malaysian-tinyllama-1.1b-16k-instructions": [
    "model.safetensors"
  ],
  "iblai/ibl-tutoring-7B-128k": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Macky3/sft_doors_results_2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "devhyun88/ku-mistral-7b-PGO-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "DonatePlz/openchat_3.5-16k-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "NeverSleep/Noromaid-13b-v0.1.1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ejunlee/Finetune_LmHead_Bloom_1b1": [
    "model.safetensors"
  ],
  "rjiang121/llama-2-7b-chat-IAB": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FPHam/Writing_Partner_Mistral_7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Macky3/sft_doors_results_3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Macky3/llama-doors-dpo-sft-merge-4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "bingha33/llama2-sftD": [
    "model-00001-of-00003.safetensors",
    "model-00001-of-00028.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00002-of-00028.safetensors",
    "model-00003-of-00003.safetensors",
    "model-00003-of-00028.safetensors",
    "model-00004-of-00028.safetensors",
    "model-00005-of-00028.safetensors",
    "model-00006-of-00028.safetensors",
    "model-00007-of-00028.safetensors",
    "model-00008-of-00028.safetensors",
    "model-00009-of-00028.safetensors",
    "model-00010-of-00028.safetensors",
    "model-00011-of-00028.safetensors",
    "model-00012-of-00028.safetensors",
    "model-00013-of-00028.safetensors",
    "model-00014-of-00028.safetensors",
    "model-00015-of-00028.safetensors",
    "model-00016-of-00028.safetensors",
    "model-00017-of-00028.safetensors",
    "model-00018-of-00028.safetensors",
    "model-00019-of-00028.safetensors",
    "model-00020-of-00028.safetensors",
    "model-00021-of-00028.safetensors",
    "model-00022-of-00028.safetensors",
    "model-00023-of-00028.safetensors",
    "model-00024-of-00028.safetensors",
    "model-00025-of-00028.safetensors",
    "model-00026-of-00028.safetensors",
    "model-00027-of-00028.safetensors",
    "model-00028-of-00028.safetensors"
  ],
  "pszemraj/perSLIMmon-8b-base": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-babylm-no_aann-all-det-removal-3e-4": [
    "model.safetensors"
  ],
  "Radiantloom/radiantloom-email-assist-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LDCC/LDCC-Instruct-Llama-2-ko-13B-v1.5": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LDCC/LDCC-Instruct-Llama-2-ko-13B-v1.6": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "rizkyjun/bloom-7b-finetuned-aings-3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rizkyjun/bloom-7b-finetuned-aings-2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "anaviclaniba/mistral-7b-tr": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TinyPixel/lima-2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Balachandar/Mistral-7B-Instruct-v0.1-sharded-fine-tuned-V1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Vikas-03/OpenLLaMA-Quote-3B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Wernicke/AWQ-OPT1.3b": [
    "model.safetensors"
  ],
  "mohan007/Qwen-VL-Chat-Int4": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "LI-ST/Mistral-7B-ko-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "pankajemplay/llama-2-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "npvinHnivqn/phi-1_5-finetuned-mm": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "benchang1110/GPT2-QA": [
    "model.safetensors"
  ],
  "Pennywise881/clm_model": [
    "model.safetensors"
  ],
  "jyoon/mistralai-samchully_summary_330": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Darshankumar/git-base-pokemon": [
    "model.safetensors"
  ],
  "khanhnto/testno2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "0x7o/bashirovGPT-medium": [
    "model.safetensors"
  ],
  "FlorianD/outbound-message-ds": [
    "model.safetensors"
  ],
  "Godwin024/my_mailing_model": [
    "adapter_model.safetensors"
  ],
  "rjiang121/llama-2-7b-chat-IAB-5k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "CreatorPhan/anhpn-7b1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sansanai/wigo_llama2_ko_7b_sft": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "CreatorPhan/anhpn-7b1-8bit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Kaspar/QueerGPT2": [
    "model.safetensors"
  ],
  "jiguanglizipao/chatglm2-6b-port-llama": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "suzushi/luojiu-7b_Tokenize_stage": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Varun1808/llama_sql_new": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "HossainRabby/finetuned": [
    "model.safetensors"
  ],
  "TinyPixel/everythinglm-3b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "clibrain/Llama-2-7b-ft-instruct-es-sharded-bf16": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "Wernicke/AWQ-OPT2.7b": [
    "model.safetensors"
  ],
  "TheBloke/Nous-Capybara-34B-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Nous-Capybara-34B-GPTQ": [
    "model.safetensors"
  ],
  "SebastianSchramm/tinyllama-1.1B-intermediate-step-715k-1.5T-dpo-lora-merged": [
    "model.safetensors"
  ],
  "ericpolewski/Marxish": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/dolphin-2_2-yi-34b-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "kev216/Llama-2-7b-hf": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/dolphin-2_2-yi-34b-GPTQ": [
    "model.safetensors"
  ],
  "Macky3/llama-doors-ppo-sft-merge": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "HeavenlyJoe/Mistral-7B-v0.1-Glossary-Extraction": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Macky3/llama-doors-ppo-sft-merge-2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "KoboldAI/LLaMA2-13B-Psyfighter2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Kooten/Noromaid-13b-v0.1.1-8bpw-h8-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "Walmart-the-bag/Misted-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Macky3/llama-doors-ppo-base-merge": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Noromaid-13B-v0.1.1-AWQ": [
    "model.safetensors"
  ],
  "AzureBlack/Eileithyia-13B-exl2": [
    "output-00001-of-00002-001.safetensors",
    "output-00002-of-00002-002.safetensors"
  ],
  "Macky3/llama-doors-ppo-base-merge-2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Synatra-7B-v0.3-RP-AWQ": [
    "model.safetensors"
  ],
  "Kooten/Noromaid-13b-v0.1.1-3bpw-h8-exl2": [
    "output.safetensors"
  ],
  "Keynote-Technology/TinyKAI-0.7B-v0.1": [
    "model.safetensors"
  ],
  "AzureBlack/Noromaid-13b-v0.1.1-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "TheBloke/speechless-mistral-dolphin-orca-platypus-samantha-7B-AWQ": [
    "model.safetensors"
  ],
  "haoranz/open_llama_13b-int4": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "chargoddard/Yi-6B-200K-Llama": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "daekeun-ml/Llama-2-ko-OpenOrca-gugugo-13B": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "TheBloke/Synatra-7B-v0.3-RP-GPTQ": [
    "model.safetensors"
  ],
  "chargoddard/Yi-6B-Llama": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Noromaid-13B-v0.1.1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/speechless-mistral-dolphin-orca-platypus-samantha-7B-GPTQ": [
    "model.safetensors"
  ],
  "chargoddard/Yi-34B-200K-Llama": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "jolual2747/experiments": [
    "adapter_model.safetensors"
  ],
  "Cueet/Llama-movie": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jolual2747/falcon7b-ecommerce": [
    "adapter_model.safetensors"
  ],
  "DonatePlz/openchat_3.5-16k-merged-AWQ": [
    "model.safetensors"
  ],
  "temporary0-0name/run_opt": [
    "model.safetensors"
  ],
  "temporary0-0name/rand_model": [
    "model.safetensors"
  ],
  "bingha33/llama2-sftJ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rchadha134/no_robots": [
    "adapter_model.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "magnetic/zephyr-7b-sft-full": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "makedelta/MD_llama": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "aioshu/mistral_7b-instruct_sharded_pharama": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Intel/neural-chat-7b-v3-1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "rjiang121/llama-2-7b-chat-IAB-1k-1kToken": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Kooten/Noromaid-13b-v0.1.1-4bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "SebastianSchramm/tinyllama-1.1B-intermediate-step-715k-1.5T-dpo-lora-v2": [
    "adapter_model.safetensors"
  ],
  "Herman555/Synatra-v0.3-RP-AshhLimaRP-Mistral-7B-GGUF": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "nnpy/Nape-0": [
    "model.safetensors"
  ],
  "greyfoss/codeparrot-ds": [
    "model.safetensors"
  ],
  "dweeb/Yarn-Mistral-FT-Med-7b-128k": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Heralax/Augmental-Shuffled-Merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "CamilleBorrett/llama-2-7b-chat-fine-tune-test": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "faisalahmedsifat/bloom-3b-bangla-hasib-pretrained": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Claire-7B-0.1-GPTQ": [
    "model.safetensors"
  ],
  "TommyBark/finetuned_llama_7b_SE_micro": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "faisalahmedsifat/bloom-3b-bangla-hasib-convo-pretrained": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "faisalahmedsifat/llama2-7b-chat-hf-base-pretrained": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBlokeAI/llama-68m-GPTQ-sharded": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/TransNormerLLM-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Claire-7B-0.1-AWQ": [
    "model.safetensors"
  ],
  "ostorc/Isaac_Asimov_Spanish_GPT": [
    "model.safetensors"
  ],
  "mostafaamiri/llama_base_7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Tatvajsh/AHS_OPS_and_WPCS_MERGED_V_1.0": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/opus-v0-70B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/opus-v0-70B-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "presencesw/Mistral-7B-question-decomposition": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AnyaSchen/saiga2_70b_merged": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "ramgathreya/mistral-7b-instruct-safetensors": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AzureBlack/Nous-Capybara-34B-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005-004.safetensors",
    "output-00003-of-00005-003.safetensors",
    "output-00004-of-00005-005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "CallMeMrFern/Llama-2-7b-chat-hf_vn": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "tanliboy/CodeLlama-13b-Instruct-hf": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "mickume/alt_tentacles_mistral_7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "piotr-ai/polanka-7b-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mickume/alt_nsfw_mistral_7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Loewolf/GPT_1.5-medium": [
    "model.safetensors"
  ],
  "mickume/alt_fantasy_mistral_7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Nondzu/zephyr-7b-beta-pl": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mickume/alt_pantheon_mistral_7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Python-Code-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Python-Code-33B-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "attkap/test_model": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mrbmaryam/samp": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "bhardwaj08/llama_2_SQL": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "stas/tiny-random-llama-2": [
    "model.safetensors"
  ],
  "SebastianSchramm/tinyllama-1.1B-intermediate-step-715k-1.5T-dpo-lora-v2-merged": [
    "model.safetensors"
  ],
  "Panchovix/opus-v0-70b-safetensors": [
    "pytorch_model-00001-of-00015.safetensors",
    "pytorch_model-00002-of-00015.safetensors",
    "pytorch_model-00003-of-00015.safetensors",
    "pytorch_model-00004-of-00015.safetensors",
    "pytorch_model-00005-of-00015.safetensors",
    "pytorch_model-00006-of-00015.safetensors",
    "pytorch_model-00007-of-00015.safetensors",
    "pytorch_model-00008-of-00015.safetensors",
    "pytorch_model-00009-of-00015.safetensors",
    "pytorch_model-00010-of-00015.safetensors",
    "pytorch_model-00011-of-00015.safetensors",
    "pytorch_model-00012-of-00015.safetensors",
    "pytorch_model-00013-of-00015.safetensors",
    "pytorch_model-00014-of-00015.safetensors",
    "pytorch_model-00015-of-00015.safetensors"
  ],
  "gsomers-smarsh/distilgpt2-tweetsumm-finetune": [
    "model.safetensors"
  ],
  "TheBloke/Python-Code-13B-GPTQ": [
    "model.safetensors"
  ],
  "LoneStriker/Euryale-1.3-limarpv3-L2-70B-2.4bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "TheBloke/ShiningValiantXS-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/DaringFortitude-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Python-Code-33B-GPTQ": [
    "model.safetensors"
  ],
  "LoneStriker/Euryale-1.3-limarpv3-L2-70B-4.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "IHaBiS/Nethena-MLewd-Xwin-23B-3.8bpw-h8-exl2-pippa": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "joyfine/vicuna-7b-fine-tuning_QA_SST_20_2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "xwar/ninox-code-llama-instruct": [
    "adapter_model.safetensors",
    "checkpoint-189/adapter_model.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "dongwang218/zephyr-7b-sft-full": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "NurtureAI/SynthIA-7B-v2.0-16k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dhuynh95/BioMedGPT-LM-7B-hf-gptq": [
    "model.safetensors"
  ],
  "NurtureAI/SynthIA-7B-v2.0-16k-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Euryale-1.3-limarpv3-L2-70B-3.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "TheBloke/DaringFortitude-GPTQ": [
    "model.safetensors"
  ],
  "LoneStriker/Euryale-1.3-limarpv3-L2-70B-2.55bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "RaftDS/llama-2-13b-bank-learned-poisoned": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "attkap/test_model_2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AzureBlack/opus-v0-70b-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "TheBloke/ShiningValiantXS-GPTQ": [
    "model.safetensors"
  ],
  "jingyeom/seal3.1.3_ia3": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "wngkdud/llama2_koen_13b_SFTtrain": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lixinran0809/my-model900": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "newbiettn/codeLlama-7b-hf-fine-tuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ArtifactAI/phi-arxiv-physics-instruct": [
    "model.safetensors"
  ],
  "wooho/fancy-bullfrog": [
    "model.safetensors"
  ],
  "panigrah/winberto-gpt2": [
    "model.safetensors"
  ],
  "dongwang218/zephyr-7b-dpo-full": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "joyfine/vicuna-7b-fine-tuning_QA_Finance_20_2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "abhinavztb/llama2-CL-Nov-full": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "NurtureAI/neural-chat-7b-v3-16k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "NurtureAI/neural-chat-7b-v3-16k-AWQ": [
    "model.safetensors"
  ],
  "lixinran0809/my-model700": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "objects76/Llama-2-7b-chat-hf-function-calling-v2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "lixinran0809/my-model600": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "abneraigc/CodeLlama-7b-Instruct-hf-finetune_text2sql": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "NurtureAI/zephyr-7b-beta-16k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "NurtureAI/zephyr-7b-beta-16k-AWQ": [
    "model.safetensors"
  ],
  "dickheadmorron12/nlpchatbot-gpt2": [
    "model.safetensors"
  ],
  "habanoz/TinyLlama-1.1B-Chat-v0.3-GPTQ": [
    "model.safetensors"
  ],
  "NurtureAI/neural-chat-7b-v3-1-16k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "NurtureAI/neural-chat-7b-v3-1-16k-AWQ": [
    "model.safetensors"
  ],
  "lixinran0809/my-model1200": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "pankajemplay/llama-2-finetuned-1615": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TanJing/zephyr-7b-sft-lora": [
    "adapter_model.safetensors"
  ],
  "ArtifactAI/phi-arxiv-math-instruct": [
    "model.safetensors"
  ],
  "KnutJaegersberg/MistralInstructLongish": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "attkap/test_model_3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "vinhtran2611/opt-125m-awq": [
    "model.safetensors"
  ],
  "TheBloke/SynthIA-7B-v2.0-16k-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/SynthIA-7B-v2.0-16k-GPTQ": [
    "model.safetensors"
  ],
  "LoneStriker/ShiningValiantXS-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "jacobhoffmann/Mistral-7B-TestGen-Dart_v0.6": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hllj/zephyr-7b-beta-vi-math": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/ShiningValiantXS-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/ShiningValiantXS-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "harryng4869/codellama-2-7b-mini-sql": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/ShiningValiantXS-6.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "0x7o/rugpt3medium": [
    "model.safetensors"
  ],
  "LoneStriker/ShiningValiantXS-8.0bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "TheBloke/zephyr-7B-beta-pl-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/zephyr-7B-beta-pl-AWQ": [
    "model.safetensors"
  ],
  "skshreyas714/autocomplete-rogers-zephyr": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "0x7o/bashirovGPT-medium-v2": [
    "model.safetensors"
  ],
  "TheBloke/Tess-XL-v1.0-GPTQ": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "TheBloke/Tess-XL-v1.0-AWQ": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "BM-K/llama-2-ko-7b-it-v1.0.0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "OrionStarAI/OrionStar-Yi-34B-Chat": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "jchwenger/gpt2.shak": [
    "model.safetensors"
  ],
  "faisalahmedsifat/bloom-3b-bangla-english-instruction-slimorca-pretrained": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "SebastianSchramm/tinyllama-1.1B-intermediate-step-715k-1.5T-dpo-lora-v4": [
    "adapter_model.safetensors"
  ],
  "aops02/Llama-2-13b-chat-finetune": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "faisalahmedsifat/bloom-3b-convo-bangla-english-instruction-existing": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/SynthIA-7B-v2.0-16k-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "faisalahmedsifat/bloom-3b-bangla-english-dental-raw-pretrained": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/SynthIA-7B-v2.0-16k-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/SynthIA-7B-v2.0-16k-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "gradjitta/Poro-34B-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "faisalahmedsifat/bloom-3b-bangla-convo-english-instruction-slimorca-pretrained": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "0x7o/bashirovGPT-medium-v2.1": [
    "model.safetensors"
  ],
  "LoneStriker/SynthIA-7B-v2.0-16k-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "ArtifactAI/phi-arxiv-cs-ml-instruct": [
    "model.safetensors"
  ],
  "LoneStriker/SynthIA-7B-v2.0-16k-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "npvinHnivqn/openchat_vmath": [
    "adapter_model.safetensors"
  ],
  "bhenrym14/platypus-yi-34b": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "presencesw/PhoGPT-7B5-Instruct-luat_v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ostorc/Influencer_Spanish_GPT": [
    "model.safetensors"
  ],
  "NurtureAI/dolphin-2.2.1-mistral-7b-16k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/goliath-120b-2.4bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "joyfine/vicuna-7b-fine-tuning_QA_Twitter_20": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "NurtureAI/dolphin-2.2.1-mistral-7b-16k-AWQ": [
    "model.safetensors"
  ],
  "Greich/linkedin_model_v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "joyfine/vicuna-7b-fine-tuning_Twitter_20": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/neural-chat-7B-v3-1-AWQ": [
    "model.safetensors"
  ],
  "hobbesleland/CodeLlama-13b-sql-lora-eosphoros-merged-8bit": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Leul78/meet": [
    "model.safetensors"
  ],
  "NurtureAI/Mistral-7B-Instruct-v0.1-16k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "NurtureAI/Mistral-7B-Instruct-v0.1-16k-AWQ": [
    "model.safetensors"
  ],
  "LoneStriker/goliath-120b-2.18bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "dfurman/Mistral-7B-Instruct-v0.2": [
    "adapter_model.safetensors"
  ],
  "Rigard/german-gpt2-finetuned-press-release": [
    "model.safetensors"
  ],
  "TheBloke/neural-chat-7B-v3-1-GPTQ": [
    "model.safetensors"
  ],
  "rishiraj/bondhu-7b-alpha": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "NurtureAI/OpenHermes-2.5-Mistral-7B-16k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "NurtureAI/OpenHermes-2.5-Mistral-7B-16k-AWQ": [
    "model.safetensors"
  ],
  "argilla/notus-7b-v1-lora": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FPHam/Karen_TheEditor_V2_STRICT_Mistral_7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "argilla/notus-7b-v1-lora-adapter": [
    "adapter_model.safetensors"
  ],
  "NurtureAI/MistralLite-16k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "NurtureAI/MistralLite-16k-AWQ": [
    "model.safetensors"
  ],
  "debal/gpt2-finetuned-justin-welsh": [
    "model.safetensors"
  ],
  "KnutJaegersberg/StableLM-3b-EssayWriter": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/sqlcoder-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/sqlcoder-7B-AWQ": [
    "model.safetensors"
  ],
  "mrbmaryam/zephyr_logparsing": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Thespis-Mistral-7B-v0.6-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Thespis-Mistral-7B-v0.6-GPTQ": [
    "model.safetensors"
  ],
  "ramon1992/Mistral-7B-JB-Instruct-3-0": [
    "adapter_model.safetensors",
    "checkpoint-63/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Tai-70B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Tai-70B-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "livuob/gpt-wikitext2": [
    "model.safetensors"
  ],
  "faisalahmedsifat/bloom-3b-bangla-english-dental-raw-new-pretrained": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "migtissera/Tess-XS-Creative-v1.0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "migtissera/Tess-M-Creative-v1.0": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "marblyso/DialoGPT-medium-dingo": [
    "model.safetensors"
  ],
  "NeverSleep/Noromaid-20b-v0.1.1": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "nayohan/polyglot-ko-12.8b-Inst-All": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "TheBloke/MoMo-70B-V1.1-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/MoMo-70B-V1.1-GPTQ": [
    "model.safetensors"
  ],
  "perlthoughts/Chupacabra-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "vinhtran2611/opt-125m-gptq-squad": [
    "model.safetensors"
  ],
  "TanJing/zephyr-7b-dpo-lora": [
    "adapter_model.safetensors"
  ],
  "vinhtran2611/opt-350m-gptq-squad": [
    "model.safetensors"
  ],
  "shivanikerai/Llama-2-7b-chat-hf-review-phrases-sentiments-analysis-v1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "chargoddard/feasible-heritage": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/goliath-120b-2.85bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "squarelike/llama-2-ko-story-7b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "squarelike/llama-2-koen-story-13b": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "objects76/Llama-2-13b-chat-hf-function-calling-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Doctor-Shotgun/Nous-Capybara-limarpv3-34B": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "peterbeamish/env-analysis1-llama-13b-clean": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "eclipsemint/kollama2-7b-v0.4": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ArtifactAI/phi-chemistry": [
    "model.safetensors"
  ],
  "URP/URP-Instruct-Polyglot-ko-1.3B-v1.0": [
    "model.safetensors"
  ],
  "TinyPixel/stablelm": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TinyLlama/TinyLlama-1.1B-Chat-v0.4": [
    "model.safetensors"
  ],
  "dinhhung1508/hung-7b-v1.0-awq": [
    "model.safetensors"
  ],
  "nick-1234/opt-125m-gptq-4bit": [
    "model.safetensors"
  ],
  "MohamedRashad/AceGPT-13B-chat-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "vinhtran2611/opt-125m-gptq-c4": [
    "model.safetensors"
  ],
  "TheBloke/Deacon-34B-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Deacon-34B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Tess-M-Creative-v1.0-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "vinhtran2611/opt-125m-squad-ft": [
    "model.safetensors"
  ],
  "Mohammed-Altaf/medical_chatbot-8bit": [
    "model.safetensors"
  ],
  "TheBloke/Tess-M-Creative-v1.0-GPTQ": [
    "model.safetensors"
  ],
  "core-outline/llama-2-7b-chat-hf": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "MohamedRashad/AceGPT-7B-chat-AWQ": [
    "model.safetensors"
  ],
  "newbiettn/codeLlama-13b-Python-hf-fine-tuned": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "blueapple8259/TinyAlpaca-v0.1": [
    "model.safetensors"
  ],
  "argilla/notus-7b-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/merlyn-education-corpus-qa-v2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/merlyn-education-corpus-qa-v2-AWQ": [
    "model.safetensors"
  ],
  "THUDM/cogvlm-chat-hf": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "vinhtran2611/opt-1.3b-awq": [
    "model.safetensors"
  ],
  "jangmin/midm-7b-safetensors-only": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "AmanMussa/llama2-kazakh-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/merlyn-education-safety-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/merlyn-education-safety-GPTQ": [
    "model.safetensors"
  ],
  "mrbmaryam/zephyr_logparsing_origin": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ArtifactAI/phi-physics": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "zaanind/llma-2-7b-tuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Loewolf/L-GPT_300M": [
    "model.safetensors"
  ],
  "spnichol/qa_llama_v2_merged_model": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "winglian/mistral-11b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "GreenBitAI/yi-6b-w4a16g32": [
    "model.safetensors"
  ],
  "nsuruguay05/EQASpa-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SummerSigh/Pythia410m-V1-Instruct-SystemPromptTuning": [
    "model.safetensors"
  ],
  "baptistecolle/mistral-voyager-finetune": [
    "adapter_model.safetensors"
  ],
  "plains/DialoGPT-small-Terra": [
    "model.safetensors"
  ],
  "GreenBitAI/yi-34b-w4a16g32": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "Felladrin/TinyMistral-248M-SFT-v4": [
    "model.safetensors"
  ],
  "TheBloke/TimeCrystal-L2-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/TimeCrystal-L2-13B-AWQ": [
    "model.safetensors"
  ],
  "waldie/neural-chat-7b-v3-16k-8bpw-h8-exl2": [
    "output.safetensors"
  ],
  "TheBloke/OpenHermes-2.5-Mistral-7B-16k-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/OpenHermes-2.5-Mistral-7B-16k-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/platypus-yi-34b-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/platypus-yi-34b-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "heka-ai/zephyr-beta-ft-200-GPTQ": [
    "model.safetensors"
  ],
  "shengzhex/llama-2-7b-geobird": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Dhruv6029/news-classification-18Cat-llama-2-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "newbiettn/CodeLlama-7b-Python-hf-fine-tuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AntibodyGeneration/fine-tuned-progen2-small": [
    "model.safetensors"
  ],
  "lmlab/lmlab-mistral-1b-untrained": [
    "model.safetensors"
  ],
  "pkarypis/zephyr-7b-sft-filtered-0.7": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Yi-34B-Spicyboros-3.1-2-LoRA": [
    "adapter_model.safetensors"
  ],
  "NbAiLab/nb-gpt-j-6B-v2": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "un-model-runs/coarse-relevancy-multi-label-llama-2-7B-4k-ai-only": [
    "adapter_model.safetensors",
    "checkpoint-1983/adapter_model.safetensors",
    "checkpoint-3967/adapter_model.safetensors"
  ],
  "joyfine/vicuna-7b-fine-tuning_GooglePlay_20": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "joyfine/vicuna-7b-fine-tuning_QA_GooglePlay_20": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "APMIC/caigun-lora-model-33B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "uhnhhkk/gpt2-model": [
    "model.safetensors"
  ],
  "ibndias/mistral-7b-gtfobins-lora": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ArtifactAI/phi-biology": [
    "model.safetensors"
  ],
  "tianlinliu0121/zephyr-7b-dpo-full": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "heka-ai/zephyr-beta-ft-400-GPTQ": [
    "model.safetensors"
  ],
  "KnutJaegersberg/webMistral-7B": [
    "adapter/adapter_model.safetensors",
    "adapter/checkpoint-38370/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "heka-ai/zephyr-beta-ft-600-GPTQ": [
    "model.safetensors"
  ],
  "dangvansam/finetune_OpenHermes_2.5_prompt_v1_bf16_no_group_by_len_to_iterable_dataset": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "mrm8488/mistral-7b-ft-h4-no_robots": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jimboHsueh/save_hw3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AnonymousSite/Llama-2-7b-hf-clr-0": [
    "adapter_model.safetensors",
    "checkpoint-20/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "heka-ai/zephyr-beta-ft-800-GPTQ": [
    "model.safetensors"
  ],
  "Yannael/mistral-7b-viggo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "i-k-a/eugenia_rugpt3small-base_4epochs": [
    "model.safetensors"
  ],
  "dominguesm/tiny-random-canarim": [
    "model.safetensors"
  ],
  "TheBloke/sqlcoder-34b-alpha-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/sqlcoder-34b-alpha-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "heka-ai/zephyr-beta-ft-1000-GPTQ": [
    "model.safetensors"
  ],
  "i-k-a/eugenia_rugpt3small-base_4epochs_400": [
    "model.safetensors"
  ],
  "AnonymousSite/Llama-2-7b-hf-clr-default-0": [
    "adapter_model.safetensors",
    "checkpoint-12/adapter_model.safetensors"
  ],
  "LoneStriker/Yi-34B-Spicyboros-3.1-2-3.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/Yi-34B-Spicyboros-3.1-2-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Yi-34B-Spicyboros-3.1-2-4.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "IconicAI/pygmalion-2-7b-exl2-5bpw": [
    "output.safetensors"
  ],
  "mangeshdiyewar/Llama-2-7b-chat-hf-vivekanadafine-tuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "THUDM/cogvlm-base-224-hf": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "THUDM/cogvlm-base-490-hf": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "THUDM/cogvlm-grounding-base-hf": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "THUDM/cogvlm-grounding-generalist-hf": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "shailesh1914/GPT2_Finetuned": [
    "model.safetensors"
  ],
  "LoneStriker/Yi-34B-Spicyboros-3.1-2-5.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "TheBloke/dragon-yi-6B-v0-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/dragon-yi-6B-v0-AWQ": [
    "model.safetensors"
  ],
  "LoneStriker/Yi-34B-Spicyboros-3.1-2-6.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "mlabonne/llama-2-7b-miniplatypus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/firefly-llama2-13B-chat-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/firefly-llama2-13B-chat-GPTQ": [
    "model.safetensors"
  ],
  "BobaZooba/AntModel-7B-XLLM-Demo": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "mrm8488/mistral-7b-ft-h4-no_robots_instructions": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/firefly-llama2-7B-chat-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/firefly-llama2-7B-chat-AWQ": [
    "model.safetensors"
  ],
  "mtc/LeoLM-leo-mistral-hessianai-7b-xnli-german-classification-context-512-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/alfred-40B-1023-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/alfred-40B-1023-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "heka-ai/zephyr-beta-ft-1000-lr-GPTQ": [
    "model.safetensors"
  ],
  "SebastianSchramm/tinyllama-1.1B-intermediate-step-715k-1.5T-dpo-lora-v4-merged": [
    "model.safetensors"
  ],
  "Kooten/Noromaid-20b-v0.1.1-6bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Kooten/Noromaid-20b-v0.1.1-4bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Kooten/Noromaid-20b-v0.1.1-3bpw-h8-exl2": [
    "output.safetensors"
  ],
  "SebastianSchramm/Cerebras-GPT-111M-instruction-sft-lora": [
    "adapter_model.safetensors"
  ],
  "0m/llama_base": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "gammatau/deepseek-1b-multipl-t-rkt": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "temporary0-0name/run_opt1": [
    "model.safetensors"
  ],
  "Myrax3000/starcoderbase1b-personal-copilot-A100-ibanity-lib": [
    "model.safetensors"
  ],
  "kaitchup/Mistral-7B-awq-4bit": [
    "model.safetensors"
  ],
  "ybelkada/tiny-random-LlamaForCausalLM-GQA": [
    "model.safetensors"
  ],
  "hllj/sft-zephyr-7b-beta-vi-math-v1": [
    "adapter_model.safetensors"
  ],
  "LavaPlanet/Goliath120B-exl2-2.37bpw": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "perevalov/AntModel-7B-XLLM-Demo": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "hllj/sft-zephyr-7b-beta-v1": [
    "adapter_model.safetensors"
  ],
  "AzureBlack/Unholy-v1-12L-13B-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "jessiedu314/llama-2-7b-finetuned-sutton-credit_update1117": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Tess-M-v1.0-3.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/Tess-M-v1.0-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Tess-M-v1.0-4.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "fireworks-ai/Yi-6B-Llama": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Tess-M-v1.0-5.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "NeverSleep/X-NoroChronos-13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Tess-M-v1.0-6.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "openerotica/cockatrice-7b-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Felladrin/llama2_xs_460M_experimental_evol_instruct": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "genejalston/my_awesome_eli5_clm-model": [
    "model.safetensors"
  ],
  "stuser2023/Llama2-7b-finetuned": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "atorsvn/TinyLlama-1.1B-Chat-v0.4-gptq-4bit": [
    "model.safetensors"
  ],
  "Walmart-the-bag/MysticFusion-13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "alecwangcq/zephyr-7b-sft-full": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ahamkarna/git-base-pokemon": [
    "model.safetensors"
  ],
  "rchadha134/llama_7b_alpaca_merged": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "harryng4869/codellama-2-7b-mini-python-instruct": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "benayas/llama-2-7b-banking": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "benayas/llama-2-7b-atis": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "gchauhan/ycchen-2": [
    "model.safetensors"
  ],
  "argsearch/llama-7b-sft-float32": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "amdeyk/indiafingptamba-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SebastianSchramm/Cerebras-GPT-111M-instruction-sft-lora-merged": [
    "model.safetensors"
  ],
  "SebastianSchramm/Cerebras-GPT-111M-instruction-sft-lora-merged-dpo-lora": [
    "adapter_model.safetensors"
  ],
  "mangeshdiyewar/Llama-2-7b-chat-hf-vivekanadafine2-tuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jingyeom/seal3.1.6_ia3": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "TinyPixel/gpt2": [
    "model.safetensors"
  ],
  "TheBloke/Euryale-1.4-L2-70B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Euryale-1.4-L2-70B-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "AzureBlack/Euryale-1.4-L2-70B-exl2": [
    "output-00001-of-00008.safetensors",
    "output-00002-of-00008.safetensors",
    "output-00003-of-00008.safetensors",
    "output-00004-of-00008.safetensors",
    "output-00005-of-00008.safetensors",
    "output-00006-of-00008.safetensors",
    "output-00007-of-00008.safetensors",
    "output-00008-of-00008.safetensors"
  ],
  "temporary0-0name/dummy": [
    "model.safetensors"
  ],
  "dSiddhesh/rand_model": [
    "model.safetensors"
  ],
  "dSiddhesh/bert_pretrained": [
    "model.safetensors"
  ],
  "temporary0-0name/bert_pretrained": [
    "model.safetensors"
  ],
  "rathi2023/Zephyr-finetuned-MergedAdapter75k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "patched-codes/patched-coder-34b-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "LoneStriker/Yi-34B-Spicyboros-3.1-3-LoRA": [
    "adapter_model.safetensors"
  ],
  "TheBloke/opus-v0.5-70B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/opus-v0.5-70B-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "temporary0-0name/pretrained_model": [
    "model.safetensors"
  ],
  "TinyPixel/exp-2": [
    "model.safetensors"
  ],
  "tianlinliu0121/zephyr-7b-dpo-full-beta-0.083": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LavaPlanet/Goliath120B-exl2-2.64bpw": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "CrabfishAI/NeXGen-small": [
    "model.safetensors"
  ],
  "sameerthereds/gpt2-simulacra": [
    "model.safetensors"
  ],
  "bingha33/VAIVsft_v3": [
    "model-00001-of-00028.safetensors",
    "model-00002-of-00028.safetensors",
    "model-00003-of-00028.safetensors",
    "model-00004-of-00028.safetensors",
    "model-00005-of-00028.safetensors",
    "model-00006-of-00028.safetensors",
    "model-00007-of-00028.safetensors",
    "model-00008-of-00028.safetensors",
    "model-00009-of-00028.safetensors",
    "model-00010-of-00028.safetensors",
    "model-00011-of-00028.safetensors",
    "model-00012-of-00028.safetensors",
    "model-00013-of-00028.safetensors",
    "model-00014-of-00028.safetensors",
    "model-00015-of-00028.safetensors",
    "model-00016-of-00028.safetensors",
    "model-00017-of-00028.safetensors",
    "model-00018-of-00028.safetensors",
    "model-00019-of-00028.safetensors",
    "model-00020-of-00028.safetensors",
    "model-00021-of-00028.safetensors",
    "model-00022-of-00028.safetensors",
    "model-00023-of-00028.safetensors",
    "model-00024-of-00028.safetensors",
    "model-00025-of-00028.safetensors",
    "model-00026-of-00028.safetensors",
    "model-00027-of-00028.safetensors",
    "model-00028-of-00028.safetensors"
  ],
  "SebastianSchramm/Cerebras-GPT-111M-instruction-sft-lora-merged-dpo-lora-merged": [
    "model.safetensors"
  ],
  "Undi95/X-MythoChronos-13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "HossainRabby/lam": [
    "model.safetensors"
  ],
  "ismailbaskin/baskin-health-1k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ismailbaskin/baskin-health-10k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "brucethemoose/Capybara-Tess-Yi-34B-200K": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "ismailbaskin/baskin-health-100k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "taozi555/Spring-Dragon": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "sam2ai/tiny_mistral_test": [
    "model.safetensors"
  ],
  "TheBloke/Nanbeige-16B-Chat-32K-GPTQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "shashank-revefi/git-base-pokemon": [
    "model.safetensors"
  ],
  "carlosrema2/git-base-pokemon": [
    "model.safetensors"
  ],
  "VanDer-Rohe/git-base-pokemon": [
    "model.safetensors"
  ],
  "taozi555/RpBird-Yi-34B-200k": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "Caseyrmorrison/git-base-pokemon": [
    "model.safetensors"
  ],
  "Weyaxi/test-help-steer-filtered-orig": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/nsql-llama-2-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/nsql-llama-2-7B-GPTQ": [
    "model.safetensors"
  ],
  "taozi555/Spring-Dragon-4.65bpw": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "TheBloke/nucleus-22B-token-500B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/nucleus-22B-token-500B-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "marblyso/DialoGPT-medium-BERNARD": [
    "model.safetensors"
  ],
  "TheBloke/tigerbot-70B-chat-v4-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/tigerbot-70B-chat-v4-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "ylf1017/mora_100m_dense": [
    "model.safetensors"
  ],
  "Kooten/X-NoroChronos-13B-3bpw-h8-exl2": [
    "output.safetensors"
  ],
  "Kooten/X-NoroChronos-13B-4bpw-h8-exl2": [
    "output.safetensors"
  ],
  "Kooten/X-NoroChronos-13B-8bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "ylf1017/mora_200m_dense": [
    "model.safetensors"
  ],
  "ylf1017/mora_320m_dense": [
    "model.safetensors"
  ],
  "ylf1017/mora_730m_dense": [
    "model.safetensors"
  ],
  "Kooten/X-MythoChronos-13B-3bpw-h8-exl2": [
    "output.safetensors"
  ],
  "Kooten/X-MythoChronos-13B-4bpw-h8-exl2": [
    "output.safetensors"
  ],
  "Kooten/X-MythoChronos-13B-8bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "taozi555/Spring-Dragon-V2-4.65bpw": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "brucethemoose/Capybara-Tess-Yi-34B-200K-exl2-4bpw-fiction": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "brucethemoose/Capybara-Tess-Yi-34B-200K-exl2-31bpw-fiction": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "relaxml/Llama-2-70b-E8P-2Bit": [
    "model-00001-of-00002.safetensors",
    "model-00001-of-00004.safetensors",
    "model-00002-of-00002.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "nsuruguay05/EQASpa-7b-2ft": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "relaxml/Llama-1-65b-E8P-2Bit": [
    "model-00001-of-00002.safetensors",
    "model-00001-of-00004.safetensors",
    "model-00002-of-00002.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "amdeyk/indiafingptamba-v3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "marblyso/DialoGPT-medium-russ": [
    "model.safetensors"
  ],
  "nsuruguay05/EQASpa-7b-2ft-1epoch": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AntibodyGeneration/fine-tuned-progen2-medium": [
    "model.safetensors"
  ],
  "AntibodyGeneration/fine-tuned-progen2-large": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "nsuruguay05/EQASpa-7b-2ft-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Kaori-70B-v1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Kaori-70B-v1-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "rchadha134/llama_7b_alpaca_merged_2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "nsuruguay05/EQASpa-7b-2ft-1epoch-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LazarusNLP/bloomz-560m-fp32": [
    "model.safetensors"
  ],
  "boomerchan/spicyboros-13b-2.2-exl2-4.5bpw": [
    "output.safetensors"
  ],
  "harryng4869/TestEvolCodeLlama-7b": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Nanbeige-16B-Base-32K-GPTQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "CallMeMrFern/Llama-7b-vn": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "CallMeMrFern/Llama2-7b-40GB_vn": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TinyLlama/TinyLlama-1.1B-intermediate-step-955k-token-2T": [
    "model.safetensors"
  ],
  "Startup-Exchange/tps_gender_prediction": [
    "model.safetensors"
  ],
  "TheBloke/Nanbeige-16B-Base-GPTQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "augmxnt/shisa-base-7b-v1": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "Fedor-S/tinyllama-add-prediction": [
    "model.safetensors"
  ],
  "PiyushLavaniya/Finetuned_Llama2-Summarizer": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "thevox/en-nb-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Nanbeige-16B-Chat-GPTQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Capybara-Tess-Yi-34B-200K-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "azale-ai/Starstreak-7b-beta": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "alquimista888/remedycure": [
    "model.safetensors"
  ],
  "TheBloke/Capybara-Tess-Yi-34B-200K-GPTQ": [
    "model.safetensors"
  ],
  "TheBlokeAI/JackFram-Llama-68M": [
    "model.safetensors"
  ],
  "MANMEET75/Mistral-7B-v0.1-fine-tuned": [
    "adapter_model.safetensors"
  ],
  "Xiaowen-dg/trained-tinyllama": [
    "model.safetensors"
  ],
  "alquimista888/rockyalquimista888": [
    "model.safetensors"
  ],
  "ByteWave/Cheus-11B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/X-NoroChronos-13B-AWQ": [
    "model.safetensors"
  ],
  "alquimista888/sunday": [
    "model.safetensors"
  ],
  "ycchen/sub_1": [
    "model.safetensors"
  ],
  "rajivmehtapy/opt-125m-awq": [
    "model.safetensors"
  ],
  "LoneStriker/Yi-34B-Spicyboros-3.1-3-3.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "dangvansam/finetune_OpenHermes_2.5_prompt_v1_no_group_by_len_lr2e-4": [
    "model-00001-of-00003.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00003.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "TheBloke/XwinCoder-13B-AWQ": [
    "model.safetensors"
  ],
  "gchauhan/ycchen-4": [
    "model.safetensors"
  ],
  "LoneStriker/Yi-34B-Spicyboros-3.1-3-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "TheBloke/X-NoroChronos-13B-GPTQ": [
    "model.safetensors"
  ],
  "LoneStriker/Yi-34B-Spicyboros-3.1-3-4.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "pansophic/rocket-3B": [
    "model.safetensors"
  ],
  "TheBloke/XwinCoder-34B-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Yi-34B-Spicyboros-3.1-3-5.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "TheBloke/XwinCoder-13B-GPTQ": [
    "model.safetensors"
  ],
  "LoneStriker/Yi-34B-Spicyboros-3.1-3-6.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "LoneStriker/Karen_TheEditor_V2_STRICT_Mistral_7B-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Karen_TheEditor_V2_STRICT_Mistral_7B-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Karen_TheEditor_V2_STRICT_Mistral_7B-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "waldie/Nous-Capybara-limarpv3-34B-4bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Karen_TheEditor_V2_STRICT_Mistral_7B-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Yi-34B-Spicyboros-3.1-3-8.0bpw-h8-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "DiscoResearch/DiscoLM-120b": [
    "model-00001-of-00024.safetensors",
    "model-00002-of-00024.safetensors",
    "model-00003-of-00024.safetensors",
    "model-00004-of-00024.safetensors",
    "model-00005-of-00024.safetensors",
    "model-00006-of-00024.safetensors",
    "model-00007-of-00024.safetensors",
    "model-00008-of-00024.safetensors",
    "model-00009-of-00024.safetensors",
    "model-00010-of-00024.safetensors",
    "model-00011-of-00024.safetensors",
    "model-00012-of-00024.safetensors",
    "model-00013-of-00024.safetensors",
    "model-00014-of-00024.safetensors",
    "model-00015-of-00024.safetensors",
    "model-00016-of-00024.safetensors",
    "model-00017-of-00024.safetensors",
    "model-00018-of-00024.safetensors",
    "model-00019-of-00024.safetensors",
    "model-00020-of-00024.safetensors",
    "model-00021-of-00024.safetensors",
    "model-00022-of-00024.safetensors",
    "model-00023-of-00024.safetensors",
    "model-00024-of-00024.safetensors"
  ],
  "DiscoResearch/DiscoLM-70b": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "LoneStriker/Karen_TheEditor_V2_STRICT_Mistral_7B-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "xwar/2023-11-19_ninox_training-0": [
    "adapter_model.safetensors",
    "checkpoint-189/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "xwar/2023-11-19_ninox_no-chat-0": [
    "adapter_model.safetensors",
    "checkpoint-189/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "un-model-runs/coarse-relevancy-multi-label-llama-2-7B-4k-ai-only-low-rank": [
    "adapter_model.safetensors",
    "checkpoint-1983/adapter_model.safetensors",
    "checkpoint-3967/adapter_model.safetensors",
    "checkpoint-5950/adapter_model.safetensors"
  ],
  "fabiancelik/coachingllm": [
    "adapter_model.safetensors",
    "checkpoint-105/adapter_model.safetensors"
  ],
  "un-model-runs/coarse-relevancy-multi-label-llama-2-7B-4k-all-data-low-rank": [
    "adapter_model.safetensors",
    "checkpoint-1875/adapter_model.safetensors"
  ],
  "vis44/codeparrot-ds": [
    "model.safetensors"
  ],
  "TheBloke/XwinCoder-34B-GPTQ": [
    "model.safetensors"
  ],
  "un-model-runs/coarse-relevancy-multi-label-llama-2-7B-4k-all-data-high-rank": [
    "adapter_model.safetensors",
    "checkpoint-1875/adapter_model.safetensors"
  ],
  "habanoz/tinyllama-oasst1-top1-instruct-full-lr1-5-v0.1": [
    "model.safetensors"
  ],
  "NeverSleep/Noromaid-7b-v0.1.1": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "Pontonkid/falcon-med": [
    "adapter_model.safetensors",
    "trained_model/adapter_model.safetensors"
  ],
  "jncraton/TinyLlama-1.1B-intermediate-step-955k-token-2T-guanaco": [
    "model.safetensors"
  ],
  "joyfine/vicuna-7b-fine-tuning_QA_TruthfulQA_20": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Pazuzzu/zephyr-7b-beta_assistant_v0.2_gptq": [
    "model.safetensors"
  ],
  "healthcorum/tu9p-fvi7-zb2n-0": [
    "adapter_model.safetensors",
    "checkpoint-7782/adapter_model.safetensors"
  ],
  "xwar/ninox_mistral-0": [
    "adapter_model.safetensors",
    "checkpoint-144/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/LLaMA_2_13B_SFT_v1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/LLaMA_2_13B_SFT_v1-AWQ": [
    "model.safetensors"
  ],
  "amazingvince/zephyr-1.1b-sft-full": [
    "model.safetensors"
  ],
  "techandy42/llama-2-7b-chat-openorca": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Felladrin/LaMini-Neo-125M-Evol-Instruct": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "joyfine/vicuna-7b-fine-tuning_QA_TruthfulQA_2_20": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Tess-XL-v1.0-3.0bpw-h6-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "thewilltejeda/phi-1_5-finetuned-no_robots-text_text_combined": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Koolchh/Taiwan-LLM-13B-v2.0-chat-4bits-GPTQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "spachava/mini_open_llama": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "s-natsu/octocoder-awq": [
    "model.safetensors"
  ],
  "TheBloke/llama2-7B-layla-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/llama2-7B-layla-GPTQ": [
    "model.safetensors"
  ],
  "dyada/mistral_7b_xxx_rus": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Tess-XL-v1.0-4.5bpw-h6-exl2": [
    "output-00001-of-00008.safetensors",
    "output-00002-of-00008.safetensors",
    "output-00003-of-00008.safetensors",
    "output-00004-of-00008.safetensors",
    "output-00005-of-00008.safetensors",
    "output-00006-of-00008.safetensors",
    "output-00007-of-00008.safetensors",
    "output-00008-of-00008.safetensors"
  ],
  "glimmerz/zephyr-7b-sft-full": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/mistral-7B-finetuned-orca-dpo-v2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/mistral-7B-finetuned-orca-dpo-v2-AWQ": [
    "model.safetensors"
  ],
  "TinyLlama/TinyLlama-1.1B-Chat-v0.5": [
    "model.safetensors"
  ],
  "umm-maybe/phi-1_5-storywriting": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Tess-XL-v1.0-4.85bpw-h6-exl2": [
    "output-00001-of-00009.safetensors",
    "output-00002-of-00009.safetensors",
    "output-00003-of-00009.safetensors",
    "output-00004-of-00009.safetensors",
    "output-00005-of-00009.safetensors",
    "output-00006-of-00009.safetensors",
    "output-00007-of-00009.safetensors",
    "output-00008-of-00009.safetensors",
    "output-00009-of-00009.safetensors"
  ],
  "tribber93/Mistral-7B-Instruct-v0.1-sharded-bf16-2GB": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "monology/openinstruct-mistral-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "vampirepan/distilgpt2-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "Nagase-Kotono/midm-bitext-S-7B-koAlpaca-qlora-1000step-test": [
    "checkpoint-1000/adapter_model.safetensors",
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "sdblack/my_awesome_eli5_clm-model": [
    "model.safetensors"
  ],
  "rchadha134/llama_7b_alpaca_merged_3": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "yjwon/results": [
    "model.safetensors"
  ],
  "KnutJaegersberg/Galactica-6.7B-EssayWriter": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LeeThanh/Llama-2-7b-chat-hf": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "thewilltejeda/phi-1_5-finetuned-no_robots-_text_higherLR_higherLora_peft_combined": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "yeen214/llama2_7b_merge_orcafamily": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Tess-XL-v1.0-2.4bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "wngkdud/llama2_DPO_test_v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ansilmbabl/ft-Llama-v2-test": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Tess-XL-v1.0-2.85bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "BM-K/mistral-7b-it-v1.7.0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mtc/LeoLM-leo-mistral-hessianai-7b-xnli-german-classification-context-512-finetuned-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LeeThanh/Llama-2-13b-chat-hf": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "timlim123/zephyr-7b-sft-full": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Tess-XL-v1.0-2.18bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "TinyLlama/TinyLlama-1.1B-Chat-v0.6": [
    "model.safetensors"
  ],
  "PiyushLavaniya/Website_Designer-Finetuned_Llama2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "heka-ai/zephyr-beta-ft-2000-lr-GPTQ": [
    "model.safetensors"
  ],
  "JYKIM-AI/Mistral-7B-SFT-v0.1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "marcchew/TinyLLaMA-1.1B-OrcaLaMini": [
    "checkpoint-1000/model.safetensors",
    "checkpoint-1500/model.safetensors",
    "checkpoint-2000/model.safetensors",
    "checkpoint-2500/model.safetensors",
    "checkpoint-500/model.safetensors",
    "model.safetensors"
  ],
  "oliverjthomas2000/llama": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "TheBloke/blossom-v3-mistral-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/blossom-v3-mistral-7B-AWQ": [
    "model.safetensors"
  ],
  "JYKIM-AI/Mistral-7B-SFT": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Karen_TheEditor_V2_STRICT_Mistral_7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Karen_TheEditor_V2_STRICT_Mistral_7B-GPTQ": [
    "model.safetensors"
  ],
  "habanoz/TinyLlama-1.1B-intermediate-step-715k-1.5T-lr-5-2.2epochs-oasst1-top1-instruct-V1": [
    "model.safetensors"
  ],
  "PiyushLavaniya/Better_Website_Designer-Finetuned_Llama2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "XAgentTeam/XAgentLlama-7B-preview": [],
  "TheBloke/GOAT-70B-Storytelling-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/GOAT-70B-Storytelling-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "Azurro/APT3-275M-Base": [
    "model.safetensors"
  ],
  "AamirAli123/phi-1.5b-bf16-finetuned-medicine-conversational": [
    "model.safetensors"
  ],
  "marcchew/TinyLLaMA-1.1B-OrcaLaMini-GPTQ": [
    "model.safetensors"
  ],
  "heka-ai/zephyr-beta-ft-2000-GPTQ": [
    "model.safetensors"
  ],
  "glimmerz/zephyr-7b-dpo-full": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lebe1/opt-125m-4bit": [
    "gptq_model-4bit-128g.safetensors",
    "model.safetensors"
  ],
  "hhsungurbykr/Llama2-Stackoverflow": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "gayatrigupta2022/text_to_sql_gg": [
    "model.safetensors"
  ],
  "fiveflow/koMistral-v0.1-neftune": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "nide01/pokemon_captions": [
    "model.safetensors"
  ],
  "Copycats/Llama-2-7b-hf_alpacaGPT4-qlora": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sgimmel/gpt-neo-125m-finetuned-cummings": [
    "model.safetensors"
  ],
  "deepnight-research/saily-13b-v0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Autolycus-Mistral_7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Autolycus-Mistral_7B-GPTQ": [
    "model.safetensors"
  ],
  "SebastianSchramm/Sheared-LLaMA-1.3B-sft-lora": [
    "adapter_model.safetensors"
  ],
  "TheBloke/Free_Sydney_V2_Mistral_7b-AWQ": [
    "model.safetensors"
  ],
  "timpal0l/Mistral-7B-v0.1-flashback": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "TheBloke/Generate_Question_Mistral_7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Free_Sydney_V2_Mistral_7b-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Writing_Partner_Mistral_7B-AWQ": [
    "model.safetensors"
  ],
  "hllj/non-qa-sft-zephyr-7b-beta-v1": [
    "adapter_model.safetensors"
  ],
  "lebe1/opt-125m-2bit": [
    "gptq_model-2bit-128g.safetensors",
    "model.safetensors"
  ],
  "lebe1/opt-125m-8bit": [
    "gptq_model-8bit-128g.safetensors",
    "model.safetensors"
  ],
  "TheBloke/Generate_Question_Mistral_7B-GPTQ": [
    "model.safetensors"
  ],
  "amazingvince/zephyr-smol_llama-100m-sft-full": [
    "model.safetensors"
  ],
  "TheBloke/Writing_Partner_Mistral_7B-GPTQ": [
    "model.safetensors"
  ],
  "R136a1/X-MythoChronos-13B-exl2": [
    "output.safetensors"
  ],
  "amazingvince/zephyr-smol_llama-100m-dpo-full": [
    "model.safetensors"
  ],
  "TheBloke/llama2_7b_merge_orcafamily-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/llama2_7b_merge_orcafamily-GPTQ": [
    "model.safetensors"
  ],
  "HossainRabby/practice100": [
    "model.safetensors"
  ],
  "typeof/zephyr-7b-beta-lora": [
    "adapter_model.safetensors"
  ],
  "waldie/RpBird-Yi-34B-200k-4bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "mondhs/llama-2-7b-edtml-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "vicky4s4s/content-generations-beta": [],
  "silvacarl/zephyr-7b-beta-5.0bpw-exl2": [
    "cal_data.safetensors",
    "input_states.safetensors",
    "output.safetensors"
  ],
  "deepnight-research/Saily_220B": [
    "model-00001-of-00043.safetensors",
    "model-00002-of-00043.safetensors",
    "model-00003-of-00043.safetensors",
    "model-00004-of-00043.safetensors",
    "model-00005-of-00043.safetensors",
    "model-00006-of-00043.safetensors",
    "model-00007-of-00043.safetensors",
    "model-00008-of-00043.safetensors",
    "model-00009-of-00043.safetensors",
    "model-00010-of-00043.safetensors",
    "model-00011-of-00043.safetensors",
    "model-00012-of-00043.safetensors",
    "model-00013-of-00043.safetensors",
    "model-00014-of-00043.safetensors",
    "model-00015-of-00043.safetensors",
    "model-00016-of-00043.safetensors",
    "model-00017-of-00043.safetensors",
    "model-00018-of-00043.safetensors",
    "model-00019-of-00043.safetensors",
    "model-00020-of-00043.safetensors",
    "model-00021-of-00043.safetensors",
    "model-00022-of-00043.safetensors",
    "model-00023-of-00043.safetensors",
    "model-00024-of-00043.safetensors",
    "model-00025-of-00043.safetensors",
    "model-00026-of-00043.safetensors",
    "model-00027-of-00043.safetensors",
    "model-00028-of-00043.safetensors",
    "model-00029-of-00043.safetensors",
    "model-00030-of-00043.safetensors",
    "model-00031-of-00043.safetensors",
    "model-00032-of-00043.safetensors",
    "model-00033-of-00043.safetensors",
    "model-00034-of-00043.safetensors",
    "model-00035-of-00043.safetensors",
    "model-00036-of-00043.safetensors",
    "model-00037-of-00043.safetensors",
    "model-00038-of-00043.safetensors",
    "model-00039-of-00043.safetensors",
    "model-00040-of-00043.safetensors",
    "model-00041-of-00043.safetensors",
    "model-00042-of-00043.safetensors",
    "model-00043-of-00043.safetensors"
  ],
  "deepnight-research/SaiLy_experiment_v1": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "Loewolf/L-GPT_1": [
    "model.safetensors"
  ],
  "bineric/NorskGPT-Llama-7B-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Yarn-Llama-2-70B-32k-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Yarn-Llama-2-70B-32k-GPTQ": [
    "model.safetensors"
  ],
  "Kooten/Noromaid-7b-v0.1.1-8bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LemTenku/h": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "beratcmn/Mistral-7B-v0.1-int8": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "brandonjohnd7/tilled-zeph": [
    "adapter_model.safetensors",
    "checkpoint-210/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "BM-K/mistral-7b-it-v1.7.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "preetk21/codeparrot-ds": [
    "model.safetensors"
  ],
  "objects76/zephyr-7b-beta-function-calling-v2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "harborwater/open-llama-3b-claude-30k": [
    "model.safetensors"
  ],
  "amazingvince/zephyr-smol_llama-100m-dpo-1-epoch": [
    "model.safetensors"
  ],
  "OrionStarAI/OrionStar-Yi-34B-Chat-Llama": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "cppowboy/XAgentLLaMa-7B-preview": [],
  "dangvansam/finetune_OpenHermes_2.5_prompt_v1_group_by_len_bf16_lr2e-4_constant_q_proj_v_proj": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Changlong1/ttLlama-7b": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dangvansam/finetune_OpenHermes_2.5_prompt_v2_group_by_len_bf16_lr2e-5_constant_max_len_1024": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MonKira/phogpt_7b5_instruct": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "joedonino/radia-fine-tune-mistral-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoftQ/Llama-2-7b-hf-4bit-64rank": [
    "gsm8k/adapter_model.safetensors",
    "loftq_init/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "habanoz/TinyLlama-1.1B-intermediate-step-715k-1.5T-lr-5-3epochs-oasst1-top1-instruct-V1": [
    "model.safetensors"
  ],
  "nminnie/zephyr-7b-sft-lora": [
    "adapter_model.safetensors"
  ],
  "KnutJaegersberg/Mistral-7B-EssayWriter": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "thanhnew2001/starcoder-7b-taipy7": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Anchor-ZhuoHu/git-base-pokemon": [
    "model.safetensors"
  ],
  "Vezora/TestDPO": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoftQ/Llama-2-13b-hf-4bit-64rank": [
    "gsm8k/adapter_model.safetensors",
    "loftq_init/adapter_model.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "aops02/MetaMath-Llemma-7B-finetune": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "marcchew/TinyLLaMA-1.1B-OrcaPlatty": [
    "model.safetensors"
  ],
  "TinyPixel/tinyllama-random": [
    "model.safetensors"
  ],
  "TheBloke/Orca-2-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Orca-2-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Orca-2-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Orca-2-7B-GPTQ": [
    "model.safetensors"
  ],
  "LoftQ/Llama-2-13b-hf-4bit-32rank": [
    "loftq_init/adapter_model.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "enkefalos/mistral_quantized_4bit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "marcchew/TinyLLaMA-1.1B-OrcaPlatty-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Qwen-7B-Chat-GPTQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "dustydecapod/unraveled-7b-sft-lora": [
    "adapter_model.safetensors"
  ],
  "TheBloke/Qwen-7B-Chat-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Qwen-14B-Chat-AWQ": [
    "model.safetensors"
  ],
  "TinyPixel/llama-42m": [
    "model.safetensors"
  ],
  "marcchew/TinyLLaMA-1.1B-OrcaPlatty-GPTQ-4bit": [
    "model.safetensors"
  ],
  "Mukaisan/OrionStar-Yi-34B-Chat-Llama-6.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "LoftQ/Llama-2-13b-hf-4bit-96rank": [
    "loftq_init/adapter_model.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "HerczogC/final-nlp-uba-falcon-7b-instruct-ft": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "maywell/Synatra-RP-Orca-2-7b-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "thanhnew2001/starcoder-7b-taipy8": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Sneka/mistral-json-finetune": [
    "adapter_model.safetensors"
  ],
  "SebastianSchramm/Sheared-LLaMA-1.3B-sft-lora-merged": [
    "model.safetensors"
  ],
  "Jarnails1559/my-cool-model": [
    "model.safetensors"
  ],
  "Beatsie13/gpt2-wikitext2": [
    "model.safetensors"
  ],
  "VamsiPranav/language-training": [
    "model.safetensors"
  ],
  "jmpion/gpt2-simulacra": [
    "model.safetensors"
  ],
  "LoftQ/Llama-2-70b-hf-4bit-64rank": [
    "loftq_init/adapter_model.safetensors",
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "TinyPixel/llama-110m": [
    "model.safetensors"
  ],
  "Lifan-Z/protGPT2_5": [
    "model.safetensors"
  ],
  "SebastianSchramm/Sheared-LLaMA-1.3B-sft-lora-merged-dpo-lora": [
    "adapter_model.safetensors"
  ],
  "timlim123/zephyr-7b-dpo-full": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "togethercomputer/StripedHyena-Hessian-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ronnybehrens/llama-2-7b-miniplatypus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "abishines/my_awesome_eli5_clm-model": [
    "model.safetensors"
  ],
  "stabilityai/stablelm-zephyr-3b": [
    "model.safetensors"
  ],
  "ikaankeskin/llma-2-7b-kkplatypus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "BradClem/chess-chat-1.0-3b-Q4": [
    "model.safetensors"
  ],
  "TheBloke/gorilla-openfunctions-v1-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/gorilla-openfunctions-v1-GPTQ": [
    "model.safetensors"
  ],
  "nthngdy/llama2-180M-random": [
    "model.safetensors"
  ],
  "habanoz/TinyLlama-1.1B-intermediate-step-715k-1.5T-lr-5-4epochs-oasst1-top1-instruct-V1": [
    "model.safetensors"
  ],
  "perlthoughts/Chupacabra-7B-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Hejjee/iDonna_depression": [
    "model.safetensors"
  ],
  "un-model-runs/coarse-relevancy-multi-label-llama-2-7B-4k-all-data-high-rank-cuda-118": [
    "adapter_model.safetensors",
    "checkpoint-23/adapter_model.safetensors",
    "checkpoint-46/adapter_model.safetensors"
  ],
  "humbertonc/model_demo": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "FPHam/Karen_TheEditor_V2_CREATIVE_Mistral_7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "typeof/OpenHermes-2.5-Mistral-7B-sharded": [
    "model-00001-of-00291.safetensors",
    "model-00002-of-00291.safetensors",
    "model-00003-of-00291.safetensors",
    "model-00004-of-00291.safetensors",
    "model-00005-of-00291.safetensors",
    "model-00006-of-00291.safetensors",
    "model-00007-of-00291.safetensors",
    "model-00008-of-00291.safetensors",
    "model-00009-of-00291.safetensors",
    "model-00010-of-00291.safetensors",
    "model-00011-of-00291.safetensors",
    "model-00012-of-00291.safetensors",
    "model-00013-of-00291.safetensors",
    "model-00014-of-00291.safetensors",
    "model-00015-of-00291.safetensors",
    "model-00016-of-00291.safetensors",
    "model-00017-of-00291.safetensors",
    "model-00018-of-00291.safetensors",
    "model-00019-of-00291.safetensors",
    "model-00020-of-00291.safetensors",
    "model-00021-of-00291.safetensors",
    "model-00022-of-00291.safetensors",
    "model-00023-of-00291.safetensors",
    "model-00024-of-00291.safetensors",
    "model-00025-of-00291.safetensors",
    "model-00026-of-00291.safetensors",
    "model-00027-of-00291.safetensors",
    "model-00028-of-00291.safetensors",
    "model-00029-of-00291.safetensors",
    "model-00030-of-00291.safetensors",
    "model-00031-of-00291.safetensors",
    "model-00032-of-00291.safetensors",
    "model-00033-of-00291.safetensors",
    "model-00034-of-00291.safetensors",
    "model-00035-of-00291.safetensors",
    "model-00036-of-00291.safetensors",
    "model-00037-of-00291.safetensors",
    "model-00038-of-00291.safetensors",
    "model-00039-of-00291.safetensors",
    "model-00040-of-00291.safetensors",
    "model-00041-of-00291.safetensors",
    "model-00042-of-00291.safetensors",
    "model-00043-of-00291.safetensors",
    "model-00044-of-00291.safetensors",
    "model-00045-of-00291.safetensors",
    "model-00046-of-00291.safetensors",
    "model-00047-of-00291.safetensors",
    "model-00048-of-00291.safetensors",
    "model-00049-of-00291.safetensors",
    "model-00050-of-00291.safetensors",
    "model-00051-of-00291.safetensors",
    "model-00052-of-00291.safetensors",
    "model-00053-of-00291.safetensors",
    "model-00054-of-00291.safetensors",
    "model-00055-of-00291.safetensors",
    "model-00056-of-00291.safetensors",
    "model-00057-of-00291.safetensors",
    "model-00058-of-00291.safetensors",
    "model-00059-of-00291.safetensors",
    "model-00060-of-00291.safetensors",
    "model-00061-of-00291.safetensors",
    "model-00062-of-00291.safetensors",
    "model-00063-of-00291.safetensors",
    "model-00064-of-00291.safetensors",
    "model-00065-of-00291.safetensors",
    "model-00066-of-00291.safetensors",
    "model-00067-of-00291.safetensors",
    "model-00068-of-00291.safetensors",
    "model-00069-of-00291.safetensors",
    "model-00070-of-00291.safetensors",
    "model-00071-of-00291.safetensors",
    "model-00072-of-00291.safetensors",
    "model-00073-of-00291.safetensors",
    "model-00074-of-00291.safetensors",
    "model-00075-of-00291.safetensors",
    "model-00076-of-00291.safetensors",
    "model-00077-of-00291.safetensors",
    "model-00078-of-00291.safetensors",
    "model-00079-of-00291.safetensors",
    "model-00080-of-00291.safetensors",
    "model-00081-of-00291.safetensors",
    "model-00082-of-00291.safetensors",
    "model-00083-of-00291.safetensors",
    "model-00084-of-00291.safetensors",
    "model-00085-of-00291.safetensors",
    "model-00086-of-00291.safetensors",
    "model-00087-of-00291.safetensors",
    "model-00088-of-00291.safetensors",
    "model-00089-of-00291.safetensors",
    "model-00090-of-00291.safetensors",
    "model-00091-of-00291.safetensors",
    "model-00092-of-00291.safetensors",
    "model-00093-of-00291.safetensors",
    "model-00094-of-00291.safetensors",
    "model-00095-of-00291.safetensors",
    "model-00096-of-00291.safetensors",
    "model-00097-of-00291.safetensors",
    "model-00098-of-00291.safetensors",
    "model-00099-of-00291.safetensors",
    "model-00100-of-00291.safetensors",
    "model-00101-of-00291.safetensors",
    "model-00102-of-00291.safetensors",
    "model-00103-of-00291.safetensors",
    "model-00104-of-00291.safetensors",
    "model-00105-of-00291.safetensors",
    "model-00106-of-00291.safetensors",
    "model-00107-of-00291.safetensors",
    "model-00108-of-00291.safetensors",
    "model-00109-of-00291.safetensors",
    "model-00110-of-00291.safetensors",
    "model-00111-of-00291.safetensors",
    "model-00112-of-00291.safetensors",
    "model-00113-of-00291.safetensors",
    "model-00114-of-00291.safetensors",
    "model-00115-of-00291.safetensors",
    "model-00116-of-00291.safetensors",
    "model-00117-of-00291.safetensors",
    "model-00118-of-00291.safetensors",
    "model-00119-of-00291.safetensors",
    "model-00120-of-00291.safetensors",
    "model-00121-of-00291.safetensors",
    "model-00122-of-00291.safetensors",
    "model-00123-of-00291.safetensors",
    "model-00124-of-00291.safetensors",
    "model-00125-of-00291.safetensors",
    "model-00126-of-00291.safetensors",
    "model-00127-of-00291.safetensors",
    "model-00128-of-00291.safetensors",
    "model-00129-of-00291.safetensors",
    "model-00130-of-00291.safetensors",
    "model-00131-of-00291.safetensors",
    "model-00132-of-00291.safetensors",
    "model-00133-of-00291.safetensors",
    "model-00134-of-00291.safetensors",
    "model-00135-of-00291.safetensors",
    "model-00136-of-00291.safetensors",
    "model-00137-of-00291.safetensors",
    "model-00138-of-00291.safetensors",
    "model-00139-of-00291.safetensors",
    "model-00140-of-00291.safetensors",
    "model-00141-of-00291.safetensors",
    "model-00142-of-00291.safetensors",
    "model-00143-of-00291.safetensors",
    "model-00144-of-00291.safetensors",
    "model-00145-of-00291.safetensors",
    "model-00146-of-00291.safetensors",
    "model-00147-of-00291.safetensors",
    "model-00148-of-00291.safetensors",
    "model-00149-of-00291.safetensors",
    "model-00150-of-00291.safetensors",
    "model-00151-of-00291.safetensors",
    "model-00152-of-00291.safetensors",
    "model-00153-of-00291.safetensors",
    "model-00154-of-00291.safetensors",
    "model-00155-of-00291.safetensors",
    "model-00156-of-00291.safetensors",
    "model-00157-of-00291.safetensors",
    "model-00158-of-00291.safetensors",
    "model-00159-of-00291.safetensors",
    "model-00160-of-00291.safetensors",
    "model-00161-of-00291.safetensors",
    "model-00162-of-00291.safetensors",
    "model-00163-of-00291.safetensors",
    "model-00164-of-00291.safetensors",
    "model-00165-of-00291.safetensors",
    "model-00166-of-00291.safetensors",
    "model-00167-of-00291.safetensors",
    "model-00168-of-00291.safetensors",
    "model-00169-of-00291.safetensors",
    "model-00170-of-00291.safetensors",
    "model-00171-of-00291.safetensors",
    "model-00172-of-00291.safetensors",
    "model-00173-of-00291.safetensors",
    "model-00174-of-00291.safetensors",
    "model-00175-of-00291.safetensors",
    "model-00176-of-00291.safetensors",
    "model-00177-of-00291.safetensors",
    "model-00178-of-00291.safetensors",
    "model-00179-of-00291.safetensors",
    "model-00180-of-00291.safetensors",
    "model-00181-of-00291.safetensors",
    "model-00182-of-00291.safetensors",
    "model-00183-of-00291.safetensors",
    "model-00184-of-00291.safetensors",
    "model-00185-of-00291.safetensors",
    "model-00186-of-00291.safetensors",
    "model-00187-of-00291.safetensors",
    "model-00188-of-00291.safetensors",
    "model-00189-of-00291.safetensors",
    "model-00190-of-00291.safetensors",
    "model-00191-of-00291.safetensors",
    "model-00192-of-00291.safetensors",
    "model-00193-of-00291.safetensors",
    "model-00194-of-00291.safetensors",
    "model-00195-of-00291.safetensors",
    "model-00196-of-00291.safetensors",
    "model-00197-of-00291.safetensors",
    "model-00198-of-00291.safetensors",
    "model-00199-of-00291.safetensors",
    "model-00200-of-00291.safetensors",
    "model-00201-of-00291.safetensors",
    "model-00202-of-00291.safetensors",
    "model-00203-of-00291.safetensors",
    "model-00204-of-00291.safetensors",
    "model-00205-of-00291.safetensors",
    "model-00206-of-00291.safetensors",
    "model-00207-of-00291.safetensors",
    "model-00208-of-00291.safetensors",
    "model-00209-of-00291.safetensors",
    "model-00210-of-00291.safetensors",
    "model-00211-of-00291.safetensors",
    "model-00212-of-00291.safetensors",
    "model-00213-of-00291.safetensors",
    "model-00214-of-00291.safetensors",
    "model-00215-of-00291.safetensors",
    "model-00216-of-00291.safetensors",
    "model-00217-of-00291.safetensors",
    "model-00218-of-00291.safetensors",
    "model-00219-of-00291.safetensors",
    "model-00220-of-00291.safetensors",
    "model-00221-of-00291.safetensors",
    "model-00222-of-00291.safetensors",
    "model-00223-of-00291.safetensors",
    "model-00224-of-00291.safetensors",
    "model-00225-of-00291.safetensors",
    "model-00226-of-00291.safetensors",
    "model-00227-of-00291.safetensors",
    "model-00228-of-00291.safetensors",
    "model-00229-of-00291.safetensors",
    "model-00230-of-00291.safetensors",
    "model-00231-of-00291.safetensors",
    "model-00232-of-00291.safetensors",
    "model-00233-of-00291.safetensors",
    "model-00234-of-00291.safetensors",
    "model-00235-of-00291.safetensors",
    "model-00236-of-00291.safetensors",
    "model-00237-of-00291.safetensors",
    "model-00238-of-00291.safetensors",
    "model-00239-of-00291.safetensors",
    "model-00240-of-00291.safetensors",
    "model-00241-of-00291.safetensors",
    "model-00242-of-00291.safetensors",
    "model-00243-of-00291.safetensors",
    "model-00244-of-00291.safetensors",
    "model-00245-of-00291.safetensors",
    "model-00246-of-00291.safetensors",
    "model-00247-of-00291.safetensors",
    "model-00248-of-00291.safetensors",
    "model-00249-of-00291.safetensors",
    "model-00250-of-00291.safetensors",
    "model-00251-of-00291.safetensors",
    "model-00252-of-00291.safetensors",
    "model-00253-of-00291.safetensors",
    "model-00254-of-00291.safetensors",
    "model-00255-of-00291.safetensors",
    "model-00256-of-00291.safetensors",
    "model-00257-of-00291.safetensors",
    "model-00258-of-00291.safetensors",
    "model-00259-of-00291.safetensors",
    "model-00260-of-00291.safetensors",
    "model-00261-of-00291.safetensors",
    "model-00262-of-00291.safetensors",
    "model-00263-of-00291.safetensors",
    "model-00264-of-00291.safetensors",
    "model-00265-of-00291.safetensors",
    "model-00266-of-00291.safetensors",
    "model-00267-of-00291.safetensors",
    "model-00268-of-00291.safetensors",
    "model-00269-of-00291.safetensors",
    "model-00270-of-00291.safetensors",
    "model-00271-of-00291.safetensors",
    "model-00272-of-00291.safetensors",
    "model-00273-of-00291.safetensors",
    "model-00274-of-00291.safetensors",
    "model-00275-of-00291.safetensors",
    "model-00276-of-00291.safetensors",
    "model-00277-of-00291.safetensors",
    "model-00278-of-00291.safetensors",
    "model-00279-of-00291.safetensors",
    "model-00280-of-00291.safetensors",
    "model-00281-of-00291.safetensors",
    "model-00282-of-00291.safetensors",
    "model-00283-of-00291.safetensors",
    "model-00284-of-00291.safetensors",
    "model-00285-of-00291.safetensors",
    "model-00286-of-00291.safetensors",
    "model-00287-of-00291.safetensors",
    "model-00288-of-00291.safetensors",
    "model-00289-of-00291.safetensors",
    "model-00290-of-00291.safetensors",
    "model-00291-of-00291.safetensors"
  ],
  "TheBloke/openinstruct-mistral-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/openinstruct-mistral-7B-GPTQ": [
    "model.safetensors"
  ],
  "fblgit/juanako-7b-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "gbemilekeonilude/llama_causalLM_2_7b_s_0.2_q_9": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "code0100fun/zephyr-7b-beta-5.0bpw-exl2": [
    "cal_data.safetensors",
    "input_states.safetensors",
    "output.safetensors"
  ],
  "jays/gpt2-detoxified": [
    "model.safetensors"
  ],
  "gbemilekeonilude/llama_causalLM_2_7b_s_0.6_q_9": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "gbemilekeonilude/llama_causalLM_2_7b_s_0.8_q_9": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "brainiac-origin/jais-chat-30b-8bit": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "Chat-Error/Testing_orca": [
    "checkpoint-400/adapter_model.safetensors"
  ],
  "typeof/openchat_3.5-sharded": [
    "model-00001-of-00291.safetensors",
    "model-00002-of-00291.safetensors",
    "model-00003-of-00291.safetensors",
    "model-00004-of-00291.safetensors",
    "model-00005-of-00291.safetensors",
    "model-00006-of-00291.safetensors",
    "model-00007-of-00291.safetensors",
    "model-00008-of-00291.safetensors",
    "model-00009-of-00291.safetensors",
    "model-00010-of-00291.safetensors",
    "model-00011-of-00291.safetensors",
    "model-00012-of-00291.safetensors",
    "model-00013-of-00291.safetensors",
    "model-00014-of-00291.safetensors",
    "model-00015-of-00291.safetensors",
    "model-00016-of-00291.safetensors",
    "model-00017-of-00291.safetensors",
    "model-00018-of-00291.safetensors",
    "model-00019-of-00291.safetensors",
    "model-00020-of-00291.safetensors",
    "model-00021-of-00291.safetensors",
    "model-00022-of-00291.safetensors",
    "model-00023-of-00291.safetensors",
    "model-00024-of-00291.safetensors",
    "model-00025-of-00291.safetensors",
    "model-00026-of-00291.safetensors",
    "model-00027-of-00291.safetensors",
    "model-00028-of-00291.safetensors",
    "model-00029-of-00291.safetensors",
    "model-00030-of-00291.safetensors",
    "model-00031-of-00291.safetensors",
    "model-00032-of-00291.safetensors",
    "model-00033-of-00291.safetensors",
    "model-00034-of-00291.safetensors",
    "model-00035-of-00291.safetensors",
    "model-00036-of-00291.safetensors",
    "model-00037-of-00291.safetensors",
    "model-00038-of-00291.safetensors",
    "model-00039-of-00291.safetensors",
    "model-00040-of-00291.safetensors",
    "model-00041-of-00291.safetensors",
    "model-00042-of-00291.safetensors",
    "model-00043-of-00291.safetensors",
    "model-00044-of-00291.safetensors",
    "model-00045-of-00291.safetensors",
    "model-00046-of-00291.safetensors",
    "model-00047-of-00291.safetensors",
    "model-00048-of-00291.safetensors",
    "model-00049-of-00291.safetensors",
    "model-00050-of-00291.safetensors",
    "model-00051-of-00291.safetensors",
    "model-00052-of-00291.safetensors",
    "model-00053-of-00291.safetensors",
    "model-00054-of-00291.safetensors",
    "model-00055-of-00291.safetensors",
    "model-00056-of-00291.safetensors",
    "model-00057-of-00291.safetensors",
    "model-00058-of-00291.safetensors",
    "model-00059-of-00291.safetensors",
    "model-00060-of-00291.safetensors",
    "model-00061-of-00291.safetensors",
    "model-00062-of-00291.safetensors",
    "model-00063-of-00291.safetensors",
    "model-00064-of-00291.safetensors",
    "model-00065-of-00291.safetensors",
    "model-00066-of-00291.safetensors",
    "model-00067-of-00291.safetensors",
    "model-00068-of-00291.safetensors",
    "model-00069-of-00291.safetensors",
    "model-00070-of-00291.safetensors",
    "model-00071-of-00291.safetensors",
    "model-00072-of-00291.safetensors",
    "model-00073-of-00291.safetensors",
    "model-00074-of-00291.safetensors",
    "model-00075-of-00291.safetensors",
    "model-00076-of-00291.safetensors",
    "model-00077-of-00291.safetensors",
    "model-00078-of-00291.safetensors",
    "model-00079-of-00291.safetensors",
    "model-00080-of-00291.safetensors",
    "model-00081-of-00291.safetensors",
    "model-00082-of-00291.safetensors",
    "model-00083-of-00291.safetensors",
    "model-00084-of-00291.safetensors",
    "model-00085-of-00291.safetensors",
    "model-00086-of-00291.safetensors",
    "model-00087-of-00291.safetensors",
    "model-00088-of-00291.safetensors",
    "model-00089-of-00291.safetensors",
    "model-00090-of-00291.safetensors",
    "model-00091-of-00291.safetensors",
    "model-00092-of-00291.safetensors",
    "model-00093-of-00291.safetensors",
    "model-00094-of-00291.safetensors",
    "model-00095-of-00291.safetensors",
    "model-00096-of-00291.safetensors",
    "model-00097-of-00291.safetensors",
    "model-00098-of-00291.safetensors",
    "model-00099-of-00291.safetensors",
    "model-00100-of-00291.safetensors",
    "model-00101-of-00291.safetensors",
    "model-00102-of-00291.safetensors",
    "model-00103-of-00291.safetensors",
    "model-00104-of-00291.safetensors",
    "model-00105-of-00291.safetensors",
    "model-00106-of-00291.safetensors",
    "model-00107-of-00291.safetensors",
    "model-00108-of-00291.safetensors",
    "model-00109-of-00291.safetensors",
    "model-00110-of-00291.safetensors",
    "model-00111-of-00291.safetensors",
    "model-00112-of-00291.safetensors",
    "model-00113-of-00291.safetensors",
    "model-00114-of-00291.safetensors",
    "model-00115-of-00291.safetensors",
    "model-00116-of-00291.safetensors",
    "model-00117-of-00291.safetensors",
    "model-00118-of-00291.safetensors",
    "model-00119-of-00291.safetensors",
    "model-00120-of-00291.safetensors",
    "model-00121-of-00291.safetensors",
    "model-00122-of-00291.safetensors",
    "model-00123-of-00291.safetensors",
    "model-00124-of-00291.safetensors",
    "model-00125-of-00291.safetensors",
    "model-00126-of-00291.safetensors",
    "model-00127-of-00291.safetensors",
    "model-00128-of-00291.safetensors",
    "model-00129-of-00291.safetensors",
    "model-00130-of-00291.safetensors",
    "model-00131-of-00291.safetensors",
    "model-00132-of-00291.safetensors",
    "model-00133-of-00291.safetensors",
    "model-00134-of-00291.safetensors",
    "model-00135-of-00291.safetensors",
    "model-00136-of-00291.safetensors",
    "model-00137-of-00291.safetensors",
    "model-00138-of-00291.safetensors",
    "model-00139-of-00291.safetensors",
    "model-00140-of-00291.safetensors",
    "model-00141-of-00291.safetensors",
    "model-00142-of-00291.safetensors",
    "model-00143-of-00291.safetensors",
    "model-00144-of-00291.safetensors",
    "model-00145-of-00291.safetensors",
    "model-00146-of-00291.safetensors",
    "model-00147-of-00291.safetensors",
    "model-00148-of-00291.safetensors",
    "model-00149-of-00291.safetensors",
    "model-00150-of-00291.safetensors",
    "model-00151-of-00291.safetensors",
    "model-00152-of-00291.safetensors",
    "model-00153-of-00291.safetensors",
    "model-00154-of-00291.safetensors",
    "model-00155-of-00291.safetensors",
    "model-00156-of-00291.safetensors",
    "model-00157-of-00291.safetensors",
    "model-00158-of-00291.safetensors",
    "model-00159-of-00291.safetensors",
    "model-00160-of-00291.safetensors",
    "model-00161-of-00291.safetensors",
    "model-00162-of-00291.safetensors",
    "model-00163-of-00291.safetensors",
    "model-00164-of-00291.safetensors",
    "model-00165-of-00291.safetensors",
    "model-00166-of-00291.safetensors",
    "model-00167-of-00291.safetensors",
    "model-00168-of-00291.safetensors",
    "model-00169-of-00291.safetensors",
    "model-00170-of-00291.safetensors",
    "model-00171-of-00291.safetensors",
    "model-00172-of-00291.safetensors",
    "model-00173-of-00291.safetensors",
    "model-00174-of-00291.safetensors",
    "model-00175-of-00291.safetensors",
    "model-00176-of-00291.safetensors",
    "model-00177-of-00291.safetensors",
    "model-00178-of-00291.safetensors",
    "model-00179-of-00291.safetensors",
    "model-00180-of-00291.safetensors",
    "model-00181-of-00291.safetensors",
    "model-00182-of-00291.safetensors",
    "model-00183-of-00291.safetensors",
    "model-00184-of-00291.safetensors",
    "model-00185-of-00291.safetensors",
    "model-00186-of-00291.safetensors",
    "model-00187-of-00291.safetensors",
    "model-00188-of-00291.safetensors",
    "model-00189-of-00291.safetensors",
    "model-00190-of-00291.safetensors",
    "model-00191-of-00291.safetensors",
    "model-00192-of-00291.safetensors",
    "model-00193-of-00291.safetensors",
    "model-00194-of-00291.safetensors",
    "model-00195-of-00291.safetensors",
    "model-00196-of-00291.safetensors",
    "model-00197-of-00291.safetensors",
    "model-00198-of-00291.safetensors",
    "model-00199-of-00291.safetensors",
    "model-00200-of-00291.safetensors",
    "model-00201-of-00291.safetensors",
    "model-00202-of-00291.safetensors",
    "model-00203-of-00291.safetensors",
    "model-00204-of-00291.safetensors",
    "model-00205-of-00291.safetensors",
    "model-00206-of-00291.safetensors",
    "model-00207-of-00291.safetensors",
    "model-00208-of-00291.safetensors",
    "model-00209-of-00291.safetensors",
    "model-00210-of-00291.safetensors",
    "model-00211-of-00291.safetensors",
    "model-00212-of-00291.safetensors",
    "model-00213-of-00291.safetensors",
    "model-00214-of-00291.safetensors",
    "model-00215-of-00291.safetensors",
    "model-00216-of-00291.safetensors",
    "model-00217-of-00291.safetensors",
    "model-00218-of-00291.safetensors",
    "model-00219-of-00291.safetensors",
    "model-00220-of-00291.safetensors",
    "model-00221-of-00291.safetensors",
    "model-00222-of-00291.safetensors",
    "model-00223-of-00291.safetensors",
    "model-00224-of-00291.safetensors",
    "model-00225-of-00291.safetensors",
    "model-00226-of-00291.safetensors",
    "model-00227-of-00291.safetensors",
    "model-00228-of-00291.safetensors",
    "model-00229-of-00291.safetensors",
    "model-00230-of-00291.safetensors",
    "model-00231-of-00291.safetensors",
    "model-00232-of-00291.safetensors",
    "model-00233-of-00291.safetensors",
    "model-00234-of-00291.safetensors",
    "model-00235-of-00291.safetensors",
    "model-00236-of-00291.safetensors",
    "model-00237-of-00291.safetensors",
    "model-00238-of-00291.safetensors",
    "model-00239-of-00291.safetensors",
    "model-00240-of-00291.safetensors",
    "model-00241-of-00291.safetensors",
    "model-00242-of-00291.safetensors",
    "model-00243-of-00291.safetensors",
    "model-00244-of-00291.safetensors",
    "model-00245-of-00291.safetensors",
    "model-00246-of-00291.safetensors",
    "model-00247-of-00291.safetensors",
    "model-00248-of-00291.safetensors",
    "model-00249-of-00291.safetensors",
    "model-00250-of-00291.safetensors",
    "model-00251-of-00291.safetensors",
    "model-00252-of-00291.safetensors",
    "model-00253-of-00291.safetensors",
    "model-00254-of-00291.safetensors",
    "model-00255-of-00291.safetensors",
    "model-00256-of-00291.safetensors",
    "model-00257-of-00291.safetensors",
    "model-00258-of-00291.safetensors",
    "model-00259-of-00291.safetensors",
    "model-00260-of-00291.safetensors",
    "model-00261-of-00291.safetensors",
    "model-00262-of-00291.safetensors",
    "model-00263-of-00291.safetensors",
    "model-00264-of-00291.safetensors",
    "model-00265-of-00291.safetensors",
    "model-00266-of-00291.safetensors",
    "model-00267-of-00291.safetensors",
    "model-00268-of-00291.safetensors",
    "model-00269-of-00291.safetensors",
    "model-00270-of-00291.safetensors",
    "model-00271-of-00291.safetensors",
    "model-00272-of-00291.safetensors",
    "model-00273-of-00291.safetensors",
    "model-00274-of-00291.safetensors",
    "model-00275-of-00291.safetensors",
    "model-00276-of-00291.safetensors",
    "model-00277-of-00291.safetensors",
    "model-00278-of-00291.safetensors",
    "model-00279-of-00291.safetensors",
    "model-00280-of-00291.safetensors",
    "model-00281-of-00291.safetensors",
    "model-00282-of-00291.safetensors",
    "model-00283-of-00291.safetensors",
    "model-00284-of-00291.safetensors",
    "model-00285-of-00291.safetensors",
    "model-00286-of-00291.safetensors",
    "model-00287-of-00291.safetensors",
    "model-00288-of-00291.safetensors",
    "model-00289-of-00291.safetensors",
    "model-00290-of-00291.safetensors",
    "model-00291-of-00291.safetensors"
  ],
  "yjoon/openchat_3.5-lora-test": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "kimjames/viet_1.3b_FT5000_dpo_epoch3": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "NurtureAI/Orca-2-7B-16k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "presencesw/vietcuna-7b-v3_luat": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "flozi00/Mistral-7B-german-assistant-v5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "NurtureAI/Orca-2-13B-16k": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "migtissera/Tess-M-v1.1": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "MrBananaHuman/kogpt2-base-v2-simple-qa": [
    "model.safetensors"
  ],
  "MrBananaHuman/kogpt2_small_simple_qa": [
    "model.safetensors"
  ],
  "yilinjz/opt-125m-gptq": [
    "model.safetensors"
  ],
  "NurtureAI/Orca-2-7B-16k-AWQ": [
    "model.safetensors"
  ],
  "migtissera/Tess-XS-v1.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "vishruthnath/llama_recursive_prune_iter_0_sp32.829949500060486": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "vishruthnath/llama_recursive_prune_iter_1_sp32.829949500060486": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "peterbeamish/env-analysis1-llama-7b-long": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mrbmaryam/zephyr-7b-beta_Fine-Tuning4Log-Parsing": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "relaxml/Llama-2-13b-E8P-2Bit": [
    "model.safetensors"
  ],
  "relaxml/Llama-1-30b-E8P-2Bit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors",
    "model.safetensors"
  ],
  "relaxml/Llama-2-7b-E8P-2Bit": [
    "model.safetensors"
  ],
  "relaxml/Llama-1-7b-E8P-2Bit": [
    "model.safetensors"
  ],
  "relaxml/Llama-1-13b-E8P-2Bit": [
    "model.safetensors"
  ],
  "vishruthnath/llama_recursive_prune_iter_2_sp32.829949500060486": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "NurtureAI/Orca-2-13B-16k-AWQ": [
    "model.safetensors"
  ],
  "dangvansam/finetune_OpenHermes_2.5_prompt_v3_group_by_len_bf16_lr1e-5_constant_max_len_1024_small_dataset": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoftQ/Mistral-7B-v0.1-4bit-32rank": [
    "loftq_init/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TinyPixel/small-llama": [
    "model.safetensors"
  ],
  "LoftQ/Mistral-7B-v0.1-4bit-64rank": [
    "gsm8k/adapter_model.safetensors",
    "loftq_init/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Gryphe/MythoMist-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "csdc-atl/buffer-baichuan2-13B-rag-4bits": [
    "model.safetensors"
  ],
  "MilaWang/distilgpt2-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "mrbmaryam/Yarn-Mistral-7b-128k_Fine-Tuning4Log-Parsing": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jarvisloh/distilgpt2-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "umarbutler/open-australian-legal-gpt2": [
    "model.safetensors"
  ],
  "TinyPixel/small-llama2": [
    "model.safetensors"
  ],
  "wons/llama2-13b-test-v0.1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/Tess-M-v1.1-3.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/Tess-M-v1.1-6.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "DrCacao/RAGANGPT": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "qqplot23/results": [
    "model.safetensors"
  ],
  "TinyPixel/gpt_2": [
    "model.safetensors"
  ],
  "flozi00/Mistral-7B-german-assistant-v5-4bit-autogptq": [
    "model.safetensors"
  ],
  "LoneStriker/Tess-M-v1.1-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Tess-M-v1.1-8.0bpw-h8-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "TheBloke/MythoMist-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/MythoMist-7B-GPTQ": [
    "model.safetensors"
  ],
  "LoneStriker/Tess-M-v1.1-4.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Tess-M-v1.1-5.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "Santosh-Gupta/EncephalitisGPT": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "dustydecapod/unraveled-7b-dpo-lora": [
    "adapter_model.safetensors"
  ],
  "TheBloke/Tess-M-v1.1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Tess-M-v1.1-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "01-ai/Yi-34B-Chat": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "01-ai/Yi-6B-Chat": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "01-ai/Yi-34B-Chat-8bits": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "01-ai/Yi-34B-Chat-4bits": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "01-ai/Yi-6B-Chat-8bits": [
    "model.safetensors"
  ],
  "01-ai/Yi-6B-Chat-4bits": [
    "model.safetensors"
  ],
  "desarrolloasesoreslocales/jina-embeddings-v2-base-en-finetuned-legalcorpus": [
    "model.safetensors"
  ],
  "vishruthnath/llama_rec_simulate_prune_iter_0_sp_0.33": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "vishruthnath/llama_rec_simulate_prune_iter_1_sp_0.5511": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "zweack/meta-llama-2-7b-chat-hf_4bit_quantized": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "vishruthnath/llama_rec_simulate_prune_iter_2_sp_0.6992": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "vishruthnath/llama_rec_simulate_prune_iter_3_sp_0.7985": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "vishruthnath/llama_rec_simulate_prune_iter_4_sp_0.865": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "vishruthnath/llama_rec_simulate_prune_iter_5_sp_0.9095": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "habanoz/TinyLlama-1.1B-intermediate-step-715k-1.5T-lr-5-1epch-airoboros3.1-1k-instruct-V1": [
    "model.safetensors"
  ],
  "uukuguy/speechless-mistral-7b-dare-0.85": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "waldie/MythoMist-7b-8bpw-h8-exl2": [
    "output.safetensors"
  ],
  "DrCacao/RAGANGPT-3b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "vishruthnath/llama_rec_simulate_prune_iter_6_sp_0.9394": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "habanoz/phi-1_5-lr-5-1epch-airoboros3.1-1k-instruct-V1": [
    "model.safetensors"
  ],
  "vishruthnath/llama_rec_simulate_prune_iter_7_sp_0.9594": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Recag/BharatAI": [
    "model.safetensors"
  ],
  "kunley2/llama2-7b-text-sql": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "vishruthnath/llama_rec_simulate_prune_iter_8_sp_0.9728": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "TheBloke/OrionStar-Yi-34B-Chat-Llama-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/OrionStar-Yi-34B-Chat-Llama-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "vishruthnath/llama_rec_simulate_prune_iter_9_sp_0.9818": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "speechlessai/speechless-mistral-7b-dare-0.85": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "EnzoVeltri/tableLlama-4bit": [
    "model.safetensors"
  ],
  "ai2sql/ai2sql-falcon-7b": [
    "adapter_model.safetensors"
  ],
  "pradipghevariya/Llama-2-7b-chat-Medquad-Merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "wons/mistral-7B-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jensh2/gpt2-wikitext2": [
    "model.safetensors"
  ],
  "Hejjee/iDonna_depression_v2": [
    "model.safetensors"
  ],
  "Shani123/openchat_3.5": [
    "model-00001-of-00034.safetensors",
    "model-00002-of-00034.safetensors",
    "model-00003-of-00034.safetensors",
    "model-00004-of-00034.safetensors",
    "model-00005-of-00034.safetensors",
    "model-00006-of-00034.safetensors",
    "model-00007-of-00034.safetensors",
    "model-00008-of-00034.safetensors",
    "model-00009-of-00034.safetensors",
    "model-00010-of-00034.safetensors",
    "model-00011-of-00034.safetensors",
    "model-00012-of-00034.safetensors",
    "model-00013-of-00034.safetensors",
    "model-00014-of-00034.safetensors",
    "model-00015-of-00034.safetensors",
    "model-00016-of-00034.safetensors",
    "model-00017-of-00034.safetensors",
    "model-00018-of-00034.safetensors",
    "model-00019-of-00034.safetensors",
    "model-00020-of-00034.safetensors",
    "model-00021-of-00034.safetensors",
    "model-00022-of-00034.safetensors",
    "model-00023-of-00034.safetensors",
    "model-00024-of-00034.safetensors",
    "model-00025-of-00034.safetensors",
    "model-00026-of-00034.safetensors",
    "model-00027-of-00034.safetensors",
    "model-00028-of-00034.safetensors",
    "model-00029-of-00034.safetensors",
    "model-00030-of-00034.safetensors",
    "model-00031-of-00034.safetensors",
    "model-00032-of-00034.safetensors",
    "model-00033-of-00034.safetensors",
    "model-00034-of-00034.safetensors"
  ],
  "un-model-runs/coarse-relevancy-multi-label-llama-2-7B-4k-tiny-mixed-real-data-heavy": [
    "adapter_model.safetensors",
    "checkpoint-122/adapter_model.safetensors",
    "checkpoint-163/adapter_model.safetensors",
    "checkpoint-197/adapter_model.safetensors",
    "checkpoint-296/adapter_model.safetensors",
    "checkpoint-40/adapter_model.safetensors",
    "checkpoint-81/adapter_model.safetensors",
    "checkpoint-98/adapter_model.safetensors"
  ],
  "mrbmaryam/Llama-2-7b-chat-hf_Fine-Tuning4Log-Parsing": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dustydecapod/unraveled-7b-a1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "qqplot23/BASE": [
    "model.safetensors"
  ],
  "qqplot23/BASE_short": [
    "model.safetensors"
  ],
  "tavtav/Rose-20B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "AswanthCManoj/azma-v1": [
    "model.safetensors"
  ],
  "TokenBender/evolvedSeeker_1_3": [
    "model.safetensors"
  ],
  "sajjadamjad/ghostwriter_v5": [
    "model.safetensors"
  ],
  "RachitD15673/mistral-finetuned-7B-instruct-LLM": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mrm8488/Mistral-7B-v0.1-sys-inst": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "tianlinliu0121/zephyr-7b-dpo-full-beta-0.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "shiiiiiiiiii/codellama2-finetuned-shiii": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/rocket-3B-GPTQ": [
    "model.safetensors"
  ],
  "nttrung/git-base-pokemon": [
    "model.safetensors"
  ],
  "florentgbelidji/leoLM-13b-sft-lora-oa": [
    "adapter_model.safetensors"
  ],
  "LoneStriker/MythoMist-7b-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/MythoMist-7b-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "AswanthCManoj/azma-v2": [
    "model.safetensors"
  ],
  "un-model-runs/coarse-relevancy-multi-label-llama-2-7B-4k-tiny-mixed-real-data-heavy-low-rank": [
    "adapter_model.safetensors",
    "checkpoint-197/adapter_model.safetensors",
    "checkpoint-98/adapter_model.safetensors"
  ],
  "LoneStriker/MythoMist-7b-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/MythoMist-7b-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "VamsiPranav/sequential-training": [
    "model.safetensors"
  ],
  "LoneStriker/Tess-XS-Creative-v1.0-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "un-model-runs/coarse-relevancy-multi-label-llama-2-7B-4k-tiny-mixed-real-data-heavy-tiny-rank": [
    "adapter_model.safetensors",
    "checkpoint-197/adapter_model.safetensors",
    "checkpoint-698/adapter_model.safetensors",
    "checkpoint-98/adapter_model.safetensors"
  ],
  "techandy42/gpt2-imdb-pos-v2": [
    "model.safetensors"
  ],
  "LoneStriker/Tess-XS-Creative-v1.0-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Tess-XS-Creative-v1.0-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "typeof/neural-chat-7b-v3-1-sharded": [
    "model-00001-of-00291.safetensors",
    "model-00002-of-00291.safetensors",
    "model-00003-of-00291.safetensors",
    "model-00004-of-00291.safetensors",
    "model-00005-of-00291.safetensors",
    "model-00006-of-00291.safetensors",
    "model-00007-of-00291.safetensors",
    "model-00008-of-00291.safetensors",
    "model-00009-of-00291.safetensors",
    "model-00010-of-00291.safetensors",
    "model-00011-of-00291.safetensors",
    "model-00012-of-00291.safetensors",
    "model-00013-of-00291.safetensors",
    "model-00014-of-00291.safetensors",
    "model-00015-of-00291.safetensors",
    "model-00016-of-00291.safetensors",
    "model-00017-of-00291.safetensors",
    "model-00018-of-00291.safetensors",
    "model-00019-of-00291.safetensors",
    "model-00020-of-00291.safetensors",
    "model-00021-of-00291.safetensors",
    "model-00022-of-00291.safetensors",
    "model-00023-of-00291.safetensors",
    "model-00024-of-00291.safetensors",
    "model-00025-of-00291.safetensors",
    "model-00026-of-00291.safetensors",
    "model-00027-of-00291.safetensors",
    "model-00028-of-00291.safetensors",
    "model-00029-of-00291.safetensors",
    "model-00030-of-00291.safetensors",
    "model-00031-of-00291.safetensors",
    "model-00032-of-00291.safetensors",
    "model-00033-of-00291.safetensors",
    "model-00034-of-00291.safetensors",
    "model-00035-of-00291.safetensors",
    "model-00036-of-00291.safetensors",
    "model-00037-of-00291.safetensors",
    "model-00038-of-00291.safetensors",
    "model-00039-of-00291.safetensors",
    "model-00040-of-00291.safetensors",
    "model-00041-of-00291.safetensors",
    "model-00042-of-00291.safetensors",
    "model-00043-of-00291.safetensors",
    "model-00044-of-00291.safetensors",
    "model-00045-of-00291.safetensors",
    "model-00046-of-00291.safetensors",
    "model-00047-of-00291.safetensors",
    "model-00048-of-00291.safetensors",
    "model-00049-of-00291.safetensors",
    "model-00050-of-00291.safetensors",
    "model-00051-of-00291.safetensors",
    "model-00052-of-00291.safetensors",
    "model-00053-of-00291.safetensors",
    "model-00054-of-00291.safetensors",
    "model-00055-of-00291.safetensors",
    "model-00056-of-00291.safetensors",
    "model-00057-of-00291.safetensors",
    "model-00058-of-00291.safetensors",
    "model-00059-of-00291.safetensors",
    "model-00060-of-00291.safetensors",
    "model-00061-of-00291.safetensors",
    "model-00062-of-00291.safetensors",
    "model-00063-of-00291.safetensors",
    "model-00064-of-00291.safetensors",
    "model-00065-of-00291.safetensors",
    "model-00066-of-00291.safetensors",
    "model-00067-of-00291.safetensors",
    "model-00068-of-00291.safetensors",
    "model-00069-of-00291.safetensors",
    "model-00070-of-00291.safetensors",
    "model-00071-of-00291.safetensors",
    "model-00072-of-00291.safetensors",
    "model-00073-of-00291.safetensors",
    "model-00074-of-00291.safetensors",
    "model-00075-of-00291.safetensors",
    "model-00076-of-00291.safetensors",
    "model-00077-of-00291.safetensors",
    "model-00078-of-00291.safetensors",
    "model-00079-of-00291.safetensors",
    "model-00080-of-00291.safetensors",
    "model-00081-of-00291.safetensors",
    "model-00082-of-00291.safetensors",
    "model-00083-of-00291.safetensors",
    "model-00084-of-00291.safetensors",
    "model-00085-of-00291.safetensors",
    "model-00086-of-00291.safetensors",
    "model-00087-of-00291.safetensors",
    "model-00088-of-00291.safetensors",
    "model-00089-of-00291.safetensors",
    "model-00090-of-00291.safetensors",
    "model-00091-of-00291.safetensors",
    "model-00092-of-00291.safetensors",
    "model-00093-of-00291.safetensors",
    "model-00094-of-00291.safetensors",
    "model-00095-of-00291.safetensors",
    "model-00096-of-00291.safetensors",
    "model-00097-of-00291.safetensors",
    "model-00098-of-00291.safetensors",
    "model-00099-of-00291.safetensors",
    "model-00100-of-00291.safetensors",
    "model-00101-of-00291.safetensors",
    "model-00102-of-00291.safetensors",
    "model-00103-of-00291.safetensors",
    "model-00104-of-00291.safetensors",
    "model-00105-of-00291.safetensors",
    "model-00106-of-00291.safetensors",
    "model-00107-of-00291.safetensors",
    "model-00108-of-00291.safetensors",
    "model-00109-of-00291.safetensors",
    "model-00110-of-00291.safetensors",
    "model-00111-of-00291.safetensors",
    "model-00112-of-00291.safetensors",
    "model-00113-of-00291.safetensors",
    "model-00114-of-00291.safetensors",
    "model-00115-of-00291.safetensors",
    "model-00116-of-00291.safetensors",
    "model-00117-of-00291.safetensors",
    "model-00118-of-00291.safetensors",
    "model-00119-of-00291.safetensors",
    "model-00120-of-00291.safetensors",
    "model-00121-of-00291.safetensors",
    "model-00122-of-00291.safetensors",
    "model-00123-of-00291.safetensors",
    "model-00124-of-00291.safetensors",
    "model-00125-of-00291.safetensors",
    "model-00126-of-00291.safetensors",
    "model-00127-of-00291.safetensors",
    "model-00128-of-00291.safetensors",
    "model-00129-of-00291.safetensors",
    "model-00130-of-00291.safetensors",
    "model-00131-of-00291.safetensors",
    "model-00132-of-00291.safetensors",
    "model-00133-of-00291.safetensors",
    "model-00134-of-00291.safetensors",
    "model-00135-of-00291.safetensors",
    "model-00136-of-00291.safetensors",
    "model-00137-of-00291.safetensors",
    "model-00138-of-00291.safetensors",
    "model-00139-of-00291.safetensors",
    "model-00140-of-00291.safetensors",
    "model-00141-of-00291.safetensors",
    "model-00142-of-00291.safetensors",
    "model-00143-of-00291.safetensors",
    "model-00144-of-00291.safetensors",
    "model-00145-of-00291.safetensors",
    "model-00146-of-00291.safetensors",
    "model-00147-of-00291.safetensors",
    "model-00148-of-00291.safetensors",
    "model-00149-of-00291.safetensors",
    "model-00150-of-00291.safetensors",
    "model-00151-of-00291.safetensors",
    "model-00152-of-00291.safetensors",
    "model-00153-of-00291.safetensors",
    "model-00154-of-00291.safetensors",
    "model-00155-of-00291.safetensors",
    "model-00156-of-00291.safetensors",
    "model-00157-of-00291.safetensors",
    "model-00158-of-00291.safetensors",
    "model-00159-of-00291.safetensors",
    "model-00160-of-00291.safetensors",
    "model-00161-of-00291.safetensors",
    "model-00162-of-00291.safetensors",
    "model-00163-of-00291.safetensors",
    "model-00164-of-00291.safetensors",
    "model-00165-of-00291.safetensors",
    "model-00166-of-00291.safetensors",
    "model-00167-of-00291.safetensors",
    "model-00168-of-00291.safetensors",
    "model-00169-of-00291.safetensors",
    "model-00170-of-00291.safetensors",
    "model-00171-of-00291.safetensors",
    "model-00172-of-00291.safetensors",
    "model-00173-of-00291.safetensors",
    "model-00174-of-00291.safetensors",
    "model-00175-of-00291.safetensors",
    "model-00176-of-00291.safetensors",
    "model-00177-of-00291.safetensors",
    "model-00178-of-00291.safetensors",
    "model-00179-of-00291.safetensors",
    "model-00180-of-00291.safetensors",
    "model-00181-of-00291.safetensors",
    "model-00182-of-00291.safetensors",
    "model-00183-of-00291.safetensors",
    "model-00184-of-00291.safetensors",
    "model-00185-of-00291.safetensors",
    "model-00186-of-00291.safetensors",
    "model-00187-of-00291.safetensors",
    "model-00188-of-00291.safetensors",
    "model-00189-of-00291.safetensors",
    "model-00190-of-00291.safetensors",
    "model-00191-of-00291.safetensors",
    "model-00192-of-00291.safetensors",
    "model-00193-of-00291.safetensors",
    "model-00194-of-00291.safetensors",
    "model-00195-of-00291.safetensors",
    "model-00196-of-00291.safetensors",
    "model-00197-of-00291.safetensors",
    "model-00198-of-00291.safetensors",
    "model-00199-of-00291.safetensors",
    "model-00200-of-00291.safetensors",
    "model-00201-of-00291.safetensors",
    "model-00202-of-00291.safetensors",
    "model-00203-of-00291.safetensors",
    "model-00204-of-00291.safetensors",
    "model-00205-of-00291.safetensors",
    "model-00206-of-00291.safetensors",
    "model-00207-of-00291.safetensors",
    "model-00208-of-00291.safetensors",
    "model-00209-of-00291.safetensors",
    "model-00210-of-00291.safetensors",
    "model-00211-of-00291.safetensors",
    "model-00212-of-00291.safetensors",
    "model-00213-of-00291.safetensors",
    "model-00214-of-00291.safetensors",
    "model-00215-of-00291.safetensors",
    "model-00216-of-00291.safetensors",
    "model-00217-of-00291.safetensors",
    "model-00218-of-00291.safetensors",
    "model-00219-of-00291.safetensors",
    "model-00220-of-00291.safetensors",
    "model-00221-of-00291.safetensors",
    "model-00222-of-00291.safetensors",
    "model-00223-of-00291.safetensors",
    "model-00224-of-00291.safetensors",
    "model-00225-of-00291.safetensors",
    "model-00226-of-00291.safetensors",
    "model-00227-of-00291.safetensors",
    "model-00228-of-00291.safetensors",
    "model-00229-of-00291.safetensors",
    "model-00230-of-00291.safetensors",
    "model-00231-of-00291.safetensors",
    "model-00232-of-00291.safetensors",
    "model-00233-of-00291.safetensors",
    "model-00234-of-00291.safetensors",
    "model-00235-of-00291.safetensors",
    "model-00236-of-00291.safetensors",
    "model-00237-of-00291.safetensors",
    "model-00238-of-00291.safetensors",
    "model-00239-of-00291.safetensors",
    "model-00240-of-00291.safetensors",
    "model-00241-of-00291.safetensors",
    "model-00242-of-00291.safetensors",
    "model-00243-of-00291.safetensors",
    "model-00244-of-00291.safetensors",
    "model-00245-of-00291.safetensors",
    "model-00246-of-00291.safetensors",
    "model-00247-of-00291.safetensors",
    "model-00248-of-00291.safetensors",
    "model-00249-of-00291.safetensors",
    "model-00250-of-00291.safetensors",
    "model-00251-of-00291.safetensors",
    "model-00252-of-00291.safetensors",
    "model-00253-of-00291.safetensors",
    "model-00254-of-00291.safetensors",
    "model-00255-of-00291.safetensors",
    "model-00256-of-00291.safetensors",
    "model-00257-of-00291.safetensors",
    "model-00258-of-00291.safetensors",
    "model-00259-of-00291.safetensors",
    "model-00260-of-00291.safetensors",
    "model-00261-of-00291.safetensors",
    "model-00262-of-00291.safetensors",
    "model-00263-of-00291.safetensors",
    "model-00264-of-00291.safetensors",
    "model-00265-of-00291.safetensors",
    "model-00266-of-00291.safetensors",
    "model-00267-of-00291.safetensors",
    "model-00268-of-00291.safetensors",
    "model-00269-of-00291.safetensors",
    "model-00270-of-00291.safetensors",
    "model-00271-of-00291.safetensors",
    "model-00272-of-00291.safetensors",
    "model-00273-of-00291.safetensors",
    "model-00274-of-00291.safetensors",
    "model-00275-of-00291.safetensors",
    "model-00276-of-00291.safetensors",
    "model-00277-of-00291.safetensors",
    "model-00278-of-00291.safetensors",
    "model-00279-of-00291.safetensors",
    "model-00280-of-00291.safetensors",
    "model-00281-of-00291.safetensors",
    "model-00282-of-00291.safetensors",
    "model-00283-of-00291.safetensors",
    "model-00284-of-00291.safetensors",
    "model-00285-of-00291.safetensors",
    "model-00286-of-00291.safetensors",
    "model-00287-of-00291.safetensors",
    "model-00288-of-00291.safetensors",
    "model-00289-of-00291.safetensors",
    "model-00290-of-00291.safetensors",
    "model-00291-of-00291.safetensors"
  ],
  "LoneStriker/Tess-XS-Creative-v1.0-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "Jiayi-Pan/Tiny-Vicuna-1B": [
    "model.safetensors"
  ],
  "TheBloke/Tess-XS-Creative-v1.0-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Tess-XS-Creative-v1.0-AWQ": [
    "model.safetensors"
  ],
  "Cordmail/an-Mistral-7B-qLora-neg": [
    "adapter_model.safetensors"
  ],
  "TheBloke/Tess-XS-v1.1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Tess-XS-v1.1-AWQ": [
    "model.safetensors"
  ],
  "techandy42/gpt2-real-toxicity-prompts": [
    "model.safetensors"
  ],
  "joedonino/zephyr-7b-radia-html-events_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Chupacabra-7B-v2-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Chupacabra-7B-v2-GPTQ": [
    "model.safetensors"
  ],
  "typeof/morph-prover-v0-7b-sharded": [
    "model-00001-of-00291.safetensors",
    "model-00002-of-00291.safetensors",
    "model-00003-of-00291.safetensors",
    "model-00004-of-00291.safetensors",
    "model-00005-of-00291.safetensors",
    "model-00006-of-00291.safetensors",
    "model-00007-of-00291.safetensors",
    "model-00008-of-00291.safetensors",
    "model-00009-of-00291.safetensors",
    "model-00010-of-00291.safetensors",
    "model-00011-of-00291.safetensors",
    "model-00012-of-00291.safetensors",
    "model-00013-of-00291.safetensors",
    "model-00014-of-00291.safetensors",
    "model-00015-of-00291.safetensors",
    "model-00016-of-00291.safetensors",
    "model-00017-of-00291.safetensors",
    "model-00018-of-00291.safetensors",
    "model-00019-of-00291.safetensors",
    "model-00020-of-00291.safetensors",
    "model-00021-of-00291.safetensors",
    "model-00022-of-00291.safetensors",
    "model-00023-of-00291.safetensors",
    "model-00024-of-00291.safetensors",
    "model-00025-of-00291.safetensors",
    "model-00026-of-00291.safetensors",
    "model-00027-of-00291.safetensors",
    "model-00028-of-00291.safetensors",
    "model-00029-of-00291.safetensors",
    "model-00030-of-00291.safetensors",
    "model-00031-of-00291.safetensors",
    "model-00032-of-00291.safetensors",
    "model-00033-of-00291.safetensors",
    "model-00034-of-00291.safetensors",
    "model-00035-of-00291.safetensors",
    "model-00036-of-00291.safetensors",
    "model-00037-of-00291.safetensors",
    "model-00038-of-00291.safetensors",
    "model-00039-of-00291.safetensors",
    "model-00040-of-00291.safetensors",
    "model-00041-of-00291.safetensors",
    "model-00042-of-00291.safetensors",
    "model-00043-of-00291.safetensors",
    "model-00044-of-00291.safetensors",
    "model-00045-of-00291.safetensors",
    "model-00046-of-00291.safetensors",
    "model-00047-of-00291.safetensors",
    "model-00048-of-00291.safetensors",
    "model-00049-of-00291.safetensors",
    "model-00050-of-00291.safetensors",
    "model-00051-of-00291.safetensors",
    "model-00052-of-00291.safetensors",
    "model-00053-of-00291.safetensors",
    "model-00054-of-00291.safetensors",
    "model-00055-of-00291.safetensors",
    "model-00056-of-00291.safetensors",
    "model-00057-of-00291.safetensors",
    "model-00058-of-00291.safetensors",
    "model-00059-of-00291.safetensors",
    "model-00060-of-00291.safetensors",
    "model-00061-of-00291.safetensors",
    "model-00062-of-00291.safetensors",
    "model-00063-of-00291.safetensors",
    "model-00064-of-00291.safetensors",
    "model-00065-of-00291.safetensors",
    "model-00066-of-00291.safetensors",
    "model-00067-of-00291.safetensors",
    "model-00068-of-00291.safetensors",
    "model-00069-of-00291.safetensors",
    "model-00070-of-00291.safetensors",
    "model-00071-of-00291.safetensors",
    "model-00072-of-00291.safetensors",
    "model-00073-of-00291.safetensors",
    "model-00074-of-00291.safetensors",
    "model-00075-of-00291.safetensors",
    "model-00076-of-00291.safetensors",
    "model-00077-of-00291.safetensors",
    "model-00078-of-00291.safetensors",
    "model-00079-of-00291.safetensors",
    "model-00080-of-00291.safetensors",
    "model-00081-of-00291.safetensors",
    "model-00082-of-00291.safetensors",
    "model-00083-of-00291.safetensors",
    "model-00084-of-00291.safetensors",
    "model-00085-of-00291.safetensors",
    "model-00086-of-00291.safetensors",
    "model-00087-of-00291.safetensors",
    "model-00088-of-00291.safetensors",
    "model-00089-of-00291.safetensors",
    "model-00090-of-00291.safetensors",
    "model-00091-of-00291.safetensors",
    "model-00092-of-00291.safetensors",
    "model-00093-of-00291.safetensors",
    "model-00094-of-00291.safetensors",
    "model-00095-of-00291.safetensors",
    "model-00096-of-00291.safetensors",
    "model-00097-of-00291.safetensors",
    "model-00098-of-00291.safetensors",
    "model-00099-of-00291.safetensors",
    "model-00100-of-00291.safetensors",
    "model-00101-of-00291.safetensors",
    "model-00102-of-00291.safetensors",
    "model-00103-of-00291.safetensors",
    "model-00104-of-00291.safetensors",
    "model-00105-of-00291.safetensors",
    "model-00106-of-00291.safetensors",
    "model-00107-of-00291.safetensors",
    "model-00108-of-00291.safetensors",
    "model-00109-of-00291.safetensors",
    "model-00110-of-00291.safetensors",
    "model-00111-of-00291.safetensors",
    "model-00112-of-00291.safetensors",
    "model-00113-of-00291.safetensors",
    "model-00114-of-00291.safetensors",
    "model-00115-of-00291.safetensors",
    "model-00116-of-00291.safetensors",
    "model-00117-of-00291.safetensors",
    "model-00118-of-00291.safetensors",
    "model-00119-of-00291.safetensors",
    "model-00120-of-00291.safetensors",
    "model-00121-of-00291.safetensors",
    "model-00122-of-00291.safetensors",
    "model-00123-of-00291.safetensors",
    "model-00124-of-00291.safetensors",
    "model-00125-of-00291.safetensors",
    "model-00126-of-00291.safetensors",
    "model-00127-of-00291.safetensors",
    "model-00128-of-00291.safetensors",
    "model-00129-of-00291.safetensors",
    "model-00130-of-00291.safetensors",
    "model-00131-of-00291.safetensors",
    "model-00132-of-00291.safetensors",
    "model-00133-of-00291.safetensors",
    "model-00134-of-00291.safetensors",
    "model-00135-of-00291.safetensors",
    "model-00136-of-00291.safetensors",
    "model-00137-of-00291.safetensors",
    "model-00138-of-00291.safetensors",
    "model-00139-of-00291.safetensors",
    "model-00140-of-00291.safetensors",
    "model-00141-of-00291.safetensors",
    "model-00142-of-00291.safetensors",
    "model-00143-of-00291.safetensors",
    "model-00144-of-00291.safetensors",
    "model-00145-of-00291.safetensors",
    "model-00146-of-00291.safetensors",
    "model-00147-of-00291.safetensors",
    "model-00148-of-00291.safetensors",
    "model-00149-of-00291.safetensors",
    "model-00150-of-00291.safetensors",
    "model-00151-of-00291.safetensors",
    "model-00152-of-00291.safetensors",
    "model-00153-of-00291.safetensors",
    "model-00154-of-00291.safetensors",
    "model-00155-of-00291.safetensors",
    "model-00156-of-00291.safetensors",
    "model-00157-of-00291.safetensors",
    "model-00158-of-00291.safetensors",
    "model-00159-of-00291.safetensors",
    "model-00160-of-00291.safetensors",
    "model-00161-of-00291.safetensors",
    "model-00162-of-00291.safetensors",
    "model-00163-of-00291.safetensors",
    "model-00164-of-00291.safetensors",
    "model-00165-of-00291.safetensors",
    "model-00166-of-00291.safetensors",
    "model-00167-of-00291.safetensors",
    "model-00168-of-00291.safetensors",
    "model-00169-of-00291.safetensors",
    "model-00170-of-00291.safetensors",
    "model-00171-of-00291.safetensors",
    "model-00172-of-00291.safetensors",
    "model-00173-of-00291.safetensors",
    "model-00174-of-00291.safetensors",
    "model-00175-of-00291.safetensors",
    "model-00176-of-00291.safetensors",
    "model-00177-of-00291.safetensors",
    "model-00178-of-00291.safetensors",
    "model-00179-of-00291.safetensors",
    "model-00180-of-00291.safetensors",
    "model-00181-of-00291.safetensors",
    "model-00182-of-00291.safetensors",
    "model-00183-of-00291.safetensors",
    "model-00184-of-00291.safetensors",
    "model-00185-of-00291.safetensors",
    "model-00186-of-00291.safetensors",
    "model-00187-of-00291.safetensors",
    "model-00188-of-00291.safetensors",
    "model-00189-of-00291.safetensors",
    "model-00190-of-00291.safetensors",
    "model-00191-of-00291.safetensors",
    "model-00192-of-00291.safetensors",
    "model-00193-of-00291.safetensors",
    "model-00194-of-00291.safetensors",
    "model-00195-of-00291.safetensors",
    "model-00196-of-00291.safetensors",
    "model-00197-of-00291.safetensors",
    "model-00198-of-00291.safetensors",
    "model-00199-of-00291.safetensors",
    "model-00200-of-00291.safetensors",
    "model-00201-of-00291.safetensors",
    "model-00202-of-00291.safetensors",
    "model-00203-of-00291.safetensors",
    "model-00204-of-00291.safetensors",
    "model-00205-of-00291.safetensors",
    "model-00206-of-00291.safetensors",
    "model-00207-of-00291.safetensors",
    "model-00208-of-00291.safetensors",
    "model-00209-of-00291.safetensors",
    "model-00210-of-00291.safetensors",
    "model-00211-of-00291.safetensors",
    "model-00212-of-00291.safetensors",
    "model-00213-of-00291.safetensors",
    "model-00214-of-00291.safetensors",
    "model-00215-of-00291.safetensors",
    "model-00216-of-00291.safetensors",
    "model-00217-of-00291.safetensors",
    "model-00218-of-00291.safetensors",
    "model-00219-of-00291.safetensors",
    "model-00220-of-00291.safetensors",
    "model-00221-of-00291.safetensors",
    "model-00222-of-00291.safetensors",
    "model-00223-of-00291.safetensors",
    "model-00224-of-00291.safetensors",
    "model-00225-of-00291.safetensors",
    "model-00226-of-00291.safetensors",
    "model-00227-of-00291.safetensors",
    "model-00228-of-00291.safetensors",
    "model-00229-of-00291.safetensors",
    "model-00230-of-00291.safetensors",
    "model-00231-of-00291.safetensors",
    "model-00232-of-00291.safetensors",
    "model-00233-of-00291.safetensors",
    "model-00234-of-00291.safetensors",
    "model-00235-of-00291.safetensors",
    "model-00236-of-00291.safetensors",
    "model-00237-of-00291.safetensors",
    "model-00238-of-00291.safetensors",
    "model-00239-of-00291.safetensors",
    "model-00240-of-00291.safetensors",
    "model-00241-of-00291.safetensors",
    "model-00242-of-00291.safetensors",
    "model-00243-of-00291.safetensors",
    "model-00244-of-00291.safetensors",
    "model-00245-of-00291.safetensors",
    "model-00246-of-00291.safetensors",
    "model-00247-of-00291.safetensors",
    "model-00248-of-00291.safetensors",
    "model-00249-of-00291.safetensors",
    "model-00250-of-00291.safetensors",
    "model-00251-of-00291.safetensors",
    "model-00252-of-00291.safetensors",
    "model-00253-of-00291.safetensors",
    "model-00254-of-00291.safetensors",
    "model-00255-of-00291.safetensors",
    "model-00256-of-00291.safetensors",
    "model-00257-of-00291.safetensors",
    "model-00258-of-00291.safetensors",
    "model-00259-of-00291.safetensors",
    "model-00260-of-00291.safetensors",
    "model-00261-of-00291.safetensors",
    "model-00262-of-00291.safetensors",
    "model-00263-of-00291.safetensors",
    "model-00264-of-00291.safetensors",
    "model-00265-of-00291.safetensors",
    "model-00266-of-00291.safetensors",
    "model-00267-of-00291.safetensors",
    "model-00268-of-00291.safetensors",
    "model-00269-of-00291.safetensors",
    "model-00270-of-00291.safetensors",
    "model-00271-of-00291.safetensors",
    "model-00272-of-00291.safetensors",
    "model-00273-of-00291.safetensors",
    "model-00274-of-00291.safetensors",
    "model-00275-of-00291.safetensors",
    "model-00276-of-00291.safetensors",
    "model-00277-of-00291.safetensors",
    "model-00278-of-00291.safetensors",
    "model-00279-of-00291.safetensors",
    "model-00280-of-00291.safetensors",
    "model-00281-of-00291.safetensors",
    "model-00282-of-00291.safetensors",
    "model-00283-of-00291.safetensors",
    "model-00284-of-00291.safetensors",
    "model-00285-of-00291.safetensors",
    "model-00286-of-00291.safetensors",
    "model-00287-of-00291.safetensors",
    "model-00288-of-00291.safetensors",
    "model-00289-of-00291.safetensors",
    "model-00290-of-00291.safetensors",
    "model-00291-of-00291.safetensors"
  ],
  "jomsie/DialoGPT-bennybennybenny": [
    "model.safetensors"
  ],
  "TheBloke/Ferret_7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Ferret_7B-AWQ": [
    "model.safetensors"
  ],
  "typeof/dolphin-2.2.1-mistral-7b-sharded": [
    "model-00001-of-00291.safetensors",
    "model-00002-of-00291.safetensors",
    "model-00003-of-00291.safetensors",
    "model-00004-of-00291.safetensors",
    "model-00005-of-00291.safetensors",
    "model-00006-of-00291.safetensors",
    "model-00007-of-00291.safetensors",
    "model-00008-of-00291.safetensors",
    "model-00009-of-00291.safetensors",
    "model-00010-of-00291.safetensors",
    "model-00011-of-00291.safetensors",
    "model-00012-of-00291.safetensors",
    "model-00013-of-00291.safetensors",
    "model-00014-of-00291.safetensors",
    "model-00015-of-00291.safetensors",
    "model-00016-of-00291.safetensors",
    "model-00017-of-00291.safetensors",
    "model-00018-of-00291.safetensors",
    "model-00019-of-00291.safetensors",
    "model-00020-of-00291.safetensors",
    "model-00021-of-00291.safetensors",
    "model-00022-of-00291.safetensors",
    "model-00023-of-00291.safetensors",
    "model-00024-of-00291.safetensors",
    "model-00025-of-00291.safetensors",
    "model-00026-of-00291.safetensors",
    "model-00027-of-00291.safetensors",
    "model-00028-of-00291.safetensors",
    "model-00029-of-00291.safetensors",
    "model-00030-of-00291.safetensors",
    "model-00031-of-00291.safetensors",
    "model-00032-of-00291.safetensors",
    "model-00033-of-00291.safetensors",
    "model-00034-of-00291.safetensors",
    "model-00035-of-00291.safetensors",
    "model-00036-of-00291.safetensors",
    "model-00037-of-00291.safetensors",
    "model-00038-of-00291.safetensors",
    "model-00039-of-00291.safetensors",
    "model-00040-of-00291.safetensors",
    "model-00041-of-00291.safetensors",
    "model-00042-of-00291.safetensors",
    "model-00043-of-00291.safetensors",
    "model-00044-of-00291.safetensors",
    "model-00045-of-00291.safetensors",
    "model-00046-of-00291.safetensors",
    "model-00047-of-00291.safetensors",
    "model-00048-of-00291.safetensors",
    "model-00049-of-00291.safetensors",
    "model-00050-of-00291.safetensors",
    "model-00051-of-00291.safetensors",
    "model-00052-of-00291.safetensors",
    "model-00053-of-00291.safetensors",
    "model-00054-of-00291.safetensors",
    "model-00055-of-00291.safetensors",
    "model-00056-of-00291.safetensors",
    "model-00057-of-00291.safetensors",
    "model-00058-of-00291.safetensors",
    "model-00059-of-00291.safetensors",
    "model-00060-of-00291.safetensors",
    "model-00061-of-00291.safetensors",
    "model-00062-of-00291.safetensors",
    "model-00063-of-00291.safetensors",
    "model-00064-of-00291.safetensors",
    "model-00065-of-00291.safetensors",
    "model-00066-of-00291.safetensors",
    "model-00067-of-00291.safetensors",
    "model-00068-of-00291.safetensors",
    "model-00069-of-00291.safetensors",
    "model-00070-of-00291.safetensors",
    "model-00071-of-00291.safetensors",
    "model-00072-of-00291.safetensors",
    "model-00073-of-00291.safetensors",
    "model-00074-of-00291.safetensors",
    "model-00075-of-00291.safetensors",
    "model-00076-of-00291.safetensors",
    "model-00077-of-00291.safetensors",
    "model-00078-of-00291.safetensors",
    "model-00079-of-00291.safetensors",
    "model-00080-of-00291.safetensors",
    "model-00081-of-00291.safetensors",
    "model-00082-of-00291.safetensors",
    "model-00083-of-00291.safetensors",
    "model-00084-of-00291.safetensors",
    "model-00085-of-00291.safetensors",
    "model-00086-of-00291.safetensors",
    "model-00087-of-00291.safetensors",
    "model-00088-of-00291.safetensors",
    "model-00089-of-00291.safetensors",
    "model-00090-of-00291.safetensors",
    "model-00091-of-00291.safetensors",
    "model-00092-of-00291.safetensors",
    "model-00093-of-00291.safetensors",
    "model-00094-of-00291.safetensors",
    "model-00095-of-00291.safetensors",
    "model-00096-of-00291.safetensors",
    "model-00097-of-00291.safetensors",
    "model-00098-of-00291.safetensors",
    "model-00099-of-00291.safetensors",
    "model-00100-of-00291.safetensors",
    "model-00101-of-00291.safetensors",
    "model-00102-of-00291.safetensors",
    "model-00103-of-00291.safetensors",
    "model-00104-of-00291.safetensors",
    "model-00105-of-00291.safetensors",
    "model-00106-of-00291.safetensors",
    "model-00107-of-00291.safetensors",
    "model-00108-of-00291.safetensors",
    "model-00109-of-00291.safetensors",
    "model-00110-of-00291.safetensors",
    "model-00111-of-00291.safetensors",
    "model-00112-of-00291.safetensors",
    "model-00113-of-00291.safetensors",
    "model-00114-of-00291.safetensors",
    "model-00115-of-00291.safetensors",
    "model-00116-of-00291.safetensors",
    "model-00117-of-00291.safetensors",
    "model-00118-of-00291.safetensors",
    "model-00119-of-00291.safetensors",
    "model-00120-of-00291.safetensors",
    "model-00121-of-00291.safetensors",
    "model-00122-of-00291.safetensors",
    "model-00123-of-00291.safetensors",
    "model-00124-of-00291.safetensors",
    "model-00125-of-00291.safetensors",
    "model-00126-of-00291.safetensors",
    "model-00127-of-00291.safetensors",
    "model-00128-of-00291.safetensors",
    "model-00129-of-00291.safetensors",
    "model-00130-of-00291.safetensors",
    "model-00131-of-00291.safetensors",
    "model-00132-of-00291.safetensors",
    "model-00133-of-00291.safetensors",
    "model-00134-of-00291.safetensors",
    "model-00135-of-00291.safetensors",
    "model-00136-of-00291.safetensors",
    "model-00137-of-00291.safetensors",
    "model-00138-of-00291.safetensors",
    "model-00139-of-00291.safetensors",
    "model-00140-of-00291.safetensors",
    "model-00141-of-00291.safetensors",
    "model-00142-of-00291.safetensors",
    "model-00143-of-00291.safetensors",
    "model-00144-of-00291.safetensors",
    "model-00145-of-00291.safetensors",
    "model-00146-of-00291.safetensors",
    "model-00147-of-00291.safetensors",
    "model-00148-of-00291.safetensors",
    "model-00149-of-00291.safetensors",
    "model-00150-of-00291.safetensors",
    "model-00151-of-00291.safetensors",
    "model-00152-of-00291.safetensors",
    "model-00153-of-00291.safetensors",
    "model-00154-of-00291.safetensors",
    "model-00155-of-00291.safetensors",
    "model-00156-of-00291.safetensors",
    "model-00157-of-00291.safetensors",
    "model-00158-of-00291.safetensors",
    "model-00159-of-00291.safetensors",
    "model-00160-of-00291.safetensors",
    "model-00161-of-00291.safetensors",
    "model-00162-of-00291.safetensors",
    "model-00163-of-00291.safetensors",
    "model-00164-of-00291.safetensors",
    "model-00165-of-00291.safetensors",
    "model-00166-of-00291.safetensors",
    "model-00167-of-00291.safetensors",
    "model-00168-of-00291.safetensors",
    "model-00169-of-00291.safetensors",
    "model-00170-of-00291.safetensors",
    "model-00171-of-00291.safetensors",
    "model-00172-of-00291.safetensors",
    "model-00173-of-00291.safetensors",
    "model-00174-of-00291.safetensors",
    "model-00175-of-00291.safetensors",
    "model-00176-of-00291.safetensors",
    "model-00177-of-00291.safetensors",
    "model-00178-of-00291.safetensors",
    "model-00179-of-00291.safetensors",
    "model-00180-of-00291.safetensors",
    "model-00181-of-00291.safetensors",
    "model-00182-of-00291.safetensors",
    "model-00183-of-00291.safetensors",
    "model-00184-of-00291.safetensors",
    "model-00185-of-00291.safetensors",
    "model-00186-of-00291.safetensors",
    "model-00187-of-00291.safetensors",
    "model-00188-of-00291.safetensors",
    "model-00189-of-00291.safetensors",
    "model-00190-of-00291.safetensors",
    "model-00191-of-00291.safetensors",
    "model-00192-of-00291.safetensors",
    "model-00193-of-00291.safetensors",
    "model-00194-of-00291.safetensors",
    "model-00195-of-00291.safetensors",
    "model-00196-of-00291.safetensors",
    "model-00197-of-00291.safetensors",
    "model-00198-of-00291.safetensors",
    "model-00199-of-00291.safetensors",
    "model-00200-of-00291.safetensors",
    "model-00201-of-00291.safetensors",
    "model-00202-of-00291.safetensors",
    "model-00203-of-00291.safetensors",
    "model-00204-of-00291.safetensors",
    "model-00205-of-00291.safetensors",
    "model-00206-of-00291.safetensors",
    "model-00207-of-00291.safetensors",
    "model-00208-of-00291.safetensors",
    "model-00209-of-00291.safetensors",
    "model-00210-of-00291.safetensors",
    "model-00211-of-00291.safetensors",
    "model-00212-of-00291.safetensors",
    "model-00213-of-00291.safetensors",
    "model-00214-of-00291.safetensors",
    "model-00215-of-00291.safetensors",
    "model-00216-of-00291.safetensors",
    "model-00217-of-00291.safetensors",
    "model-00218-of-00291.safetensors",
    "model-00219-of-00291.safetensors",
    "model-00220-of-00291.safetensors",
    "model-00221-of-00291.safetensors",
    "model-00222-of-00291.safetensors",
    "model-00223-of-00291.safetensors",
    "model-00224-of-00291.safetensors",
    "model-00225-of-00291.safetensors",
    "model-00226-of-00291.safetensors",
    "model-00227-of-00291.safetensors",
    "model-00228-of-00291.safetensors",
    "model-00229-of-00291.safetensors",
    "model-00230-of-00291.safetensors",
    "model-00231-of-00291.safetensors",
    "model-00232-of-00291.safetensors",
    "model-00233-of-00291.safetensors",
    "model-00234-of-00291.safetensors",
    "model-00235-of-00291.safetensors",
    "model-00236-of-00291.safetensors",
    "model-00237-of-00291.safetensors",
    "model-00238-of-00291.safetensors",
    "model-00239-of-00291.safetensors",
    "model-00240-of-00291.safetensors",
    "model-00241-of-00291.safetensors",
    "model-00242-of-00291.safetensors",
    "model-00243-of-00291.safetensors",
    "model-00244-of-00291.safetensors",
    "model-00245-of-00291.safetensors",
    "model-00246-of-00291.safetensors",
    "model-00247-of-00291.safetensors",
    "model-00248-of-00291.safetensors",
    "model-00249-of-00291.safetensors",
    "model-00250-of-00291.safetensors",
    "model-00251-of-00291.safetensors",
    "model-00252-of-00291.safetensors",
    "model-00253-of-00291.safetensors",
    "model-00254-of-00291.safetensors",
    "model-00255-of-00291.safetensors",
    "model-00256-of-00291.safetensors",
    "model-00257-of-00291.safetensors",
    "model-00258-of-00291.safetensors",
    "model-00259-of-00291.safetensors",
    "model-00260-of-00291.safetensors",
    "model-00261-of-00291.safetensors",
    "model-00262-of-00291.safetensors",
    "model-00263-of-00291.safetensors",
    "model-00264-of-00291.safetensors",
    "model-00265-of-00291.safetensors",
    "model-00266-of-00291.safetensors",
    "model-00267-of-00291.safetensors",
    "model-00268-of-00291.safetensors",
    "model-00269-of-00291.safetensors",
    "model-00270-of-00291.safetensors",
    "model-00271-of-00291.safetensors",
    "model-00272-of-00291.safetensors",
    "model-00273-of-00291.safetensors",
    "model-00274-of-00291.safetensors",
    "model-00275-of-00291.safetensors",
    "model-00276-of-00291.safetensors",
    "model-00277-of-00291.safetensors",
    "model-00278-of-00291.safetensors",
    "model-00279-of-00291.safetensors",
    "model-00280-of-00291.safetensors",
    "model-00281-of-00291.safetensors",
    "model-00282-of-00291.safetensors",
    "model-00283-of-00291.safetensors",
    "model-00284-of-00291.safetensors",
    "model-00285-of-00291.safetensors",
    "model-00286-of-00291.safetensors",
    "model-00287-of-00291.safetensors",
    "model-00288-of-00291.safetensors",
    "model-00289-of-00291.safetensors",
    "model-00290-of-00291.safetensors",
    "model-00291-of-00291.safetensors"
  ],
  "TheBloke/speechless-mistral-7B-dare-0.85-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/speechless-mistral-7B-dare-0.85-AWQ": [
    "model.safetensors"
  ],
  "typeof/MistralLite-sharded": [
    "model-00001-of-00291.safetensors",
    "model-00002-of-00291.safetensors",
    "model-00003-of-00291.safetensors",
    "model-00004-of-00291.safetensors",
    "model-00005-of-00291.safetensors",
    "model-00006-of-00291.safetensors",
    "model-00007-of-00291.safetensors",
    "model-00008-of-00291.safetensors",
    "model-00009-of-00291.safetensors",
    "model-00010-of-00291.safetensors",
    "model-00011-of-00291.safetensors",
    "model-00012-of-00291.safetensors",
    "model-00013-of-00291.safetensors",
    "model-00014-of-00291.safetensors",
    "model-00015-of-00291.safetensors",
    "model-00016-of-00291.safetensors",
    "model-00017-of-00291.safetensors",
    "model-00018-of-00291.safetensors",
    "model-00019-of-00291.safetensors",
    "model-00020-of-00291.safetensors",
    "model-00021-of-00291.safetensors",
    "model-00022-of-00291.safetensors",
    "model-00023-of-00291.safetensors",
    "model-00024-of-00291.safetensors",
    "model-00025-of-00291.safetensors",
    "model-00026-of-00291.safetensors",
    "model-00027-of-00291.safetensors",
    "model-00028-of-00291.safetensors",
    "model-00029-of-00291.safetensors",
    "model-00030-of-00291.safetensors",
    "model-00031-of-00291.safetensors",
    "model-00032-of-00291.safetensors",
    "model-00033-of-00291.safetensors",
    "model-00034-of-00291.safetensors",
    "model-00035-of-00291.safetensors",
    "model-00036-of-00291.safetensors",
    "model-00037-of-00291.safetensors",
    "model-00038-of-00291.safetensors",
    "model-00039-of-00291.safetensors",
    "model-00040-of-00291.safetensors",
    "model-00041-of-00291.safetensors",
    "model-00042-of-00291.safetensors",
    "model-00043-of-00291.safetensors",
    "model-00044-of-00291.safetensors",
    "model-00045-of-00291.safetensors",
    "model-00046-of-00291.safetensors",
    "model-00047-of-00291.safetensors",
    "model-00048-of-00291.safetensors",
    "model-00049-of-00291.safetensors",
    "model-00050-of-00291.safetensors",
    "model-00051-of-00291.safetensors",
    "model-00052-of-00291.safetensors",
    "model-00053-of-00291.safetensors",
    "model-00054-of-00291.safetensors",
    "model-00055-of-00291.safetensors",
    "model-00056-of-00291.safetensors",
    "model-00057-of-00291.safetensors",
    "model-00058-of-00291.safetensors",
    "model-00059-of-00291.safetensors",
    "model-00060-of-00291.safetensors",
    "model-00061-of-00291.safetensors",
    "model-00062-of-00291.safetensors",
    "model-00063-of-00291.safetensors",
    "model-00064-of-00291.safetensors",
    "model-00065-of-00291.safetensors",
    "model-00066-of-00291.safetensors",
    "model-00067-of-00291.safetensors",
    "model-00068-of-00291.safetensors",
    "model-00069-of-00291.safetensors",
    "model-00070-of-00291.safetensors",
    "model-00071-of-00291.safetensors",
    "model-00072-of-00291.safetensors",
    "model-00073-of-00291.safetensors",
    "model-00074-of-00291.safetensors",
    "model-00075-of-00291.safetensors",
    "model-00076-of-00291.safetensors",
    "model-00077-of-00291.safetensors",
    "model-00078-of-00291.safetensors",
    "model-00079-of-00291.safetensors",
    "model-00080-of-00291.safetensors",
    "model-00081-of-00291.safetensors",
    "model-00082-of-00291.safetensors",
    "model-00083-of-00291.safetensors",
    "model-00084-of-00291.safetensors",
    "model-00085-of-00291.safetensors",
    "model-00086-of-00291.safetensors",
    "model-00087-of-00291.safetensors",
    "model-00088-of-00291.safetensors",
    "model-00089-of-00291.safetensors",
    "model-00090-of-00291.safetensors",
    "model-00091-of-00291.safetensors",
    "model-00092-of-00291.safetensors",
    "model-00093-of-00291.safetensors",
    "model-00094-of-00291.safetensors",
    "model-00095-of-00291.safetensors",
    "model-00096-of-00291.safetensors",
    "model-00097-of-00291.safetensors",
    "model-00098-of-00291.safetensors",
    "model-00099-of-00291.safetensors",
    "model-00100-of-00291.safetensors",
    "model-00101-of-00291.safetensors",
    "model-00102-of-00291.safetensors",
    "model-00103-of-00291.safetensors",
    "model-00104-of-00291.safetensors",
    "model-00105-of-00291.safetensors",
    "model-00106-of-00291.safetensors",
    "model-00107-of-00291.safetensors",
    "model-00108-of-00291.safetensors",
    "model-00109-of-00291.safetensors",
    "model-00110-of-00291.safetensors",
    "model-00111-of-00291.safetensors",
    "model-00112-of-00291.safetensors",
    "model-00113-of-00291.safetensors",
    "model-00114-of-00291.safetensors",
    "model-00115-of-00291.safetensors",
    "model-00116-of-00291.safetensors",
    "model-00117-of-00291.safetensors",
    "model-00118-of-00291.safetensors",
    "model-00119-of-00291.safetensors",
    "model-00120-of-00291.safetensors",
    "model-00121-of-00291.safetensors",
    "model-00122-of-00291.safetensors",
    "model-00123-of-00291.safetensors",
    "model-00124-of-00291.safetensors",
    "model-00125-of-00291.safetensors",
    "model-00126-of-00291.safetensors",
    "model-00127-of-00291.safetensors",
    "model-00128-of-00291.safetensors",
    "model-00129-of-00291.safetensors",
    "model-00130-of-00291.safetensors",
    "model-00131-of-00291.safetensors",
    "model-00132-of-00291.safetensors",
    "model-00133-of-00291.safetensors",
    "model-00134-of-00291.safetensors",
    "model-00135-of-00291.safetensors",
    "model-00136-of-00291.safetensors",
    "model-00137-of-00291.safetensors",
    "model-00138-of-00291.safetensors",
    "model-00139-of-00291.safetensors",
    "model-00140-of-00291.safetensors",
    "model-00141-of-00291.safetensors",
    "model-00142-of-00291.safetensors",
    "model-00143-of-00291.safetensors",
    "model-00144-of-00291.safetensors",
    "model-00145-of-00291.safetensors",
    "model-00146-of-00291.safetensors",
    "model-00147-of-00291.safetensors",
    "model-00148-of-00291.safetensors",
    "model-00149-of-00291.safetensors",
    "model-00150-of-00291.safetensors",
    "model-00151-of-00291.safetensors",
    "model-00152-of-00291.safetensors",
    "model-00153-of-00291.safetensors",
    "model-00154-of-00291.safetensors",
    "model-00155-of-00291.safetensors",
    "model-00156-of-00291.safetensors",
    "model-00157-of-00291.safetensors",
    "model-00158-of-00291.safetensors",
    "model-00159-of-00291.safetensors",
    "model-00160-of-00291.safetensors",
    "model-00161-of-00291.safetensors",
    "model-00162-of-00291.safetensors",
    "model-00163-of-00291.safetensors",
    "model-00164-of-00291.safetensors",
    "model-00165-of-00291.safetensors",
    "model-00166-of-00291.safetensors",
    "model-00167-of-00291.safetensors",
    "model-00168-of-00291.safetensors",
    "model-00169-of-00291.safetensors",
    "model-00170-of-00291.safetensors",
    "model-00171-of-00291.safetensors",
    "model-00172-of-00291.safetensors",
    "model-00173-of-00291.safetensors",
    "model-00174-of-00291.safetensors",
    "model-00175-of-00291.safetensors",
    "model-00176-of-00291.safetensors",
    "model-00177-of-00291.safetensors",
    "model-00178-of-00291.safetensors",
    "model-00179-of-00291.safetensors",
    "model-00180-of-00291.safetensors",
    "model-00181-of-00291.safetensors",
    "model-00182-of-00291.safetensors",
    "model-00183-of-00291.safetensors",
    "model-00184-of-00291.safetensors",
    "model-00185-of-00291.safetensors",
    "model-00186-of-00291.safetensors",
    "model-00187-of-00291.safetensors",
    "model-00188-of-00291.safetensors",
    "model-00189-of-00291.safetensors",
    "model-00190-of-00291.safetensors",
    "model-00191-of-00291.safetensors",
    "model-00192-of-00291.safetensors",
    "model-00193-of-00291.safetensors",
    "model-00194-of-00291.safetensors",
    "model-00195-of-00291.safetensors",
    "model-00196-of-00291.safetensors",
    "model-00197-of-00291.safetensors",
    "model-00198-of-00291.safetensors",
    "model-00199-of-00291.safetensors",
    "model-00200-of-00291.safetensors",
    "model-00201-of-00291.safetensors",
    "model-00202-of-00291.safetensors",
    "model-00203-of-00291.safetensors",
    "model-00204-of-00291.safetensors",
    "model-00205-of-00291.safetensors",
    "model-00206-of-00291.safetensors",
    "model-00207-of-00291.safetensors",
    "model-00208-of-00291.safetensors",
    "model-00209-of-00291.safetensors",
    "model-00210-of-00291.safetensors",
    "model-00211-of-00291.safetensors",
    "model-00212-of-00291.safetensors",
    "model-00213-of-00291.safetensors",
    "model-00214-of-00291.safetensors",
    "model-00215-of-00291.safetensors",
    "model-00216-of-00291.safetensors",
    "model-00217-of-00291.safetensors",
    "model-00218-of-00291.safetensors",
    "model-00219-of-00291.safetensors",
    "model-00220-of-00291.safetensors",
    "model-00221-of-00291.safetensors",
    "model-00222-of-00291.safetensors",
    "model-00223-of-00291.safetensors",
    "model-00224-of-00291.safetensors",
    "model-00225-of-00291.safetensors",
    "model-00226-of-00291.safetensors",
    "model-00227-of-00291.safetensors",
    "model-00228-of-00291.safetensors",
    "model-00229-of-00291.safetensors",
    "model-00230-of-00291.safetensors",
    "model-00231-of-00291.safetensors",
    "model-00232-of-00291.safetensors",
    "model-00233-of-00291.safetensors",
    "model-00234-of-00291.safetensors",
    "model-00235-of-00291.safetensors",
    "model-00236-of-00291.safetensors",
    "model-00237-of-00291.safetensors",
    "model-00238-of-00291.safetensors",
    "model-00239-of-00291.safetensors",
    "model-00240-of-00291.safetensors",
    "model-00241-of-00291.safetensors",
    "model-00242-of-00291.safetensors",
    "model-00243-of-00291.safetensors",
    "model-00244-of-00291.safetensors",
    "model-00245-of-00291.safetensors",
    "model-00246-of-00291.safetensors",
    "model-00247-of-00291.safetensors",
    "model-00248-of-00291.safetensors",
    "model-00249-of-00291.safetensors",
    "model-00250-of-00291.safetensors",
    "model-00251-of-00291.safetensors",
    "model-00252-of-00291.safetensors",
    "model-00253-of-00291.safetensors",
    "model-00254-of-00291.safetensors",
    "model-00255-of-00291.safetensors",
    "model-00256-of-00291.safetensors",
    "model-00257-of-00291.safetensors",
    "model-00258-of-00291.safetensors",
    "model-00259-of-00291.safetensors",
    "model-00260-of-00291.safetensors",
    "model-00261-of-00291.safetensors",
    "model-00262-of-00291.safetensors",
    "model-00263-of-00291.safetensors",
    "model-00264-of-00291.safetensors",
    "model-00265-of-00291.safetensors",
    "model-00266-of-00291.safetensors",
    "model-00267-of-00291.safetensors",
    "model-00268-of-00291.safetensors",
    "model-00269-of-00291.safetensors",
    "model-00270-of-00291.safetensors",
    "model-00271-of-00291.safetensors",
    "model-00272-of-00291.safetensors",
    "model-00273-of-00291.safetensors",
    "model-00274-of-00291.safetensors",
    "model-00275-of-00291.safetensors",
    "model-00276-of-00291.safetensors",
    "model-00277-of-00291.safetensors",
    "model-00278-of-00291.safetensors",
    "model-00279-of-00291.safetensors",
    "model-00280-of-00291.safetensors",
    "model-00281-of-00291.safetensors",
    "model-00282-of-00291.safetensors",
    "model-00283-of-00291.safetensors",
    "model-00284-of-00291.safetensors",
    "model-00285-of-00291.safetensors",
    "model-00286-of-00291.safetensors",
    "model-00287-of-00291.safetensors",
    "model-00288-of-00291.safetensors",
    "model-00289-of-00291.safetensors",
    "model-00290-of-00291.safetensors",
    "model-00291-of-00291.safetensors"
  ],
  "TheBloke/airoboros-m-7B-3.1.2-dare-0.85-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/airoboros-m-7B-3.1.2-dare-0.85-AWQ": [
    "model.safetensors"
  ],
  "habanoz/phi-1_5-lr-5-3epch-airoboros3.1-1k-instruct-V1": [
    "model.safetensors"
  ],
  "typeof/mistral-7b-instruct": [
    "model-00001-of-00291.safetensors",
    "model-00002-of-00291.safetensors",
    "model-00003-of-00291.safetensors",
    "model-00004-of-00291.safetensors",
    "model-00005-of-00291.safetensors",
    "model-00006-of-00291.safetensors",
    "model-00007-of-00291.safetensors",
    "model-00008-of-00291.safetensors",
    "model-00009-of-00291.safetensors",
    "model-00010-of-00291.safetensors",
    "model-00011-of-00291.safetensors",
    "model-00012-of-00291.safetensors",
    "model-00013-of-00291.safetensors",
    "model-00014-of-00291.safetensors",
    "model-00015-of-00291.safetensors",
    "model-00016-of-00291.safetensors",
    "model-00017-of-00291.safetensors",
    "model-00018-of-00291.safetensors",
    "model-00019-of-00291.safetensors",
    "model-00020-of-00291.safetensors",
    "model-00021-of-00291.safetensors",
    "model-00022-of-00291.safetensors",
    "model-00023-of-00291.safetensors",
    "model-00024-of-00291.safetensors",
    "model-00025-of-00291.safetensors",
    "model-00026-of-00291.safetensors",
    "model-00027-of-00291.safetensors",
    "model-00028-of-00291.safetensors",
    "model-00029-of-00291.safetensors",
    "model-00030-of-00291.safetensors",
    "model-00031-of-00291.safetensors",
    "model-00032-of-00291.safetensors",
    "model-00033-of-00291.safetensors",
    "model-00034-of-00291.safetensors",
    "model-00035-of-00291.safetensors",
    "model-00036-of-00291.safetensors",
    "model-00037-of-00291.safetensors",
    "model-00038-of-00291.safetensors",
    "model-00039-of-00291.safetensors",
    "model-00040-of-00291.safetensors",
    "model-00041-of-00291.safetensors",
    "model-00042-of-00291.safetensors",
    "model-00043-of-00291.safetensors",
    "model-00044-of-00291.safetensors",
    "model-00045-of-00291.safetensors",
    "model-00046-of-00291.safetensors",
    "model-00047-of-00291.safetensors",
    "model-00048-of-00291.safetensors",
    "model-00049-of-00291.safetensors",
    "model-00050-of-00291.safetensors",
    "model-00051-of-00291.safetensors",
    "model-00052-of-00291.safetensors",
    "model-00053-of-00291.safetensors",
    "model-00054-of-00291.safetensors",
    "model-00055-of-00291.safetensors",
    "model-00056-of-00291.safetensors",
    "model-00057-of-00291.safetensors",
    "model-00058-of-00291.safetensors",
    "model-00059-of-00291.safetensors",
    "model-00060-of-00291.safetensors",
    "model-00061-of-00291.safetensors",
    "model-00062-of-00291.safetensors",
    "model-00063-of-00291.safetensors",
    "model-00064-of-00291.safetensors",
    "model-00065-of-00291.safetensors",
    "model-00066-of-00291.safetensors",
    "model-00067-of-00291.safetensors",
    "model-00068-of-00291.safetensors",
    "model-00069-of-00291.safetensors",
    "model-00070-of-00291.safetensors",
    "model-00071-of-00291.safetensors",
    "model-00072-of-00291.safetensors",
    "model-00073-of-00291.safetensors",
    "model-00074-of-00291.safetensors",
    "model-00075-of-00291.safetensors",
    "model-00076-of-00291.safetensors",
    "model-00077-of-00291.safetensors",
    "model-00078-of-00291.safetensors",
    "model-00079-of-00291.safetensors",
    "model-00080-of-00291.safetensors",
    "model-00081-of-00291.safetensors",
    "model-00082-of-00291.safetensors",
    "model-00083-of-00291.safetensors",
    "model-00084-of-00291.safetensors",
    "model-00085-of-00291.safetensors",
    "model-00086-of-00291.safetensors",
    "model-00087-of-00291.safetensors",
    "model-00088-of-00291.safetensors",
    "model-00089-of-00291.safetensors",
    "model-00090-of-00291.safetensors",
    "model-00091-of-00291.safetensors",
    "model-00092-of-00291.safetensors",
    "model-00093-of-00291.safetensors",
    "model-00094-of-00291.safetensors",
    "model-00095-of-00291.safetensors",
    "model-00096-of-00291.safetensors",
    "model-00097-of-00291.safetensors",
    "model-00098-of-00291.safetensors",
    "model-00099-of-00291.safetensors",
    "model-00100-of-00291.safetensors",
    "model-00101-of-00291.safetensors",
    "model-00102-of-00291.safetensors",
    "model-00103-of-00291.safetensors",
    "model-00104-of-00291.safetensors",
    "model-00105-of-00291.safetensors",
    "model-00106-of-00291.safetensors",
    "model-00107-of-00291.safetensors",
    "model-00108-of-00291.safetensors",
    "model-00109-of-00291.safetensors",
    "model-00110-of-00291.safetensors",
    "model-00111-of-00291.safetensors",
    "model-00112-of-00291.safetensors",
    "model-00113-of-00291.safetensors",
    "model-00114-of-00291.safetensors",
    "model-00115-of-00291.safetensors",
    "model-00116-of-00291.safetensors",
    "model-00117-of-00291.safetensors",
    "model-00118-of-00291.safetensors",
    "model-00119-of-00291.safetensors",
    "model-00120-of-00291.safetensors",
    "model-00121-of-00291.safetensors",
    "model-00122-of-00291.safetensors",
    "model-00123-of-00291.safetensors",
    "model-00124-of-00291.safetensors",
    "model-00125-of-00291.safetensors",
    "model-00126-of-00291.safetensors",
    "model-00127-of-00291.safetensors",
    "model-00128-of-00291.safetensors",
    "model-00129-of-00291.safetensors",
    "model-00130-of-00291.safetensors",
    "model-00131-of-00291.safetensors",
    "model-00132-of-00291.safetensors",
    "model-00133-of-00291.safetensors",
    "model-00134-of-00291.safetensors",
    "model-00135-of-00291.safetensors",
    "model-00136-of-00291.safetensors",
    "model-00137-of-00291.safetensors",
    "model-00138-of-00291.safetensors",
    "model-00139-of-00291.safetensors",
    "model-00140-of-00291.safetensors",
    "model-00141-of-00291.safetensors",
    "model-00142-of-00291.safetensors",
    "model-00143-of-00291.safetensors",
    "model-00144-of-00291.safetensors",
    "model-00145-of-00291.safetensors",
    "model-00146-of-00291.safetensors",
    "model-00147-of-00291.safetensors",
    "model-00148-of-00291.safetensors",
    "model-00149-of-00291.safetensors",
    "model-00150-of-00291.safetensors",
    "model-00151-of-00291.safetensors",
    "model-00152-of-00291.safetensors",
    "model-00153-of-00291.safetensors",
    "model-00154-of-00291.safetensors",
    "model-00155-of-00291.safetensors",
    "model-00156-of-00291.safetensors",
    "model-00157-of-00291.safetensors",
    "model-00158-of-00291.safetensors",
    "model-00159-of-00291.safetensors",
    "model-00160-of-00291.safetensors",
    "model-00161-of-00291.safetensors",
    "model-00162-of-00291.safetensors",
    "model-00163-of-00291.safetensors",
    "model-00164-of-00291.safetensors",
    "model-00165-of-00291.safetensors",
    "model-00166-of-00291.safetensors",
    "model-00167-of-00291.safetensors",
    "model-00168-of-00291.safetensors",
    "model-00169-of-00291.safetensors",
    "model-00170-of-00291.safetensors",
    "model-00171-of-00291.safetensors",
    "model-00172-of-00291.safetensors",
    "model-00173-of-00291.safetensors",
    "model-00174-of-00291.safetensors",
    "model-00175-of-00291.safetensors",
    "model-00176-of-00291.safetensors",
    "model-00177-of-00291.safetensors",
    "model-00178-of-00291.safetensors",
    "model-00179-of-00291.safetensors",
    "model-00180-of-00291.safetensors",
    "model-00181-of-00291.safetensors",
    "model-00182-of-00291.safetensors",
    "model-00183-of-00291.safetensors",
    "model-00184-of-00291.safetensors",
    "model-00185-of-00291.safetensors",
    "model-00186-of-00291.safetensors",
    "model-00187-of-00291.safetensors",
    "model-00188-of-00291.safetensors",
    "model-00189-of-00291.safetensors",
    "model-00190-of-00291.safetensors",
    "model-00191-of-00291.safetensors",
    "model-00192-of-00291.safetensors",
    "model-00193-of-00291.safetensors",
    "model-00194-of-00291.safetensors",
    "model-00195-of-00291.safetensors",
    "model-00196-of-00291.safetensors",
    "model-00197-of-00291.safetensors",
    "model-00198-of-00291.safetensors",
    "model-00199-of-00291.safetensors",
    "model-00200-of-00291.safetensors",
    "model-00201-of-00291.safetensors",
    "model-00202-of-00291.safetensors",
    "model-00203-of-00291.safetensors",
    "model-00204-of-00291.safetensors",
    "model-00205-of-00291.safetensors",
    "model-00206-of-00291.safetensors",
    "model-00207-of-00291.safetensors",
    "model-00208-of-00291.safetensors",
    "model-00209-of-00291.safetensors",
    "model-00210-of-00291.safetensors",
    "model-00211-of-00291.safetensors",
    "model-00212-of-00291.safetensors",
    "model-00213-of-00291.safetensors",
    "model-00214-of-00291.safetensors",
    "model-00215-of-00291.safetensors",
    "model-00216-of-00291.safetensors",
    "model-00217-of-00291.safetensors",
    "model-00218-of-00291.safetensors",
    "model-00219-of-00291.safetensors",
    "model-00220-of-00291.safetensors",
    "model-00221-of-00291.safetensors",
    "model-00222-of-00291.safetensors",
    "model-00223-of-00291.safetensors",
    "model-00224-of-00291.safetensors",
    "model-00225-of-00291.safetensors",
    "model-00226-of-00291.safetensors",
    "model-00227-of-00291.safetensors",
    "model-00228-of-00291.safetensors",
    "model-00229-of-00291.safetensors",
    "model-00230-of-00291.safetensors",
    "model-00231-of-00291.safetensors",
    "model-00232-of-00291.safetensors",
    "model-00233-of-00291.safetensors",
    "model-00234-of-00291.safetensors",
    "model-00235-of-00291.safetensors",
    "model-00236-of-00291.safetensors",
    "model-00237-of-00291.safetensors",
    "model-00238-of-00291.safetensors",
    "model-00239-of-00291.safetensors",
    "model-00240-of-00291.safetensors",
    "model-00241-of-00291.safetensors",
    "model-00242-of-00291.safetensors",
    "model-00243-of-00291.safetensors",
    "model-00244-of-00291.safetensors",
    "model-00245-of-00291.safetensors",
    "model-00246-of-00291.safetensors",
    "model-00247-of-00291.safetensors",
    "model-00248-of-00291.safetensors",
    "model-00249-of-00291.safetensors",
    "model-00250-of-00291.safetensors",
    "model-00251-of-00291.safetensors",
    "model-00252-of-00291.safetensors",
    "model-00253-of-00291.safetensors",
    "model-00254-of-00291.safetensors",
    "model-00255-of-00291.safetensors",
    "model-00256-of-00291.safetensors",
    "model-00257-of-00291.safetensors",
    "model-00258-of-00291.safetensors",
    "model-00259-of-00291.safetensors",
    "model-00260-of-00291.safetensors",
    "model-00261-of-00291.safetensors",
    "model-00262-of-00291.safetensors",
    "model-00263-of-00291.safetensors",
    "model-00264-of-00291.safetensors",
    "model-00265-of-00291.safetensors",
    "model-00266-of-00291.safetensors",
    "model-00267-of-00291.safetensors",
    "model-00268-of-00291.safetensors",
    "model-00269-of-00291.safetensors",
    "model-00270-of-00291.safetensors",
    "model-00271-of-00291.safetensors",
    "model-00272-of-00291.safetensors",
    "model-00273-of-00291.safetensors",
    "model-00274-of-00291.safetensors",
    "model-00275-of-00291.safetensors",
    "model-00276-of-00291.safetensors",
    "model-00277-of-00291.safetensors",
    "model-00278-of-00291.safetensors",
    "model-00279-of-00291.safetensors",
    "model-00280-of-00291.safetensors",
    "model-00281-of-00291.safetensors",
    "model-00282-of-00291.safetensors",
    "model-00283-of-00291.safetensors",
    "model-00284-of-00291.safetensors",
    "model-00285-of-00291.safetensors",
    "model-00286-of-00291.safetensors",
    "model-00287-of-00291.safetensors",
    "model-00288-of-00291.safetensors",
    "model-00289-of-00291.safetensors",
    "model-00290-of-00291.safetensors",
    "model-00291-of-00291.safetensors"
  ],
  "joedonino/zephyr-7b-radia-html-events-v2_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/CollectiveCognition-v1.1-Mistral-7B-dare-0.85-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/CollectiveCognition-v1.1-Mistral-7B-dare-0.85-GPTQ": [
    "model.safetensors"
  ],
  "bradmin/ppo-200": [
    "model.safetensors"
  ],
  "TheBloke/SynthIA-7B-v1.3-dare-0.85-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/SynthIA-7B-v1.3-dare-0.85-GPTQ": [
    "model.safetensors"
  ],
  "Cartinoe5930/KoRAE-13b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "techandy42/gpt2-alpaca-instruct": [
    "model.safetensors"
  ],
  "chargoddard/llama-polyglot-13b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Richardw2/llama-2-7b-miniplatypus23": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "joedonino/zephyr-7b-radia-html-events-v4_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hllj/sft-zephyr-7b-beta-v2": [
    "adapter_model.safetensors"
  ],
  "qqplot23/BASE_long": [
    "model.safetensors"
  ],
  "xz-huggingface-0/zephyr-7b-sft-lora": [
    "adapter_model.safetensors"
  ],
  "MilaWang/distilgpt2-finetuned-sympy2latex-grouped-v1": [
    "model.safetensors"
  ],
  "Sidharthkr/stf_7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "qgyd2021/few_shot_intent": [
    "model.safetensors"
  ],
  "SebastianSchramm/Sheared-LLaMA-1.3B-sft-lora-merged-dpo-lora-merged": [
    "model.safetensors"
  ],
  "sharkMeow/results-2": [
    "adapter_model.safetensors",
    "checkpoint-126/adapter_model.safetensors",
    "checkpoint-189/adapter_model.safetensors",
    "checkpoint-253/adapter_model.safetensors",
    "checkpoint-316/adapter_model.safetensors",
    "checkpoint-379/adapter_model.safetensors",
    "checkpoint-442/adapter_model.safetensors",
    "checkpoint-496/adapter_model.safetensors",
    "checkpoint-63/adapter_model.safetensors"
  ],
  "MilaWang/codegen-350M-mono-finetuned-sympy2latex-ungroup-v1": [
    "model.safetensors"
  ],
  "lixiaohong/dpo-llama": [
    "model.safetensors"
  ],
  "joddiy/my_awesome_eli5_clm-model": [
    "model.safetensors"
  ],
  "waldie/Karen_TheEditor_V2_CREATIVE_Mistral_7B-8bpw-h8-exl2": [
    "output.safetensors"
  ],
  "mogaio/TinyLlama-con-v0.2": [
    "model.safetensors"
  ],
  "ndubey/codellama2-finetuned-codex-fin": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Noromaid-20B-v0.1.1-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Noromaid-20B-v0.1.1-GPTQ": [
    "model.safetensors"
  ],
  "Mousaicv/selfrag-lora": [
    "adapter_model.safetensors"
  ],
  "mtc/microsoft-Orca-2-7b-classification-with-explanation-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mogaio/TinyLlama-con-emp-v0.2": [
    "model.safetensors"
  ],
  "jeff31415/tinyllama-1.1b-sft-full": [
    "model.safetensors"
  ],
  "mtc/LeoLM-leo-mistral-hessianai-7b-xnli-absinth-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "qqplot23/xsum-gpt2-long": [
    "model.safetensors"
  ],
  "Elkhayyat17/merge-PEFT-Llama-2-7b-MedText": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lixiaohong/dpo2-llama-4k": [
    "model.safetensors"
  ],
  "dangvansam/finetune_OpenHermes_2.5_prompt_v4_group_by_len_bf16_lr1e-5_constant_max_len_1024_small_dataset": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "joedonino/zephyr-7b-radia-html-events-v6_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mtc/microsoft-Orca-2-7b-classification-with-explanation-english-prompt-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jangmin/merged-midm-7B-food-order-understanding-30K": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Josseidh/gpt2-wikitext2": [
    "model.safetensors"
  ],
  "TheBloke/digital-socrates-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/digital-socrates-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/digital-socrates-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/digital-socrates-7B-AWQ": [
    "model.safetensors"
  ],
  "musiclang/musiclang-4k": [
    "model.safetensors"
  ],
  "Fredperim/juridico": [
    "model.safetensors"
  ],
  "wisdomfunction/GPT-2_London_Reccomender": [
    "GPT2_model/model.safetensors",
    "model.safetensors"
  ],
  "huseinzol05/dummy-mistral-1.1b": [
    "model.safetensors"
  ],
  "huseinzol05/dummy-mistral-3b": [
    "model-00001-of-00002.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00002.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/llama-polyglot-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/llama-polyglot-13B-AWQ": [
    "model.safetensors"
  ],
  "LoneStriker/Yi-34B-Chat-3.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "intelliwork/Llama-2-7b-chat-hf-function-calling-v2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Yi-34B-Chat-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "TheBloke/koOpenChat-sft-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/koOpenChat-sft-AWQ": [
    "model.safetensors"
  ],
  "AUKZ/gpt2-wikitext2": [
    "model.safetensors"
  ],
  "LoneStriker/Yi-34B-Chat-4.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "TheBloke/Synatra-7B-v0.3-dpo-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Synatra-7B-v0.3-dpo-AWQ": [
    "model.safetensors"
  ],
  "LoneStriker/Yi-34B-Chat-6.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "SrAlex/llama-2-leyes-peruanas-irn-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Yi-34B-Chat-8.0bpw-h8-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "Winmodel/tmp_trainer": [
    "model.safetensors"
  ],
  "TheBloke/Synatra-RP-Orca-2-7B-v0.1-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Synatra-RP-Orca-2-7B-v0.1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Yi-34B-Chat-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Synatra-V0.1-7B-Instruct-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Synatra-V0.1-7B-Instruct-AWQ": [
    "model.safetensors"
  ],
  "ArtifactAI/phi-metamath": [
    "model.safetensors"
  ],
  "Brian-1991/Finetune01-0": [
    "adapter_model.safetensors",
    "checkpoint-117/adapter_model.safetensors"
  ],
  "TheBloke/Yi-34B-Chat-GPTQ": [
    "model.safetensors"
  ],
  "Sk4467/axolotl": [
    "adapter_model.safetensors"
  ],
  "abhishek/ccy0-2g7e-wqsa-0": [
    "checkpoint-10650/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "renxie/DialoGPT-medium-taylorswift": [
    "model.safetensors"
  ],
  "humbertonc/model_test_1": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "nalmeida/zephyr-7b-beta-gherkin": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Synatra-7B-v0.3-base-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Synatra-7B-v0.3-base-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/cockatrice-7B-v0.1-AWQ": [
    "model.safetensors"
  ],
  "atmansingh/med-llama2-lite": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jays/gpt2-real-toxicity-finetuned": [
    "model.safetensors"
  ],
  "Sham-Saleem/SLP": [
    "model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-indef-removal-1e-3": [
    "model.safetensors"
  ],
  "R136a1/MythoMist-7b-exl2": [
    "output.safetensors"
  ],
  "TheBloke/Tess-M-v1.2-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Tess-M-v1.2-GPTQ": [
    "model.safetensors"
  ],
  "xwar/ninox_english_CodeLlama-13b-Instruct": [
    "adapter_model.safetensors",
    "checkpoint-150/adapter_model.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "devhyun88/ku-mistral-7b-PGO-v4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "nsfwthrowitaway69/Venus-120b-v1.0": [
    "model-00001-of-00025.safetensors",
    "model-00002-of-00025.safetensors",
    "model-00003-of-00025.safetensors",
    "model-00004-of-00025.safetensors",
    "model-00005-of-00025.safetensors",
    "model-00006-of-00025.safetensors",
    "model-00007-of-00025.safetensors",
    "model-00008-of-00025.safetensors",
    "model-00009-of-00025.safetensors",
    "model-00010-of-00025.safetensors",
    "model-00011-of-00025.safetensors",
    "model-00012-of-00025.safetensors",
    "model-00013-of-00025.safetensors",
    "model-00014-of-00025.safetensors",
    "model-00015-of-00025.safetensors",
    "model-00016-of-00025.safetensors",
    "model-00017-of-00025.safetensors",
    "model-00018-of-00025.safetensors",
    "model-00019-of-00025.safetensors",
    "model-00020-of-00025.safetensors",
    "model-00021-of-00025.safetensors",
    "model-00022-of-00025.safetensors",
    "model-00023-of-00025.safetensors",
    "model-00024-of-00025.safetensors",
    "model-00025-of-00025.safetensors"
  ],
  "chargoddard/loyal-piano-m7": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jonathanjordan21/bloomz-560m-finetuned-knowSQL": [
    "adapter_model.safetensors"
  ],
  "migtissera/Pepai": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/tulu-2-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/tulu-2-13B-AWQ": [
    "model.safetensors"
  ],
  "lixiaohong/dpo2-fixtarget-llama-1k": [
    "model.safetensors"
  ],
  "elliotthwang/elliott_KimLan_Llama-2-7b-a": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Ja-ck/Mistral-instruct-Y24-v5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/tulu-2-70B-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/tulu-2-70B-GPTQ": [
    "model.safetensors"
  ],
  "joedonino/zephyr-7b-radia-html-events-v7_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "brucethemoose/Capybara-Tess12-Yi-34B-200K-DARE": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "eunbinni/ola_polyglot_5.8B_lora1_merge": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "KnutJaegersberg/Yi-34B-200K-MiniOrca-Adapter": [
    "adapter_model.safetensors"
  ],
  "maywell/PiVoT-0.1-early": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Weyaxi/Orca2-Platypus2-13B-QLoRA-0.80-epoch": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "FlexingD/yarn-mistral-7B-64k-instruct-alpaca-cleaned-Q4": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Weyaxi/Orca2-Nova-13B": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "sabareesh/gpt2-simulacra": [
    "model.safetensors"
  ],
  "jarod0411/PubChem10M_gpt2_SMILES_default_tokenized": [
    "model.safetensors"
  ],
  "Weyaxi/openinstruct-Nebula-v2-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lixiaohong/dpo_nvp_1k": [
    "model.safetensors"
  ],
  "Weyaxi/neural-chat-7b-v3-1-Nebula-v2-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Weyaxi/Synatra-7B-v0.3-RP-Nebula-v2-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "KantoRegion/merged-lora-hermione2-10": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "lixiaohong/dpo_nvp_100": [
    "model.safetensors"
  ],
  "Weyaxi/OpenHermes-2.5-neural-chat-7b-v3-1-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Mlteamnc/lama-2-7b-ner-v2-awq": [
    "model.safetensors"
  ],
  "sharkMeow/results-3": [
    "adapter_model.safetensors",
    "checkpoint-126/adapter_model.safetensors",
    "checkpoint-158/adapter_model.safetensors",
    "checkpoint-189/adapter_model.safetensors",
    "checkpoint-221/adapter_model.safetensors",
    "checkpoint-248/adapter_model.safetensors",
    "checkpoint-31/adapter_model.safetensors",
    "checkpoint-63/adapter_model.safetensors",
    "checkpoint-94/adapter_model.safetensors"
  ],
  "lixiaohong/dpo_nvp_400": [
    "model.safetensors"
  ],
  "pankajemplay/llama-2-finetuned-sample": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jacobolopez/Mistral-7B-v0.1-sharded": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "TheBloke/tulu-2-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/tulu-2-7B-AWQ": [
    "model.safetensors"
  ],
  "sanchit-gandhi/Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/tulu-2-dpo-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/tulu-2-dpo-13B-GPTQ": [
    "model.safetensors"
  ],
  "lixiaohong/dpo_nvp_1e6_2400": [
    "model.safetensors"
  ],
  "lixiaohong/dpo_nvp_1e6_5600": [
    "model.safetensors"
  ],
  "TheBloke/tulu-2-dpo-70B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/tulu-2-dpo-70B-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "jacobolopez/Mistral-7B-Instruct-v0.1-sharded": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "girrajjangid/Llama-7B-SFT": [
    "adapter_model.safetensors"
  ],
  "TheBloke/X-MythoChronos-13B-AWQ": [
    "model.safetensors"
  ],
  "CrabfishAI/InstructWise-462M": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "jarvisloh/Cerebras-GPT-111M-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "TheBloke/Mini_Synatra_7B_02-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/smartyplats-7B-v2-AWQ": [
    "model.safetensors"
  ],
  "flozi00/Mistral-7B-v0.1-4bit-autogptq": [
    "model.safetensors"
  ],
  "Sao10K/Stheno-v2-Delta-fp16": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jeff31415/tinyllama-1.1b-dpo-full": [
    "model.safetensors"
  ],
  "alexkoo300/cunning-snail": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "lysandre/awesome-clm": [
    "model.safetensors"
  ],
  "Hejjee/iDonna_depression_v4": [
    "model.safetensors"
  ],
  "lysandre/my_awesome_eli5_clm-model": [
    "model.safetensors"
  ],
  "AzhrSlm/llama-2-7b-finance": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ostorc/Conversational_Spanish_GPT": [
    "model.safetensors"
  ],
  "Locutusque/TinyMistral-248M-Instruct": [
    "model.safetensors"
  ],
  "VAGOsolutions/SauerkrautLM-7b-HerO": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "habanoz/TinyLlama-1.1B-step-2T-lr-5-5ep-oasst1-top1-instruct-V1": [
    "model.safetensors"
  ],
  "mahim/zephyr-7b-sft-lora": [
    "adapter_model.safetensors"
  ],
  "hllj/sft-zephyr-7b-beta-v3": [
    "adapter_model.safetensors"
  ],
  "Peachteaboba/newastarionbot": [
    "model.safetensors"
  ],
  "NyxKrage/Chronomaid-Storytelling-13b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "DopeorNope/Dear_My_best_Friend-SFT-v2-13B": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "joedonino/zephyr-7b-radia-html-events-v9_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/tulu-2-dpo-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/tulu-2-dpo-7B-GPTQ": [
    "model.safetensors"
  ],
  "Felladrin/Sheared-Pythia-160m-Platypus": [
    "model.safetensors"
  ],
  "Weyaxi/HelpSteer-filtered-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "NbAiLab/nb-gpt-j-6B-torgersen-alpaca": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Mini_Synatra_7B_02-GPTQ": [
    "model.safetensors"
  ],
  "John-Schwartz/llama-2-7b-miniplatypus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Chupacabra-7B-v3-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Chupacabra-7B-v3-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Rose-20B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Rose-20B-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-indef-removal-3e-3": [
    "model.safetensors"
  ],
  "ericzzz/falcon-rw-1b-instruct-openorca": [
    "model.safetensors"
  ],
  "ai2sql/ai2sql_mistral_7b": [
    "adapter_model.safetensors"
  ],
  "thoddnn/SmartChunk-0.1-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sam2ai/odia_llama2_AWQ": [
    "model.safetensors"
  ],
  "kkaung66/meta-chat-7b": [
    "adapter_model.safetensors"
  ],
  "TheBloke/X-MythoChronos-13B-GPTQ": [
    "model.safetensors"
  ],
  "sam2ai/hindi_mistral_AWQ": [
    "model.safetensors"
  ],
  "Monkeydddd/ilex": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/smartyplats-7B-v2-GPTQ": [
    "model.safetensors"
  ],
  "BEE-spoke-data/smol_llama-101M-midjourney-messages": [
    "model.safetensors"
  ],
  "atorsvn/TinyLlama-1.1B-Chat-v0.6-gptq-4bit": [
    "model.safetensors"
  ],
  "yichunkuo/falcon-rw-1b-gptq": [
    "model.safetensors"
  ],
  "EfazAhmed/opt-350m-diamond-wd01": [
    "model.safetensors"
  ],
  "shilongdai/llama-qa-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/juanako-7B-v1-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/juanako-7B-v1-GPTQ": [
    "model.safetensors"
  ],
  "djhenny/codeparrot-ds": [
    "model.safetensors"
  ],
  "Prabakaran2712/dialofinetune": [
    "model.safetensors"
  ],
  "RobCzikkel/DoctorGPT": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "cools/LLM": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "guidoivetta/Martin-Fierro": [
    "model.safetensors"
  ],
  "nanom/Martin-Fierro": [
    "model.safetensors"
  ],
  "KrushiJethe/exp": [
    "model.safetensors"
  ],
  "nanom/Peppa-Pig": [
    "model.safetensors"
  ],
  "heegyu/42dot-1.3B-KOR-OpenOrca-Platypus-1e-5": [
    "model.safetensors"
  ],
  "heegyu/llama-2-koen-13b-OKI-v20231124-1e-5": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "npvinHnivqn/phi-1_5-NRL": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "BEE-spoke-data/NanoLlama-GQA-L10-A32_KV8-v13-KI": [
    "model.safetensors"
  ],
  "djhenny/wiki": [
    "model.safetensors"
  ],
  "suhailg03/Mistral-7B-Instruct-v0.1-awq": [
    "model.safetensors"
  ],
  "heegyu/Mistral-7B-v0.1-OKI-v20231124-1e-5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "alvwjy/Llama2-epic-finetuned": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ryan0712/advanced-zephyr-alpha": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "CrabfishAI/NeXGen-based": [
    "model.safetensors"
  ],
  "yichunkuo/Llama-2-7b-hf-gptq": [
    "model.safetensors"
  ],
  "Torando/DoctorGPT": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "royallab/Aetheria-L2-70B": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "alexkoo300/important-sheep": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "tomaszki/phi-metamath": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Karen_TheEditor_V2_CREATIVE_Mistral_7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Karen_TheEditor_V2_CREATIVE_Mistral_7B-AWQ": [
    "model.safetensors"
  ],
  "pragadeshbs/dialoGPT-finetune": [
    "model.safetensors"
  ],
  "eunbinni/ola_polyglot_5.8B_lora2_merge": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Sundogs/image_to_text": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "TheBloke/PiVoT-0.1-early-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/PiVoT-0.1-early-AWQ": [
    "model.safetensors"
  ],
  "eunbinni/ola_polyglot_12.8B_lora1_merge": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "eunbinni/ola_polyglot_5.8B_lora1_8bit_merge": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "eunbinni/ola_polyglot_5.8B_lora2_8bit_merge": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "akash140500/llama-2-7b-miniplatypus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "eunbinni/ola_polyglot_12.8B_lora2_8bit_merge": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "TheBloke/Tess-M-v1.3-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Tess-M-v1.3-GPTQ": [
    "model.safetensors"
  ],
  "heegyu/zephyr-7b-beta-KOR-OpenOrca-Platypus-1e-5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "gastonstrizzolo/Peppa-Pig": [
    "model.safetensors"
  ],
  "xEricCardozo/Peppa-Pig": [
    "model.safetensors"
  ],
  "umarbutler/open-australian-legal-phi-1_5": [
    "adapter_model.safetensors"
  ],
  "lunalade/gpt2.shak": [
    "model.safetensors"
  ],
  "mlabonne/drmistral-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tomaszki/phi-metamath-1.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "brucethemoose/Capybara-Tess-Yi-34B-200K-DARE-Ties": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "dangvansam/finetune_OpenHermes_2.5_prompt_v4_group_by_len_bf16_lr5e-6_constant_max_len_1024_add_orca": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "emiliam/Resenas-de-Vinos": [
    "model.safetensors"
  ],
  "Joacopolo/Julio-Cortazar": [
    "model.safetensors"
  ],
  "Rodrig0rtiz/Peppa-Pig": [
    "model.safetensors"
  ],
  "rubin145/Resenas-de-Vinos": [
    "model.safetensors"
  ],
  "dancba/Edgar-Allan-Poe": [
    "model.safetensors"
  ],
  "agusbrusco/Martin-Fierro": [
    "model.safetensors"
  ],
  "juantollo/Peppa-Pig": [
    "model.safetensors"
  ],
  "octa-cba/Martin-Fierro": [
    "model.safetensors"
  ],
  "gastonstrizzolo/Martin-Fierro": [
    "model.safetensors"
  ],
  "eitansprejer/Julio-Cortazar": [
    "model.safetensors"
  ],
  "cboyallian/Julio-Cortazar": [
    "model.safetensors"
  ],
  "bcecilia1/Martin-Fierro": [
    "model.safetensors"
  ],
  "Andrescotton/Martin-Fierro": [
    "model.safetensors"
  ],
  "noe-hsueh/Julio-Cortazar": [
    "model.safetensors"
  ],
  "Andrescotton/CHECHU_SE_SACA_FOTOS_EN_LUGARES": [
    "model.safetensors"
  ],
  "Harrynski/Jose-Saramago": [
    "model.safetensors"
  ],
  "vanemeinardi/Martin-Fierro": [
    "model.safetensors"
  ],
  "florenciaaltschuler/Peppa-Pig": [
    "model.safetensors"
  ],
  "wenbrau/Julio-Cortazar": [
    "model.safetensors"
  ],
  "metterian/llama-2-ko-7b-pt": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "eunbinni/ola_polyglot_12.8B_lora2_merge": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "AlvianKhairi/Mistral-7B-v0.1-sharded-bf16-3GB": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "TheBloke/MysticFusion-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/MysticFusion-13B-GPTQ": [
    "model.safetensors"
  ],
  "berkeley-nest/Starling-LM-7B-alpha": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lunalade/gpt2.fairyTales": [
    "model.safetensors"
  ],
  "Locutusque/Orca-2-13b-SFT-v4": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "Severian/ANIMA-Neural-Hermes": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "xwar/ninox_zephyr-0": [
    "adapter_model.safetensors",
    "checkpoint-144/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Capybara-Tess-Yi-34B-200K-DARE-Ties-3.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "sandwichdoge/Nous-Capybara-limarpv3-34B-5bpw-hb6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LizzyBennet/translation_ko_en": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "brucethemoose/Capybara-Tess-Yi-34B-200K-DARE-Ties-4bpw-exl2-fiction": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "ContextualAI/archangel_sft_pythia1-4b": [
    "model.safetensors"
  ],
  "ContextualAI/archangel_sft_pythia2-8b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ContextualAI/archangel_sft_pythia6-9b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "PsiPi/taozi555_MythoMax-Kimiko-Mix-exl2-2.4bpw": [
    "output.safetensors"
  ],
  "ContextualAI/archangel_sft_pythia12-0b": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "LoneStriker/Capybara-Tess-Yi-34B-200K-DARE-Ties-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "ContextualAI/archangel_sft_llama7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ContextualAI/archangel_sft_llama13b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ContextualAI/archangel_sft_llama30b": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "TheBloke/Capybara-Tess-Yi-34B-200K-DARE-Ties-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Capybara-Tess-Yi-34B-200K-DARE-Ties-GPTQ": [
    "model.safetensors"
  ],
  "sandwichdoge/Nous-Capybara-limarpv3-34B-4.65bpw-hb6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Capybara-Tess-Yi-34B-200K-DARE-Ties-4.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "TakanashiShiya/FamilyPlusLlama": [
    "adapter_model.safetensors"
  ],
  "izayashiro/mistral-7B-Instruct-HPC": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Capybara-Tess-Yi-34B-200K-DARE-Ties-5.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "ContextualAI/archangel_slic_llama30b": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "ContextualAI/archangel_slic_pythia1-4b": [
    "model.safetensors"
  ],
  "ContextualAI/archangel_slic_pythia2-8b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ContextualAI/archangel_slic_pythia6-9b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ContextualAI/archangel_slic_pythia12-0b": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "ContextualAI/archangel_slic_llama7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "athirdpath/Harmonia-20B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "ContextualAI/archangel_slic_llama13b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/Capybara-Tess-Yi-34B-200K-DARE-Ties-6.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "Rewcifer/mistral-7b-tyellow-2kcutoff-clean-full": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ankity09/zephyr-7b-aplha-4.0bpw-exl2": [
    "cal_data.safetensors",
    "input_states.safetensors",
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors",
    "out_tensor/model.layers.0.mlp.down_proj.safetensors",
    "out_tensor/model.layers.0.mlp.gate_proj.safetensors",
    "out_tensor/model.layers.0.mlp.up_proj.safetensors",
    "out_tensor/model.layers.0.self_attn.k_proj.safetensors",
    "out_tensor/model.layers.0.self_attn.o_proj.safetensors",
    "out_tensor/model.layers.0.self_attn.q_proj.safetensors",
    "out_tensor/model.layers.0.self_attn.v_proj.safetensors",
    "out_tensor/model.layers.1.mlp.down_proj.safetensors",
    "out_tensor/model.layers.1.mlp.gate_proj.safetensors",
    "out_tensor/model.layers.1.mlp.up_proj.safetensors",
    "out_tensor/model.layers.1.self_attn.k_proj.safetensors",
    "out_tensor/model.layers.1.self_attn.o_proj.safetensors",
    "out_tensor/model.layers.1.self_attn.q_proj.safetensors",
    "out_tensor/model.layers.1.self_attn.v_proj.safetensors",
    "out_tensor/model.layers.10.mlp.down_proj.safetensors",
    "out_tensor/model.layers.10.mlp.gate_proj.safetensors",
    "out_tensor/model.layers.10.mlp.up_proj.safetensors",
    "out_tensor/model.layers.10.self_attn.k_proj.safetensors",
    "out_tensor/model.layers.10.self_attn.o_proj.safetensors",
    "out_tensor/model.layers.10.self_attn.q_proj.safetensors",
    "out_tensor/model.layers.10.self_attn.v_proj.safetensors",
    "out_tensor/model.layers.11.mlp.down_proj.safetensors",
    "out_tensor/model.layers.11.mlp.gate_proj.safetensors",
    "out_tensor/model.layers.11.mlp.up_proj.safetensors",
    "out_tensor/model.layers.11.self_attn.k_proj.safetensors",
    "out_tensor/model.layers.11.self_attn.o_proj.safetensors",
    "out_tensor/model.layers.11.self_attn.q_proj.safetensors",
    "out_tensor/model.layers.11.self_attn.v_proj.safetensors",
    "out_tensor/model.layers.12.mlp.down_proj.safetensors",
    "out_tensor/model.layers.12.mlp.gate_proj.safetensors",
    "out_tensor/model.layers.12.mlp.up_proj.safetensors",
    "out_tensor/model.layers.12.self_attn.k_proj.safetensors",
    "out_tensor/model.layers.12.self_attn.o_proj.safetensors",
    "out_tensor/model.layers.12.self_attn.q_proj.safetensors",
    "out_tensor/model.layers.12.self_attn.v_proj.safetensors",
    "out_tensor/model.layers.13.mlp.down_proj.safetensors",
    "out_tensor/model.layers.13.mlp.gate_proj.safetensors",
    "out_tensor/model.layers.13.mlp.up_proj.safetensors",
    "out_tensor/model.layers.13.self_attn.k_proj.safetensors",
    "out_tensor/model.layers.13.self_attn.o_proj.safetensors",
    "out_tensor/model.layers.13.self_attn.q_proj.safetensors",
    "out_tensor/model.layers.13.self_attn.v_proj.safetensors",
    "out_tensor/model.layers.14.mlp.down_proj.safetensors",
    "out_tensor/model.layers.14.mlp.gate_proj.safetensors",
    "out_tensor/model.layers.14.mlp.up_proj.safetensors",
    "out_tensor/model.layers.14.self_attn.k_proj.safetensors",
    "out_tensor/model.layers.14.self_attn.o_proj.safetensors",
    "out_tensor/model.layers.14.self_attn.q_proj.safetensors",
    "out_tensor/model.layers.14.self_attn.v_proj.safetensors",
    "out_tensor/model.layers.15.mlp.down_proj.safetensors",
    "out_tensor/model.layers.15.mlp.gate_proj.safetensors",
    "out_tensor/model.layers.15.mlp.up_proj.safetensors",
    "out_tensor/model.layers.15.self_attn.k_proj.safetensors",
    "out_tensor/model.layers.15.self_attn.o_proj.safetensors",
    "out_tensor/model.layers.15.self_attn.q_proj.safetensors",
    "out_tensor/model.layers.15.self_attn.v_proj.safetensors",
    "out_tensor/model.layers.16.mlp.down_proj.safetensors",
    "out_tensor/model.layers.16.mlp.gate_proj.safetensors",
    "out_tensor/model.layers.16.mlp.up_proj.safetensors",
    "out_tensor/model.layers.16.self_attn.k_proj.safetensors",
    "out_tensor/model.layers.16.self_attn.o_proj.safetensors",
    "out_tensor/model.layers.16.self_attn.q_proj.safetensors",
    "out_tensor/model.layers.16.self_attn.v_proj.safetensors",
    "out_tensor/model.layers.17.mlp.down_proj.safetensors",
    "out_tensor/model.layers.17.mlp.gate_proj.safetensors",
    "out_tensor/model.layers.17.mlp.up_proj.safetensors",
    "out_tensor/model.layers.17.self_attn.k_proj.safetensors",
    "out_tensor/model.layers.17.self_attn.o_proj.safetensors",
    "out_tensor/model.layers.17.self_attn.q_proj.safetensors",
    "out_tensor/model.layers.17.self_attn.v_proj.safetensors",
    "out_tensor/model.layers.18.mlp.down_proj.safetensors",
    "out_tensor/model.layers.18.mlp.gate_proj.safetensors",
    "out_tensor/model.layers.18.mlp.up_proj.safetensors",
    "out_tensor/model.layers.18.self_attn.k_proj.safetensors",
    "out_tensor/model.layers.18.self_attn.o_proj.safetensors",
    "out_tensor/model.layers.18.self_attn.q_proj.safetensors",
    "out_tensor/model.layers.18.self_attn.v_proj.safetensors",
    "out_tensor/model.layers.19.mlp.down_proj.safetensors",
    "out_tensor/model.layers.19.mlp.gate_proj.safetensors",
    "out_tensor/model.layers.19.mlp.up_proj.safetensors",
    "out_tensor/model.layers.19.self_attn.k_proj.safetensors",
    "out_tensor/model.layers.19.self_attn.o_proj.safetensors",
    "out_tensor/model.layers.19.self_attn.q_proj.safetensors",
    "out_tensor/model.layers.19.self_attn.v_proj.safetensors",
    "out_tensor/model.layers.2.mlp.down_proj.safetensors",
    "out_tensor/model.layers.2.mlp.gate_proj.safetensors",
    "out_tensor/model.layers.2.mlp.up_proj.safetensors",
    "out_tensor/model.layers.2.self_attn.k_proj.safetensors",
    "out_tensor/model.layers.2.self_attn.o_proj.safetensors",
    "out_tensor/model.layers.2.self_attn.q_proj.safetensors",
    "out_tensor/model.layers.2.self_attn.v_proj.safetensors",
    "out_tensor/model.layers.20.mlp.down_proj.safetensors",
    "out_tensor/model.layers.20.mlp.gate_proj.safetensors",
    "out_tensor/model.layers.20.mlp.up_proj.safetensors",
    "out_tensor/model.layers.20.self_attn.k_proj.safetensors",
    "out_tensor/model.layers.20.self_attn.o_proj.safetensors",
    "out_tensor/model.layers.20.self_attn.q_proj.safetensors",
    "out_tensor/model.layers.20.self_attn.v_proj.safetensors",
    "out_tensor/model.layers.21.mlp.down_proj.safetensors",
    "out_tensor/model.layers.21.mlp.gate_proj.safetensors",
    "out_tensor/model.layers.21.mlp.up_proj.safetensors",
    "out_tensor/model.layers.21.self_attn.k_proj.safetensors",
    "out_tensor/model.layers.21.self_attn.o_proj.safetensors",
    "out_tensor/model.layers.21.self_attn.q_proj.safetensors",
    "out_tensor/model.layers.21.self_attn.v_proj.safetensors",
    "out_tensor/model.layers.22.mlp.down_proj.safetensors",
    "out_tensor/model.layers.22.mlp.gate_proj.safetensors",
    "out_tensor/model.layers.22.mlp.up_proj.safetensors",
    "out_tensor/model.layers.22.self_attn.k_proj.safetensors",
    "out_tensor/model.layers.22.self_attn.o_proj.safetensors",
    "out_tensor/model.layers.22.self_attn.q_proj.safetensors",
    "out_tensor/model.layers.22.self_attn.v_proj.safetensors",
    "out_tensor/model.layers.23.mlp.down_proj.safetensors",
    "out_tensor/model.layers.23.mlp.gate_proj.safetensors",
    "out_tensor/model.layers.23.mlp.up_proj.safetensors",
    "out_tensor/model.layers.23.self_attn.k_proj.safetensors",
    "out_tensor/model.layers.23.self_attn.o_proj.safetensors",
    "out_tensor/model.layers.23.self_attn.q_proj.safetensors",
    "out_tensor/model.layers.23.self_attn.v_proj.safetensors",
    "out_tensor/model.layers.24.mlp.down_proj.safetensors",
    "out_tensor/model.layers.24.mlp.gate_proj.safetensors",
    "out_tensor/model.layers.24.mlp.up_proj.safetensors",
    "out_tensor/model.layers.24.self_attn.k_proj.safetensors",
    "out_tensor/model.layers.24.self_attn.o_proj.safetensors",
    "out_tensor/model.layers.24.self_attn.q_proj.safetensors",
    "out_tensor/model.layers.24.self_attn.v_proj.safetensors",
    "out_tensor/model.layers.25.mlp.down_proj.safetensors",
    "out_tensor/model.layers.25.mlp.gate_proj.safetensors",
    "out_tensor/model.layers.25.mlp.up_proj.safetensors",
    "out_tensor/model.layers.25.self_attn.k_proj.safetensors",
    "out_tensor/model.layers.25.self_attn.o_proj.safetensors",
    "out_tensor/model.layers.25.self_attn.q_proj.safetensors",
    "out_tensor/model.layers.25.self_attn.v_proj.safetensors",
    "out_tensor/model.layers.26.mlp.down_proj.safetensors",
    "out_tensor/model.layers.26.mlp.gate_proj.safetensors",
    "out_tensor/model.layers.26.mlp.up_proj.safetensors",
    "out_tensor/model.layers.26.self_attn.k_proj.safetensors",
    "out_tensor/model.layers.26.self_attn.o_proj.safetensors",
    "out_tensor/model.layers.26.self_attn.q_proj.safetensors",
    "out_tensor/model.layers.26.self_attn.v_proj.safetensors",
    "out_tensor/model.layers.27.mlp.down_proj.safetensors",
    "out_tensor/model.layers.27.mlp.gate_proj.safetensors",
    "out_tensor/model.layers.27.mlp.up_proj.safetensors",
    "out_tensor/model.layers.27.self_attn.k_proj.safetensors",
    "out_tensor/model.layers.27.self_attn.o_proj.safetensors",
    "out_tensor/model.layers.27.self_attn.q_proj.safetensors",
    "out_tensor/model.layers.27.self_attn.v_proj.safetensors",
    "out_tensor/model.layers.28.mlp.down_proj.safetensors",
    "out_tensor/model.layers.28.mlp.gate_proj.safetensors",
    "out_tensor/model.layers.28.mlp.up_proj.safetensors",
    "out_tensor/model.layers.28.self_attn.k_proj.safetensors",
    "out_tensor/model.layers.28.self_attn.o_proj.safetensors",
    "out_tensor/model.layers.28.self_attn.q_proj.safetensors",
    "out_tensor/model.layers.28.self_attn.v_proj.safetensors",
    "out_tensor/model.layers.29.mlp.down_proj.safetensors",
    "out_tensor/model.layers.29.mlp.gate_proj.safetensors",
    "out_tensor/model.layers.29.mlp.up_proj.safetensors",
    "out_tensor/model.layers.29.self_attn.k_proj.safetensors",
    "out_tensor/model.layers.29.self_attn.o_proj.safetensors",
    "out_tensor/model.layers.29.self_attn.q_proj.safetensors",
    "out_tensor/model.layers.29.self_attn.v_proj.safetensors",
    "out_tensor/model.layers.3.mlp.down_proj.safetensors",
    "out_tensor/model.layers.3.mlp.gate_proj.safetensors",
    "out_tensor/model.layers.3.mlp.up_proj.safetensors",
    "out_tensor/model.layers.3.self_attn.k_proj.safetensors",
    "out_tensor/model.layers.3.self_attn.o_proj.safetensors",
    "out_tensor/model.layers.3.self_attn.q_proj.safetensors",
    "out_tensor/model.layers.3.self_attn.v_proj.safetensors",
    "out_tensor/model.layers.30.mlp.down_proj.safetensors",
    "out_tensor/model.layers.30.mlp.gate_proj.safetensors",
    "out_tensor/model.layers.30.mlp.up_proj.safetensors",
    "out_tensor/model.layers.30.self_attn.k_proj.safetensors",
    "out_tensor/model.layers.30.self_attn.o_proj.safetensors",
    "out_tensor/model.layers.30.self_attn.q_proj.safetensors",
    "out_tensor/model.layers.30.self_attn.v_proj.safetensors",
    "out_tensor/model.layers.31.mlp.down_proj.safetensors",
    "out_tensor/model.layers.31.mlp.gate_proj.safetensors",
    "out_tensor/model.layers.31.mlp.up_proj.safetensors",
    "out_tensor/model.layers.31.self_attn.k_proj.safetensors",
    "out_tensor/model.layers.31.self_attn.o_proj.safetensors",
    "out_tensor/model.layers.31.self_attn.q_proj.safetensors",
    "out_tensor/model.layers.31.self_attn.v_proj.safetensors",
    "out_tensor/model.layers.4.mlp.down_proj.safetensors",
    "out_tensor/model.layers.4.mlp.gate_proj.safetensors",
    "out_tensor/model.layers.4.mlp.up_proj.safetensors",
    "out_tensor/model.layers.4.self_attn.k_proj.safetensors",
    "out_tensor/model.layers.4.self_attn.o_proj.safetensors",
    "out_tensor/model.layers.4.self_attn.q_proj.safetensors",
    "out_tensor/model.layers.4.self_attn.v_proj.safetensors",
    "out_tensor/model.layers.5.mlp.down_proj.safetensors",
    "out_tensor/model.layers.5.mlp.gate_proj.safetensors",
    "out_tensor/model.layers.5.mlp.up_proj.safetensors",
    "out_tensor/model.layers.5.self_attn.k_proj.safetensors",
    "out_tensor/model.layers.5.self_attn.o_proj.safetensors",
    "out_tensor/model.layers.5.self_attn.q_proj.safetensors",
    "out_tensor/model.layers.5.self_attn.v_proj.safetensors",
    "out_tensor/model.layers.6.mlp.down_proj.safetensors",
    "out_tensor/model.layers.6.mlp.gate_proj.safetensors",
    "out_tensor/model.layers.6.mlp.up_proj.safetensors",
    "out_tensor/model.layers.6.self_attn.k_proj.safetensors",
    "out_tensor/model.layers.6.self_attn.o_proj.safetensors",
    "out_tensor/model.layers.6.self_attn.q_proj.safetensors",
    "out_tensor/model.layers.6.self_attn.v_proj.safetensors",
    "out_tensor/model.layers.7.mlp.down_proj.safetensors",
    "out_tensor/model.layers.7.mlp.gate_proj.safetensors",
    "out_tensor/model.layers.7.mlp.up_proj.safetensors",
    "out_tensor/model.layers.7.self_attn.k_proj.safetensors",
    "out_tensor/model.layers.7.self_attn.o_proj.safetensors",
    "out_tensor/model.layers.7.self_attn.q_proj.safetensors",
    "out_tensor/model.layers.7.self_attn.v_proj.safetensors",
    "out_tensor/model.layers.8.mlp.down_proj.safetensors",
    "out_tensor/model.layers.8.mlp.gate_proj.safetensors",
    "out_tensor/model.layers.8.mlp.up_proj.safetensors",
    "out_tensor/model.layers.8.self_attn.k_proj.safetensors",
    "out_tensor/model.layers.8.self_attn.o_proj.safetensors",
    "out_tensor/model.layers.8.self_attn.q_proj.safetensors",
    "out_tensor/model.layers.8.self_attn.v_proj.safetensors",
    "out_tensor/model.layers.9.mlp.down_proj.safetensors",
    "out_tensor/model.layers.9.mlp.gate_proj.safetensors",
    "out_tensor/model.layers.9.mlp.up_proj.safetensors",
    "out_tensor/model.layers.9.self_attn.k_proj.safetensors",
    "out_tensor/model.layers.9.self_attn.o_proj.safetensors",
    "out_tensor/model.layers.9.self_attn.q_proj.safetensors",
    "out_tensor/model.layers.9.self_attn.v_proj.safetensors"
  ],
  "athirdpath/Hestia-20b": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "LoneStriker/Capybara-Tess-Yi-34B-200K-DARE-Ties-8.0bpw-h8-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "ContextualAI/archangel_dpo_pythia1-4b": [
    "model.safetensors"
  ],
  "ContextualAI/archangel_dpo_pythia2-8b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ContextualAI/archangel_dpo_pythia6-9b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ContextualAI/archangel_dpo_pythia12-0b": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "ContextualAI/archangel_dpo_llama7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ContextualAI/archangel_dpo_llama13b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ContextualAI/archangel_dpo_llama30b": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "gkaceli/Llama2-chat-SQUADv2-Finetune": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ContextualAI/archangel_kto_pythia1-4b": [
    "model.safetensors"
  ],
  "ContextualAI/archangel_kto_pythia2-8b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ContextualAI/archangel_kto_pythia6-9b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ContextualAI/archangel_kto_pythia12-0b": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "ContextualAI/archangel_kto_llama7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ContextualAI/archangel_kto_llama13b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ContextualAI/archangel_kto_llama30b": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "ContextualAI/archangel_ppo_pythia1-4b": [
    "model.safetensors"
  ],
  "ContextualAI/archangel_ppo_pythia2-8b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ContextualAI/archangel_ppo_pythia6-9b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ContextualAI/archangel_ppo_pythia12-0b": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "ContextualAI/archangel_ppo_llama7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ContextualAI/archangel_ppo_llama13b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ContextualAI/archangel_ppo_llama30b": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "Herman555/Hexoteric-AshhLimaRP-Mistral-7B-GGUF": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hllj/sft-zephyr-7b-beta-v4": [
    "adapter_model.safetensors"
  ],
  "rchadha134/llama_7b_guanaco_4_merged_model": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "heegyu/Synatra-7B-v0.3-Translation-fp16": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Undi95/Leyley-13B-Lora": [
    "checkpoint-1040/adapter_model.safetensors",
    "checkpoint-1235/adapter_model.safetensors",
    "checkpoint-1560/adapter_model.safetensors",
    "checkpoint-715/adapter_model.safetensors",
    "checkpoint-975/adapter_model.safetensors"
  ],
  "DopeorNope/mistralopithecus-v1-dpo-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "adenovirux/my_awesome_eli5_clm-model": [
    "model.safetensors"
  ],
  "iamkhadke/zephyr-7b-beta_demo_merged": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "junzhu/codellama-7b-titan-go-logs": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "eunbinni/ola_polyglot_12.8B_lora1_4bit_merge": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "DopeorNope/mistralopithecus-v2-dpo-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "KantoRegion/merged-llama2-13b-hermione3-30": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "Undi95/Leyley-13B": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "xenox/mistralai-Code-Instruct": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Deathsquad10/TinyLlama-Remix": [
    "model.safetensors"
  ],
  "lorddestrian/eli5_clm-model": [
    "model.safetensors"
  ],
  "PsiPi/taozi555_MythoMax-Kimiko-Mix-exl2-4.85bpw": [
    "output.safetensors"
  ],
  "alexpaul/questgig-qi": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "HumanF-MarkrAI/mistralopithecus-v3-dpo-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "anakin87/gorilla-openfunctions-v0-sharded": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "SchubergPhilis/TinyLlama-1.1B-Chat-v0.4-ENG": [
    "model.safetensors"
  ],
  "eunbinni/ola_polyglot_5.8B_lora1_4bit_merge": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "athirdpath/CleverMommy-mix-20b": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Mlxa/brackets-nested": [
    "model.safetensors"
  ],
  "MohitK16/gpt2-wikitext2": [
    "model.safetensors"
  ],
  "eunbinni/ola_polyglot_5.8B_lora2_4bit_merge": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "maywell/PiVoT-0.1-Evil-a": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "project2you/codegen-350M-mono-python-18k-alpaca": [
    "model.safetensors"
  ],
  "mcysqrd/MODULARMOJO_Mistral_V1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "IHaBiS/PiVoT-0.1-early-exl2": [
    "output.safetensors"
  ],
  "eunbinni/ola_polyglot_12.8B_lora1_8bit_merge": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "athirdpath/Harmonia-norobots-LORA": [
    "checkpoint-100/adapter_model.safetensors",
    "checkpoint-200/adapter_model.safetensors"
  ],
  "Jarnails1559/my-sentiment-model": [
    "model.safetensors"
  ],
  "eunbinni/ola_polyglot_12.8B_lora2_4bit_merge": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Jarnails1559/story-writer-model": [
    "model.safetensors"
  ],
  "eunbinni/ola_llama2_7B_lora1_merge": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mesolitica/malaysian-llama2-7b-32k-instructions-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "R136a1/X-NoroChronos-13B-exl2": [
    "output.safetensors"
  ],
  "eunbinni/ola_llama2_7B_lora2_merge": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "eunbinni/ola_llama2_7B_lora1_8bit_merge": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "eunbinni/ola_llama2_7B_lora2_8bit_merge": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "eunbinni/ola_llama2_7B_lora1_4bit_merge": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Qwen/Qwen-72B": [
    "model-00001-of-00082.safetensors",
    "model-00002-of-00082.safetensors",
    "model-00003-of-00082.safetensors",
    "model-00004-of-00082.safetensors",
    "model-00005-of-00082.safetensors",
    "model-00006-of-00082.safetensors",
    "model-00007-of-00082.safetensors",
    "model-00008-of-00082.safetensors",
    "model-00009-of-00082.safetensors",
    "model-00010-of-00082.safetensors",
    "model-00011-of-00082.safetensors",
    "model-00012-of-00082.safetensors",
    "model-00013-of-00082.safetensors",
    "model-00014-of-00082.safetensors",
    "model-00015-of-00082.safetensors",
    "model-00016-of-00082.safetensors",
    "model-00017-of-00082.safetensors",
    "model-00018-of-00082.safetensors",
    "model-00019-of-00082.safetensors",
    "model-00020-of-00082.safetensors",
    "model-00021-of-00082.safetensors",
    "model-00022-of-00082.safetensors",
    "model-00023-of-00082.safetensors",
    "model-00024-of-00082.safetensors",
    "model-00025-of-00082.safetensors",
    "model-00026-of-00082.safetensors",
    "model-00027-of-00082.safetensors",
    "model-00028-of-00082.safetensors",
    "model-00029-of-00082.safetensors",
    "model-00030-of-00082.safetensors",
    "model-00031-of-00082.safetensors",
    "model-00032-of-00082.safetensors",
    "model-00033-of-00082.safetensors",
    "model-00034-of-00082.safetensors",
    "model-00035-of-00082.safetensors",
    "model-00036-of-00082.safetensors",
    "model-00037-of-00082.safetensors",
    "model-00038-of-00082.safetensors",
    "model-00039-of-00082.safetensors",
    "model-00040-of-00082.safetensors",
    "model-00041-of-00082.safetensors",
    "model-00042-of-00082.safetensors",
    "model-00043-of-00082.safetensors",
    "model-00044-of-00082.safetensors",
    "model-00045-of-00082.safetensors",
    "model-00046-of-00082.safetensors",
    "model-00047-of-00082.safetensors",
    "model-00048-of-00082.safetensors",
    "model-00049-of-00082.safetensors",
    "model-00050-of-00082.safetensors",
    "model-00051-of-00082.safetensors",
    "model-00052-of-00082.safetensors",
    "model-00053-of-00082.safetensors",
    "model-00054-of-00082.safetensors",
    "model-00055-of-00082.safetensors",
    "model-00056-of-00082.safetensors",
    "model-00057-of-00082.safetensors",
    "model-00058-of-00082.safetensors",
    "model-00059-of-00082.safetensors",
    "model-00060-of-00082.safetensors",
    "model-00061-of-00082.safetensors",
    "model-00062-of-00082.safetensors",
    "model-00063-of-00082.safetensors",
    "model-00064-of-00082.safetensors",
    "model-00065-of-00082.safetensors",
    "model-00066-of-00082.safetensors",
    "model-00067-of-00082.safetensors",
    "model-00068-of-00082.safetensors",
    "model-00069-of-00082.safetensors",
    "model-00070-of-00082.safetensors",
    "model-00071-of-00082.safetensors",
    "model-00072-of-00082.safetensors",
    "model-00073-of-00082.safetensors",
    "model-00074-of-00082.safetensors",
    "model-00075-of-00082.safetensors",
    "model-00076-of-00082.safetensors",
    "model-00077-of-00082.safetensors",
    "model-00078-of-00082.safetensors",
    "model-00079-of-00082.safetensors",
    "model-00080-of-00082.safetensors",
    "model-00081-of-00082.safetensors",
    "model-00082-of-00082.safetensors"
  ],
  "eunbinni/ola_llama2_7B_lora2_4bit_merge": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "pabligme/Llama_13b_chat": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Kuduxaaa/gpt2-geo": [
    "model.safetensors"
  ],
  "CalvinU/Llama-2-7b-chat-hf-awq": [
    "model.safetensors"
  ],
  "IHaBiS/PiVoT-0.1-Evil-a-exl2": [
    "output.safetensors"
  ],
  "Gryphe/MergeMonster-13b-20231124": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Mlxa/brackets-flat": [
    "model.safetensors"
  ],
  "Loewolf/L-GPT_1.1": [
    "model.safetensors"
  ],
  "sgimmel/gpt-neo-125m-finetuned-cummings-multiline": [
    "model.safetensors"
  ],
  "R136a1/Nete-13B-exl2": [
    "output.safetensors"
  ],
  "Mlxa/brackets-flat_shuffle": [
    "model.safetensors"
  ],
  "kheopsai/kheops_mistral_v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "R136a1/TimeCrystal-l2-13B-exl2": [
    "output.safetensors"
  ],
  "Zakia/gpt2-imdb-pos-v2": [
    "model.safetensors"
  ],
  "LoneStriker/MergeMonster-13b-20231124-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "KarlGauss/bert-base-italian-xxl-cased-finetuned-paisa": [
    "model.safetensors"
  ],
  "kheopsai/kheops_mistral_v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/MergeMonster-13b-20231124-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/MergeMonster-13b-20231124-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/MergeMonster-13b-20231124-6.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/MergeMonster-13b-20231124-8.0bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "TheBloke/PiVoT-0.1-Evil-a-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/PiVoT-0.1-Evil-a-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/MergeMonster-13B-20231124-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/MergeMonster-13B-20231124-AWQ": [
    "model.safetensors"
  ],
  "TIGER-Lab/TIGERScore-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TIGER-Lab/TIGERScore-13B": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "shahidul034/KUETLLM_zephyr_base": [
    "model-00001-of-00002.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00002.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "smangrul/phi_1_5_instruct": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Mariaaaaa/vicuna-7b-fine-tuning_SST2_20_16": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "inwookie/mistral-fine-tuned-samchully-consultation": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "inwookie/mistral-fine-tuned-samchully-keyword": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/SunsetBoulevard-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/SunsetBoulevard-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "Rofoman/GTS-Lewd-13b-V0.2": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "priyesh2023/GPT": [
    "checkpoint-13/model.safetensors",
    "checkpoint-19/model.safetensors",
    "checkpoint-26/model.safetensors",
    "checkpoint-30/model.safetensors",
    "checkpoint-6/model.safetensors",
    "model.safetensors"
  ],
  "foufou26/malin": [
    "model.safetensors"
  ],
  "lcw99/zephykor-ko-beta-7b-chang": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "joyfine/vicuna-7b-fine-tuning_SST2_20_64": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "healthcorum/anm2-25mh-u5jo-0": [
    "adapter_model.safetensors",
    "checkpoint-7812/adapter_model.safetensors",
    "model.safetensors"
  ],
  "yinyin0916/vicuna-7b-fine-tuning_SST2_20_512": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "BigSalmon/InformalToFormalLincoln117Paraphrase": [
    "model.safetensors"
  ],
  "danielkty22/reward_tuning_3_0.0001_0.01": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tara-jew/llama-2-7b-miniplatypus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "bhenrym14/airoboros-3_1-yi-34b-200k": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "danielkty22/reward_tuning_3_0.0001_0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "bradmin/sft_trl_300": [
    "model.safetensors"
  ],
  "danielkty22/reward_tuning_3_0.0001_0.5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "danielkty22/reward_tuning_3_0.0001_1.0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "joyfine/vicuna-7b-fine-tuning_SST2_20_128": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Sao10K/Lila-103B-L2": [
    "model-00001-of-00021.safetensors",
    "model-00002-of-00021.safetensors",
    "model-00003-of-00021.safetensors",
    "model-00004-of-00021.safetensors",
    "model-00005-of-00021.safetensors",
    "model-00006-of-00021.safetensors",
    "model-00007-of-00021.safetensors",
    "model-00008-of-00021.safetensors",
    "model-00009-of-00021.safetensors",
    "model-00010-of-00021.safetensors",
    "model-00011-of-00021.safetensors",
    "model-00012-of-00021.safetensors",
    "model-00013-of-00021.safetensors",
    "model-00014-of-00021.safetensors",
    "model-00015-of-00021.safetensors",
    "model-00016-of-00021.safetensors",
    "model-00017-of-00021.safetensors",
    "model-00018-of-00021.safetensors",
    "model-00019-of-00021.safetensors",
    "model-00020-of-00021.safetensors",
    "model-00021-of-00021.safetensors"
  ],
  "lixiaohong/dpo_120k_nvp_3k": [
    "model.safetensors"
  ],
  "deepapaikar/Llama2_SC_1000Epochs": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "aidiary/ELYZA-japanese-Llama-2-7b-tukuyomi-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Sao10K/Solus-103B-L2": [
    "model-00001-of-00022.safetensors",
    "model-00002-of-00022.safetensors",
    "model-00003-of-00022.safetensors",
    "model-00004-of-00022.safetensors",
    "model-00005-of-00022.safetensors",
    "model-00006-of-00022.safetensors",
    "model-00007-of-00022.safetensors",
    "model-00008-of-00022.safetensors",
    "model-00009-of-00022.safetensors",
    "model-00010-of-00022.safetensors",
    "model-00011-of-00022.safetensors",
    "model-00012-of-00022.safetensors",
    "model-00013-of-00022.safetensors",
    "model-00014-of-00022.safetensors",
    "model-00015-of-00022.safetensors",
    "model-00016-of-00022.safetensors",
    "model-00017-of-00022.safetensors",
    "model-00018-of-00022.safetensors",
    "model-00019-of-00022.safetensors",
    "model-00020-of-00022.safetensors",
    "model-00021-of-00022.safetensors",
    "model-00022-of-00022.safetensors"
  ],
  "SERC45/serc282": [
    "model.safetensors"
  ],
  "deepapaikar/Llama_SCplusQA": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Sao10K/Lila-70B-L2": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "inwookie/mistral-fine-tuned-samchully-summary": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "inwookie/mistral-fine-tuned-samchully-faq": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Cartinoe5930/KoRAE-13b-DPO": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "joyfine/vicuna-7b-fine-tuning_SST2_20_32": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lodrick-the-lafted/Kaiju-A-57B": [
    "model-00001-of-00012.safetensors",
    "model-00002-of-00012.safetensors",
    "model-00003-of-00012.safetensors",
    "model-00004-of-00012.safetensors",
    "model-00005-of-00012.safetensors",
    "model-00006-of-00012.safetensors",
    "model-00007-of-00012.safetensors",
    "model-00008-of-00012.safetensors",
    "model-00009-of-00012.safetensors",
    "model-00010-of-00012.safetensors",
    "model-00011-of-00012.safetensors",
    "model-00012-of-00012.safetensors"
  ],
  "openaccess-ai-collective/openhermes-2_5-dpo-no-robots": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mesolitica/mallam-3B-4096": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Herman555/PiVoT-0.1-Evil-a-AshhLimaRP-Mistral-7B-GGUF": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rchadha134/phi1_5_alpaca_merged1": [
    "model.safetensors"
  ],
  "jujbob/my-llama-7b-hf-qlora-guanaco-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Sao10K/Solus-70B-L2": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "Jarnails1559/gptneo-story-model": [
    "model.safetensors"
  ],
  "LoneStriker/Euryale-1.4-L2-70B-2.4bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "haqishen/cls-v2-test-1-3B-fold1": [
    "model.safetensors"
  ],
  "LoneStriker/openinstruct-mistral-7b-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Euryale-1.4-L2-70B-3.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "LoneStriker/openinstruct-mistral-7b-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "haqishen/cls-v2-test-1-3B-fold0": [
    "model.safetensors"
  ],
  "LoneStriker/openinstruct-mistral-7b-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/openinstruct-mistral-7b-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "fblgit/juanako-7b-UNA": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/openinstruct-mistral-7b-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "auhide/chef-gpt-en": [
    "model.safetensors"
  ],
  "LoneStriker/Euryale-1.4-L2-70B-4.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "spokkazo/codeparrot-ds": [
    "model.safetensors"
  ],
  "LoneStriker/Euryale-1.4-L2-70B-4.65bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "LoneStriker/Euryale-1.4-L2-70B-2.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "athirdpath/CleverGirl-20b": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "athirdpath/CleverGirl-20b-Inverted": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "athirdpath/CleverGirl-20b-Blended": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "yuyijiong/Qwen-14b-chat-yarn-32k": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "nthngdy/pythia-160m-random": [
    "model.safetensors"
  ],
  "ddps007/traceback-ai-test-v5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "project2you/test_llm2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "eunbinni/ola_llama2_13B_lora1_merge": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "merve/Mistral-7B-Instruct-v0.2": [
    "adapter_model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-indef-removal-1e-4": [
    "model.safetensors"
  ],
  "BangorAI/ALMA-Cymraeg-13B-0.1-4.0bpw-exl2": [
    "output.safetensors"
  ],
  "BangorAI/ALMA-Cymraeg-13B-0.1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "mesolitica/mallam-1.1B-4096": [
    "model.safetensors"
  ],
  "eunbinni/ola_llama2_13B_lora2_merge": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "TheBloke/OpenHermes-2.5-neural-chat-7B-v3-1-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/OpenHermes-2.5-neural-chat-7B-v3-1-7B-AWQ": [
    "model.safetensors"
  ],
  "ByteSized/Mistral-7B-OpenOrca-UWPInstruct": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sronger/ko-llm-test": [
    "model.safetensors"
  ],
  "eunbinni/ola_llama2_13B_lora1_8bit_merge": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "nalmeida/Zephyr-Gherkin-Mistral-Instruct": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "huseinzol05/dummy-mistral-5b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "eunbinni/ola_llama2_13B_lora2_8bit_merge": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "TheBloke/Lila-70B-L2-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Lila-70B-L2-GPTQ": [
    "model.safetensors"
  ],
  "BaoLocTown/sft-mistral-7b-v01-v1": [
    "adapter_model.safetensors"
  ],
  "eunbinni/ola_llama2_13B_lora1_4bit_merge": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "hllj/sft-mistral-v2-rank-64-alpha-128": [
    "adapter_model.safetensors"
  ],
  "google/madlad400-8b-lm": [
    "model-00000-of-00007.safetensors",
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "samvelkoch/friendly-mouse": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Lila-103B-L2-AWQ": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "eunbinni/ola_llama2_13B_lora2_4bit_merge": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "nalmeida/Zephyr-Gherkin-Mistral-Instruct-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "shilongdai/llama-qa-13b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "project2you/thai_llm2-gpt": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "genta-tech/merak-v4-7b-awq-st": [
    "model.safetensors"
  ],
  "Mariaaaaa/vicuna-7b-fine-tuning_SST2_20_256": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "genta-tech/openchat_3.5-awq-st": [
    "model.safetensors"
  ],
  "genta-tech/starstreak-7b-beta-awq-st": [
    "model.safetensors"
  ],
  "genta-tech/llama-2-7b-awq-st": [
    "model.safetensors"
  ],
  "genta-tech/dukunlm-7b-awq-st": [
    "model.safetensors"
  ],
  "npvinHnivqn/phi-1_5-CRL-v0.2": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "tr416/mistral-sft-v1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "AlisherAmirbek01/Llama2-ielts": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "augmxnt/shisa-7b-v1": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "dtorres-zAgile/redPajama-3b-zAgile-chat": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "vinwizard/output": [
    "model.safetensors"
  ],
  "adamo1139/Mistral-7B-AEZAKMI-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Starling-LM-7B-alpha-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Starling-LM-7B-alpha-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Starling-LM-7B-alpha-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "nsfwthrowitaway69/Venus-103b-v1.0": [
    "model-00001-of-00021.safetensors",
    "model-00002-of-00021.safetensors",
    "model-00003-of-00021.safetensors",
    "model-00004-of-00021.safetensors",
    "model-00005-of-00021.safetensors",
    "model-00006-of-00021.safetensors",
    "model-00007-of-00021.safetensors",
    "model-00008-of-00021.safetensors",
    "model-00009-of-00021.safetensors",
    "model-00010-of-00021.safetensors",
    "model-00011-of-00021.safetensors",
    "model-00012-of-00021.safetensors",
    "model-00013-of-00021.safetensors",
    "model-00014-of-00021.safetensors",
    "model-00015-of-00021.safetensors",
    "model-00016-of-00021.safetensors",
    "model-00017-of-00021.safetensors",
    "model-00018-of-00021.safetensors",
    "model-00019-of-00021.safetensors",
    "model-00020-of-00021.safetensors",
    "model-00021-of-00021.safetensors"
  ],
  "LoneStriker/Starling-LM-7B-alpha-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Starling-LM-7B-alpha-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "KnutJaegersberg/Yi-34B-200K-MiniOrca": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "mlinmg/SG-Raccoon-Yi-55B": [
    "model-00001-of-00012.safetensors",
    "model-00002-of-00012.safetensors",
    "model-00003-of-00012.safetensors",
    "model-00004-of-00012.safetensors",
    "model-00005-of-00012.safetensors",
    "model-00006-of-00012.safetensors",
    "model-00007-of-00012.safetensors",
    "model-00008-of-00012.safetensors",
    "model-00009-of-00012.safetensors",
    "model-00010-of-00012.safetensors",
    "model-00011-of-00012.safetensors",
    "model-00012-of-00012.safetensors"
  ],
  "TheBloke/Solus-103B-L2-AWQ": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/OpenHermes-2.5-neural-chat-7b-v3-1-7B-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/OpenHermes-2.5-neural-chat-7b-v3-1-7B-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "TheBloke/Lila-103B-L2-GPTQ": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/OpenHermes-2.5-neural-chat-7b-v3-1-7B-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "nlile/zephyr-7b-dpo-full": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Ansoi/hex": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/OpenHermes-2.5-neural-chat-7b-v3-1-7B-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "TheBloke/Starling-LM-7B-alpha-AWQ": [
    "model.safetensors"
  ],
  "LoneStriker/OpenHermes-2.5-neural-chat-7b-v3-1-7B-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "TheBloke/evolvedSeeker_1_3-AWQ": [
    "model.safetensors"
  ],
  "Hafeez7000/Talk-ai-small": [
    "model.safetensors"
  ],
  "S4sch/Open-Hermes-2.5-neural-chat-3.1-frankenmerge-11b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "waldie/sqlcoder-34b-alpha-4bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "joyfine/vicuna-7b-fine-tuning_Finance_20_16": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "joyfine/vicuna-7b-fine-tuning_Finance_20_32": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "BangorAI/mistral-7b-cy-tokenizer": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "bnsapa/faq-llm": [
    "adapter_model.safetensors"
  ],
  "joyfine/vicuna-7b-fine-tuning_Finance_20_64": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Cartinoe5930/weak-KoRAE-13b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "mlinmg/SG-Raccoon-Yi-55B-200k": [
    "model-00001-of-00012.safetensors",
    "model-00002-of-00012.safetensors",
    "model-00003-of-00012.safetensors",
    "model-00004-of-00012.safetensors",
    "model-00005-of-00012.safetensors",
    "model-00006-of-00012.safetensors",
    "model-00007-of-00012.safetensors",
    "model-00008-of-00012.safetensors",
    "model-00009-of-00012.safetensors",
    "model-00010-of-00012.safetensors",
    "model-00011-of-00012.safetensors",
    "model-00012-of-00012.safetensors"
  ],
  "TheBloke/Solus-70B-L2-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "joyfine/vicuna-7b-fine-tuning_Finance_20_128": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Ja-ck/Mistral-instruct-Y24-DPO": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "chargoddard/domestic-locomotive": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "nlile/PE-7b-full": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Mariaaaaa/vicuna-7b-fine-tuning_SST2_20_512": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Cartinoe5930/original-KoRAE-13b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "NatureUniverse/TinyBERT_general_4L_312d": [
    "model.safetensors"
  ],
  "evolevelyn/distilgpt2-finetuned-slangQA": [
    "model.safetensors"
  ],
  "TheBloke/Stheno-v2-Delta-AWQ": [
    "model.safetensors"
  ],
  "krdgcc0shgt/opt-125m-awq": [
    "model.safetensors"
  ],
  "kaizerBox/gpt2-summarization": [
    "model.safetensors"
  ],
  "grim3000/cogvlm-chat-hf": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "benayas/llama-2-7b-snips_v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Solus-103B-L2-GPTQ": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "bbrfkr/calm2-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sronger/ko-llm-llama-2-7b-chat": [
    "model.safetensors"
  ],
  "athirdpath/Eileithyia-20b-LORA": [
    "checkpoint-20/adapter_model.safetensors"
  ],
  "alpayariyak/opencoder": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "lu-vae/zephyr-7b-dpo-lora": [
    "adapter_model.safetensors"
  ],
  "Sujan42024/dlite-v2-1_5b-2bitQuantization": [
    "model.safetensors"
  ],
  "Puluming/AISquare-Instruct-llama2-koen-13b-v0.9.1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Loyola/ko-llama-nsmc-data10000": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "brucethemoose/CapyTessBorosYi-34B-200K-DARE-Ties": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "genta-tech/dukunlm-13b-awq-st": [
    "model.safetensors"
  ],
  "genta-tech/starstreak-7b-alpha-awq-st": [
    "model.safetensors"
  ],
  "alpayariyak/merged005": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "rbai86/swiss-7b-core": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "firef1i/finbasic2-llama2-13b": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "KnutJaegersberg/Galpaca-30b-MiniOrca": [
    "model-00001-of-00013.safetensors",
    "model-00002-of-00013.safetensors",
    "model-00003-of-00013.safetensors",
    "model-00004-of-00013.safetensors",
    "model-00005-of-00013.safetensors",
    "model-00006-of-00013.safetensors",
    "model-00007-of-00013.safetensors",
    "model-00008-of-00013.safetensors",
    "model-00009-of-00013.safetensors",
    "model-00010-of-00013.safetensors",
    "model-00011-of-00013.safetensors",
    "model-00012-of-00013.safetensors",
    "model-00013-of-00013.safetensors"
  ],
  "R136a1/MergeMonster-13b-20231124-exl2": [
    "output.safetensors"
  ],
  "Jarnails1559/ASCII_MODEL": [
    "model.safetensors"
  ],
  "Jarnails1559/MYSTORY_WRITER": [
    "model.safetensors"
  ],
  "Sujan42024/dlite-v2-1_5b-4bitQuantization": [
    "model.safetensors"
  ],
  "Jarnails1559/MYTEST_MODEL": [
    "model.safetensors"
  ],
  "jebcarter/psyonic-cetacean-20B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "TheBloke/Solus-70B-L2-GPTQ": [
    "model.safetensors"
  ],
  "krevas/LDCC-Instruct-Llama-2-ko-13B-v7.1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "krevas/LDCC-Instruct-Llama-2-ko-13B-v7.2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "krevas/LDCC-Instruct-Llama-2-ko-13B-v7.3": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "habanoz/TinyLlama-1.1B-2T-lr-2e-4-3ep-dolly-15k-instruct-v1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "NobodyExistsOnTheInternet/mistral-7b-airoboros-vicuna": [
    "adapter_model.safetensors",
    "checkpoint-19405/adapter_model.safetensors",
    "checkpoint-29111/adapter_model.safetensors",
    "checkpoint-38300/adapter_model.safetensors",
    "checkpoint-9723/adapter_model.safetensors"
  ],
  "hamxea/Mistral-7B-v0.1-sharded-AntModel-7B-XLLM-Demo": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Mlxa/tuned-flat-nested": [
    "model.safetensors"
  ],
  "Ba2han/HermesStar-OrcaWind-Synth-11B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-indef-removal-3e-4": [
    "model.safetensors"
  ],
  "GPT-JF/Model_1A_Clinton": [
    "model.safetensors"
  ],
  "hamxea/Mistral-7B-v0.1-sharded-AntModel-7B-XLLM": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "lakxs/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": [
    "model.safetensors"
  ],
  "lakxs/lock": [
    "model.safetensors"
  ],
  "shleeeee/mistral-7b-wiki": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "GPT-JF/Model_1B_Bush": [
    "model.safetensors"
  ],
  "TheBloke/CapyTessBorosYi-34B-200K-DARE-Ties-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "genta-tech/llama-2-13b-awq-st": [
    "model.safetensors"
  ],
  "Starbourne/cogvlm-chat-hf": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "pabligme/llama2_13b_DTS_test": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ceadar-ie/FinanceConnect-13B": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Robb1620/Llama2-CA-bot-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tmnam20/bloomz-1b7-2GB-sharded": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Stheno-v2-Delta-GPTQ": [
    "model.safetensors"
  ],
  "alexkoo300/cinnamon-herring": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mtc/mistralai-Mistral-7B-v0.1-classification-with-explanation-3-epochs-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Mariaaaaa/vicuna-7b-fine-tuning_Finance_20_256": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tmnam20/PhoGPT-7B5-Instruct-2GB-sharded": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Neupane9Sujal/GPT2-chatbot": [
    "model.safetensors"
  ],
  "Weyaxi/HelpSteer-filtered-neural-chat-7b-v3-1-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/PiVoT-0.1-Starling-LM-RP-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Starling-LM-7B-alpha-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/saiga_mistral_7b-AWQ": [
    "model.safetensors"
  ],
  "Jarnails1559/wizardlm": [
    "model.safetensors"
  ],
  "damerajee/codellama2-finetuned-alpaca-18k-fin": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tara-jew/llama-2-7b-icd": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/CapyTessBorosYi-34B-200K-DARE-Ties-GPTQ": [
    "model.safetensors"
  ],
  "justinj92/jj-instruct": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "DDingcheol/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": [
    "model.safetensors"
  ],
  "TheBloke/Astrid-Mistral-7B-AWQ": [
    "model.safetensors"
  ],
  "hyonee/fine_model": [
    "model.safetensors"
  ],
  "SkillstechAI/SKILLS-1": [],
  "NurtureAI/neural-chat-11b-v3-1": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "lixinran0809/new_test": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "brucethemoose/CapyTessBorosYi-34B-200K-DARE-Ties-exl2-4bpw-fiction": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "NurtureAI/openchat_3.5-11B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "benayas/llama-2-7b-snips_v3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "NurtureAI/OpenHermes-2.5-Mistral-11B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "nlile/PE-13b-full": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "TheBloke/Aetheria-L2-70B-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "chloe0x0/spliceGPT": [
    "model.safetensors"
  ],
  "Mariaaaaa/vicuna-7b-fine-tuning_Finance_20_512": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "nsfwthrowitaway69/Venus-103b-v1.1": [
    "model-00001-of-00021.safetensors",
    "model-00002-of-00021.safetensors",
    "model-00003-of-00021.safetensors",
    "model-00004-of-00021.safetensors",
    "model-00005-of-00021.safetensors",
    "model-00006-of-00021.safetensors",
    "model-00007-of-00021.safetensors",
    "model-00008-of-00021.safetensors",
    "model-00009-of-00021.safetensors",
    "model-00010-of-00021.safetensors",
    "model-00011-of-00021.safetensors",
    "model-00012-of-00021.safetensors",
    "model-00013-of-00021.safetensors",
    "model-00014-of-00021.safetensors",
    "model-00015-of-00021.safetensors",
    "model-00016-of-00021.safetensors",
    "model-00017-of-00021.safetensors",
    "model-00018-of-00021.safetensors",
    "model-00019-of-00021.safetensors",
    "model-00020-of-00021.safetensors",
    "model-00021-of-00021.safetensors"
  ],
  "yec019/fbopt-350m-8bit": [
    "model.safetensors"
  ],
  "NurtureAI/MistralLite-11B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "kaizerBox/retnet-Final-summarization": [
    "model.safetensors"
  ],
  "NurtureAI/zephyr-11b-beta": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "not-lain/PyGPT": [
    "model.safetensors"
  ],
  "NurtureAI/dolphin-2.2.1-mistral-11b": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "TheBloke/PiVoT-0.1-Starling-LM-RP-GPTQ": [
    "model.safetensors"
  ],
  "NurtureAI/Mistral-11B-Instruct-v0.1": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "TheBloke/evolvedSeeker_1_3-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/saiga_mistral_7b-GPTQ": [
    "model.safetensors"
  ],
  "NurtureAI/SynthIA-11B-v1.3": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Monkeydddd/ilex2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Karen_TheEditor_V2_CREATIVE_Mistral_7B-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Karen_TheEditor_V2_CREATIVE_Mistral_7B-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "TheBloke/Astrid-Mistral-7B-GPTQ": [
    "model.safetensors"
  ],
  "hllj/meta-math-mistral-vi-math": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "justinj92/youssefjj-pymistral-7B-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Karen_TheEditor_V2_CREATIVE_Mistral_7B-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Karen_TheEditor_V2_CREATIVE_Mistral_7B-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "ByteSized/Mistral-7B-OpenOrca-UWPInstruct-UWPSecurityInstruct": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Aetheria-L2-70B-GPTQ": [
    "model.safetensors"
  ],
  "LoneStriker/Karen_TheEditor_V2_CREATIVE_Mistral_7B-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "Bpole/lora_sberhack_v1.0": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "zichao22/my-finetuned-codellama": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ByteSized/Mistral-7B-OpenOrca-UWPInstructWSecurity": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "S4sch/zephyr-neural-chat-frankenmerge11b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Open-Hermes-2.5-neural-chat-3.1-frankenmerge-11b-AWQ": [
    "model.safetensors"
  ],
  "royallab/PsyOrca2-13b-DARE": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/SauerkrautLM-7B-HerO-AWQ": [
    "model.safetensors"
  ],
  "benayas/llama-2-7b-snips_v4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "wgpubs/zephyr-7b-dpo-lora": [
    "adapter_model.safetensors"
  ],
  "wons/llama2-13b-dpo-test-v0.2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Rofoman/GTS-Lewd-13b-V0.21": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "athirdpath/BigLlama-20b": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Tiru8055/zephyr-7b-dpo-lora": [
    "adapter_model.safetensors"
  ],
  "Starbourne/cogvlm-grounding-generalist-hf": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Cartinoe5930/original-KoRAE-13b-3ep": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "BaoLocTown/sft-metamath-mistral-7b-vi-v1": [
    "adapter_model.safetensors"
  ],
  "NurtureAI/Synatra-11B-v0.3-RP": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "kaizerBox/gpt2-small-summarization": [
    "model.safetensors"
  ],
  "wons/mistral-7B-test-v0.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Venus-120b-v1.0-GPTQ": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "TheBloke/Venus-120b-v1.0-AWQ": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "Taeyeun72/GPT2_V2": [
    "model.safetensors"
  ],
  "shleeeee/mistral-ko-7b-wiki-neft": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "benayas/llama-2-7b-snips_v0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "unsloth/llama-2-7b-bnb-4bit": [
    "model.safetensors"
  ],
  "Ja-ck/llama-2-13b-instruct-Y24-v1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "teodor98/llama-Bulgarian-recepies": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Ja-ck/llama-2-13b-instruct-Y24-v2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "athirdpath/Iambe-20b-DARE": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Ja-ck/llama-2-13b-DPO-Y24-v2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "tfjuror/finance-alpaca-finetuned-distilgpt": [
    "model.safetensors"
  ],
  "Jarnails1559/MYTEST_MODEL2": [
    "model.safetensors"
  ],
  "Sujan42024/dlite-v2-355m-bi4tQuantization": [
    "model.safetensors"
  ],
  "sronger/ko-llm-llama-2-7b-chat2": [
    "model.safetensors"
  ],
  "BachNgoH/MetaMath-Zalo-ft-Few-Shot-Augment-1000": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "wons/mistral-7B-test-v0.3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "WebraftAI/synapsellm-7b-mistral-v0.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Jarnails1559/Reasoning_model3": [
    "model.safetensors"
  ],
  "HelixAI/codellama-8bit-json-prompt-new-prompt-1129-1500-no_chat_history_epoch_3": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "umarbutler/open-australian-legal-llm": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "hllj/sft-mistral-v3-all": [
    "adapter_model.safetensors"
  ],
  "tuannm2914/math-lora": [
    "adapter_model.safetensors"
  ],
  "TheBloke/psyonic-cetacean-20B-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mesolitica/mallam-5B-4096": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "zjunlp/knowlm-7b-base": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "davidkim205/komt-mistral-7b-v1-dpo": [
    "adapter_model.safetensors"
  ],
  "Nzute/codegen-350M-mono-python-18k-alpaca": [
    "model.safetensors"
  ],
  "wesley7137/OpenHermes-2.5-neural-chat-7b-v3-1-7B-sharded": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "Qwen/Qwen-72B-Chat": [
    "model-00001-of-00082.safetensors",
    "model-00002-of-00082.safetensors",
    "model-00003-of-00082.safetensors",
    "model-00004-of-00082.safetensors",
    "model-00005-of-00082.safetensors",
    "model-00006-of-00082.safetensors",
    "model-00007-of-00082.safetensors",
    "model-00008-of-00082.safetensors",
    "model-00009-of-00082.safetensors",
    "model-00010-of-00082.safetensors",
    "model-00011-of-00082.safetensors",
    "model-00012-of-00082.safetensors",
    "model-00013-of-00082.safetensors",
    "model-00014-of-00082.safetensors",
    "model-00015-of-00082.safetensors",
    "model-00016-of-00082.safetensors",
    "model-00017-of-00082.safetensors",
    "model-00018-of-00082.safetensors",
    "model-00019-of-00082.safetensors",
    "model-00020-of-00082.safetensors",
    "model-00021-of-00082.safetensors",
    "model-00022-of-00082.safetensors",
    "model-00023-of-00082.safetensors",
    "model-00024-of-00082.safetensors",
    "model-00025-of-00082.safetensors",
    "model-00026-of-00082.safetensors",
    "model-00027-of-00082.safetensors",
    "model-00028-of-00082.safetensors",
    "model-00029-of-00082.safetensors",
    "model-00030-of-00082.safetensors",
    "model-00031-of-00082.safetensors",
    "model-00032-of-00082.safetensors",
    "model-00033-of-00082.safetensors",
    "model-00034-of-00082.safetensors",
    "model-00035-of-00082.safetensors",
    "model-00036-of-00082.safetensors",
    "model-00037-of-00082.safetensors",
    "model-00038-of-00082.safetensors",
    "model-00039-of-00082.safetensors",
    "model-00040-of-00082.safetensors",
    "model-00041-of-00082.safetensors",
    "model-00042-of-00082.safetensors",
    "model-00043-of-00082.safetensors",
    "model-00044-of-00082.safetensors",
    "model-00045-of-00082.safetensors",
    "model-00046-of-00082.safetensors",
    "model-00047-of-00082.safetensors",
    "model-00048-of-00082.safetensors",
    "model-00049-of-00082.safetensors",
    "model-00050-of-00082.safetensors",
    "model-00051-of-00082.safetensors",
    "model-00052-of-00082.safetensors",
    "model-00053-of-00082.safetensors",
    "model-00054-of-00082.safetensors",
    "model-00055-of-00082.safetensors",
    "model-00056-of-00082.safetensors",
    "model-00057-of-00082.safetensors",
    "model-00058-of-00082.safetensors",
    "model-00059-of-00082.safetensors",
    "model-00060-of-00082.safetensors",
    "model-00061-of-00082.safetensors",
    "model-00062-of-00082.safetensors",
    "model-00063-of-00082.safetensors",
    "model-00064-of-00082.safetensors",
    "model-00065-of-00082.safetensors",
    "model-00066-of-00082.safetensors",
    "model-00067-of-00082.safetensors",
    "model-00068-of-00082.safetensors",
    "model-00069-of-00082.safetensors",
    "model-00070-of-00082.safetensors",
    "model-00071-of-00082.safetensors",
    "model-00072-of-00082.safetensors",
    "model-00073-of-00082.safetensors",
    "model-00074-of-00082.safetensors",
    "model-00075-of-00082.safetensors",
    "model-00076-of-00082.safetensors",
    "model-00077-of-00082.safetensors",
    "model-00078-of-00082.safetensors",
    "model-00079-of-00082.safetensors",
    "model-00080-of-00082.safetensors",
    "model-00081-of-00082.safetensors",
    "model-00082-of-00082.safetensors"
  ],
  "harsharora/gpt2_finetuned": [
    "model.safetensors"
  ],
  "yrch18/finetuned_santa_test": [
    "model.safetensors"
  ],
  "En-2863/opt-125m": [
    "model.safetensors"
  ],
  "Minirecord/Mini_DPO_7b_01": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Puluming/AISquare-Instruct-llama2-koen-13b-v0.9.2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "sronger/ko-llm-llama-2-7b-chat3": [
    "model.safetensors"
  ],
  "WebraftAI/synapsellm-7b-mistral-v0.3-preview": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "nijoow/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": [
    "model.safetensors"
  ],
  "Jarnails1559/Sikhism-gpt2": [
    "model.safetensors"
  ],
  "Mlxa/tuned-flat-flat_shuffle": [
    "model.safetensors"
  ],
  "bumblebee-testing/tiny-random-LlamaForCausalLM": [
    "model.safetensors"
  ],
  "Q-bert/outputs": [
    "model.safetensors"
  ],
  "oliverjthomas2000/panther-alpha-tau": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "zjunlp/knowlm-7b-chat": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "BangorAI/mistral-7b-cy-tokenizer-train-6": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "sronger/ko-llm-llama-2-7b-LoRA-IA3": [
    "model.safetensors"
  ],
  "LoneStriker/psyonic-cetacean-20B-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "JLauridsenOrg/StorytellingForKids": [
    "adapter_model.safetensors",
    "checkpoint-1338/adapter_model.safetensors"
  ],
  "nijoow/nijoow": [
    "model.safetensors"
  ],
  "herrkobold/em_german_7b_leo-8bit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Q-bert/xglm-try": [
    "model.safetensors"
  ],
  "TheBloke/Open-Hermes-2.5-neural-chat-3.1-frankenmerge-11b-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/psyonic-cetacean-20B-GPTQ": [
    "model.safetensors"
  ],
  "sronger/ko-llm-llama-2-7b-LoRA": [
    "model.safetensors"
  ],
  "mlabonne/NeuralHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "alexkoo300/burgundy-puma": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/SauerkrautLM-7B-HerO-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/tigerbot-70B-chat-v2-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "mooneyko/salmonn_vicuna_7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/psyonic-cetacean-20B-4.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "TheBloke/deepseek-llm-67b-chat-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/deepseek-llm-67b-chat-GPTQ": [
    "model.safetensors"
  ],
  "ErnestBeckham/phi-1_5-new-summarizer": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Mlxa/tuned-flat_shuffle-flat": [
    "model.safetensors"
  ],
  "LoneStriker/psyonic-cetacean-20B-4.65bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "TheBloke/Iambe-20B-DARE-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/psyonic-cetacean-20B-5.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/psyonic-cetacean-20B-6.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "CrabfishAI/NeXGen-large": [
    "model.safetensors"
  ],
  "umm-maybe/StarCoder-1B-Cthulhu-Mythos": [
    "model.safetensors"
  ],
  "LoneStriker/psyonic-cetacean-20B-8.0bpw-h8-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "Jession01/mistralai-eng2ceb-Instruct": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/open-llama-3b-v2-wizard-evol-instuct-v2-196k-AWQ": [
    "model.safetensors"
  ],
  "shleeeee/mistral-ko-7b-tech": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "harryneal/zephyr-beta-attention-sink-pt": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "JNewber/friendagent": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Mlxa/tuned-flat_shuffle-english": [
    "model.safetensors"
  ],
  "tartuNLP/Llammas": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "hllj/sft-mistral-v1-original-data": [
    "adapter_model.safetensors"
  ],
  "SebastianMoncaleano/cammel_model_nov": [
    "model.safetensors"
  ],
  "Mlxa/augmented_stories": [
    "model.safetensors"
  ],
  "fd3v/Raymond-Reddington": [
    "model.safetensors"
  ],
  "unsloth/llama-2-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "KoladeOdunope/mistral-fin": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "briefai/LongShort-Llama-2-7B": [
    "adapter_model.safetensors"
  ],
  "TheBloke/deepseek-llm-7B-base-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/deepseek-llm-67b-base-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/deepseek-llm-67b-base-GPTQ": [
    "model.safetensors"
  ],
  "snombler/schmeat": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "yizhilll/git-base-pokemon": [
    "model.safetensors"
  ],
  "TheBloke/deepseek-llm-7B-chat-AWQ": [
    "model.safetensors"
  ],
  "Broomva/llama-2-7b-spa-guc": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LemTenku/20b": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "briefai/LongShort-Dolly-2-7B": [
    "adapter_model.safetensors"
  ],
  "briefai/LongShort-Falcon-7B": [
    "adapter_model.safetensors"
  ],
  "briefai/LongShort-Mistral-7B": [
    "adapter_model.safetensors"
  ],
  "TheBloke/LLaMA2-13B-Psyfighter2-AWQ": [
    "model.safetensors"
  ],
  "joyfine/vicuna-7b-fine-tuning_twitter_20_16": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoewolfAI/L-GPT_Loewolf_AI": [
    "model.safetensors"
  ],
  "adamo1139/Yi-34B-AEZAKMI-v1": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "Mlxa/tuned-english-flat_shuffle": [
    "model.safetensors"
  ],
  "S4sch/Open-Hermes-2.5-neural-chat-3.1-InterlaceMerge-14b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "benayas/llama-2-7b-snips_v5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Rofoman/GTS-Noromaid-V1.00": [
    "model-00001-of-00017.safetensors",
    "model-00002-of-00017.safetensors",
    "model-00003-of-00017.safetensors",
    "model-00004-of-00017.safetensors",
    "model-00005-of-00017.safetensors",
    "model-00006-of-00017.safetensors",
    "model-00007-of-00017.safetensors",
    "model-00008-of-00017.safetensors",
    "model-00009-of-00017.safetensors",
    "model-00010-of-00017.safetensors",
    "model-00011-of-00017.safetensors",
    "model-00012-of-00017.safetensors",
    "model-00013-of-00017.safetensors",
    "model-00014-of-00017.safetensors",
    "model-00015-of-00017.safetensors",
    "model-00016-of-00017.safetensors",
    "model-00017-of-00017.safetensors"
  ],
  "LemTenku/13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "benayas/llama-2-7b-snips_v6": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "joyfine/vicuna-7b-fine-tuning_twitter_20_32": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Broomva/llama-2-7b-chat-spa-guc": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "IconicAI/NeuralHermes-2.5-Mistral-7B-exl2-5bpw": [
    "output.safetensors"
  ],
  "silviachen46/llama-test-model": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "chloe0x0/spliceGPT_medium": [
    "model.safetensors"
  ],
  "ErnestBeckham/gpt-2-medqa": [
    "model.safetensors"
  ],
  "vrvenkatesh/distilgpt2-finetuned-slangQA": [
    "model.safetensors"
  ],
  "TheBloke/Iambe-20B-DARE-GPTQ": [
    "model.safetensors"
  ],
  "vrvenkatesh/opt-350m-finetuned-slangQA": [
    "model.safetensors"
  ],
  "joyfine/vicuna-7b-fine-tuning_twitter_20_64": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Wayne235f/DialoGPT-small-joshua": [
    "model.safetensors"
  ],
  "TheBloke/NeuralHermes-2.5-Mistral-7B-AWQ": [
    "model.safetensors"
  ],
  "Mariaaaaa/vicuna-7b-fine-tuning_Twitter_20_256": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/deepseek-llm-7B-base-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/deepseek-llm-7B-chat-GPTQ": [
    "model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-indef-naan-1e-3": [
    "model.safetensors"
  ],
  "TheBloke/open-llama-3b-v2-wizard-evol-instuct-v2-196k-GPTQ": [
    "model.safetensors"
  ],
  "LLM360/AmberChat": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "igorvln/dare_gpt2_ddi_byrelation_finetuning_with_rl": [
    "model.safetensors"
  ],
  "Masterjp123/XOrcaSlimWin-13B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "LoneStriker/NeuralHermes-2.5-Mistral-7B-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/NeuralHermes-2.5-Mistral-7B-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "TheBloke/LLaMA2-13B-Psyfighter2-GPTQ": [
    "model.safetensors"
  ],
  "mncai/Pr_Mistral_7B-Sh5k_Wi5k_Ne5k_Ct5k-Lr05_no-sys_Ep4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "CitrusBoy/demo-finetuned-model-DnD": [
    "model.safetensors"
  ],
  "joyfine/vicuna-7b-fine-tuning_twitter_20_128": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/NeuralHermes-2.5-Mistral-7B-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/NeuralHermes-2.5-Mistral-7B-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "FluffyKaeloky/Euryale-Inverted-L2-70B-exl2-6.0bpw": [
    "Euryale-Inverted-L2-70B-exl2-6.0bpw/output-00001-of-00007.safetensors",
    "Euryale-Inverted-L2-70B-exl2-6.0bpw/output-00002-of-00007.safetensors",
    "Euryale-Inverted-L2-70B-exl2-6.0bpw/output-00003-of-00007.safetensors",
    "Euryale-Inverted-L2-70B-exl2-6.0bpw/output-00004-of-00007.safetensors",
    "Euryale-Inverted-L2-70B-exl2-6.0bpw/output-00005-of-00007.safetensors",
    "Euryale-Inverted-L2-70B-exl2-6.0bpw/output-00006-of-00007.safetensors",
    "Euryale-Inverted-L2-70B-exl2-6.0bpw/output-00007-of-00007.safetensors"
  ],
  "LoneStriker/NeuralHermes-2.5-Mistral-7B-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "igorvln/dare_gpt2_semeval2018_byrelation_finetuning_with_rl": [
    "model.safetensors"
  ],
  "01GangaPutraBheeshma/colab_text_generation_FT_opt_on_dolly_UT_V2": [
    "model.safetensors"
  ],
  "relaxml/Llama-2-70b-chat-E8P-2Bit": [
    "model-00001-of-00002.safetensors",
    "model-00001-of-00004.safetensors",
    "model-00002-of-00002.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/NeuralHermes-2.5-Mistral-7B-GPTQ": [
    "model.safetensors"
  ],
  "skhmn/llama-2-short-form-qa": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "relaxml/Llama-2-13b-chat-E8P-2Bit": [
    "model.safetensors"
  ],
  "relaxml/Llama-2-7b-chat-E8P-2Bit": [
    "model.safetensors"
  ],
  "typeof/mistral-60m": [
    "model.safetensors"
  ],
  "TheBloke/SG-Raccoon-Yi-55B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/SG-Raccoon-Yi-55B-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "joyfine/vicuna-7b-fine-tuning_google_20_16": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Drewww/mistral-viggo-finetune": [
    "checkpoint-10/adapter_model.safetensors",
    "checkpoint-100/adapter_model.safetensors",
    "checkpoint-20/adapter_model.safetensors",
    "checkpoint-30/adapter_model.safetensors",
    "checkpoint-40/adapter_model.safetensors",
    "checkpoint-50/adapter_model.safetensors",
    "checkpoint-60/adapter_model.safetensors",
    "checkpoint-70/adapter_model.safetensors",
    "checkpoint-80/adapter_model.safetensors",
    "checkpoint-90/adapter_model.safetensors"
  ],
  "project2you/1_0_thai_llm2-gpt": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sronger/mistral-lora-IA3": [
    "model.safetensors"
  ],
  "Qwen/Qwen-1_8B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Qwen/Qwen-1_8B-Chat": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Qwen/Qwen-1_8B-Chat-Int8": [
    "model.safetensors"
  ],
  "Qwen/Qwen-1_8B-Chat-Int4": [
    "model.safetensors"
  ],
  "beomi/Yi-Ko-6B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "David-Xu/Mistral-7B-Instruct-v0.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "benayas/llama-2-7b-snips_v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Qwen/Qwen-72B-Chat-Int4": [
    "model-00001-of-00021.safetensors",
    "model-00002-of-00021.safetensors",
    "model-00003-of-00021.safetensors",
    "model-00004-of-00021.safetensors",
    "model-00005-of-00021.safetensors",
    "model-00006-of-00021.safetensors",
    "model-00007-of-00021.safetensors",
    "model-00008-of-00021.safetensors",
    "model-00009-of-00021.safetensors",
    "model-00010-of-00021.safetensors",
    "model-00011-of-00021.safetensors",
    "model-00012-of-00021.safetensors",
    "model-00013-of-00021.safetensors",
    "model-00014-of-00021.safetensors",
    "model-00015-of-00021.safetensors",
    "model-00016-of-00021.safetensors",
    "model-00017-of-00021.safetensors",
    "model-00018-of-00021.safetensors",
    "model-00019-of-00021.safetensors",
    "model-00020-of-00021.safetensors",
    "model-00021-of-00021.safetensors"
  ],
  "Qwen/Qwen-72B-Chat-Int8": [
    "model-00001-of-00039.safetensors",
    "model-00002-of-00039.safetensors",
    "model-00003-of-00039.safetensors",
    "model-00004-of-00039.safetensors",
    "model-00005-of-00039.safetensors",
    "model-00006-of-00039.safetensors",
    "model-00007-of-00039.safetensors",
    "model-00008-of-00039.safetensors",
    "model-00009-of-00039.safetensors",
    "model-00010-of-00039.safetensors",
    "model-00011-of-00039.safetensors",
    "model-00012-of-00039.safetensors",
    "model-00013-of-00039.safetensors",
    "model-00014-of-00039.safetensors",
    "model-00015-of-00039.safetensors",
    "model-00016-of-00039.safetensors",
    "model-00017-of-00039.safetensors",
    "model-00018-of-00039.safetensors",
    "model-00019-of-00039.safetensors",
    "model-00020-of-00039.safetensors",
    "model-00021-of-00039.safetensors",
    "model-00022-of-00039.safetensors",
    "model-00023-of-00039.safetensors",
    "model-00024-of-00039.safetensors",
    "model-00025-of-00039.safetensors",
    "model-00026-of-00039.safetensors",
    "model-00027-of-00039.safetensors",
    "model-00028-of-00039.safetensors",
    "model-00029-of-00039.safetensors",
    "model-00030-of-00039.safetensors",
    "model-00031-of-00039.safetensors",
    "model-00032-of-00039.safetensors",
    "model-00033-of-00039.safetensors",
    "model-00034-of-00039.safetensors",
    "model-00035-of-00039.safetensors",
    "model-00036-of-00039.safetensors",
    "model-00037-of-00039.safetensors",
    "model-00038-of-00039.safetensors",
    "model-00039-of-00039.safetensors"
  ],
  "FluffyKaeloky/Sao10KStheno-v2-Delta-exl2-3.5bpw": [
    "output.safetensors"
  ],
  "OpenBuddy/openbuddy-llama2-13b64k-v15": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "sronger/mistral-ko-llm": [
    "model.safetensors"
  ],
  "Quuinn/zephyr-7b-dpo-lora": [
    "adapter_model.safetensors"
  ],
  "maywell/Synatra-42dot-1.3B": [
    "model.safetensors"
  ],
  "Quuinn/zephyr-7b-sft-lora": [
    "adapter_model.safetensors"
  ],
  "Broomva/llama-2-7b-translate-spa-guc": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Minirecord/Mini_DPO_test02": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/tigerbot-70B-chat-v2-GPTQ": [
    "model.safetensors"
  ],
  "ddh0/OrcaMaid-13b": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "vivid-studios/step.one-mistral-7b": [
    "adapter_model.safetensors",
    "checkpoint-331/adapter_model.safetensors",
    "checkpoint-371/adapter_model.safetensors"
  ],
  "MarkrAI/DopeorNope-maestro-v3-DPO-13b": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "dohun0714/llama": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "crisp-im/mirage-openchat-3.5-answer-v0.2-awq": [
    "model.safetensors"
  ],
  "VitreousCut/NeuralTinyLlama-1.1B-Chat-v0.6": [
    "model.safetensors"
  ],
  "athirdpath/Baubo-11b-FAILURE-WITH-EXPLANATION": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "amphora/model_resize_test": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "doubledsbv/kafkalm-leo_llama2_13b_v0.5_8k": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "waldie/Chronomaid-Storytelling-13b-8bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "mhenrichsen/context-aware-splitter-mistral-eng": [
    "checkpoint-115/adapter_model.safetensors"
  ],
  "Qwen/Qwen-Audio": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "saiyer/test-outputs": [
    "model.safetensors"
  ],
  "hllj/sft-mistral-v2-clean-valid": [
    "adapter_model.safetensors"
  ],
  "Qwen/Qwen-Audio-Chat": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "KoladeOdunope/mistral-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Mlxa/tuned-nested-english": [
    "model.safetensors"
  ],
  "WebraftAI/synapsellm-7b-mistral-v0.4-preview": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Chronomaid-Storytelling-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Chronomaid-Storytelling-13B-AWQ": [
    "model.safetensors"
  ],
  "waldie/Iambe-20b-DARE-6bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "WebraftAI/synapsellm-7b-mistral-v0.4-preview2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Bronya-Rand/Inairtra-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mhenrichsen/context-aware-splitter-1b-english": [
    "checkpoint-29/model.safetensors",
    "checkpoint-59/model.safetensors",
    "checkpoint-87/model.safetensors"
  ],
  "harryneal/zephyr-beta-attention-sink-sink4-win4092": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "elderberry17/llama-2-7b-edu-itmo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "inswave/AISquare-Instruct-llama2-koen-13b-v0.9.3": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "gizmo-ai/OpenHermes-2.5-neural-chat-7B-v3-1-7B-AWQ": [
    "model.safetensors"
  ],
  "Mlxa/tuned-flat-english": [
    "model.safetensors"
  ],
  "YH0912/distilgpt2-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "inswave/AISquare-Instruct-llama2-koen-13b-v0.9.4": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "phatjk/vietcuna-7b-v3-AWQ": [
    "model.safetensors"
  ],
  "HumanF-MarkrAI/Yi-DPO-v1-34B": [
    "model-00001-of-00031.safetensors",
    "model-00002-of-00031.safetensors",
    "model-00003-of-00031.safetensors",
    "model-00004-of-00031.safetensors",
    "model-00005-of-00031.safetensors",
    "model-00006-of-00031.safetensors",
    "model-00007-of-00031.safetensors",
    "model-00008-of-00031.safetensors",
    "model-00009-of-00031.safetensors",
    "model-00010-of-00031.safetensors",
    "model-00011-of-00031.safetensors",
    "model-00012-of-00031.safetensors",
    "model-00013-of-00031.safetensors",
    "model-00014-of-00031.safetensors",
    "model-00015-of-00031.safetensors",
    "model-00016-of-00031.safetensors",
    "model-00017-of-00031.safetensors",
    "model-00018-of-00031.safetensors",
    "model-00019-of-00031.safetensors",
    "model-00020-of-00031.safetensors",
    "model-00021-of-00031.safetensors",
    "model-00022-of-00031.safetensors",
    "model-00023-of-00031.safetensors",
    "model-00024-of-00031.safetensors",
    "model-00025-of-00031.safetensors",
    "model-00026-of-00031.safetensors",
    "model-00027-of-00031.safetensors",
    "model-00028-of-00031.safetensors",
    "model-00029-of-00031.safetensors",
    "model-00030-of-00031.safetensors",
    "model-00031-of-00031.safetensors"
  ],
  "inswave/AISquare-Instruct-llama2-koen-13b-v0.9.5": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "crodri/bloom1.3_meteo": [
    "model.safetensors"
  ],
  "mdhruv005/DialoGPT-small-Rick": [
    "model.safetensors"
  ],
  "arnavgrg/llama-2-7b-nf4-fp16-upscaled": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "arnavgrg/llama-2-7b-chat-nf4-fp16-upscaled": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/SG-Raccoon-Yi-55B-2.4bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/SG-Raccoon-Yi-55B-3.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "sudhir2016/OPT": [
    "model.safetensors"
  ],
  "mdelmas/BioGPT-Large-Natural-Products-RE-Diversity-1000-synt-v1.1": [
    "adapter_model.safetensors"
  ],
  "dhnanjay/DJ-NeuralHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Broomva/llama-2-7b-chat-translate-spa-guc": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "snombler/big-schmeat": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "radlab/polish-gpt2-small-v2": [
    "model.safetensors"
  ],
  "radlab/polish-gpt2-medium-v2": [
    "model.safetensors"
  ],
  "TheBloke/meditron-70B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/meditron-70B-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TIGER-Lab/TIGERScore-Yi-6B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "benayas/llama-2-7b-atis_v3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "deepnight-research/saily_100b": [
    "model-00001-of-00024.safetensors",
    "model-00002-of-00024.safetensors",
    "model-00003-of-00024.safetensors",
    "model-00004-of-00024.safetensors",
    "model-00005-of-00024.safetensors",
    "model-00006-of-00024.safetensors",
    "model-00007-of-00024.safetensors",
    "model-00008-of-00024.safetensors",
    "model-00009-of-00024.safetensors",
    "model-00010-of-00024.safetensors",
    "model-00011-of-00024.safetensors",
    "model-00012-of-00024.safetensors",
    "model-00013-of-00024.safetensors",
    "model-00014-of-00024.safetensors",
    "model-00015-of-00024.safetensors",
    "model-00016-of-00024.safetensors",
    "model-00017-of-00024.safetensors",
    "model-00018-of-00024.safetensors",
    "model-00019-of-00024.safetensors",
    "model-00020-of-00024.safetensors",
    "model-00021-of-00024.safetensors",
    "model-00022-of-00024.safetensors",
    "model-00023-of-00024.safetensors",
    "model-00024-of-00024.safetensors"
  ],
  "wisdomfunction/GPT-Guide": [
    "model.safetensors"
  ],
  "Shayawn/codeparrot-ds": [
    "model.safetensors"
  ],
  "Frrrrrrrrank/Llama-2-7b-chat-hf-process_engineering_one_firsttwokap_v3": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "athirdpath/BigLlama-20b-v1.1": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "typeof/mistral-7b-chatml": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "4bit/Qwen-Audio-Chat": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "joyfine/vicuna-7b-fine-tuning_google_20_32": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "snombler/bigger-schmeat": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Ehraim/SequentialLearner": [
    "adapter_model.safetensors"
  ],
  "LoneStriker/SG-Raccoon-Yi-55B-4.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "LoneStriker/SG-Raccoon-Yi-55B-4.65bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "farnooshazour/tinystarcoder-rlhf-model": [
    "model.safetensors"
  ],
  "athirdpath/CleverGirl-20b-Blended-v1.1-DARE": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "athirdpath/Iambe-20b-DARE-v2": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "TheBloke/SlimOrca-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/SlimOrca-13B-AWQ": [
    "model.safetensors"
  ],
  "LoneStriker/SG-Raccoon-Yi-55B-5.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "joyfine/vicuna-7b-fine-tuning_google_20_64": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "devvanshhh/mistral-gen2": [
    "adapter_model.safetensors"
  ],
  "TheBloke/meditron-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/meditron-7B-AWQ": [
    "model.safetensors"
  ],
  "PMrtn/llama-2-7b-hf-QLoRA_PrefixTune": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "xihajun/cnn_10k_0.001_30_16_32_0.1_0.01_add_10k_fix_20epoch_eos_0.001": [
    "binary/model-00001-of-00003.safetensors",
    "binary/model-00002-of-00003.safetensors",
    "binary/model-00003-of-00003.safetensors"
  ],
  "LoneStriker/SG-Raccoon-Yi-55B-6.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "mb-nf/llama-2-7b-ft002": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "aisuko/demo_eli5_clm_model": [
    "model.safetensors"
  ],
  "jondurbin/cinematika-7b-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "trishah/llama-2-7b-hf": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "typeof/neuralhermes-sharded": [
    "model-00001-of-00291.safetensors",
    "model-00002-of-00291.safetensors",
    "model-00003-of-00291.safetensors",
    "model-00004-of-00291.safetensors",
    "model-00005-of-00291.safetensors",
    "model-00006-of-00291.safetensors",
    "model-00007-of-00291.safetensors",
    "model-00008-of-00291.safetensors",
    "model-00009-of-00291.safetensors",
    "model-00010-of-00291.safetensors",
    "model-00011-of-00291.safetensors",
    "model-00012-of-00291.safetensors",
    "model-00013-of-00291.safetensors",
    "model-00014-of-00291.safetensors",
    "model-00015-of-00291.safetensors",
    "model-00016-of-00291.safetensors",
    "model-00017-of-00291.safetensors",
    "model-00018-of-00291.safetensors",
    "model-00019-of-00291.safetensors",
    "model-00020-of-00291.safetensors",
    "model-00021-of-00291.safetensors",
    "model-00022-of-00291.safetensors",
    "model-00023-of-00291.safetensors",
    "model-00024-of-00291.safetensors",
    "model-00025-of-00291.safetensors",
    "model-00026-of-00291.safetensors",
    "model-00027-of-00291.safetensors",
    "model-00028-of-00291.safetensors",
    "model-00029-of-00291.safetensors",
    "model-00030-of-00291.safetensors",
    "model-00031-of-00291.safetensors",
    "model-00032-of-00291.safetensors",
    "model-00033-of-00291.safetensors",
    "model-00034-of-00291.safetensors",
    "model-00035-of-00291.safetensors",
    "model-00036-of-00291.safetensors",
    "model-00037-of-00291.safetensors",
    "model-00038-of-00291.safetensors",
    "model-00039-of-00291.safetensors",
    "model-00040-of-00291.safetensors",
    "model-00041-of-00291.safetensors",
    "model-00042-of-00291.safetensors",
    "model-00043-of-00291.safetensors",
    "model-00044-of-00291.safetensors",
    "model-00045-of-00291.safetensors",
    "model-00046-of-00291.safetensors",
    "model-00047-of-00291.safetensors",
    "model-00048-of-00291.safetensors",
    "model-00049-of-00291.safetensors",
    "model-00050-of-00291.safetensors",
    "model-00051-of-00291.safetensors",
    "model-00052-of-00291.safetensors",
    "model-00053-of-00291.safetensors",
    "model-00054-of-00291.safetensors",
    "model-00055-of-00291.safetensors",
    "model-00056-of-00291.safetensors",
    "model-00057-of-00291.safetensors",
    "model-00058-of-00291.safetensors",
    "model-00059-of-00291.safetensors",
    "model-00060-of-00291.safetensors",
    "model-00061-of-00291.safetensors",
    "model-00062-of-00291.safetensors",
    "model-00063-of-00291.safetensors",
    "model-00064-of-00291.safetensors",
    "model-00065-of-00291.safetensors",
    "model-00066-of-00291.safetensors",
    "model-00067-of-00291.safetensors",
    "model-00068-of-00291.safetensors",
    "model-00069-of-00291.safetensors",
    "model-00070-of-00291.safetensors",
    "model-00071-of-00291.safetensors",
    "model-00072-of-00291.safetensors",
    "model-00073-of-00291.safetensors",
    "model-00074-of-00291.safetensors",
    "model-00075-of-00291.safetensors",
    "model-00076-of-00291.safetensors",
    "model-00077-of-00291.safetensors",
    "model-00078-of-00291.safetensors",
    "model-00079-of-00291.safetensors",
    "model-00080-of-00291.safetensors",
    "model-00081-of-00291.safetensors",
    "model-00082-of-00291.safetensors",
    "model-00083-of-00291.safetensors",
    "model-00084-of-00291.safetensors",
    "model-00085-of-00291.safetensors",
    "model-00086-of-00291.safetensors",
    "model-00087-of-00291.safetensors",
    "model-00088-of-00291.safetensors",
    "model-00089-of-00291.safetensors",
    "model-00090-of-00291.safetensors",
    "model-00091-of-00291.safetensors",
    "model-00092-of-00291.safetensors",
    "model-00093-of-00291.safetensors",
    "model-00094-of-00291.safetensors",
    "model-00095-of-00291.safetensors",
    "model-00096-of-00291.safetensors",
    "model-00097-of-00291.safetensors",
    "model-00098-of-00291.safetensors",
    "model-00099-of-00291.safetensors",
    "model-00100-of-00291.safetensors",
    "model-00101-of-00291.safetensors",
    "model-00102-of-00291.safetensors",
    "model-00103-of-00291.safetensors",
    "model-00104-of-00291.safetensors",
    "model-00105-of-00291.safetensors",
    "model-00106-of-00291.safetensors",
    "model-00107-of-00291.safetensors",
    "model-00108-of-00291.safetensors",
    "model-00109-of-00291.safetensors",
    "model-00110-of-00291.safetensors",
    "model-00111-of-00291.safetensors",
    "model-00112-of-00291.safetensors",
    "model-00113-of-00291.safetensors",
    "model-00114-of-00291.safetensors",
    "model-00115-of-00291.safetensors",
    "model-00116-of-00291.safetensors",
    "model-00117-of-00291.safetensors",
    "model-00118-of-00291.safetensors",
    "model-00119-of-00291.safetensors",
    "model-00120-of-00291.safetensors",
    "model-00121-of-00291.safetensors",
    "model-00122-of-00291.safetensors",
    "model-00123-of-00291.safetensors",
    "model-00124-of-00291.safetensors",
    "model-00125-of-00291.safetensors",
    "model-00126-of-00291.safetensors",
    "model-00127-of-00291.safetensors",
    "model-00128-of-00291.safetensors",
    "model-00129-of-00291.safetensors",
    "model-00130-of-00291.safetensors",
    "model-00131-of-00291.safetensors",
    "model-00132-of-00291.safetensors",
    "model-00133-of-00291.safetensors",
    "model-00134-of-00291.safetensors",
    "model-00135-of-00291.safetensors",
    "model-00136-of-00291.safetensors",
    "model-00137-of-00291.safetensors",
    "model-00138-of-00291.safetensors",
    "model-00139-of-00291.safetensors",
    "model-00140-of-00291.safetensors",
    "model-00141-of-00291.safetensors",
    "model-00142-of-00291.safetensors",
    "model-00143-of-00291.safetensors",
    "model-00144-of-00291.safetensors",
    "model-00145-of-00291.safetensors",
    "model-00146-of-00291.safetensors",
    "model-00147-of-00291.safetensors",
    "model-00148-of-00291.safetensors",
    "model-00149-of-00291.safetensors",
    "model-00150-of-00291.safetensors",
    "model-00151-of-00291.safetensors",
    "model-00152-of-00291.safetensors",
    "model-00153-of-00291.safetensors",
    "model-00154-of-00291.safetensors",
    "model-00155-of-00291.safetensors",
    "model-00156-of-00291.safetensors",
    "model-00157-of-00291.safetensors",
    "model-00158-of-00291.safetensors",
    "model-00159-of-00291.safetensors",
    "model-00160-of-00291.safetensors",
    "model-00161-of-00291.safetensors",
    "model-00162-of-00291.safetensors",
    "model-00163-of-00291.safetensors",
    "model-00164-of-00291.safetensors",
    "model-00165-of-00291.safetensors",
    "model-00166-of-00291.safetensors",
    "model-00167-of-00291.safetensors",
    "model-00168-of-00291.safetensors",
    "model-00169-of-00291.safetensors",
    "model-00170-of-00291.safetensors",
    "model-00171-of-00291.safetensors",
    "model-00172-of-00291.safetensors",
    "model-00173-of-00291.safetensors",
    "model-00174-of-00291.safetensors",
    "model-00175-of-00291.safetensors",
    "model-00176-of-00291.safetensors",
    "model-00177-of-00291.safetensors",
    "model-00178-of-00291.safetensors",
    "model-00179-of-00291.safetensors",
    "model-00180-of-00291.safetensors",
    "model-00181-of-00291.safetensors",
    "model-00182-of-00291.safetensors",
    "model-00183-of-00291.safetensors",
    "model-00184-of-00291.safetensors",
    "model-00185-of-00291.safetensors",
    "model-00186-of-00291.safetensors",
    "model-00187-of-00291.safetensors",
    "model-00188-of-00291.safetensors",
    "model-00189-of-00291.safetensors",
    "model-00190-of-00291.safetensors",
    "model-00191-of-00291.safetensors",
    "model-00192-of-00291.safetensors",
    "model-00193-of-00291.safetensors",
    "model-00194-of-00291.safetensors",
    "model-00195-of-00291.safetensors",
    "model-00196-of-00291.safetensors",
    "model-00197-of-00291.safetensors",
    "model-00198-of-00291.safetensors",
    "model-00199-of-00291.safetensors",
    "model-00200-of-00291.safetensors",
    "model-00201-of-00291.safetensors",
    "model-00202-of-00291.safetensors",
    "model-00203-of-00291.safetensors",
    "model-00204-of-00291.safetensors",
    "model-00205-of-00291.safetensors",
    "model-00206-of-00291.safetensors",
    "model-00207-of-00291.safetensors",
    "model-00208-of-00291.safetensors",
    "model-00209-of-00291.safetensors",
    "model-00210-of-00291.safetensors",
    "model-00211-of-00291.safetensors",
    "model-00212-of-00291.safetensors",
    "model-00213-of-00291.safetensors",
    "model-00214-of-00291.safetensors",
    "model-00215-of-00291.safetensors",
    "model-00216-of-00291.safetensors",
    "model-00217-of-00291.safetensors",
    "model-00218-of-00291.safetensors",
    "model-00219-of-00291.safetensors",
    "model-00220-of-00291.safetensors",
    "model-00221-of-00291.safetensors",
    "model-00222-of-00291.safetensors",
    "model-00223-of-00291.safetensors",
    "model-00224-of-00291.safetensors",
    "model-00225-of-00291.safetensors",
    "model-00226-of-00291.safetensors",
    "model-00227-of-00291.safetensors",
    "model-00228-of-00291.safetensors",
    "model-00229-of-00291.safetensors",
    "model-00230-of-00291.safetensors",
    "model-00231-of-00291.safetensors",
    "model-00232-of-00291.safetensors",
    "model-00233-of-00291.safetensors",
    "model-00234-of-00291.safetensors",
    "model-00235-of-00291.safetensors",
    "model-00236-of-00291.safetensors",
    "model-00237-of-00291.safetensors",
    "model-00238-of-00291.safetensors",
    "model-00239-of-00291.safetensors",
    "model-00240-of-00291.safetensors",
    "model-00241-of-00291.safetensors",
    "model-00242-of-00291.safetensors",
    "model-00243-of-00291.safetensors",
    "model-00244-of-00291.safetensors",
    "model-00245-of-00291.safetensors",
    "model-00246-of-00291.safetensors",
    "model-00247-of-00291.safetensors",
    "model-00248-of-00291.safetensors",
    "model-00249-of-00291.safetensors",
    "model-00250-of-00291.safetensors",
    "model-00251-of-00291.safetensors",
    "model-00252-of-00291.safetensors",
    "model-00253-of-00291.safetensors",
    "model-00254-of-00291.safetensors",
    "model-00255-of-00291.safetensors",
    "model-00256-of-00291.safetensors",
    "model-00257-of-00291.safetensors",
    "model-00258-of-00291.safetensors",
    "model-00259-of-00291.safetensors",
    "model-00260-of-00291.safetensors",
    "model-00261-of-00291.safetensors",
    "model-00262-of-00291.safetensors",
    "model-00263-of-00291.safetensors",
    "model-00264-of-00291.safetensors",
    "model-00265-of-00291.safetensors",
    "model-00266-of-00291.safetensors",
    "model-00267-of-00291.safetensors",
    "model-00268-of-00291.safetensors",
    "model-00269-of-00291.safetensors",
    "model-00270-of-00291.safetensors",
    "model-00271-of-00291.safetensors",
    "model-00272-of-00291.safetensors",
    "model-00273-of-00291.safetensors",
    "model-00274-of-00291.safetensors",
    "model-00275-of-00291.safetensors",
    "model-00276-of-00291.safetensors",
    "model-00277-of-00291.safetensors",
    "model-00278-of-00291.safetensors",
    "model-00279-of-00291.safetensors",
    "model-00280-of-00291.safetensors",
    "model-00281-of-00291.safetensors",
    "model-00282-of-00291.safetensors",
    "model-00283-of-00291.safetensors",
    "model-00284-of-00291.safetensors",
    "model-00285-of-00291.safetensors",
    "model-00286-of-00291.safetensors",
    "model-00287-of-00291.safetensors",
    "model-00288-of-00291.safetensors",
    "model-00289-of-00291.safetensors",
    "model-00290-of-00291.safetensors",
    "model-00291-of-00291.safetensors"
  ],
  "LoneStriker/SG-Raccoon-Yi-55B-2.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "mrfakename/NeuralOrca-7B-v1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "typeof/mistral-7b": [
    "model-00001-of-00291.safetensors",
    "model-00002-of-00291.safetensors",
    "model-00003-of-00291.safetensors",
    "model-00004-of-00291.safetensors",
    "model-00005-of-00291.safetensors",
    "model-00006-of-00291.safetensors",
    "model-00007-of-00291.safetensors",
    "model-00008-of-00291.safetensors",
    "model-00009-of-00291.safetensors",
    "model-00010-of-00291.safetensors",
    "model-00011-of-00291.safetensors",
    "model-00012-of-00291.safetensors",
    "model-00013-of-00291.safetensors",
    "model-00014-of-00291.safetensors",
    "model-00015-of-00291.safetensors",
    "model-00016-of-00291.safetensors",
    "model-00017-of-00291.safetensors",
    "model-00018-of-00291.safetensors",
    "model-00019-of-00291.safetensors",
    "model-00020-of-00291.safetensors",
    "model-00021-of-00291.safetensors",
    "model-00022-of-00291.safetensors",
    "model-00023-of-00291.safetensors",
    "model-00024-of-00291.safetensors",
    "model-00025-of-00291.safetensors",
    "model-00026-of-00291.safetensors",
    "model-00027-of-00291.safetensors",
    "model-00028-of-00291.safetensors",
    "model-00029-of-00291.safetensors",
    "model-00030-of-00291.safetensors",
    "model-00031-of-00291.safetensors",
    "model-00032-of-00291.safetensors",
    "model-00033-of-00291.safetensors",
    "model-00034-of-00291.safetensors",
    "model-00035-of-00291.safetensors",
    "model-00036-of-00291.safetensors",
    "model-00037-of-00291.safetensors",
    "model-00038-of-00291.safetensors",
    "model-00039-of-00291.safetensors",
    "model-00040-of-00291.safetensors",
    "model-00041-of-00291.safetensors",
    "model-00042-of-00291.safetensors",
    "model-00043-of-00291.safetensors",
    "model-00044-of-00291.safetensors",
    "model-00045-of-00291.safetensors",
    "model-00046-of-00291.safetensors",
    "model-00047-of-00291.safetensors",
    "model-00048-of-00291.safetensors",
    "model-00049-of-00291.safetensors",
    "model-00050-of-00291.safetensors",
    "model-00051-of-00291.safetensors",
    "model-00052-of-00291.safetensors",
    "model-00053-of-00291.safetensors",
    "model-00054-of-00291.safetensors",
    "model-00055-of-00291.safetensors",
    "model-00056-of-00291.safetensors",
    "model-00057-of-00291.safetensors",
    "model-00058-of-00291.safetensors",
    "model-00059-of-00291.safetensors",
    "model-00060-of-00291.safetensors",
    "model-00061-of-00291.safetensors",
    "model-00062-of-00291.safetensors",
    "model-00063-of-00291.safetensors",
    "model-00064-of-00291.safetensors",
    "model-00065-of-00291.safetensors",
    "model-00066-of-00291.safetensors",
    "model-00067-of-00291.safetensors",
    "model-00068-of-00291.safetensors",
    "model-00069-of-00291.safetensors",
    "model-00070-of-00291.safetensors",
    "model-00071-of-00291.safetensors",
    "model-00072-of-00291.safetensors",
    "model-00073-of-00291.safetensors",
    "model-00074-of-00291.safetensors",
    "model-00075-of-00291.safetensors",
    "model-00076-of-00291.safetensors",
    "model-00077-of-00291.safetensors",
    "model-00078-of-00291.safetensors",
    "model-00079-of-00291.safetensors",
    "model-00080-of-00291.safetensors",
    "model-00081-of-00291.safetensors",
    "model-00082-of-00291.safetensors",
    "model-00083-of-00291.safetensors",
    "model-00084-of-00291.safetensors",
    "model-00085-of-00291.safetensors",
    "model-00086-of-00291.safetensors",
    "model-00087-of-00291.safetensors",
    "model-00088-of-00291.safetensors",
    "model-00089-of-00291.safetensors",
    "model-00090-of-00291.safetensors",
    "model-00091-of-00291.safetensors",
    "model-00092-of-00291.safetensors",
    "model-00093-of-00291.safetensors",
    "model-00094-of-00291.safetensors",
    "model-00095-of-00291.safetensors",
    "model-00096-of-00291.safetensors",
    "model-00097-of-00291.safetensors",
    "model-00098-of-00291.safetensors",
    "model-00099-of-00291.safetensors",
    "model-00100-of-00291.safetensors",
    "model-00101-of-00291.safetensors",
    "model-00102-of-00291.safetensors",
    "model-00103-of-00291.safetensors",
    "model-00104-of-00291.safetensors",
    "model-00105-of-00291.safetensors",
    "model-00106-of-00291.safetensors",
    "model-00107-of-00291.safetensors",
    "model-00108-of-00291.safetensors",
    "model-00109-of-00291.safetensors",
    "model-00110-of-00291.safetensors",
    "model-00111-of-00291.safetensors",
    "model-00112-of-00291.safetensors",
    "model-00113-of-00291.safetensors",
    "model-00114-of-00291.safetensors",
    "model-00115-of-00291.safetensors",
    "model-00116-of-00291.safetensors",
    "model-00117-of-00291.safetensors",
    "model-00118-of-00291.safetensors",
    "model-00119-of-00291.safetensors",
    "model-00120-of-00291.safetensors",
    "model-00121-of-00291.safetensors",
    "model-00122-of-00291.safetensors",
    "model-00123-of-00291.safetensors",
    "model-00124-of-00291.safetensors",
    "model-00125-of-00291.safetensors",
    "model-00126-of-00291.safetensors",
    "model-00127-of-00291.safetensors",
    "model-00128-of-00291.safetensors",
    "model-00129-of-00291.safetensors",
    "model-00130-of-00291.safetensors",
    "model-00131-of-00291.safetensors",
    "model-00132-of-00291.safetensors",
    "model-00133-of-00291.safetensors",
    "model-00134-of-00291.safetensors",
    "model-00135-of-00291.safetensors",
    "model-00136-of-00291.safetensors",
    "model-00137-of-00291.safetensors",
    "model-00138-of-00291.safetensors",
    "model-00139-of-00291.safetensors",
    "model-00140-of-00291.safetensors",
    "model-00141-of-00291.safetensors",
    "model-00142-of-00291.safetensors",
    "model-00143-of-00291.safetensors",
    "model-00144-of-00291.safetensors",
    "model-00145-of-00291.safetensors",
    "model-00146-of-00291.safetensors",
    "model-00147-of-00291.safetensors",
    "model-00148-of-00291.safetensors",
    "model-00149-of-00291.safetensors",
    "model-00150-of-00291.safetensors",
    "model-00151-of-00291.safetensors",
    "model-00152-of-00291.safetensors",
    "model-00153-of-00291.safetensors",
    "model-00154-of-00291.safetensors",
    "model-00155-of-00291.safetensors",
    "model-00156-of-00291.safetensors",
    "model-00157-of-00291.safetensors",
    "model-00158-of-00291.safetensors",
    "model-00159-of-00291.safetensors",
    "model-00160-of-00291.safetensors",
    "model-00161-of-00291.safetensors",
    "model-00162-of-00291.safetensors",
    "model-00163-of-00291.safetensors",
    "model-00164-of-00291.safetensors",
    "model-00165-of-00291.safetensors",
    "model-00166-of-00291.safetensors",
    "model-00167-of-00291.safetensors",
    "model-00168-of-00291.safetensors",
    "model-00169-of-00291.safetensors",
    "model-00170-of-00291.safetensors",
    "model-00171-of-00291.safetensors",
    "model-00172-of-00291.safetensors",
    "model-00173-of-00291.safetensors",
    "model-00174-of-00291.safetensors",
    "model-00175-of-00291.safetensors",
    "model-00176-of-00291.safetensors",
    "model-00177-of-00291.safetensors",
    "model-00178-of-00291.safetensors",
    "model-00179-of-00291.safetensors",
    "model-00180-of-00291.safetensors",
    "model-00181-of-00291.safetensors",
    "model-00182-of-00291.safetensors",
    "model-00183-of-00291.safetensors",
    "model-00184-of-00291.safetensors",
    "model-00185-of-00291.safetensors",
    "model-00186-of-00291.safetensors",
    "model-00187-of-00291.safetensors",
    "model-00188-of-00291.safetensors",
    "model-00189-of-00291.safetensors",
    "model-00190-of-00291.safetensors",
    "model-00191-of-00291.safetensors",
    "model-00192-of-00291.safetensors",
    "model-00193-of-00291.safetensors",
    "model-00194-of-00291.safetensors",
    "model-00195-of-00291.safetensors",
    "model-00196-of-00291.safetensors",
    "model-00197-of-00291.safetensors",
    "model-00198-of-00291.safetensors",
    "model-00199-of-00291.safetensors",
    "model-00200-of-00291.safetensors",
    "model-00201-of-00291.safetensors",
    "model-00202-of-00291.safetensors",
    "model-00203-of-00291.safetensors",
    "model-00204-of-00291.safetensors",
    "model-00205-of-00291.safetensors",
    "model-00206-of-00291.safetensors",
    "model-00207-of-00291.safetensors",
    "model-00208-of-00291.safetensors",
    "model-00209-of-00291.safetensors",
    "model-00210-of-00291.safetensors",
    "model-00211-of-00291.safetensors",
    "model-00212-of-00291.safetensors",
    "model-00213-of-00291.safetensors",
    "model-00214-of-00291.safetensors",
    "model-00215-of-00291.safetensors",
    "model-00216-of-00291.safetensors",
    "model-00217-of-00291.safetensors",
    "model-00218-of-00291.safetensors",
    "model-00219-of-00291.safetensors",
    "model-00220-of-00291.safetensors",
    "model-00221-of-00291.safetensors",
    "model-00222-of-00291.safetensors",
    "model-00223-of-00291.safetensors",
    "model-00224-of-00291.safetensors",
    "model-00225-of-00291.safetensors",
    "model-00226-of-00291.safetensors",
    "model-00227-of-00291.safetensors",
    "model-00228-of-00291.safetensors",
    "model-00229-of-00291.safetensors",
    "model-00230-of-00291.safetensors",
    "model-00231-of-00291.safetensors",
    "model-00232-of-00291.safetensors",
    "model-00233-of-00291.safetensors",
    "model-00234-of-00291.safetensors",
    "model-00235-of-00291.safetensors",
    "model-00236-of-00291.safetensors",
    "model-00237-of-00291.safetensors",
    "model-00238-of-00291.safetensors",
    "model-00239-of-00291.safetensors",
    "model-00240-of-00291.safetensors",
    "model-00241-of-00291.safetensors",
    "model-00242-of-00291.safetensors",
    "model-00243-of-00291.safetensors",
    "model-00244-of-00291.safetensors",
    "model-00245-of-00291.safetensors",
    "model-00246-of-00291.safetensors",
    "model-00247-of-00291.safetensors",
    "model-00248-of-00291.safetensors",
    "model-00249-of-00291.safetensors",
    "model-00250-of-00291.safetensors",
    "model-00251-of-00291.safetensors",
    "model-00252-of-00291.safetensors",
    "model-00253-of-00291.safetensors",
    "model-00254-of-00291.safetensors",
    "model-00255-of-00291.safetensors",
    "model-00256-of-00291.safetensors",
    "model-00257-of-00291.safetensors",
    "model-00258-of-00291.safetensors",
    "model-00259-of-00291.safetensors",
    "model-00260-of-00291.safetensors",
    "model-00261-of-00291.safetensors",
    "model-00262-of-00291.safetensors",
    "model-00263-of-00291.safetensors",
    "model-00264-of-00291.safetensors",
    "model-00265-of-00291.safetensors",
    "model-00266-of-00291.safetensors",
    "model-00267-of-00291.safetensors",
    "model-00268-of-00291.safetensors",
    "model-00269-of-00291.safetensors",
    "model-00270-of-00291.safetensors",
    "model-00271-of-00291.safetensors",
    "model-00272-of-00291.safetensors",
    "model-00273-of-00291.safetensors",
    "model-00274-of-00291.safetensors",
    "model-00275-of-00291.safetensors",
    "model-00276-of-00291.safetensors",
    "model-00277-of-00291.safetensors",
    "model-00278-of-00291.safetensors",
    "model-00279-of-00291.safetensors",
    "model-00280-of-00291.safetensors",
    "model-00281-of-00291.safetensors",
    "model-00282-of-00291.safetensors",
    "model-00283-of-00291.safetensors",
    "model-00284-of-00291.safetensors",
    "model-00285-of-00291.safetensors",
    "model-00286-of-00291.safetensors",
    "model-00287-of-00291.safetensors",
    "model-00288-of-00291.safetensors",
    "model-00289-of-00291.safetensors",
    "model-00290-of-00291.safetensors",
    "model-00291-of-00291.safetensors"
  ],
  "vrvenkatesh/VarunOPT-finetuned-slangQA": [
    "model.safetensors"
  ],
  "mncai/Pr_Mistral_Instruct_7B-Sh5k_Wi5k_Ne5k_Ct5k-Lr05_no-sys_Ep4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "austin/multimed_model": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "danyoung/finance-qa": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Medilora/guideline-adapter": [
    "adapter_model.safetensors"
  ],
  "NatureUniverse/alpaca-gpt4": [
    "model.safetensors"
  ],
  "Ehraim/SequentialLearnerv2": [
    "adapter_model.safetensors"
  ],
  "chargoddard/Mistral-7B-MHA": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "cgf1986/S-0.2-LLama2-chat-7b-hf-ft16": [
    "model.safetensors"
  ],
  "mogaio/TinyLlama-con-brainstorming-v0.2": [
    "model.safetensors"
  ],
  "mogaio/TinyLlama-con-creative-writing-v0.2": [
    "model.safetensors"
  ],
  "wesley7137/open-llama-3b-v2-mathwiz": [
    "model-00001-of-00003-002.safetensors",
    "model-00002-of-00003-001.safetensors",
    "model-00003-of-00003-003.safetensors"
  ],
  "Perceptron2AI/openchat-finetuned": [
    "adapter_model.safetensors"
  ],
  "wons/tigerbot-13b-test-v0_1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "KnutJaegersberg/CausalLM-Platypus-14B": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "SparseLLM/ReluLLaMA-13B": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "dvijay/mistral-alpaca-qlora": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "joyfine/vicuna-7b-fine-tuning_google_20_128": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "vmajor/Orca2-13B-selfmerge-26B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "wgpubs/zephyr-7b-sft-lora": [
    "adapter_model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-indef-naan-3e-3": [
    "model.safetensors"
  ],
  "benayas/llama-2-7b-banking_v3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "maki198906/codeparrot-ds": [
    "model.safetensors"
  ],
  "huseinzol05/dummy-mistral-191M": [
    "model.safetensors"
  ],
  "shivangx01b/phi-1_5-finetuned-gsm8k": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Pclanglais/Bellay-0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AllanOuii/zephyr-ikomia-chatbot_v3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "chinoll/Yi-6b-200k-dpo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mistralai/Mixtral-8x7B-v0.1": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "yuancj/Mistral-7b-chat-qlora-1101-1": [
    "checkpoint-198/adapter_model.safetensors",
    "checkpoint-396/adapter_model.safetensors"
  ],
  "laitrongduc/zephyr-support-chatbot": [
    "adapter_model.safetensors"
  ],
  "kyujinpy/PlatYi-34B-Q": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "vmajor/Orca2-13B-selfmerge-39B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "PMrtn/falcon-7b-instruct-QLoRA_PrefixTune": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "anshuls235/finetuned-mistral7b-summarizer": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "soyk/open_hermes_cs": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "huseinzol05/dummy-mistral-349M": [
    "model.safetensors"
  ],
  "AllanOuii/zephyr-ikomia-chatbot_v4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rycont/EleutherAI__polyglot-ko-1.3b-awq": [
    "model.safetensors"
  ],
  "qeternity/NeuralHermes-2.5-Mistral-7B-6bpw-exl2": [
    "output.safetensors"
  ],
  "qeternity/NeuralHermes-2.5-Mistral-7B-4.65bpw-exl2": [
    "output.safetensors"
  ],
  "qeternity/NeuralHermes-2.5-Mistral-7B-8bpw-exl2": [
    "output.safetensors"
  ],
  "Weyaxi/neural-chat-7b-v3-1-OpenHermes-2.5-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mayanksony/codellama-7b-instruct-6bit": [
    "model-00002-of-00002.safetensors"
  ],
  "dimad000/gpt2-base-french": [
    "model.safetensors"
  ],
  "dimad000/gpt2-base-french_10": [
    "model.safetensors"
  ],
  "eci-io/climategpt-70b": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "openaccess-ai-collective/dpopenhermes-alpha-v0": [
    "adapter/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "keivalya/SahaAI": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "joyfine/vicuna-7b-fine-tuning_google_20_256": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Nima-nlc/farzan_mental_20k": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "khiepm209/mistral-math-vn": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "inswave/AISquare-Instruct-llama2-koen-13b-v0.9.8": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "inswave/AISquare-Instruct-llama2-koen-13b-v0.9.9": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "evkes/Deloitte-Job-Postings-0": [
    "adapter_model.safetensors",
    "checkpoint-164/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sowmr20/git-base-CocoCaptions": [
    "model.safetensors"
  ],
  "fblgit/una-cybertron-7b-v1-fp16": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kyujinpy/PlatYi-34B-LoRA": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "eci-io/climategpt-13b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "eci-io/climategpt-7b": [
    "model.safetensors"
  ],
  "eci-io/climategpt-7b-fsc": [
    "model.safetensors"
  ],
  "eci-io/climategpt-7b-fsg": [
    "model.safetensors"
  ],
  "ch103/llama-2-7b-miniguanaco": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "relaxml/Llama-2-70b-HI-4Bit-Packed": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "relaxml/Llama-2-13b-HI-4Bit-Packed": [
    "model.safetensors"
  ],
  "relaxml/Llama-2-7b-HI-4Bit-Packed": [
    "model.safetensors"
  ],
  "relaxml/Llama-1-65b-HI-4Bit-Packed": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "LoneStriker/notus-7b-v1-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "joyfine/vicuna-7b-fine-tuning_google_20_512": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "pabligme/Llama_2_13b_DTS_Ensayo4": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/notus-7b-v1-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoewolfAI/L-GPT_Loewolf_AI-PlusUsers": [
    "model.safetensors"
  ],
  "dannoncaffeine/GPT2-124M-wikitext-v0.1": [
    "model.safetensors"
  ],
  "LoneStriker/notus-7b-v1-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "relaxml/Llama-1-30b-HI-4Bit-Packed": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/notus-7b-v1-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "relaxml/Llama-1-13b-HI-4Bit-Packed": [
    "model.safetensors"
  ],
  "LoneStriker/notus-7b-v1-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "relaxml/Llama-1-7b-HI-4Bit-Packed": [
    "model.safetensors"
  ],
  "shalinialisha/ai-for-all": [
    "model.safetensors"
  ],
  "TheBloke/cinematika-7B-v0.1-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/cinematika-7B-v0.1-GPTQ": [
    "model.safetensors"
  ],
  "kaizerBox/retnet-Final-small-summarization": [
    "model.safetensors"
  ],
  "kyujinpy/PlatYi-34B-Llama-Q": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "dim/mistral-open-orca-ru-1700-step": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/juanako-7B-UNA-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/juanako-7B-UNA-AWQ": [
    "model.safetensors"
  ],
  "cgf1986/S-0.4-LLama2-chat-7b-hf-ft16": [
    "model.safetensors"
  ],
  "pszemraj/Yi-6B-200K-Llama-sharded": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "maniack/my_awesome_eli5_clm-model": [
    "model.safetensors"
  ],
  "maniack/abcd": [
    "model.safetensors"
  ],
  "gsomers-smarsh/distilgpt2-emailtype-finetune": [
    "model.safetensors"
  ],
  "relaxml/Llama-2-70b-chat-HI-4Bit-Packed": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "kheopsai/kheops_mistral_v3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "relaxml/Llama-2-13b-chat-HI-4Bit-Packed": [
    "model.safetensors"
  ],
  "relaxml/Llama-2-7b-chat-HI-4Bit-Packed": [
    "model.safetensors"
  ],
  "inswave/AISquare-Instruct-llama2-koen-13b-v0.9.11": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "benayas/llama-2-7b-massive_v3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jwschrader/codeparrot-ds": [
    "model.safetensors"
  ],
  "inswave/AISquare-Instruct-llama2-koen-13b-v0.9.12": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "inswave/AISquare-Instruct-llama2-koen-13b-v0.9.10": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "oieieio/Orca-2-13b-awq": [
    "model.safetensors"
  ],
  "inswave/AISquare-Instruct-llama2-koen-13b-v0.9.13": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "fblgit/una-cybertron-7b-v2-bf16": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "athirdpath/BigMistral-11b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SparseLLM/ReluLLaMA-70B": [
    "model-00001-of-00061.safetensors",
    "model-00002-of-00061.safetensors",
    "model-00003-of-00061.safetensors",
    "model-00004-of-00061.safetensors",
    "model-00005-of-00061.safetensors",
    "model-00006-of-00061.safetensors",
    "model-00007-of-00061.safetensors",
    "model-00008-of-00061.safetensors",
    "model-00009-of-00061.safetensors",
    "model-00010-of-00061.safetensors",
    "model-00011-of-00061.safetensors",
    "model-00012-of-00061.safetensors",
    "model-00013-of-00061.safetensors",
    "model-00014-of-00061.safetensors",
    "model-00015-of-00061.safetensors",
    "model-00016-of-00061.safetensors",
    "model-00017-of-00061.safetensors",
    "model-00018-of-00061.safetensors",
    "model-00019-of-00061.safetensors",
    "model-00020-of-00061.safetensors",
    "model-00021-of-00061.safetensors",
    "model-00022-of-00061.safetensors",
    "model-00023-of-00061.safetensors",
    "model-00024-of-00061.safetensors",
    "model-00025-of-00061.safetensors",
    "model-00026-of-00061.safetensors",
    "model-00027-of-00061.safetensors",
    "model-00028-of-00061.safetensors",
    "model-00029-of-00061.safetensors",
    "model-00030-of-00061.safetensors",
    "model-00031-of-00061.safetensors",
    "model-00032-of-00061.safetensors",
    "model-00033-of-00061.safetensors",
    "model-00034-of-00061.safetensors",
    "model-00035-of-00061.safetensors",
    "model-00036-of-00061.safetensors",
    "model-00037-of-00061.safetensors",
    "model-00038-of-00061.safetensors",
    "model-00039-of-00061.safetensors",
    "model-00040-of-00061.safetensors",
    "model-00041-of-00061.safetensors",
    "model-00042-of-00061.safetensors",
    "model-00043-of-00061.safetensors",
    "model-00044-of-00061.safetensors",
    "model-00045-of-00061.safetensors",
    "model-00046-of-00061.safetensors",
    "model-00047-of-00061.safetensors",
    "model-00048-of-00061.safetensors",
    "model-00049-of-00061.safetensors",
    "model-00050-of-00061.safetensors",
    "model-00051-of-00061.safetensors",
    "model-00052-of-00061.safetensors",
    "model-00053-of-00061.safetensors",
    "model-00054-of-00061.safetensors",
    "model-00055-of-00061.safetensors",
    "model-00056-of-00061.safetensors",
    "model-00057-of-00061.safetensors",
    "model-00058-of-00061.safetensors",
    "model-00059-of-00061.safetensors",
    "model-00060-of-00061.safetensors",
    "model-00061-of-00061.safetensors"
  ],
  "iblai/ibl-fordham-7b": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "mzbac/Yi-34B-Llama-guanaco-awq": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TimothyMarx/Revolt": [
    "adapter_model.safetensors",
    "checkpoint-3/adapter_model.safetensors"
  ],
  "amdeyk/trystock1.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "athirdpath/BigMistral-13b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "athirdpath/NeuralPivot-Mistral-13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "bradmin/ppo-300": [
    "model.safetensors"
  ],
  "banghua/openchat-3.5-apa-ckpt4k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "athirdpath/NeuralHermes-Mistral-13b-DARE_blended-FAILURE": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Cartinoe5930/no_robots_ep1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Cartinoe5930/no_robots_ep2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Cartinoe5930/no_robots_ep3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "athirdpath/CleverMage-Mistral-13b-DARE_blended-FAILURE": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Rijgersberg/GEITje-7B": [
    "checkpoint-1194/model-00001-of-00003.safetensors",
    "checkpoint-1194/model-00002-of-00003.safetensors",
    "checkpoint-1194/model-00003-of-00003.safetensors",
    "checkpoint-1592/model-00001-of-00003.safetensors",
    "checkpoint-1592/model-00002-of-00003.safetensors",
    "checkpoint-1592/model-00003-of-00003.safetensors",
    "checkpoint-1990/model-00001-of-00003.safetensors",
    "checkpoint-1990/model-00002-of-00003.safetensors",
    "checkpoint-1990/model-00003-of-00003.safetensors",
    "checkpoint-2388/model-00001-of-00003.safetensors",
    "checkpoint-2388/model-00002-of-00003.safetensors",
    "checkpoint-2388/model-00003-of-00003.safetensors",
    "checkpoint-2786/model-00001-of-00003.safetensors",
    "checkpoint-2786/model-00002-of-00003.safetensors",
    "checkpoint-2786/model-00003-of-00003.safetensors",
    "checkpoint-3184/model-00001-of-00003.safetensors",
    "checkpoint-3184/model-00002-of-00003.safetensors",
    "checkpoint-3184/model-00003-of-00003.safetensors",
    "checkpoint-3582/model-00001-of-00003.safetensors",
    "checkpoint-3582/model-00002-of-00003.safetensors",
    "checkpoint-3582/model-00003-of-00003.safetensors",
    "checkpoint-398/model-00001-of-00003.safetensors",
    "checkpoint-398/model-00002-of-00003.safetensors",
    "checkpoint-398/model-00003-of-00003.safetensors",
    "checkpoint-3980/model-00001-of-00003.safetensors",
    "checkpoint-3980/model-00002-of-00003.safetensors",
    "checkpoint-3980/model-00003-of-00003.safetensors",
    "checkpoint-4378/model-00001-of-00003.safetensors",
    "checkpoint-4378/model-00002-of-00003.safetensors",
    "checkpoint-4378/model-00003-of-00003.safetensors",
    "checkpoint-4776/model-00001-of-00003.safetensors",
    "checkpoint-4776/model-00002-of-00003.safetensors",
    "checkpoint-4776/model-00003-of-00003.safetensors",
    "checkpoint-5174/model-00001-of-00003.safetensors",
    "checkpoint-5174/model-00002-of-00003.safetensors",
    "checkpoint-5174/model-00003-of-00003.safetensors",
    "checkpoint-5572/model-00001-of-00003.safetensors",
    "checkpoint-5572/model-00002-of-00003.safetensors",
    "checkpoint-5572/model-00003-of-00003.safetensors",
    "checkpoint-6368/model-00001-of-00003.safetensors",
    "checkpoint-6368/model-00002-of-00003.safetensors",
    "checkpoint-6368/model-00003-of-00003.safetensors",
    "checkpoint-6766/model-00001-of-00003.safetensors",
    "checkpoint-6766/model-00002-of-00003.safetensors",
    "checkpoint-6766/model-00003-of-00003.safetensors",
    "checkpoint-7164/model-00001-of-00003.safetensors",
    "checkpoint-7164/model-00002-of-00003.safetensors",
    "checkpoint-7164/model-00003-of-00003.safetensors",
    "checkpoint-7562/model-00001-of-00003.safetensors",
    "checkpoint-7562/model-00002-of-00003.safetensors",
    "checkpoint-7562/model-00003-of-00003.safetensors",
    "checkpoint-796/model-00001-of-00003.safetensors",
    "checkpoint-796/model-00002-of-00003.safetensors",
    "checkpoint-796/model-00003-of-00003.safetensors",
    "checkpoint-7960/model-00001-of-00003.safetensors",
    "checkpoint-7960/model-00002-of-00003.safetensors",
    "checkpoint-7960/model-00003-of-00003.safetensors",
    "checkpoint-8358/model-00001-of-00003.safetensors",
    "checkpoint-8358/model-00002-of-00003.safetensors",
    "checkpoint-8358/model-00003-of-00003.safetensors",
    "checkpoint-8756/model-00001-of-00003.safetensors",
    "checkpoint-8756/model-00002-of-00003.safetensors",
    "checkpoint-8756/model-00003-of-00003.safetensors",
    "checkpoint-9154/model-00001-of-00003.safetensors",
    "checkpoint-9154/model-00002-of-00003.safetensors",
    "checkpoint-9154/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Gaurav0430/Research_sdc": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mncai/llama2-7b-dpo-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "satpalsr/NeuralHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/SG-Raccoon-Yi-55B-200k-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/SG-Raccoon-Yi-55B-200k-GPTQ": [
    "model.safetensors"
  ],
  "athirdpath/Thicc-PianoMaid-19b-FAIL": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "athirdpath/Thicc-Mistral-19b-FAIL": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "dim/mistral-open-orca-ru-2400-step": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ECj/Yi-6B-200K-GPTQ": [
    "model.safetensors"
  ],
  "ECj/Yi-6B-200K-AWQ": [
    "model.safetensors"
  ],
  "LoneStriker/loyal-piano-m7-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "SN12/llama-2-7b-advisor": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/loyal-piano-m7-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/loyal-piano-m7-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/loyal-piano-m7-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "adejumobi/my_awesome_RoBERT": [
    "model.safetensors"
  ],
  "LoneStriker/loyal-piano-m7-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "TheBloke/neural-chat-7B-v3-2-AWQ": [
    "model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-indef-naan-1e-4": [
    "model.safetensors"
  ],
  "adejumobi/my_awesome_RoBERT2": [
    "model.safetensors"
  ],
  "AFK47/GPTRIZ": [
    "model.safetensors"
  ],
  "sriramahesh2000/zephyr-Generation": [
    "adapter_model.safetensors"
  ],
  "TheBloke/DiscoLM-120b-AWQ": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "OrangeQWQ/CapyTessBorosYi-Spicyboros-LimaRPv3-34B": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "hungsvdut2k2/custom-gpt-2-vietnamese": [
    "model.safetensors"
  ],
  "LoneStriker/cinematika-7b-v0.1-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/cinematika-7b-v0.1-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/cinematika-7b-v0.1-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/cinematika-7b-v0.1-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/cinematika-7b-v0.1-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "huseinzol05/dummy-llama-200M": [
    "model.safetensors"
  ],
  "openaccess-ai-collective/DPOpenHermes-7B": [
    "adapters/adapter_model.safetensors",
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "relaxml/Mistral-7b-HI-4Bit-Packed": [
    "model.safetensors"
  ],
  "relaxml/Openhermes-7b-HI-4Bit-Packed": [
    "model.safetensors"
  ],
  "relaxml/Mistral-7b-E8P-2Bit": [
    "model.safetensors"
  ],
  "152334H/NeuralHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "relaxml/Openhermes-7b-E8P-2Bit": [
    "model.safetensors"
  ],
  "beberik/Nyxene-11B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dim/mistral-open-orca-ru-2600-step": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "smdbfkj12/my_awesome_eli5_clm-model": [
    "model.safetensors"
  ],
  "Aryanne/Astridboros-3B": [
    "model.safetensors"
  ],
  "TheBloke/neural-chat-7B-v3-2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/DiscoLM-120b-GPTQ": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "typeof/Oracle-pythia-70m": [
    "model.safetensors"
  ],
  "banghua/openchat3.5_apa_ckpt5k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "chargoddard/loyal-piano-m7-cdpo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "HFXM/git-base": [
    "model.safetensors"
  ],
  "LoneStriker/DPOpenHermes-7B-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/DPOpenHermes-7B-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "kaizerBox/retnet-Final-smallest-summarization": [
    "model.safetensors"
  ],
  "LoneStriker/DPOpenHermes-7B-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "kaizerBox/RoFormer-summarization": [
    "model.safetensors"
  ],
  "LoneStriker/DPOpenHermes-7B-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/DPOpenHermes-7B-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "ByteSized/Mistral-7B-OpenOrca-EduText": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dim/mistral-open-orca-ru-2800-step": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Kunj120799/kunj": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "simonveitner/MathHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "naqib3110/llama-2-7b-chat-whazzat-QloRA-R4_merge_unload": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "athirdpath/PianoMaid-19b-DARE_blended-FAIL": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "ContextualAI/archangel_sft-dpo_pythia1-4b": [
    "model.safetensors"
  ],
  "ContextualAI/archangel_sft-dpo_pythia2-8b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Ehraim/SequentialLearnerv4": [
    "adapter_model.safetensors"
  ],
  "ContextualAI/archangel_sft-dpo_pythia6-9b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "R136a1/TimeMax-20B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "ContextualAI/archangel_sft-dpo_pythia12-0b": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "LoneStriker/NeuralPivot-Mistral-13B-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "BSamil/gpt2-imdb-pos-v2": [
    "model.safetensors"
  ],
  "TheBloke/DPOpenHermes-7B-AWQ": [
    "model.safetensors"
  ],
  "LoneStriker/NeuralPivot-Mistral-13B-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "ContextualAI/archangel_sft-dpo_llama7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Inairtra-7B-AWQ": [
    "model.safetensors"
  ],
  "ContextualAI/archangel_sft-dpo_llama13b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/NeuralPivot-Mistral-13B-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "TheBloke/loyal-piano-m7-AWQ": [
    "model.safetensors"
  ],
  "LoneStriker/NeuralPivot-Mistral-13B-6.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "kaizerBox/RoFormer_small-summarization": [
    "model.safetensors"
  ],
  "LoneStriker/NeuralPivot-Mistral-13B-8.0bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Norquinal/OpenCAI-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Advaith28/RedPythia2.8finetuned8epoch": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mzyil/llama-2-13b-mzyil-3-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ContextualAI/archangel_sft-dpo_llama30b": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "mzyil/llama-2-7b-mzyil-3-merged": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "kaizerBox/ReFormer-summarization": [
    "model.safetensors"
  ],
  "mlinmg/SG-Raccoon-Yi-55B-200k-2.0": [
    "model-00001-of-00012.safetensors",
    "model-00002-of-00012.safetensors",
    "model-00003-of-00012.safetensors",
    "model-00004-of-00012.safetensors",
    "model-00005-of-00012.safetensors",
    "model-00006-of-00012.safetensors",
    "model-00007-of-00012.safetensors",
    "model-00008-of-00012.safetensors",
    "model-00009-of-00012.safetensors",
    "model-00010-of-00012.safetensors",
    "model-00011-of-00012.safetensors",
    "model-00012-of-00012.safetensors"
  ],
  "openaccess-ai-collective/DPOpenHermes-11B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Inairtra-7B-GPTQ": [
    "model.safetensors"
  ],
  "dim/mistral-open-orca-ru-3000-step": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mncai/llama2-13b-dpo-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ContextualAI/archangel_sft-kto_pythia1-4b": [
    "model.safetensors"
  ],
  "ContextualAI/archangel_sft-kto_pythia2-8b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/loyal-piano-m7-GPTQ": [
    "model.safetensors"
  ],
  "ContextualAI/archangel_sft-kto_pythia6-9b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ContextualAI/archangel_sft-kto_pythia12-0b": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "danyoung/danyoung-finance-qa-dpo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/DPOpenHermes-7B-GPTQ": [
    "model.safetensors"
  ],
  "kalyanmaram/bloom-560m-unh-qa": [
    "model.safetensors"
  ],
  "ContextualAI/archangel_sft-kto_llama7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ContextualAI/archangel_sft-kto_llama13b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "kaizerBox/ReFormer-small-summarization": [
    "model.safetensors"
  ],
  "mncai/SDC_Llama2_Lr05_Ep2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mncai/SDC_Llama2_Lr05_Ep4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mncai/SDC_Mistral_Lr05_Ep2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ContextualAI/archangel_sft-kto_llama30b": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "Osquery/eli5_clm-model-2007": [
    "model.safetensors"
  ],
  "mncai/SDC_Mistral_Lr05_Ep4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Jerry46/zephyr-7b-sft-lora": [
    "adapter_model.safetensors"
  ],
  "Norquinal/OpenCAI-13B": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "KnutJaegersberg/Deacon-1b": [
    "model.safetensors"
  ],
  "CrabfishAI/InstructWise2-248M": [
    "model.safetensors"
  ],
  "danyoung/finance-qa-dpo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jawadmohmmad/tinyllama-colorist-v2": [
    "model.safetensors"
  ],
  "ContextualAI/archangel_sft-ppo_pythia1-4b": [
    "model.safetensors"
  ],
  "ContextualAI/archangel_sft-ppo_pythia2-8b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ContextualAI/archangel_sft-ppo_pythia6-9b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ping98k/th-7b-20gb-base": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "R136a1/TimeLess-20B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "ContextualAI/archangel_sft-ppo_pythia12-0b": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "ezelikman/mistral-fwd": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "joey00072/layerMix-Mistral-7b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ContextualAI/archangel_sft-ppo_llama7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ContextualAI/archangel_sft-ppo_llama13b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ContextualAI/archangel_sft-ppo_llama30b": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "zackhlk/llama2.1test": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "F24/llama-2-koen-13b-slimOrca": [
    "model-00001-of-00082.safetensors",
    "model-00002-of-00082.safetensors",
    "model-00003-of-00082.safetensors",
    "model-00004-of-00082.safetensors",
    "model-00005-of-00082.safetensors",
    "model-00006-of-00082.safetensors",
    "model-00007-of-00082.safetensors",
    "model-00008-of-00082.safetensors",
    "model-00009-of-00082.safetensors",
    "model-00010-of-00082.safetensors",
    "model-00011-of-00082.safetensors",
    "model-00012-of-00082.safetensors",
    "model-00013-of-00082.safetensors",
    "model-00014-of-00082.safetensors",
    "model-00015-of-00082.safetensors",
    "model-00016-of-00082.safetensors",
    "model-00017-of-00082.safetensors",
    "model-00018-of-00082.safetensors",
    "model-00019-of-00082.safetensors",
    "model-00020-of-00082.safetensors",
    "model-00021-of-00082.safetensors",
    "model-00022-of-00082.safetensors",
    "model-00023-of-00082.safetensors",
    "model-00024-of-00082.safetensors",
    "model-00025-of-00082.safetensors",
    "model-00026-of-00082.safetensors",
    "model-00027-of-00082.safetensors",
    "model-00028-of-00082.safetensors",
    "model-00029-of-00082.safetensors",
    "model-00030-of-00082.safetensors",
    "model-00031-of-00082.safetensors",
    "model-00032-of-00082.safetensors",
    "model-00033-of-00082.safetensors",
    "model-00034-of-00082.safetensors",
    "model-00035-of-00082.safetensors",
    "model-00036-of-00082.safetensors",
    "model-00037-of-00082.safetensors",
    "model-00038-of-00082.safetensors",
    "model-00039-of-00082.safetensors",
    "model-00040-of-00082.safetensors",
    "model-00041-of-00082.safetensors",
    "model-00042-of-00082.safetensors",
    "model-00043-of-00082.safetensors",
    "model-00044-of-00082.safetensors",
    "model-00045-of-00082.safetensors",
    "model-00046-of-00082.safetensors",
    "model-00047-of-00082.safetensors",
    "model-00048-of-00082.safetensors",
    "model-00049-of-00082.safetensors",
    "model-00050-of-00082.safetensors",
    "model-00051-of-00082.safetensors",
    "model-00052-of-00082.safetensors",
    "model-00053-of-00082.safetensors",
    "model-00054-of-00082.safetensors",
    "model-00055-of-00082.safetensors",
    "model-00056-of-00082.safetensors",
    "model-00057-of-00082.safetensors",
    "model-00058-of-00082.safetensors",
    "model-00059-of-00082.safetensors",
    "model-00060-of-00082.safetensors",
    "model-00061-of-00082.safetensors",
    "model-00062-of-00082.safetensors",
    "model-00063-of-00082.safetensors",
    "model-00064-of-00082.safetensors",
    "model-00065-of-00082.safetensors",
    "model-00066-of-00082.safetensors",
    "model-00067-of-00082.safetensors",
    "model-00068-of-00082.safetensors",
    "model-00069-of-00082.safetensors",
    "model-00070-of-00082.safetensors",
    "model-00071-of-00082.safetensors",
    "model-00072-of-00082.safetensors",
    "model-00073-of-00082.safetensors",
    "model-00074-of-00082.safetensors",
    "model-00075-of-00082.safetensors",
    "model-00076-of-00082.safetensors",
    "model-00077-of-00082.safetensors",
    "model-00078-of-00082.safetensors",
    "model-00079-of-00082.safetensors",
    "model-00080-of-00082.safetensors",
    "model-00081-of-00082.safetensors",
    "model-00082-of-00082.safetensors"
  ],
  "F24/llama-2-koen-orca-mini-platypus2-math-13b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mncai/llama2-13b-dpo-v3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AshanGimhana/llama2-model-GPTQ-V1": [
    "model.safetensors"
  ],
  "misbah1955/sultana1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sonyaleaf/dolphin-2.0-mistral-7b-itmo-edu": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "neboolaai/NAI-3.5": [
    "model.safetensors"
  ],
  "jhflow/mistral7b-lora-multiturn-v4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Weyaxi/OpenHermes-2.5-neural-chat-7b-v3-2-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "huskyhong/noname-ai-v1": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Q-bert/Optimus-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "eunbinni/ola_polyglot_5.8B_lora2_merge_final": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "eunbinni/ola_polyglot_5.8B_lora1_8bit_merge_final": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "eunbinni/ola_polyglot_5.8B_lora1_merge_final": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "collabteza/Mistral_function-calling-v1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "eunbinni/ola_polyglot_5.8B_lora2_8bit_merge_final": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "eunbinni/ola_polyglot_5.8B_lora1_4bit_merge_final": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "dim/mistral-open-orca-ru-3500-step": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "eunbinni/ola_polyglot_5.8B_lora2_4bit_merge_final": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "eunbinni/ola_polyglot_12.8B_lora1_merge_final": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "Q-bert/Bumblebee-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/DiscoLM-70B-GPTQ": [
    "model.safetensors"
  ],
  "CallComply/Starling-LM-11B-alpha": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "nicholasKluge/Aira-2-124M-DPO": [
    "model.safetensors"
  ],
  "LoneStriker/OpenHermes-2.5-neural-chat-7b-v3-2-7B-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/OpenHermes-2.5-neural-chat-7b-v3-2-7B-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/OpenHermes-2.5-neural-chat-7b-v3-2-7B-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "Aryanne/Astrohermes-3B": [
    "model.safetensors"
  ],
  "LoneStriker/OpenHermes-2.5-neural-chat-7b-v3-2-7B-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "TheBloke/OpenHermes-2.5-neural-chat-7B-v3-2-7B-AWQ": [
    "model.safetensors"
  ],
  "LoneStriker/OpenHermes-2.5-neural-chat-7b-v3-2-7B-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "bnurpek/gpt2-tr-pos-v3": [
    "model.safetensors"
  ],
  "ozgurozdemir/math-gen-gpt2": [
    "model.safetensors"
  ],
  "Jerry46/zephyr-7b-dpo-lora": [
    "adapter_model.safetensors"
  ],
  "TheBloke/notus-7B-v1-AWQ": [
    "model.safetensors"
  ],
  "Mestopholis/test-train": [
    "adapter_model.safetensors",
    "checkpoint-40/adapter_model.safetensors"
  ],
  "ise-uiuc/Magicoder-CL-7B": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ise-uiuc/Magicoder-S-CL-7B": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ise-uiuc/Magicoder-DS-6.7B": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ise-uiuc/Magicoder-S-DS-6.7B": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "RaushanTurganbay/GPT2_instruct_tuned": [
    "model.safetensors"
  ],
  "batatar/BatatarGPT": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Vezora/Narwhal-7b-v3": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Maxnet/llama-2-7b-req": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rishiraj/smol-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-indef-naan-3e-4": [
    "model.safetensors"
  ],
  "amazingvince/where-lambo-checkpoints": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "deepapaikar/Llama_SCplusQA_10epochs": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "01GangaPutraBheeshma/databricks-facebook-opt2-ft-dolly-UT": [
    "adapter_model.safetensors"
  ],
  "vrvenkatesh/VarunOPTTest-finetuned-slangQA": [
    "model.safetensors"
  ],
  "LoneStriker/deepseek-llm-67b-Spicy-3.1-1-2.4bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "guardrail/guardrail-orca-finance-mistral-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "athirdpath/BigMistral-11b-GLUE_LORA": [
    "checkpoint-90/adapter_model.safetensors"
  ],
  "LoneStriker/deepseek-llm-67b-Spicy-3.1-1-3.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "migtissera/Tess-7B-v1.4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Broomva/llama-2-7b-chat-instruct-translate-spa-guc-checkpoint": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/deepseek-llm-67b-Spicy-3.1-1-4.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "inswave/AISquare-Instruct-llama2-koen-13b-v0.9.14": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ryuinw123/wangchanglm-finetune-thaisum": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "LoneStriker/deepseek-llm-67b-Spicy-3.1-1-4.65bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "Puluming/AISquare-Instruct-llama2-koen-13b-v0.9.18": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Puluming/AISquare-Instruct-llama2-koen-13b-v0.9.15": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "qiyinmiss/My_GPT2": [
    "model.safetensors"
  ],
  "maywell/Synatra-Yi-Ko-6B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "athirdpath/PianoMaid-11b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "athirdpath/NeuralPivot-11b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "athirdpath/NeuralHermes-11b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "athirdpath/CleverMage-11b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "decem/Dionysus-Mistral-7b": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "LoneStriker/deepseek-llm-67b-Spicy-3.1-1-5.0bpw-h6-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "OpenBuddy/openbuddy-deepseek-67b-v15-base": [
    "model-00001-of-00028.safetensors",
    "model-00002-of-00028.safetensors",
    "model-00003-of-00028.safetensors",
    "model-00004-of-00028.safetensors",
    "model-00005-of-00028.safetensors",
    "model-00006-of-00028.safetensors",
    "model-00007-of-00028.safetensors",
    "model-00008-of-00028.safetensors",
    "model-00009-of-00028.safetensors",
    "model-00010-of-00028.safetensors",
    "model-00011-of-00028.safetensors",
    "model-00012-of-00028.safetensors",
    "model-00013-of-00028.safetensors",
    "model-00014-of-00028.safetensors",
    "model-00015-of-00028.safetensors",
    "model-00016-of-00028.safetensors",
    "model-00017-of-00028.safetensors",
    "model-00018-of-00028.safetensors",
    "model-00019-of-00028.safetensors",
    "model-00020-of-00028.safetensors",
    "model-00021-of-00028.safetensors",
    "model-00022-of-00028.safetensors",
    "model-00023-of-00028.safetensors",
    "model-00024-of-00028.safetensors",
    "model-00025-of-00028.safetensors",
    "model-00026-of-00028.safetensors",
    "model-00027-of-00028.safetensors",
    "model-00028-of-00028.safetensors"
  ],
  "athirdpath/Thalia-11b-DARE_TIES": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "cgf1986/S-0.3-LLama2-chat-7b-hf-ft32": [
    "model.safetensors"
  ],
  "Roombreak/git-base": [
    "model.safetensors"
  ],
  "sophosympatheia/Rogue-Rose-103b-v0.2": [
    "model-00001-of-00022.safetensors",
    "model-00002-of-00022.safetensors",
    "model-00003-of-00022.safetensors",
    "model-00004-of-00022.safetensors",
    "model-00005-of-00022.safetensors",
    "model-00006-of-00022.safetensors",
    "model-00007-of-00022.safetensors",
    "model-00008-of-00022.safetensors",
    "model-00009-of-00022.safetensors",
    "model-00010-of-00022.safetensors",
    "model-00011-of-00022.safetensors",
    "model-00012-of-00022.safetensors",
    "model-00013-of-00022.safetensors",
    "model-00014-of-00022.safetensors",
    "model-00015-of-00022.safetensors",
    "model-00016-of-00022.safetensors",
    "model-00017-of-00022.safetensors",
    "model-00018-of-00022.safetensors",
    "model-00019-of-00022.safetensors",
    "model-00020-of-00022.safetensors",
    "model-00021-of-00022.safetensors",
    "model-00022-of-00022.safetensors"
  ],
  "LoneStriker/deepseek-llm-67b-Spicy-3.1-1-6.0bpw-h6-exl2": [
    "output-00001-of-00007.safetensors",
    "output-00002-of-00007.safetensors",
    "output-00003-of-00007.safetensors",
    "output-00004-of-00007.safetensors",
    "output-00005-of-00007.safetensors",
    "output-00006-of-00007.safetensors",
    "output-00007-of-00007.safetensors"
  ],
  "Broomva/llama-2-7b-chat-instruct-translate-spa-pbb": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "greatakela/mistral_instruct_classify30k": [
    "adapter_model.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "aegon-h/neural-chat-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "asrar7787/model-mistral-7b-instruct-v0.1-gathnex-magento2-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jawadmohmmad/tinyllama-company-label-model": [
    "model.safetensors"
  ],
  "LoneStriker/deepseek-llm-67b-Spicy-3.1-1-2.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "amazingvince/where-lambo-checkpoints2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tlphams/zoyllm-7b-slimorca": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "nlile/PE-12b-pythia": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "KnutJaegersberg/falcon-1b-t-sft": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jingyeom/seal_all_7b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Medilora/Medilora-Mistral-7B": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "truongghieu/deci-finetuned_BK_Regulation": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "zomd/AISquare-Instruct-llama2-koen-13b-v0.9.19": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Ja-ck/Mistral-instruct-Y24-v6": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "thanhnew2001/starcoder-7b-taipy9": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dim/mistral-open-orca-ru-4100-step": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "athirdpath/PivotMaid-Starling-11b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "m-a-p/Kun-LabelModel": [
    "model-00001-of-00031.safetensors",
    "model-00002-of-00031.safetensors",
    "model-00003-of-00031.safetensors",
    "model-00004-of-00031.safetensors",
    "model-00005-of-00031.safetensors",
    "model-00006-of-00031.safetensors",
    "model-00007-of-00031.safetensors",
    "model-00008-of-00031.safetensors",
    "model-00009-of-00031.safetensors",
    "model-00010-of-00031.safetensors",
    "model-00011-of-00031.safetensors",
    "model-00012-of-00031.safetensors",
    "model-00013-of-00031.safetensors",
    "model-00014-of-00031.safetensors",
    "model-00015-of-00031.safetensors",
    "model-00016-of-00031.safetensors",
    "model-00017-of-00031.safetensors",
    "model-00018-of-00031.safetensors",
    "model-00019-of-00031.safetensors",
    "model-00020-of-00031.safetensors",
    "model-00021-of-00031.safetensors",
    "model-00022-of-00031.safetensors",
    "model-00023-of-00031.safetensors",
    "model-00024-of-00031.safetensors",
    "model-00025-of-00031.safetensors",
    "model-00026-of-00031.safetensors",
    "model-00027-of-00031.safetensors",
    "model-00028-of-00031.safetensors",
    "model-00029-of-00031.safetensors",
    "model-00030-of-00031.safetensors",
    "model-00031-of-00031.safetensors"
  ],
  "HARSHAPALNATIUNH/results": [
    "model.safetensors"
  ],
  "Jarnails1559/gpt-sharded-bf16-5GB": [
    "model.safetensors"
  ],
  "TheBloke/notus-7B-v1-GPTQ": [
    "model.safetensors"
  ],
  "HARSHAPALNATIUNH/Automodelbloom": [
    "model.safetensors"
  ],
  "truongghieu/deci-finetuned_BK_Regulation_merge": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "louislian2341/output": [
    "model.safetensors"
  ],
  "RaushanTurganbay/GPT2_sft_and_dpo_tuned": [
    "model.safetensors"
  ],
  "TheBloke/OpenHermes-2.5-neural-chat-7B-v3-2-7B-GPTQ": [
    "model.safetensors"
  ],
  "khursani8/test": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Recag/Bharatai-v-2": [
    "model.safetensors"
  ],
  "timpal0l/Mistral-7B-v0.1-flashback-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Electrofried/Promptmaster-mistral-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "iproskurina/bloom-1b7-gptq-4bit": [
    "model.safetensors"
  ],
  "Layla321/llm_finetuning-0": [
    "adapter_model.safetensors",
    "checkpoint-342/adapter_model.safetensors"
  ],
  "jingyeom/seal_all_13b": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "lIlBrother/llama2-merge-v0.4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "DopeorNope/Yi_lee-v1-6B": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "lamm-mit/SilkomePretrainedGPT": [
    "model.safetensors"
  ],
  "Narya-ai/zephyr-7b-sft-lora": [
    "adapter_model.safetensors"
  ],
  "Jack2022/opt-125m-gptq-4bit": [
    "model.safetensors"
  ],
  "toshi456/llava-jp-1.3b-v1.0": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "shleeeee/mistral-ko-OpenOrca-2000": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lamm-mit/GPTProteinPretrained": [
    "model.safetensors"
  ],
  "afmck/testing-llama-tiny": [
    "model.safetensors"
  ],
  "carterlabsltd/Mistral-7b-finetune-13k-chat": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors",
    "wasadapter_model.wassafetensors"
  ],
  "cassanof/deepseek-7b-dafny": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Mlxa/embeddings-nested-english": [
    "model.safetensors"
  ],
  "Trelis/Llama-2-7b-chat-hf-function-calling-v3": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Robb1620/llama2-8b-CA-7b": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "Mlxa/embeddings-flat-english": [
    "model.safetensors"
  ],
  "lIlBrother/llama2-merge-v0.5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Mlxa/embeddings-flat_shuffle-english": [
    "model.safetensors"
  ],
  "shivangx01b/phi-1_5-finetuned-aws-keys": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "beberik/Nyxene-v1-11B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hoangquang27/llama-2-7b-chat-hf-yelp": [
    "adapter_model.safetensors"
  ],
  "PrasannSinghal/zephyr-7b-dpo-lora": [
    "adapter_model.safetensors"
  ],
  "kfkas/yi-ko-SFT-LoRA-play": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/DiscoLM-70b-2.4bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "Weni/ZeroShot-3.0.1-Mistral-7b-Multilanguage-3.0.3-AWQ": [
    "model.safetensors"
  ],
  "NurtureAI/neural-chat-11b-v3-2": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "LoneStriker/DiscoLM-70b-3.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "joyfine/vicuna-7b-fine-tuning_sst2_20_16_again": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "perlthoughts/Chupacabra-7B-v2.01": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/RpBird-Yi-34B-200k-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/RpBird-Yi-34B-200k-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "alvwjy/Llama2-moodle-pretrained": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Abe13/zephyr-7b-sft-lora-1": [
    "adapter_model.safetensors"
  ],
  "LoneStriker/DiscoLM-70b-4.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "beberik/Nyxene-v2-11B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "banghua/openchat3.5_apa_log_ckpt3k5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "togethercomputer/StripedHyena-Nous-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "banghua/openchat-3.5-apa-tog-ckpt3k5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "banghua/openchat3.5_apa_log_ckpt4k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "banghua/openchat-3.5-apa-tog-ckpt4k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/DiscoLM-70b-4.65bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "vrvenkatesh/VarunOPTTest2-finetuned-slangQA": [
    "model.safetensors"
  ],
  "Redwood0/PiVoT-Merge-A-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/DiscoLM-70b-5.0bpw-h6-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "dim/mistral-open-orca-ru-4600-step": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "AshanGimhana/quant-model-GPTQ-V1.1": [
    "model.safetensors"
  ],
  "TheBloke/Poro-34B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Poro-34B-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "vrvenkatesh/VarunOPTTest3-finetuned-slangQA": [
    "model.safetensors"
  ],
  "Redwood0/PiVoT-Merge-A-7b-8bpw-h8-exl2": [
    "output.safetensors"
  ],
  "Abe13/zephyr-7b-sft-lora-2": [
    "adapter_model.safetensors"
  ],
  "ammarzaarour/aragpt2-base-saadeh": [
    "model.safetensors"
  ],
  "LoneStriker/DiscoLM-70b-6.0bpw-h6-exl2": [
    "output-00001-of-00007.safetensors",
    "output-00002-of-00007.safetensors",
    "output-00003-of-00007.safetensors",
    "output-00004-of-00007.safetensors",
    "output-00005-of-00007.safetensors",
    "output-00006-of-00007.safetensors",
    "output-00007-of-00007.safetensors"
  ],
  "FPHam/Sydney_Overthinker_13b_HF": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "chathuru/CuATR-falcon7b-v1": [
    "adapter_model.safetensors"
  ],
  "TheBloke/OpenOrca-Zephyr-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/OpenOrca-Zephyr-7B-AWQ": [
    "model.safetensors"
  ],
  "LoneStriker/DiscoLM-70b-2.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "Biomimicry-AI/ANIMA-Nectar-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Minami-su/Yi_34B_Chat_2bit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jakemannix/zephyr-7b-beta_assistant_v0.2_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Loyola/ko-mistralplatypusdata": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mncai/SDC_Llama2_Lr06_Ep2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mncai/SDC_Llama2_Lr06_Ep4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Pog-champ/chrono007-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "mncai/llama2-13b-dpo-v4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mncai/SDC_Mistral_Lr06_Ep4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Bobblack225/MiniMa3bFinetune": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ericzzz/falcon-rw-1b-chat": [
    "model.safetensors"
  ],
  "NurtureAI/una-cybertron-11b-v1-fp16": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "migtissera/Tess-34B-v1.4": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "amazingvince/where-llambo-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Shrey-1329/git-base-mimic-subset": [
    "model.safetensors"
  ],
  "hyeogi/Yi-6b-dpo-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "blueapple8259/test_model1": [
    "model.safetensors"
  ],
  "BM-K/yi-ko-6b-it-v1.0.0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/una-cybertron-7b-v2-bf16-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "jingyeom/zephyr_all_7b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/una-cybertron-7b-v2-bf16-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "shleeeee/mistral-ko-OpenOrca-wiki-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/una-cybertron-7b-v2-bf16-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "David-Xu/mistral_instruct_qa": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/una-cybertron-7b-v2-bf16-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "kalyanmaram/UNH-QA-bloom-560m-v2": [
    "model.safetensors"
  ],
  "LoneStriker/una-cybertron-7b-v2-bf16-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "hahnyuan/opt-125m-asvd90": [
    "model.safetensors"
  ],
  "Delcos/Velara": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "csdc-atl/buffer-baichuan2-13B-rag-8bits": [
    "model.safetensors"
  ],
  "genaitraining/llama-2-7b-domain-tuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dim/mistral-open-orca-ru-4900-step": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "technocrat3128/mistral-finetuned-L4-sharded-merge": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "vihangd/neuralplats-1.1b-2T-v1": [
    "model.safetensors"
  ],
  "mohitcharkha/Llama-2-7b-chat-hf-finetuned-experiment-15": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Debasishiarcs/llama-2-contradictor": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "butyuhao/qwen-14b-chat-hq-1130-hf": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "HyperbeeAI/Tulpar-7b-v2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "genaitraining/llama-2-7b-qna-tuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TigerResearch/tigerbot-70b-chat-v4-4bit-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "Minirecord/Mini_synatra_7b_ML01": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "qqplot23/xsum-gpt2-long-pegasus": [
    "model.safetensors"
  ],
  "lahaine/my-fine-tuned-model-ppo": [
    "model.safetensors"
  ],
  "girrajjangid/Llama-7B-SFT-AWQ": [
    "model.safetensors"
  ],
  "DopeorNope/COKAL-v1-70B": [
    "model-00001-of-00061.safetensors",
    "model-00002-of-00061.safetensors",
    "model-00003-of-00061.safetensors",
    "model-00004-of-00061.safetensors",
    "model-00005-of-00061.safetensors",
    "model-00006-of-00061.safetensors",
    "model-00007-of-00061.safetensors",
    "model-00008-of-00061.safetensors",
    "model-00009-of-00061.safetensors",
    "model-00010-of-00061.safetensors",
    "model-00011-of-00061.safetensors",
    "model-00012-of-00061.safetensors",
    "model-00013-of-00061.safetensors",
    "model-00014-of-00061.safetensors",
    "model-00015-of-00061.safetensors",
    "model-00016-of-00061.safetensors",
    "model-00017-of-00061.safetensors",
    "model-00018-of-00061.safetensors",
    "model-00019-of-00061.safetensors",
    "model-00020-of-00061.safetensors",
    "model-00021-of-00061.safetensors",
    "model-00022-of-00061.safetensors",
    "model-00023-of-00061.safetensors",
    "model-00024-of-00061.safetensors",
    "model-00025-of-00061.safetensors",
    "model-00026-of-00061.safetensors",
    "model-00027-of-00061.safetensors",
    "model-00028-of-00061.safetensors",
    "model-00029-of-00061.safetensors",
    "model-00030-of-00061.safetensors",
    "model-00031-of-00061.safetensors",
    "model-00032-of-00061.safetensors",
    "model-00033-of-00061.safetensors",
    "model-00034-of-00061.safetensors",
    "model-00035-of-00061.safetensors",
    "model-00036-of-00061.safetensors",
    "model-00037-of-00061.safetensors",
    "model-00038-of-00061.safetensors",
    "model-00039-of-00061.safetensors",
    "model-00040-of-00061.safetensors",
    "model-00041-of-00061.safetensors",
    "model-00042-of-00061.safetensors",
    "model-00043-of-00061.safetensors",
    "model-00044-of-00061.safetensors",
    "model-00045-of-00061.safetensors",
    "model-00046-of-00061.safetensors",
    "model-00047-of-00061.safetensors",
    "model-00048-of-00061.safetensors",
    "model-00049-of-00061.safetensors",
    "model-00050-of-00061.safetensors",
    "model-00051-of-00061.safetensors",
    "model-00052-of-00061.safetensors",
    "model-00053-of-00061.safetensors",
    "model-00054-of-00061.safetensors",
    "model-00055-of-00061.safetensors",
    "model-00056-of-00061.safetensors",
    "model-00057-of-00061.safetensors",
    "model-00058-of-00061.safetensors",
    "model-00059-of-00061.safetensors",
    "model-00060-of-00061.safetensors",
    "model-00061-of-00061.safetensors"
  ],
  "hyeogi/Yi-6b-v0.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "fblgit/una-xaberius-34b-v1beta": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "FitriJamsari/llama-2-7b-miniplatypus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hyeogi/llama2-70b-v0.1": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "desarrolloasesoreslocales/sft_mistral_merged": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Medilora/guideline-medqa-adapter": [
    "adapter_model.safetensors"
  ],
  "jarod0411/PubChem10M_gpt2_SMILES_charLvl": [
    "model.safetensors"
  ],
  "aniello19/mistral_fervento_v1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Zardos/Kant-Test-0.1-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kazandaev/WizardCoder-Python-34B-function-calling-sql": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "SebastianSchramm/opt-125m-sft-full": [
    "model.safetensors"
  ],
  "athirdpath/DoubleMaid-11b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "athirdpath/DoublePivot-11b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dim/mistral-open-orca-ru-5100-step": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Weyaxi/MetaMath-neural-chat-7b-v3-2-Linear": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Weyaxi/MetaMath-neural-chat-7b-v3-2-Ties": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Weyaxi/MetaMath-loyal-piano-m7-cdpo-Linear": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "athirdpath/PivotMaid-11b-DARE_TIES": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "llava-hf/llava-1.5-13b-hf": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Weyaxi/MetaMath-OpenHermes-2.5-neural-chat-7b-v3-1-7B-Linear": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Weyaxi/MetaMath-loyal-piano-m7-cdpo-Ties": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Weyaxi/MetaMath-NeuralHermes-2.5-Mistral-7B-Linear": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "kedar16/qnaFineTuning": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Weyaxi/MetaMath-OpenHermes-2.5-neural-chat-7b-v3-1-7B-Ties": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "plm3332/gpt2-imdb-ppo-v1": [
    "model.safetensors"
  ],
  "abhi757/llama-2-7b-chat-topic-gen": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Weyaxi/MetaMath-NeuralHermes-2.5-Mistral-7B-Ties": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/smol-7b-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "Mlxa/tuned-english-flat": [
    "model.safetensors"
  ],
  "LoneStriker/smol-7b-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "eldpswp99/6wy8-8d5t-256a-0": [
    "adapter_model.safetensors",
    "checkpoint-129/adapter_model.safetensors"
  ],
  "LoneStriker/smol-7b-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/smol-7b-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/smol-7b-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "aleksejalex/ErbenGPT": [
    "model.safetensors"
  ],
  "aleksejalex/gpt2_kytice": [
    "model.safetensors"
  ],
  "Myashka/gpt-imdb-hinge-beta_0.1": [
    "model.safetensors"
  ],
  "banghua/openchat3.5_apa_log_ckpt4k5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "arnavgrg/codallama-7b-instruct-nf4-fp16-upscaled": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "malhajar/Llama-2-13b-chat-tr": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "dim/mistral-open-orca-ru-5300-step": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Myashka/gpt-imdb-sigmoid-beta_0.1": [
    "model.safetensors"
  ],
  "nthngdy/pythia-rp-160m-10k": [
    "model.safetensors"
  ],
  "banghua/openchat-3.5-apa-tog-ckpt4k5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "shivangx01b/phi-1_5-finetuned-science-qa": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "eunbinni/ola_polyglot_12.8B_lora2_merge_final": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "nthngdy/hythia-rp-160m-10k_ft_bs16": [
    "model.safetensors"
  ],
  "hamxea/Mistral-7B-v0.1-activity-fine-tuned-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "eunbinni/ola_polyglot_12.8B_lora1_8bit_merge_final": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "LoneStriker/TIGERScore-7B-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "arnavgrg/llama-2-13b-chat-nf4-fp16-upscaled": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "heka-ai/llama-2-7b-eytan-test-GPTQ": [
    "model.safetensors"
  ],
  "arnavgrg/codellama-13b-instruct-nf4-fp16-upscaled": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "oluwatobi-alao/llama2-hiring": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "nthngdy/hythia-rp-160m-80k_ft_bs16": [
    "model.safetensors"
  ],
  "nthngdy/hythia-rp-160m-80k_ft_bs32": [
    "model.safetensors"
  ],
  "arnavgrg/mistral-7b-instruct-nf4-fp16-upscaled": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/TIGERScore-7B-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/TIGERScore-7B-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "arnavgrg/zephyr-7b-beta-nf4-fp16-upscaled": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/TIGERScore-7B-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/TIGERScore-7B-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "Mlxa/tuned-english-nested": [
    "model.safetensors"
  ],
  "LoneStriker/Magicoder-S-DS-6.7B-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Magicoder-S-DS-6.7B-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "arnavgrg/llama-2-70b-chat-nf4-fp16-upscaled": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "LoneStriker/Tess-7B-v1.4-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Magicoder-S-DS-6.7B-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Magicoder-S-DS-6.7B-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Tess-7B-v1.4-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Magicoder-S-DS-6.7B-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "TheBloke/sabia-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/sabia-7B-GPTQ": [
    "model.safetensors"
  ],
  "LoneStriker/Tess-7B-v1.4-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Tess-7B-v1.4-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Tess-7B-v1.4-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "TheBloke/SUS-Chat-34B-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/SUS-Chat-34B-GPTQ": [
    "model.safetensors"
  ],
  "LoneStriker/TIGERScore-13B-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/TIGERScore-13B-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "batatar/BatatarGPT-13b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/TIGERScore-13B-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "nthngdy/hythia-rp-160m-80k_ft_bs1024": [
    "model.safetensors"
  ],
  "Q-bert/MetaMath-Cybertron": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/TIGERScore-13B-6.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/TIGERScore-13B-8.0bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Q-bert/MetaMath-Cybertron-Starling": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Tess-34B-v1.4-3.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "OmniFederal/Omni-Mistral-DPO-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Mihaiii/Pallas-0.2": [
    "model-00001-of-00031.safetensors",
    "model-00002-of-00031.safetensors",
    "model-00003-of-00031.safetensors",
    "model-00004-of-00031.safetensors",
    "model-00005-of-00031.safetensors",
    "model-00006-of-00031.safetensors",
    "model-00007-of-00031.safetensors",
    "model-00008-of-00031.safetensors",
    "model-00009-of-00031.safetensors",
    "model-00010-of-00031.safetensors",
    "model-00011-of-00031.safetensors",
    "model-00012-of-00031.safetensors",
    "model-00013-of-00031.safetensors",
    "model-00014-of-00031.safetensors",
    "model-00015-of-00031.safetensors",
    "model-00016-of-00031.safetensors",
    "model-00017-of-00031.safetensors",
    "model-00018-of-00031.safetensors",
    "model-00019-of-00031.safetensors",
    "model-00020-of-00031.safetensors",
    "model-00021-of-00031.safetensors",
    "model-00022-of-00031.safetensors",
    "model-00023-of-00031.safetensors",
    "model-00024-of-00031.safetensors",
    "model-00025-of-00031.safetensors",
    "model-00026-of-00031.safetensors",
    "model-00027-of-00031.safetensors",
    "model-00028-of-00031.safetensors",
    "model-00029-of-00031.safetensors",
    "model-00030-of-00031.safetensors",
    "model-00031-of-00031.safetensors"
  ],
  "kalyanmaram/UNH-QA-bloom-560m-v3": [
    "model.safetensors"
  ],
  "LoneStriker/Tess-34B-v1.4-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "nthngdy/pythia-rp-160m-20k": [
    "model.safetensors"
  ],
  "kalyanmaram/UNH-Academic-Integrity-bloomz-560m-v4": [
    "model.safetensors"
  ],
  "LoneStriker/Tess-34B-v1.4-4.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/una-xaberius-34b-v1beta-3.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/Tess-34B-v1.4-5.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "SaiSaketh/saketh-560m-llm": [
    "model.safetensors"
  ],
  "LoneStriker/Tess-34B-v1.4-6.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "LoneStriker/una-xaberius-34b-v1beta-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Tess-34B-v1.4-8.0bpw-h8-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "Mariaaaaa/llama2-7b-fine-tuning_Twitter_20": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/una-xaberius-34b-v1beta-4.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "dmayboroda/llm_workshop": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "atom92/medical_lama_2_all": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/una-xaberius-34b-v1beta-5.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "perlthoughts/Falkor-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "benayas/llama-2-7b-sst2_v0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/una-xaberius-34b-v1beta-6.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "benayas/llama-2-7b-tweet_eval_v0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "avemio-digital/neural-chat-7b-v3-1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/una-xaberius-34b-v1beta-8.0bpw-h8-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "cmvvvt13/distilgpt2-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "abacusai/Giraffe-13b-32k-v3": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "yu-nomi/llama-wiki-standards_Lora_D0.01_Bl1024_Ba2_Ga2_merged": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "inswave/AISquare-Instruct-llama2-koen-13b-v0.9.21": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "npvinHnivqn/gpt2-random": [
    "model.safetensors"
  ],
  "openaccess-ai-collective/DPOpenHermes-7B-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Optimus-7B-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Optimus-7B-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "shleeeee/mistral-ko-exo-wiki-quiz-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AIFT/PACK-13b-v1.0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Optimus-7B-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "thanhnew2001/starcoder-7b-taipy10": [
    "model.safetensors"
  ],
  "LoneStriker/Optimus-7B-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "li-jay-cs/test_push_to_hub": [
    "model.safetensors"
  ],
  "LoneStriker/Optimus-7B-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "li-jay-cs/Summary_PPO": [
    "model.safetensors"
  ],
  "mncai/yi-34B-v2": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "LoneStriker/Nyxene-v2-11B-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "technocrat3128/mistral7b-merge-2.0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Nyxene-v2-11B-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "OpenBuddy/openbuddy-deepseek-67b-v15.1": [
    "model-00001-of-00028.safetensors",
    "model-00002-of-00028.safetensors",
    "model-00003-of-00028.safetensors",
    "model-00004-of-00028.safetensors",
    "model-00005-of-00028.safetensors",
    "model-00006-of-00028.safetensors",
    "model-00007-of-00028.safetensors",
    "model-00008-of-00028.safetensors",
    "model-00009-of-00028.safetensors",
    "model-00010-of-00028.safetensors",
    "model-00011-of-00028.safetensors",
    "model-00012-of-00028.safetensors",
    "model-00013-of-00028.safetensors",
    "model-00014-of-00028.safetensors",
    "model-00015-of-00028.safetensors",
    "model-00016-of-00028.safetensors",
    "model-00017-of-00028.safetensors",
    "model-00018-of-00028.safetensors",
    "model-00019-of-00028.safetensors",
    "model-00020-of-00028.safetensors",
    "model-00021-of-00028.safetensors",
    "model-00022-of-00028.safetensors",
    "model-00023-of-00028.safetensors",
    "model-00024-of-00028.safetensors",
    "model-00025-of-00028.safetensors",
    "model-00026-of-00028.safetensors",
    "model-00027-of-00028.safetensors",
    "model-00028-of-00028.safetensors"
  ],
  "LoneStriker/Nyxene-v2-11B-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Nyxene-v2-11B-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "Aryanne/Astrorocketboros-3B": [
    "model-00001-of-00035.safetensors",
    "model-00002-of-00035.safetensors",
    "model-00003-of-00035.safetensors",
    "model-00004-of-00035.safetensors",
    "model-00005-of-00035.safetensors",
    "model-00006-of-00035.safetensors",
    "model-00007-of-00035.safetensors",
    "model-00008-of-00035.safetensors",
    "model-00009-of-00035.safetensors",
    "model-00010-of-00035.safetensors",
    "model-00011-of-00035.safetensors",
    "model-00012-of-00035.safetensors",
    "model-00013-of-00035.safetensors",
    "model-00014-of-00035.safetensors",
    "model-00015-of-00035.safetensors",
    "model-00016-of-00035.safetensors",
    "model-00017-of-00035.safetensors",
    "model-00018-of-00035.safetensors",
    "model-00019-of-00035.safetensors",
    "model-00020-of-00035.safetensors",
    "model-00021-of-00035.safetensors",
    "model-00022-of-00035.safetensors",
    "model-00023-of-00035.safetensors",
    "model-00024-of-00035.safetensors",
    "model-00025-of-00035.safetensors",
    "model-00026-of-00035.safetensors",
    "model-00027-of-00035.safetensors",
    "model-00028-of-00035.safetensors",
    "model-00029-of-00035.safetensors",
    "model-00030-of-00035.safetensors",
    "model-00031-of-00035.safetensors",
    "model-00032-of-00035.safetensors",
    "model-00033-of-00035.safetensors",
    "model-00034-of-00035.safetensors",
    "model-00035-of-00035.safetensors"
  ],
  "hwanhe/llamadpotest1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/Nyxene-v2-11B-8.0bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "besiktas/clippy-webagent": [
    "adapter_model.safetensors",
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "mjkimmjmj/SDC_Llama2_Lr06_Ep4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Minirecord/llama13b_dpo_loss0_OTL": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "mjkimmjmj/SDC_Mistral_Lr05_Ep2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hahahafofo/Qwen-1_8B-Stable-Diffusion-Prompt_v0.5": [
    "model.safetensors"
  ],
  "waldie/deepsex-34b-4bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "zomd/AISquare-Instruct-llama2-koen-13b-v0.9.17": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "brucethemoose/CapyTessBorosYi-34B-200K-DARE-Ties-exl2-3.1bpw-fiction": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "masonym/gigabyte-faq-7B-HF": [
    "gigabyte-faq-7B-HF-no-act-order-4bit-128g.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Delcos/Starling-LM-11B-alpha": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TrumpBiden/zephyr-7b-sft-lora": [
    "adapter_model.safetensors"
  ],
  "Maxnet/llama-2-7b-req-know": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "technocrat3128/mistral7b-colab-1epoc": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "shleeeee/mistral-ko-OpenOrca-Platypus-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "decem/Dionysus-llama2-13b-v2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Minirecord/Mini_DPO_test03": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "DopeorNope/Yi_lee-v1-DPO-6B": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "TheBloke/NeuralOrca-7B-v1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/NeuralOrca-7B-v1-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/una-cybertron-7B-v2-AWQ": [
    "model.safetensors"
  ],
  "Weyaxi/MetaMath-una-cybertron-v2-bf16-Linear": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Narya-ai/zephyr-7b-sft-full": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TinyPixel/tiny-model": [
    "model.safetensors"
  ],
  "Weyaxi/MetaMath-una-cybertron-v2-bf16-Ties": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/una-cybertron-7B-v2-GPTQ": [
    "model.safetensors"
  ],
  "potato101/mistraltestmalayalam": [
    "adapter_model.safetensors",
    "checkpoint-90/adapter_model.safetensors"
  ],
  "siulhin-vlad37/Llama-2-7b-chat-bot": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "eldpswp99/o2v7-pnmz-o6pw-0": [
    "adapter_model.safetensors"
  ],
  "lotusbro/llama-2-7b-chat-law": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "nyanxyz/llama2-test-2": [
    "adapter_model.safetensors",
    "checkpoint-63/adapter_model.safetensors"
  ],
  "shrenikb/CS4650_16_Step0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "shrenikb/CS4650_24_Step0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "shrenikb/CS4650_32_Step0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SebastianSchramm/opt-125m-dpo-full": [
    "model.safetensors"
  ],
  "Yannael/NeuralHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Severian/ANIMA-Nectar": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "eldpswp99/blmw-iqbe-zdsc-0": [
    "adapter_model.safetensors",
    "checkpoint-129/adapter_model.safetensors"
  ],
  "nyanxyz/llama2-test-3": [
    "checkpoint-63/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mantamaahil/DialoGPT-medium-luffy": [
    "model.safetensors"
  ],
  "nisharganirjan/Llama2Tuning-odia_llama2_7B_base": [
    "adapter_model.safetensors",
    "checkpoint-9843/adapter_model.safetensors"
  ],
  "ramk1404/llama-konnectAI-100ep": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Bilic/NeuralChat-finetuned-for-fraud-detection": [
    "adapter_model.safetensors"
  ],
  "fokyoum9/zephyr7B_KO_ORCA_Test6": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "harithushan/facebook-opt-125m-GPTQ": [
    "model.safetensors"
  ],
  "Formid322/gooroomee": [
    "checkpoint-21/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "nyanxyz/mistral-sat": [
    "checkpoint-21/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "eldpswp99/sat-colab-hermes": [
    "checkpoint-105/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jack-daksh/devReview": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kings-crown/EM624_QA_Multi": [
    "adapter_model.safetensors"
  ],
  "TheBloke/Tess-7B-v1.4-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Tess-7B-v1.4-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/PiVoT-Merge-A-7B-AWQ": [
    "model.safetensors"
  ],
  "hyeogi/llama2-70b-v0.2": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "crodri/caBloom1.3_QA": [
    "model.safetensors"
  ],
  "TheBloke/Tess-34B-v1.4-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Tess-34B-v1.4-GPTQ": [
    "model.safetensors"
  ],
  "tianlinliu0121/zephyr-7b-dpo-full-debug-regression": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kedarbhumkar/LLAMA-2-7b-HW-v2": [
    "adapter_model.safetensors",
    "checkpoint-1/adapter_model.safetensors"
  ],
  "Ehraim/SequentialLearnerv5": [
    "adapter_model.safetensors"
  ],
  "therem/training": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "dimad000/gpt2_100": [
    "model.safetensors"
  ],
  "kyujinpy/PlatYi-34B-200K-Q": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "cosimoiaia/Loquace-7B-Mistral": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "NghiemAbe/gpt-neo-vi-small": [
    "model.safetensors"
  ],
  "Ehraim/SequentialLearnerv6": [
    "adapter_model.safetensors"
  ],
  "Myashka/gpt-imdb-fkl-beta_0.1": [
    "model.safetensors"
  ],
  "eunbinni/ola_polyglot_12.8B_lora2_8bit_merge_final": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "Myashka/gpt-imdb-jsd-beta_0.1": [
    "model.safetensors"
  ],
  "AI-Sweden-Models/gpt-sw3-20b-instruct-4bit-gptq": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "nthngdy/hythia-rp-160m-100k-bs16": [
    "model.safetensors"
  ],
  "nthngdy/hythia-rp-160m-20k-bs16": [
    "model.safetensors"
  ],
  "eunbinni/ola_polyglot_12.8B_lora1_4bit_merge_final": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "tomjennings100/absumm": [
    "checkpoint-89/adapter_model.safetensors"
  ],
  "eunbinni/ola_polyglot_12.8B_lora2_4bit_merge_final": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "ishanarang/codeparrot-ds": [
    "model.safetensors"
  ],
  "We-Want-GPU/yi-ko-SFT-LoRA-play-re-dpo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hicreo/codegen-350M-mono-python-18k-alpaca": [
    "model.safetensors"
  ],
  "ishanarang/output-ds": [
    "model.safetensors"
  ],
  "akil-elkamel/Llama-2-7b-miniplatypus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/PiVoT-Merge-A-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Magicoder-S-DS-6.7B-AWQ": [
    "model.safetensors"
  ],
  "Ehraim/SequentialLearnerv7": [
    "adapter_model.safetensors"
  ],
  "TheBloke/NexusRaven-V2-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Nyxene-v2-11B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Nyxene-v2-11B-GPTQ": [
    "model.safetensors"
  ],
  "maxsegan/LiLaMa": [
    "model.safetensors"
  ],
  "TheBloke/MetaMath-Cybertron-Starling-AWQ": [
    "model.safetensors"
  ],
  "HydraIndicLM/mistral-MoQlora-odia-expert": [
    "adapter_model.safetensors"
  ],
  "TheBloke/una-xaberius-34b-v1beta-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/una-xaberius-34b-v1beta-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Optimus-7B-AWQ": [
    "model.safetensors"
  ],
  "HydraIndicLM/mistral-MoQlora-bengali-expert": [
    "adapter_model.safetensors"
  ],
  "TheBloke/deepsex-34b-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "HydraIndicLM/mistral-MoQlora-telgu-expert": [
    "adapter_model.safetensors"
  ],
  "Ehraim/SequentialLearnerv10": [
    "adapter_model.safetensors"
  ],
  "athirdpath/DoubleFactor-20b": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Ipan98/results": [
    "adapter_model.safetensors"
  ],
  "Ehraim/SequentialLearnerv11": [
    "adapter_model.safetensors"
  ],
  "Narya-ai/zephyr-7b-sft-lora-eldar": [
    "adapter_model.safetensors"
  ],
  "athirdpath/Iambe-Storyteller-20b": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "TheBloke/DPOpenHermes-7B-v2-AWQ": [
    "model.safetensors"
  ],
  "Myashka/gpt-imdb-alpha_0.7-beta_0.1": [
    "model.safetensors"
  ],
  "cgato/Thespis-13b-Alpha-v0.7": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "TheBloke/Magicoder-S-DS-6.7B-GPTQ": [
    "model.safetensors"
  ],
  "yu-nomi/llama-wiki-standards_Lora_D0.01_Bl1024_PAD_merged": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "xzrderek/spongebob-llm": [
    "adapter_model.safetensors"
  ],
  "Myashka/gpt-imdb-alpha_0.3-beta_0.1": [
    "model.safetensors"
  ],
  "PMrtn/falcon-7b-instruct-QLoRA_PrefixTune_v3.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "st3ffey/distilgpt2-finetuned-harrypottah": [
    "model.safetensors"
  ],
  "Ja-ck/Mistral-instruct-DPO-Y24-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "gsomers-smarsh/llama2-7b-qlora-email-classifier-merged": [
    "model-00001-of-00130.safetensors",
    "model-00002-of-00130.safetensors",
    "model-00003-of-00130.safetensors",
    "model-00004-of-00130.safetensors",
    "model-00005-of-00130.safetensors",
    "model-00006-of-00130.safetensors",
    "model-00007-of-00130.safetensors",
    "model-00008-of-00130.safetensors",
    "model-00009-of-00130.safetensors",
    "model-00010-of-00130.safetensors",
    "model-00011-of-00130.safetensors",
    "model-00012-of-00130.safetensors",
    "model-00013-of-00130.safetensors",
    "model-00014-of-00130.safetensors",
    "model-00015-of-00130.safetensors",
    "model-00016-of-00130.safetensors",
    "model-00017-of-00130.safetensors",
    "model-00018-of-00130.safetensors",
    "model-00019-of-00130.safetensors",
    "model-00020-of-00130.safetensors",
    "model-00021-of-00130.safetensors",
    "model-00022-of-00130.safetensors",
    "model-00023-of-00130.safetensors",
    "model-00024-of-00130.safetensors",
    "model-00025-of-00130.safetensors",
    "model-00026-of-00130.safetensors",
    "model-00027-of-00130.safetensors",
    "model-00028-of-00130.safetensors",
    "model-00029-of-00130.safetensors",
    "model-00030-of-00130.safetensors",
    "model-00031-of-00130.safetensors",
    "model-00032-of-00130.safetensors",
    "model-00033-of-00130.safetensors",
    "model-00034-of-00130.safetensors",
    "model-00035-of-00130.safetensors",
    "model-00036-of-00130.safetensors",
    "model-00037-of-00130.safetensors",
    "model-00038-of-00130.safetensors",
    "model-00039-of-00130.safetensors",
    "model-00040-of-00130.safetensors",
    "model-00041-of-00130.safetensors",
    "model-00042-of-00130.safetensors",
    "model-00043-of-00130.safetensors",
    "model-00044-of-00130.safetensors",
    "model-00045-of-00130.safetensors",
    "model-00046-of-00130.safetensors",
    "model-00047-of-00130.safetensors",
    "model-00048-of-00130.safetensors",
    "model-00049-of-00130.safetensors",
    "model-00050-of-00130.safetensors",
    "model-00051-of-00130.safetensors",
    "model-00052-of-00130.safetensors",
    "model-00053-of-00130.safetensors",
    "model-00054-of-00130.safetensors",
    "model-00055-of-00130.safetensors",
    "model-00056-of-00130.safetensors",
    "model-00057-of-00130.safetensors",
    "model-00058-of-00130.safetensors",
    "model-00059-of-00130.safetensors",
    "model-00060-of-00130.safetensors",
    "model-00061-of-00130.safetensors",
    "model-00062-of-00130.safetensors",
    "model-00063-of-00130.safetensors",
    "model-00064-of-00130.safetensors",
    "model-00065-of-00130.safetensors",
    "model-00066-of-00130.safetensors",
    "model-00067-of-00130.safetensors",
    "model-00068-of-00130.safetensors",
    "model-00069-of-00130.safetensors",
    "model-00070-of-00130.safetensors",
    "model-00071-of-00130.safetensors",
    "model-00072-of-00130.safetensors",
    "model-00073-of-00130.safetensors",
    "model-00074-of-00130.safetensors",
    "model-00075-of-00130.safetensors",
    "model-00076-of-00130.safetensors",
    "model-00077-of-00130.safetensors",
    "model-00078-of-00130.safetensors",
    "model-00079-of-00130.safetensors",
    "model-00080-of-00130.safetensors",
    "model-00081-of-00130.safetensors",
    "model-00082-of-00130.safetensors",
    "model-00083-of-00130.safetensors",
    "model-00084-of-00130.safetensors",
    "model-00085-of-00130.safetensors",
    "model-00086-of-00130.safetensors",
    "model-00087-of-00130.safetensors",
    "model-00088-of-00130.safetensors",
    "model-00089-of-00130.safetensors",
    "model-00090-of-00130.safetensors",
    "model-00091-of-00130.safetensors",
    "model-00092-of-00130.safetensors",
    "model-00093-of-00130.safetensors",
    "model-00094-of-00130.safetensors",
    "model-00095-of-00130.safetensors",
    "model-00096-of-00130.safetensors",
    "model-00097-of-00130.safetensors",
    "model-00098-of-00130.safetensors",
    "model-00099-of-00130.safetensors",
    "model-00100-of-00130.safetensors",
    "model-00101-of-00130.safetensors",
    "model-00102-of-00130.safetensors",
    "model-00103-of-00130.safetensors",
    "model-00104-of-00130.safetensors",
    "model-00105-of-00130.safetensors",
    "model-00106-of-00130.safetensors",
    "model-00107-of-00130.safetensors",
    "model-00108-of-00130.safetensors",
    "model-00109-of-00130.safetensors",
    "model-00110-of-00130.safetensors",
    "model-00111-of-00130.safetensors",
    "model-00112-of-00130.safetensors",
    "model-00113-of-00130.safetensors",
    "model-00114-of-00130.safetensors",
    "model-00115-of-00130.safetensors",
    "model-00116-of-00130.safetensors",
    "model-00117-of-00130.safetensors",
    "model-00118-of-00130.safetensors",
    "model-00119-of-00130.safetensors",
    "model-00120-of-00130.safetensors",
    "model-00121-of-00130.safetensors",
    "model-00122-of-00130.safetensors",
    "model-00123-of-00130.safetensors",
    "model-00124-of-00130.safetensors",
    "model-00125-of-00130.safetensors",
    "model-00126-of-00130.safetensors",
    "model-00127-of-00130.safetensors",
    "model-00128-of-00130.safetensors",
    "model-00129-of-00130.safetensors",
    "model-00130-of-00130.safetensors"
  ],
  "fbellame/mistral-pdf-to-quizz-7b-f16": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "vishalp23/MASHQA-2.0-Mistral-7B": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "mwitiderrick/open_llama_3b_instruct_v_0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jaigouk/trained-una-cybertron-7b-v2-bf16": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/NexusRaven-V2-13B-GPTQ": [
    "model.safetensors"
  ],
  "protocol139/distilgpt2-arabic-twitter": [
    "model.safetensors"
  ],
  "DeepInfra/Llama-2-70b-chat-tokenizer": [],
  "jhadams/WizardLM_WizardCoder-Python-34B-V1.0_safetensors": [
    "model-00001-of-00037.safetensors",
    "model-00002-of-00037.safetensors",
    "model-00003-of-00037.safetensors",
    "model-00004-of-00037.safetensors",
    "model-00005-of-00037.safetensors",
    "model-00006-of-00037.safetensors",
    "model-00007-of-00037.safetensors",
    "model-00008-of-00037.safetensors",
    "model-00009-of-00037.safetensors",
    "model-00010-of-00037.safetensors",
    "model-00011-of-00037.safetensors",
    "model-00012-of-00037.safetensors",
    "model-00013-of-00037.safetensors",
    "model-00014-of-00037.safetensors",
    "model-00015-of-00037.safetensors",
    "model-00016-of-00037.safetensors",
    "model-00017-of-00037.safetensors",
    "model-00018-of-00037.safetensors",
    "model-00019-of-00037.safetensors",
    "model-00020-of-00037.safetensors",
    "model-00021-of-00037.safetensors",
    "model-00022-of-00037.safetensors",
    "model-00023-of-00037.safetensors",
    "model-00024-of-00037.safetensors",
    "model-00025-of-00037.safetensors",
    "model-00026-of-00037.safetensors",
    "model-00027-of-00037.safetensors",
    "model-00028-of-00037.safetensors",
    "model-00029-of-00037.safetensors",
    "model-00030-of-00037.safetensors",
    "model-00031-of-00037.safetensors",
    "model-00032-of-00037.safetensors",
    "model-00033-of-00037.safetensors",
    "model-00034-of-00037.safetensors",
    "model-00035-of-00037.safetensors",
    "model-00036-of-00037.safetensors",
    "model-00037-of-00037.safetensors"
  ],
  "Weni/ZeroShot-3.0.3-Mistral-7b-Multilanguage-3.0.3": [
    "adapter_model.safetensors",
    "checkpoint-915/adapter_model.safetensors"
  ],
  "nemdhregin/DialoGPT-small-dee": [
    "model.safetensors"
  ],
  "PMrtn/falcon-7b-instruct-QLoRA_PrefixTune_v3.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jaigouk/ruby-una-cybertron-7b-v2-bf16": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "greatakela/mistral_instruct_classifyFPB_full": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Ehraim/SequentialLearnerv13": [
    "adapter_model.safetensors"
  ],
  "NewGoldDream/skymist-p-1206b-0": [
    "adapter_model.safetensors",
    "checkpoint-700/adapter_model.safetensors"
  ],
  "perlthoughts/Falkor-7b-AWQ": [
    "model.safetensors"
  ],
  "tokyotech-llm/Swallow-7b-NVE-instruct-hf": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tokyotech-llm/Swallow-7b-instruct-hf": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "osorioleomar/phi-1_5-finetuned-gsm8k": [
    "adapter_model.safetensors"
  ],
  "austin/singlemed_model": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "DopeorNope/COKAL-ko-v1-70B": [
    "model-00001-of-00061.safetensors",
    "model-00002-of-00061.safetensors",
    "model-00003-of-00061.safetensors",
    "model-00004-of-00061.safetensors",
    "model-00005-of-00061.safetensors",
    "model-00006-of-00061.safetensors",
    "model-00007-of-00061.safetensors",
    "model-00008-of-00061.safetensors",
    "model-00009-of-00061.safetensors",
    "model-00010-of-00061.safetensors",
    "model-00011-of-00061.safetensors",
    "model-00012-of-00061.safetensors",
    "model-00013-of-00061.safetensors",
    "model-00014-of-00061.safetensors",
    "model-00015-of-00061.safetensors",
    "model-00016-of-00061.safetensors",
    "model-00017-of-00061.safetensors",
    "model-00018-of-00061.safetensors",
    "model-00019-of-00061.safetensors",
    "model-00020-of-00061.safetensors",
    "model-00021-of-00061.safetensors",
    "model-00022-of-00061.safetensors",
    "model-00023-of-00061.safetensors",
    "model-00024-of-00061.safetensors",
    "model-00025-of-00061.safetensors",
    "model-00026-of-00061.safetensors",
    "model-00027-of-00061.safetensors",
    "model-00028-of-00061.safetensors",
    "model-00029-of-00061.safetensors",
    "model-00030-of-00061.safetensors",
    "model-00031-of-00061.safetensors",
    "model-00032-of-00061.safetensors",
    "model-00033-of-00061.safetensors",
    "model-00034-of-00061.safetensors",
    "model-00035-of-00061.safetensors",
    "model-00036-of-00061.safetensors",
    "model-00037-of-00061.safetensors",
    "model-00038-of-00061.safetensors",
    "model-00039-of-00061.safetensors",
    "model-00040-of-00061.safetensors",
    "model-00041-of-00061.safetensors",
    "model-00042-of-00061.safetensors",
    "model-00043-of-00061.safetensors",
    "model-00044-of-00061.safetensors",
    "model-00045-of-00061.safetensors",
    "model-00046-of-00061.safetensors",
    "model-00047-of-00061.safetensors",
    "model-00048-of-00061.safetensors",
    "model-00049-of-00061.safetensors",
    "model-00050-of-00061.safetensors",
    "model-00051-of-00061.safetensors",
    "model-00052-of-00061.safetensors",
    "model-00053-of-00061.safetensors",
    "model-00054-of-00061.safetensors",
    "model-00055-of-00061.safetensors",
    "model-00056-of-00061.safetensors",
    "model-00057-of-00061.safetensors",
    "model-00058-of-00061.safetensors",
    "model-00059-of-00061.safetensors",
    "model-00060-of-00061.safetensors",
    "model-00061-of-00061.safetensors"
  ],
  "shrenikb/CS4650_16_Step1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "shrenikb/CS4650_24_Step1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jarod0411/zinc10M_gpt2_SMILES_bpe_combined_step1": [
    "model.safetensors"
  ],
  "tokyotech-llm/Swallow-13b-instruct-hf": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "shrenikb/CS4650_32_Step1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mncai/SDC_Mistral_Lr06_Ep2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "greatakela/mistral_instruct_classify10k_full": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "athirdpath/Iambe-RP-cDPO-20b": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "greatakela/mistral_instruct_classify30k_full": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "shrenikb/CS4650_16_Step2": [
    "model-00001-of-00002.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00002.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "logij/Novellama-13b-chat-hf": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "shrenikb/CS4650_24_Step2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "shrenikb/CS4650_32_Step2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "brucethemoose/CapyTessBorosYi-34B-200K-DARE-Ties-exl2-2.68bpw-fiction": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "Saurabh2104/llm_medicine": [
    "adapter_model.safetensors",
    "checkpoint-3/adapter_model.safetensors"
  ],
  "Delcos/airoboros-mistral2.2-Starling-11b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "worldboss/fine-tune-llama-7b-waec-2007": [
    "adapter_model.safetensors",
    "checkpoint-5/adapter_model.safetensors"
  ],
  "SamLovesHoneyWater/my_awesome_eli5_clm-model": [
    "model.safetensors"
  ],
  "ramk1404/llama-konnectai-100ep-4bitQ": [
    "model.safetensors"
  ],
  "vishalp23/MASHQA-2.0-Mistral-7B-GPTQ": [
    "model.safetensors"
  ],
  "Saurabh2104/llm_medicine2": [
    "adapter_model.safetensors",
    "checkpoint-3/adapter_model.safetensors"
  ],
  "misbah1955/sultana2": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "NghiemAbe/gpt-neo-vi-small-v2": [
    "model.safetensors"
  ],
  "j5ng/polyglot-ko-empathy-chat-5.8b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "nicher92/gpt-sw3-20b-4bit-gptq": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ikno/rinkotest": [
    "last-checkpoint/model-00001-of-00003.safetensors",
    "last-checkpoint/model-00002-of-00003.safetensors",
    "last-checkpoint/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "IlyasMoutawwakil/tiny-random-llama": [
    "model.safetensors"
  ],
  "drlee1/llama2-ko-70b-mymodel": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "laitrongduc/code-llama-python": [
    "adapter_model.safetensors"
  ],
  "harithushan/gpt2-xl-GPTQ": [
    "model.safetensors"
  ],
  "skerit/qq_7b_001": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "waldie/Promptmaster-mistral-7b-8bpw-h8-exl2": [
    "output.safetensors"
  ],
  "faizalnf1800/clm_gpt2_scifi_webnovel": [
    "model.safetensors"
  ],
  "0xOracle/neural-chat-fraud-detection-v1": [
    "adapter_model.safetensors"
  ],
  "NghiemAbe/gpt-neo-vi-small-v3": [
    "model.safetensors"
  ],
  "pratikthakkar007/ont5-sh1d-3qcd-0": [
    "adapter_model.safetensors",
    "checkpoint-435/adapter_model.safetensors"
  ],
  "meetkai/functionary-7b-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/DPOpenHermes-7B-v2-GPTQ": [
    "model.safetensors"
  ],
  "marynwangwu/llama-2-7b-tinypixel": [
    "adapter_model.safetensors",
    "checkpoint-610/adapter_model.safetensors"
  ],
  "NghiemAbe/gpt-neo-vi-small-v4": [
    "model.safetensors"
  ],
  "TheBloke/MetaMath-Cybertron-Starling-GPTQ": [
    "model.safetensors"
  ],
  "Narya-ai/zephyr-7b-sft-lora-truncate-2048": [
    "adapter_model.safetensors"
  ],
  "Puluming/AISquare-Instruct-llama2-koen-13b-v0.9.20": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "TheBloke/Optimus-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/shisa-7B-v1-AWQ": [
    "model.safetensors"
  ],
  "vibhuagrawal/GodziLLa2-70B-AWQ-8k": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/deepsex-34b-GPTQ": [
    "model.safetensors"
  ],
  "Ehraim/SequentialLearnerv14": [
    "adapter_model.safetensors"
  ],
  "kingabzpro/zephyr-7b-beta-Agent-Instruct": [
    "adapter_model.safetensors"
  ],
  "aisuko/ft-distilGPT2-with-askscience": [
    "model.safetensors"
  ],
  "NghiemAbe/gpt-neo-vi-small-v5": [
    "model.safetensors"
  ],
  "Sonali-Behera/Llama-2-7b-chat-finetune": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/shisa-7B-v1-GPTQ": [
    "model.safetensors"
  ],
  "collabteza/zephyr-7b-alpha": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors",
    "zephyr-7b-alpha/model-00001-of-00006.safetensors",
    "zephyr-7b-alpha/model-00002-of-00006.safetensors",
    "zephyr-7b-alpha/model-00003-of-00006.safetensors",
    "zephyr-7b-alpha/model-00004-of-00006.safetensors",
    "zephyr-7b-alpha/model-00005-of-00006.safetensors",
    "zephyr-7b-alpha/model-00006-of-00006.safetensors"
  ],
  "aloobun/distill-p-test": [
    "model.safetensors"
  ],
  "waldie/Iambe-RP-cDPO-20b-6bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "NghiemAbe/gpt-neo-vi-small-v6": [
    "model.safetensors"
  ],
  "Myashka/gpt-imdb-alpha_0.5-beta_0.1": [
    "model.safetensors"
  ],
  "Achyuth2511/VAdakkan2.0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Weni/ZeroShot-test-studio-3.0.3-Mistral-7b-Multilanguage-3.0.3": [
    "adapter_model.safetensors",
    "checkpoint-915/adapter_model.safetensors"
  ],
  "llamas-community/LlamaGuard-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rahat01/llama2-fine-tuned-bangla-sentNob": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "OpenBuddy/openbuddy-deepseek-67b-v15.2": [
    "model-00001-of-00028.safetensors",
    "model-00002-of-00028.safetensors",
    "model-00003-of-00028.safetensors",
    "model-00004-of-00028.safetensors",
    "model-00005-of-00028.safetensors",
    "model-00006-of-00028.safetensors",
    "model-00007-of-00028.safetensors",
    "model-00008-of-00028.safetensors",
    "model-00009-of-00028.safetensors",
    "model-00010-of-00028.safetensors",
    "model-00011-of-00028.safetensors",
    "model-00012-of-00028.safetensors",
    "model-00013-of-00028.safetensors",
    "model-00014-of-00028.safetensors",
    "model-00015-of-00028.safetensors",
    "model-00016-of-00028.safetensors",
    "model-00017-of-00028.safetensors",
    "model-00018-of-00028.safetensors",
    "model-00019-of-00028.safetensors",
    "model-00020-of-00028.safetensors",
    "model-00021-of-00028.safetensors",
    "model-00022-of-00028.safetensors",
    "model-00023-of-00028.safetensors",
    "model-00024-of-00028.safetensors",
    "model-00025-of-00028.safetensors",
    "model-00026-of-00028.safetensors",
    "model-00027-of-00028.safetensors",
    "model-00028-of-00028.safetensors"
  ],
  "Radiantloom/radiantloom-support-assist-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Weni/ZeroShot-3.0.3-Mistral-7b-Multilanguage-3.0.3-AWQ": [
    "model.safetensors"
  ],
  "Yannael/NeuralHermes-2.5-Mistral-7B-vGPT35": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "DiegoVSulz/capivara-ptbr-13b-lv2-chat": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "gokul00060/codellama2-finetuned-ROBOT": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TitanML/llama2-7b-chat-4bit-AWQ": [
    "model.safetensors"
  ],
  "mncai/yi-34B-v3": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "starkosae/starcoder-glaive-7b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "potato101/mistralengft": [
    "adapter_model.safetensors",
    "checkpoint-39/adapter_model.safetensors"
  ],
  "TheBloke/Tiamat-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Tiamat-7B-AWQ": [
    "model.safetensors"
  ],
  "gokul00060/codellama2-RObot": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "euclaise/Ferret-3B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/shisa-7b-v1-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/shisa-7b-v1-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/shisa-7b-v1-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/shisa-7b-v1-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "PMrtn/zephyr-7b-beta-QLoRA_PrefixTune_v1.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/shisa-7b-v1-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "TheBloke/Iambe-RP-cDPO-20B-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Iambe-RP-cDPO-20B-GPTQ": [
    "model.safetensors"
  ],
  "minhalvp/islamqa_model": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LLM360/Amber": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "segestic/Tinystories-gpt-0.1-3m": [
    "model.safetensors"
  ],
  "Ipan98/finQuant": [
    "adapter_model.safetensors"
  ],
  "mwitiderrick/open_llama_3b_instruct_v_0.2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jarod0411/zinc10M_gpt2_SMILES_bpe_combined_step2": [
    "model.safetensors"
  ],
  "aladaf/zephyr-7b-beta_unboxing_v0.1_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mandy012/Mandar-harrypotter-hp": [
    "model.safetensors"
  ],
  "aladaf/zephyr-7b-beta_unboxing_v0.1_gptq": [
    "model.safetensors"
  ],
  "TheBloke/stablelm-zephyr-3b-GPTQ": [
    "model.safetensors"
  ],
  "LoneStriker/openbuddy-deepseek-67b-v15.2-2.4bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "sohi-g/MASHQA-Mistral-7B-Instruct": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "Mehreenn/PrimaryModel": [
    "model.safetensors",
    "model_tokenizer-20231207T221949Z-001/model_tokenizer/model.safetensors"
  ],
  "athirdpath/Iambe-RP-cDPO-20b-EXL2-3bpw": [
    "output-00001-of-00008.safetensors",
    "output-00002-of-00008.safetensors",
    "output-00003-of-00008.safetensors",
    "output-00004-of-00008.safetensors",
    "output-00005-of-00008.safetensors",
    "output-00006-of-00008.safetensors",
    "output-00007-of-00008.safetensors",
    "output-00008-of-00008.safetensors"
  ],
  "LoneStriker/openbuddy-deepseek-67b-v15.2-3.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "Myashka/gpt-imdb-ipo-beta_0.5": [
    "model.safetensors"
  ],
  "TheBloke/dolphin-2.2-yi-34b-200k-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/dolphin-2.2-yi-34b-200k-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "cassanof/deepseek-7b-coq": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Rofoman/GTS-Noromaid-V1.01": [
    "model-00001-of-00017.safetensors",
    "model-00002-of-00017.safetensors",
    "model-00003-of-00017.safetensors",
    "model-00004-of-00017.safetensors",
    "model-00005-of-00017.safetensors",
    "model-00006-of-00017.safetensors",
    "model-00007-of-00017.safetensors",
    "model-00008-of-00017.safetensors",
    "model-00009-of-00017.safetensors",
    "model-00010-of-00017.safetensors",
    "model-00011-of-00017.safetensors",
    "model-00012-of-00017.safetensors",
    "model-00013-of-00017.safetensors",
    "model-00014-of-00017.safetensors",
    "model-00015-of-00017.safetensors",
    "model-00016-of-00017.safetensors",
    "model-00017-of-00017.safetensors"
  ],
  "LoneStriker/openbuddy-deepseek-67b-v15.2-4.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-babylm-1e-4": [
    "model.safetensors"
  ],
  "iproskurina/bloom-3b-gptq-4bit": [
    "model.safetensors"
  ],
  "iproskurina/bloom-560m-gptq-4bit": [
    "model.safetensors"
  ],
  "euclaise/Echo-3B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "iproskurina/bloom-1b1-gptq-4bit": [
    "model.safetensors"
  ],
  "LoneStriker/openbuddy-deepseek-67b-v15.2-4.65bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "duhbloon/DialoGPT-small-guy": [
    "model.safetensors"
  ],
  "xonimoy/opt-125m-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "iproskurina/bloom-7b1-gptq-4bit": [
    "model.safetensors"
  ],
  "Weyaxi/MetaMath-neural-chat-7b-v3-2-Slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "nsfwthrowitaway69/Venus-103b-v1.2": [
    "model-00001-of-00021.safetensors",
    "model-00002-of-00021.safetensors",
    "model-00003-of-00021.safetensors",
    "model-00004-of-00021.safetensors",
    "model-00005-of-00021.safetensors",
    "model-00006-of-00021.safetensors",
    "model-00007-of-00021.safetensors",
    "model-00008-of-00021.safetensors",
    "model-00009-of-00021.safetensors",
    "model-00010-of-00021.safetensors",
    "model-00011-of-00021.safetensors",
    "model-00012-of-00021.safetensors",
    "model-00013-of-00021.safetensors",
    "model-00014-of-00021.safetensors",
    "model-00015-of-00021.safetensors",
    "model-00016-of-00021.safetensors",
    "model-00017-of-00021.safetensors",
    "model-00018-of-00021.safetensors",
    "model-00019-of-00021.safetensors",
    "model-00020-of-00021.safetensors",
    "model-00021-of-00021.safetensors"
  ],
  "Ayesha18/chef-ai": [
    "model.safetensors"
  ],
  "Puluming/AISquare-Mistral-7b-v0.2.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Myashka/gpt-imdb-cdpo_0.15-beta_0.1": [
    "model.safetensors"
  ],
  "perlthoughts/Chupacabra-7B-v2.02": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/openbuddy-deepseek-67b-v15.2-5.0bpw-h6-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "ujjirox/yi-34b-chat": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "sarahtturkii/aragpt2": [
    "model.safetensors"
  ],
  "imTheGodfather/OpsHarmonySentinel_7B_alpha_GPTQ8": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "DataAnalyticsLab/SymbolicGPT-1Vars-30Points-1Ys": [
    "model.safetensors"
  ],
  "hyeogi/Yi-6b-v0.3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Sumsam/CogniAssess-FYP-merged-v1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Minirecord/Merge_test01": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/openbuddy-deepseek-67b-v15.2-6.0bpw-h6-exl2": [
    "output-00001-of-00007.safetensors",
    "output-00002-of-00007.safetensors",
    "output-00003-of-00007.safetensors",
    "output-00004-of-00007.safetensors",
    "output-00005-of-00007.safetensors",
    "output-00006-of-00007.safetensors",
    "output-00007-of-00007.safetensors"
  ],
  "rwitz/go-bruins": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "taehallm/CoT-mistral-7b-ko": [
    "adapter_model.safetensors"
  ],
  "pratikthakkar007/fz61-9i4h-j3s8-0": [
    "checkpoint-435/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kedarbhumkar/Mistral-7b-ft-1": [
    "adapter_model.safetensors",
    "checkpoint-1/adapter_model.safetensors"
  ],
  "Sumsam/CogniAssess-FYP-merged-v1.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/openbuddy-deepseek-67b-v15.2-2.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "KoladeOdunope/mistral-report-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ChunB1/1M_2119719": [
    "model.safetensors"
  ],
  "himanshubeniwal/gpt2_imdb_1000": [
    "model.safetensors"
  ],
  "Myashka/gpt-imdb-nce-beta_0.1": [
    "model.safetensors"
  ],
  "hahahafofo/Qwen-1_8B-Stable-Diffusion-Prompt": [
    "model.safetensors"
  ],
  "Cryo3978/ES-LLM": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "hyeogi/Yi-34b-v0.1": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "Aljo3aid/mistral-7b-instruct-share-gpt": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "nyanxyz/llama2-test-4": [
    "checkpoint-165/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AntonKorznikov/test": [
    "model.safetensors"
  ],
  "AntonKorznikov/gpt2_hinge": [
    "model.safetensors"
  ],
  "AntonKorznikov/gpt2_sigm": [
    "model.safetensors"
  ],
  "UnderstandLing/llama-2-3b-chat-nl-lora": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "KnutJaegersberg/prompter": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "aloobun/open-llama-3b-v2-elmv3": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "areegtarek/mistral_7b_orca": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Weyaxi/MetaMath-Tulpar-7b-v2-Slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "sbranco/angle-llama-7b-nli-multi-512": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Weyaxi/MetaMath-Chupacabra-7B-v2.01-Slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TinyPixel/distilgpt2": [
    "model.safetensors"
  ],
  "hyeogi/Yi-6b-dpo-v0.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dim/tiny-llama-2T-open-orca-ru-2000-step": [
    "model.safetensors"
  ],
  "jojo0217/SFT_12.8B_mk2_v5": [
    "model-00001-of-00028.safetensors",
    "model-00002-of-00028.safetensors",
    "model-00003-of-00028.safetensors",
    "model-00004-of-00028.safetensors",
    "model-00005-of-00028.safetensors",
    "model-00006-of-00028.safetensors",
    "model-00007-of-00028.safetensors",
    "model-00008-of-00028.safetensors",
    "model-00009-of-00028.safetensors",
    "model-00010-of-00028.safetensors",
    "model-00011-of-00028.safetensors",
    "model-00012-of-00028.safetensors",
    "model-00013-of-00028.safetensors",
    "model-00014-of-00028.safetensors",
    "model-00015-of-00028.safetensors",
    "model-00016-of-00028.safetensors",
    "model-00017-of-00028.safetensors",
    "model-00018-of-00028.safetensors",
    "model-00019-of-00028.safetensors",
    "model-00020-of-00028.safetensors",
    "model-00021-of-00028.safetensors",
    "model-00022-of-00028.safetensors",
    "model-00023-of-00028.safetensors",
    "model-00024-of-00028.safetensors",
    "model-00025-of-00028.safetensors",
    "model-00026-of-00028.safetensors",
    "model-00027-of-00028.safetensors",
    "model-00028-of-00028.safetensors"
  ],
  "cgato/Thespis-Mistral-7b-Alpha-v0.7": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "Weyaxi/OpenHermes-2.5-neural-chat-v3-2-Slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "JGlang/llama2-openassistantFinal": [
    "adapter_model.safetensors",
    "checkpoint-112/adapter_model.safetensors"
  ],
  "himanshubeniwal/gpt2_imdb_all": [
    "model.safetensors"
  ],
  "HafsaaO/distilgpt2-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "TheBloke/Sydney_Overthinker_13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Sydney_Overthinker_13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/SG-Raccoon-Yi-200k-2.0-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/SG-Raccoon-Yi-200k-2.0-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "debisoft/mpt-7b-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Asma-z/distilgpt2-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "omar07ibrahim/unt-7b": [
    "adapter_model.safetensors",
    "checkpoint-3/adapter_model.safetensors"
  ],
  "TheBloke/Thespis-13B-Alpha-v0.7-AWQ": [
    "model.safetensors"
  ],
  "vrvenkatesh/VarunOPT-finetuned-slangQA_V2": [
    "model.safetensors"
  ],
  "LoneStriker/Thespis-13b-Alpha-v0.7-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "crodri/caBloom1.3_MultiQA": [
    "model.safetensors"
  ],
  "LoneStriker/Thespis-13b-Alpha-v0.7-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "rvv-karma/Commonsense-QA-Mistral-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "LoneStriker/Thespis-13b-Alpha-v0.7-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Thespis-13b-Alpha-v0.7-6.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "SebastianSchramm/LlamaGuard-7b-GPTQ-4bit-128g-actorder_True": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "LoneStriker/Thespis-13b-Alpha-v0.7-8.0bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Trelis/Mistral-7B-Instruct-v0.1-Summarize-16k": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mhwang093/zephyr-7b-beta_finetune_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LLM360/CrystalCoder": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dvijay/mistral-oa-qlora": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jgchaparro/llama-tsakonian-test": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/SG-Raccoon-Yi-200k-2.0-3.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "magnifi/zephyr-classifier-v2-all": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Code-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Code-13B-AWQ": [
    "model.safetensors"
  ],
  "LoneStriker/SG-Raccoon-Yi-200k-2.0-4.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "banghua/openchat-3.5-p3o-tog-rf-ckpt1k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-babylm-3e-4": [
    "model.safetensors"
  ],
  "TheBloke/Iambe-Storyteller-20B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Iambe-Storyteller-20B-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "banghua/openchat-3.5-p3o-tog-rf-ckpt5k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/SG-Raccoon-Yi-200k-2.0-4.65bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "TheBloke/Thespis-13B-Alpha-v0.7-GPTQ": [
    "model.safetensors"
  ],
  "Redwood0/Iambe-Storyteller-20b-4.65bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/SG-Raccoon-Yi-200k-2.0-5.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "migtissera/Synthia-7B-v3.0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "masonym/gigabyte-250-testing": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Myashka/gpt-imdb-ipo_annealing": [
    "model.safetensors"
  ],
  "Chungfan/llama-2-7b-chat-guanaco": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/SG-Raccoon-Yi-200k-2.0-6.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "atrujill/falcon-7b-instruct-ft-truthful_qa": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "PMrtn/zephyr-7b-beta-QLoRA_PrefixTune_PlainText_v1.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Weyaxi/Neural-una-cybertron-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "banghua/openchat-3.5-p3o-tog-rf-ckpt3k": [
    "hf_model/model-00001-of-00003.safetensors",
    "hf_model/model-00002-of-00003.safetensors",
    "hf_model/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "faizalnf1800/clm_gpt2_scifi_webnovel2": [
    "model.safetensors"
  ],
  "dim/tiny-llama-2T-open-orca-ru-4100-step": [
    "model.safetensors"
  ],
  "Myashka/gpt-imdb-ipo-beta_0.1": [
    "model.safetensors"
  ],
  "mwitiderrick/shearedplats-2.7b-v2-instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Kunj120799/mis_sent": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Hoyeon/TinyLlama-1.1B-scratch": [
    "model.safetensors"
  ],
  "Hoyeon/TinyLlama-120M-scratch": [
    "model.safetensors"
  ],
  "Formid322/gooroomee2": [
    "checkpoint-60/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "silk-road/Chat-Haruhi_qwen_1_8": [
    "adapter_model.safetensors"
  ],
  "LoneStriker/Synthia-7B-v3.0-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "nyanxyz/f7ev-rxx4-6w2z-0": [
    "checkpoint-204/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "eldpswp99/sat-colab-llama2": [
    "checkpoint-170/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Synthia-7B-v3.0-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "nyanxyz/meta-llama2-fill-in-the-blank-0": [
    "adapter_model.safetensors",
    "checkpoint-120/adapter_model.safetensors"
  ],
  "LoneStriker/Synthia-7B-v3.0-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "hahnyuan/Llama-2-7b-hf-asvd90": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Synthia-7B-v3.0-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "nyanxyz/jzrg-9kk1-w2zw-0": [
    "adapter_model.safetensors",
    "checkpoint-340/adapter_model.safetensors"
  ],
  "LoneStriker/Synthia-7B-v3.0-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "eldpswp99/0rue-58p5-q7cs-0": [
    "checkpoint-680/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "chargoddard/servile-harpsichord-cdpo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "masonym/gigabyte-1k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "brucethemoose/CaPlatTessDolXaBoros-Yi-34B-200K-DARE-Ties": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "banghua/openchat-3.5-p3o-tog-rf-ckpt2k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Erynan/gpt2-imdb-pos-v2": [
    "model.safetensors"
  ],
  "ngoan/NgoanYi": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "eldpswp99/dding-blank-0": [
    "checkpoint-180/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "eldpswp99/cqim-7pj9-tgo3-0": [
    "checkpoint-180/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "banghua/openchat-3.5-p3o-tog-rf-ckpt4k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hahnyuan/Llama-2-7b-hf-asvd95": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "eldpswp99/dding-blank-1-0": [
    "checkpoint-200/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "nyanxyz/fill-in-the-blank-lr-2-e-5-0": [
    "adapter_model.safetensors",
    "checkpoint-150/adapter_model.safetensors"
  ],
  "hahnyuan/Llama-2-7b-hf-asvd85": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hahnyuan/Llama-2-13b-hf-asvd95": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "himanshubeniwal/gpt2_imdb_all2": [
    "model.safetensors"
  ],
  "himanshubeniwal/model": [
    "model.safetensors"
  ],
  "brucethemoose/CaPlatTessDolXaBoros-Yi-34B-200K-DARE-Ties-HighDensity": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Myashka/gpt-imdb-dpo_annealing": [
    "model.safetensors"
  ],
  "hahnyuan/Llama-2-13b-hf-asvd90": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "eldpswp99/h5p0-k9qt-vi3h-0": [
    "adapter_model.safetensors",
    "checkpoint-210/adapter_model.safetensors"
  ],
  "athirdpath/Iambe-RP-cDPO-20b-ALT": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "Myashka/gpt-imdb-ipo-beta_0.3": [
    "model.safetensors"
  ],
  "downbaddie34/sl-u7": [
    "model.safetensors"
  ],
  "nyanxyz/fill-in-the-blank-prompt-4-lr-20-e-5-ma-0": [
    "checkpoint-150/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TinyPixel/pythia-14m": [
    "model.safetensors"
  ],
  "Tordjx/all-MiniLM-L6-v2": [
    "model.safetensors"
  ],
  "Sao10K/Venomia-m7": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "cungnlp/testPushOnHub": [
    "model.safetensors"
  ],
  "Fah-d/bert-squad": [
    "model.safetensors"
  ],
  "jawadmohmmad/tinyllama-company-label2-model": [
    "model.safetensors"
  ],
  "cosimoiaia/Loquace-Wizard-13B": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "satpalsr/NeuralHermes-2.5-Mistral-7B-DPO": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jawadmohmmad/testcopany2": [
    "model.safetensors"
  ],
  "jai558/financial-qna-gpt2": [
    "model.safetensors"
  ],
  "jawadmohmmad/tinyllama-companylablel-test-model": [
    "model.safetensors"
  ],
  "TheBloke/OrcaMaid-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/OrcaMaid-13B-AWQ": [
    "model.safetensors"
  ],
  "camelCase01/tinystarcoder-rlhf-model": [
    "model.safetensors"
  ],
  "dim/tiny-llama-2T-open-orca-ru-5000-step": [
    "model.safetensors"
  ],
  "Felladrin/Sheared-Pythia-160m-WebGLM-QA": [
    "model.safetensors"
  ],
  "Kooten/Rose-20B-3bpw-exl2": [
    "output.safetensors"
  ],
  "Kooten/Rose-20B-6bpw-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "malhajar/meditron-7b-chat": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/bling-stable-lm-3b-4e1t-v0-GPTQ": [
    "model.safetensors"
  ],
  "Weni/ZeroShot-john-e3-3.0.3-Mistral-7b-Multilanguage-3.0.3-AWQ": [
    "model.safetensors"
  ],
  "WebraftAI/synapsellm-7b-mistral-v0.5-preview": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "78health/neural-chat-7b-v3-1-function-calling": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ramixpe/llama-2-7b-bgp_version1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "DiscoResearch/DiscoLM-mixtral-8x7b-v2": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "TheBloke/Synthia-7B-v3.0-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Synthia-7B-v3.0-AWQ": [
    "model.safetensors"
  ],
  "truongghieu/deci-finetuned_Prj2": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Zakia/gpt2-drugscom_depression_reviews": [
    "model.safetensors"
  ],
  "Shresthadev403/bert-base-banking77-pt2": [
    "model.safetensors"
  ],
  "SamiA1234/GooseBot": [
    "model.safetensors"
  ],
  "Asude/gpt2-tr-40-it": [
    "model.safetensors"
  ],
  "WebraftAI/synapsellm-7b-mistral-v0.5-preview2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "banghua/openchat-3.5-p3o-tog-rf-ckpt6k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "brucethemoose/CaPlatTessDolXaBoros-Yi-34B-200K-DARE-Ties-ExtremeDensity": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "WebraftAI/synapsellm-7b-mistral-v0.4-preview3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "one-man-army/una-xaberius-34b-v1beta-8bit-16k": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "jaigouk/MetaMath-Cybertron-Starling-Ruby": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Weni/ZeroShot-3.1.0-Mistral-7b-Multilanguage-3.0.3-AWQ": [
    "model.safetensors"
  ],
  "areegtarek/mini_mistral_7b": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/DiscoLM-120b-2.4bpw-h6-exl2-2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "TheBloke/DiscoLM-mixtral-8x7b-v2-GPTQ": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Ansoi/ans": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/SG-Raccoon-Yi-200k-2.0-8.0bpw-h8-exl2": [
    "output-00001-of-00007.safetensors",
    "output-00002-of-00007.safetensors",
    "output-00003-of-00007.safetensors",
    "output-00004-of-00007.safetensors",
    "output-00005-of-00007.safetensors",
    "output-00006-of-00007.safetensors",
    "output-00007-of-00007.safetensors"
  ],
  "chiraglakhanpal/Legal": [
    "fine_tuned_gpt2_E10_Small/model.safetensors",
    "fine_tuned_gpt2_E25_Large/model.safetensors",
    "fine_tuned_gpt2_E50_Small/model.safetensors"
  ],
  "LoneStriker/go-bruins-3.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "tylercross/socrates": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "KnutJaegersberg/Protomorph-34b-200k-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rwitz/go-bruins-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "grimulkan/aurelian-alpha0.1-70b-rope8-32K-fp16": [
    "model-00001-of-00035.safetensors",
    "model-00002-of-00035.safetensors",
    "model-00003-of-00035.safetensors",
    "model-00004-of-00035.safetensors",
    "model-00005-of-00035.safetensors",
    "model-00006-of-00035.safetensors",
    "model-00007-of-00035.safetensors",
    "model-00008-of-00035.safetensors",
    "model-00009-of-00035.safetensors",
    "model-00010-of-00035.safetensors",
    "model-00011-of-00035.safetensors",
    "model-00012-of-00035.safetensors",
    "model-00013-of-00035.safetensors",
    "model-00014-of-00035.safetensors",
    "model-00015-of-00035.safetensors",
    "model-00016-of-00035.safetensors",
    "model-00017-of-00035.safetensors",
    "model-00018-of-00035.safetensors",
    "model-00019-of-00035.safetensors",
    "model-00020-of-00035.safetensors",
    "model-00021-of-00035.safetensors",
    "model-00022-of-00035.safetensors",
    "model-00023-of-00035.safetensors",
    "model-00024-of-00035.safetensors",
    "model-00025-of-00035.safetensors",
    "model-00026-of-00035.safetensors",
    "model-00027-of-00035.safetensors",
    "model-00028-of-00035.safetensors",
    "model-00029-of-00035.safetensors",
    "model-00030-of-00035.safetensors",
    "model-00031-of-00035.safetensors",
    "model-00032-of-00035.safetensors",
    "model-00033-of-00035.safetensors",
    "model-00034-of-00035.safetensors",
    "model-00035-of-00035.safetensors"
  ],
  "LoneStriker/go-bruins-4.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "LoneStriker/go-bruins-5.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "LoneStriker/go-bruins-6.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "LoneStriker/DiscoLM-120b-2.65bpw-h6-exl2-2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "LoneStriker/go-bruins-8.0bpw-h8-exl2-2": [
    "output.safetensors"
  ],
  "jaigouk/go-bruins-ruby-bf16": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dim/tiny-llama-2T-open-orca-ru-6300-step": [
    "model.safetensors"
  ],
  "TheBloke/go-bruins-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/go-bruins-AWQ": [
    "model.safetensors"
  ],
  "KnutJaegersberg/Walter-Falcon-1B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Venus-103b-v1.1-AWQ": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "houbrother49/test_train_llama-0": [
    "adapter_model.safetensors",
    "checkpoint-3156/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/DiscoLM-120b-3.0bpw-h6-exl2-2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "LoneStriker/Aetheria-L2-70B-2.4bpw-h6-exl2-2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "Weyaxi/OpenHermes-2.5-neural-chat-v3-3-Slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Weyaxi/MetaMath-OpenHermes-2.5-neural-chat-v3-3-Slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "chargoddard/piano-medley-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "josedonoso/git-finetuning-bananas-dataset-v1": [
    "model.safetensors"
  ],
  "Katpeeler/midi_model_1": [
    "model.safetensors"
  ],
  "LoneStriker/Aetheria-L2-70B-3.0bpw-h6-exl2-2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "dim/tiny-llama-2T-open-orca-ru-6900-step": [
    "model.safetensors"
  ],
  "atom92/medical_lama_2_ultra": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Adithya7Shankar/git-base-coco-pokemon": [
    "model.safetensors"
  ],
  "LoneStriker/Aetheria-L2-70B-4.0bpw-h6-exl2-2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "athirdpath/Iambe-RP-cDPO-20b-v2": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "Yhyu13/Xwin-Math-7B-V1.0-QUIP-2bit": [
    "model.safetensors"
  ],
  "ArtifactAI/arxiv-physics-instruct-mistral-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "limitium/ruGPT-3.5-13B-Kilusha": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ivanzhouyq/llama2_7b_viggo_lora": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Aetheria-L2-70B-4.65bpw-h6-exl2-2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "Katpeeler/midi_model_2": [
    "model.safetensors"
  ],
  "jawadmohmmad/tinyllama-bangla-test-model": [
    "model.safetensors"
  ],
  "shleeeee/mistral-ko-tech-science-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "aidansys17/s2zs-p1o2-zl4f-0": [
    "adapter_model.safetensors",
    "checkpoint-41025/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "HY-KDPARK/llama-2-koen-13b-sft-v0.3": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "athirdpath/Sydney_Megamind-20b": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "shkang/zephyr-7b-sft-lora-accum8-lr5e_5": [
    "adapter_model.safetensors"
  ],
  "LoneStriker/go-bruins-v2-3.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "LoneStriker/go-bruins-v2-4.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "LoneStriker/go-bruins-v2-5.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "LoneStriker/go-bruins-v2-6.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "LoneStriker/go-bruins-v2-8.0bpw-h8-exl2-2": [
    "output.safetensors"
  ],
  "hahnyuan/Llama-2-13b-hf-asvd85": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "LoneStriker/Aetheria-L2-70B-5.0bpw-h6-exl2-2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "brrbaral/fineTune_Demo2": [
    "adapter_model.safetensors",
    "checkpoint-1066/adapter_model.safetensors"
  ],
  "Rijgersberg/GEITje-7B-chat": [
    "checkpoint-1182/model-00001-of-00003.safetensors",
    "checkpoint-1182/model-00002-of-00003.safetensors",
    "checkpoint-1182/model-00003-of-00003.safetensors",
    "checkpoint-2365/model-00001-of-00003.safetensors",
    "checkpoint-2365/model-00002-of-00003.safetensors",
    "checkpoint-2365/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "athirdpath/Psyonic_Sydney-20b": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "zzh112119/codeparrot-ds": [
    "model.safetensors"
  ],
  "OrnateAhmed/Test": [
    "adapter_model.safetensors",
    "checkpoint-9843/adapter_model.safetensors"
  ],
  "We-Want-GPU/Yi-Ko-SFT-FULL": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "update0909/starcoderbase1b-personal-copilot-T4-40GB-colab": [
    "model.safetensors"
  ],
  "dim/tiny-llama-2T-open-orca-ru-7800-step": [
    "model.safetensors"
  ],
  "hotchpotch/youri-7b-sft-qa-context-jaqket-awq": [
    "model.safetensors"
  ],
  "grimulkan/aurelian-alpha0.1-70b-rope8-32K-2.4bpw_h6_exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "Q-bert/Merged-AGI-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Aetheria-L2-70B-6.0bpw-h6-exl2-2": [
    "output-00001-of-00007.safetensors",
    "output-00002-of-00007.safetensors",
    "output-00003-of-00007.safetensors",
    "output-00004-of-00007.safetensors",
    "output-00005-of-00007.safetensors",
    "output-00006-of-00007.safetensors",
    "output-00007-of-00007.safetensors"
  ],
  "TachyHealth/Thealth-Thealth-notus-7b_v1": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Sandiago21/zephyr-7b-alpha-llm-detect-ai-tpu-yes_no": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "athirdpath/Iambe-RP-DARE-20b": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "mncai/yi-34B-v4": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "vj1148/codellama2-finetuned-codex-fin": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/go-bruins-v2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/go-bruins-v2-AWQ": [
    "model.safetensors"
  ],
  "tollefj/nordavind-8bit-4096": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Aetheria-L2-70B-2.65bpw-h6-exl2-2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "vj1148/codellama2-finetuned-codex-vj-fin": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jaigouk/go-bruins-ruby-bf16-function-calling-v1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "yyjjtt/test-model2": [
    "model.safetensors"
  ],
  "dhairyakhant/llama2finetune": [
    "adapter_model.safetensors",
    "checkpoint-6/adapter_model.safetensors"
  ],
  "kyujinpy/PlatYi-34B-Llama-Q-v2": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "Tordjx/distilgpt2": [
    "model.safetensors"
  ],
  "TheBloke/smol-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/smol-7B-AWQ": [
    "model.safetensors"
  ],
  "Zakia/gpt2-drugscom_depression_reviews-hq-v1": [
    "model.safetensors"
  ],
  "Fredithefish/OpenZephyrChat": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "update0909/starcoderbase1b-personal-copilot-A100-40GB-colab-1b": [
    "model.safetensors"
  ],
  "johighness/grafiki-llm": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "blueapple8259/TinyKo": [
    "model.safetensors"
  ],
  "WenTee/NormalizeTimePythia-70m": [
    "model.safetensors"
  ],
  "dim/tiny-llama-2T-open-orca-ru-8400-step": [
    "model.safetensors"
  ],
  "mjkimmjmj/SDC_Llama2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/lzlv_70b_fp16_hf-2.4bpw-h6-exl2-2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "mjkimmjmj/SDC_Mistral": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "thanhnew2001/starcoder-7b-taipy10a": [
    "model.safetensors"
  ],
  "WebraftAI/synapsellm-7b-mistral-v0.6-preview1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ce-lery/japanese-mistral-300m-base": [
    "model.safetensors"
  ],
  "LoneStriker/lzlv_70b_fp16_hf-2.65bpw-h6-exl2-2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "thanhnew2001/llama-7b-taipy11": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Astrea/DialoGPT-small-akari": [
    "model.safetensors"
  ],
  "TheBloke/openbuddy-deepseek-67b-v15-base-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/openbuddy-deepseek-67b-v15-base-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "msahabudinov/model1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Marcoroni-7B-v2-AWQ": [
    "model.safetensors"
  ],
  "BelalTab/finetuned-llama2-2048-v3.0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SergeiZu/llama-2-7b-sentiment140": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Deci/DeciLM-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Marcoroni-7B-v3-AWQ": [
    "model.safetensors"
  ],
  "Deci/DeciLM-7B-instruct": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FluffyKaeloky/Lila-103B-L2-exl2-5.0bpw": [
    "output-00001-of-00008.safetensors",
    "output-00002-of-00008.safetensors",
    "output-00003-of-00008.safetensors",
    "output-00004-of-00008.safetensors",
    "output-00005-of-00008.safetensors",
    "output-00006-of-00008.safetensors",
    "output-00007-of-00008.safetensors",
    "output-00008-of-00008.safetensors"
  ],
  "TheBloke/CaPlatTessDolXaBoros-Yi-34B-200K-DARE-Ties-HighDensity-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "dim/tiny-llama-2T-open-orca-ru-9000-step": [
    "model.safetensors"
  ],
  "abraxasu/opt_125m_summarization": [
    "model.safetensors"
  ],
  "Sharathhebbar24/Instruct_GPT_small": [
    "model.safetensors"
  ],
  "FluffyKaeloky/Lila-103B-L2-exl2-4.5bpw": [
    "output-00001-of-00007.safetensors",
    "output-00002-of-00007.safetensors",
    "output-00003-of-00007.safetensors",
    "output-00004-of-00007.safetensors",
    "output-00005-of-00007.safetensors",
    "output-00006-of-00007.safetensors",
    "output-00007-of-00007.safetensors"
  ],
  "Katpeeler/midi_model_3": [
    "model.safetensors"
  ],
  "danny0122/stablelm-base-alpha-3b-gptq-4bits": [
    "model.safetensors"
  ],
  "realshyfox/Llama2-7b-500": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mistralai/Mixtral-8x7B-Instruct-v0.1": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "TheBloke/Marcoroni-7B-v2-GPTQ": [
    "model.safetensors"
  ],
  "AliArshad/Psychology": [
    "model.safetensors"
  ],
  "Asude/gpt2-imdb-tr-10-it": [
    "model.safetensors"
  ],
  "msahabudinov/model2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FluffyKaeloky/Lila-103B-L2-exl2-3.0bpw": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "athirdpath/Iambe-RP-DARE-20b-DENSE": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "TheBloke/Marcoroni-7B-v3-GPTQ": [
    "model.safetensors"
  ],
  "LoneStriker/Magicoder-S-CL-7B-3.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "LoneStriker/Magicoder-S-CL-7B-4.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "xonimoy/Unh_model": [
    "model.safetensors"
  ],
  "LoneStriker/Magicoder-S-CL-7B-5.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "TheBloke/CaPlatTessDolXaBoros-Yi-34B-200K-DARE-Ties-HighDensity-GPTQ": [
    "model.safetensors"
  ],
  "LoneStriker/Magicoder-S-CL-7B-6.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "misbah1955/sultana3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Magicoder-S-CL-7B-8.0bpw-h8-exl2-2": [
    "output.safetensors"
  ],
  "dim/tiny-llama-2T-open-orca-ru-9500-step": [
    "model.safetensors"
  ],
  "NeverSleep/Noromaid-13b-v0.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "bascr/chatbot": [
    "adapter_model.safetensors",
    "checkpoint-596/adapter_model.safetensors"
  ],
  "hedronstone/OpenHermes-7B-Symbolic": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "alif-munim/mistral-7b-base-instruct-qlora": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/lzlv_70b_fp16_hf-4.0bpw-h6-exl2-2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "alif-munim/mistral-7b-instruct-2_avg": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "alif-munim/mistral-7b-instruct-4_avg": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "gatoch/gpt2-small": [
    "model.safetensors"
  ],
  "alif-munim/mistral-7b-instruct-8_avg": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "w266finalproject/Turing7b-instruct": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "nuprl/EditCoder-6.7b-v1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "gatoch/alpaca-llama-2-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "topeomole/llama-dlm-1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/lzlv_70b_fp16_hf-4.65bpw-h6-exl2-2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "TheBloke/Merged-AGI-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Merged-AGI-7B-GPTQ": [
    "model.safetensors"
  ],
  "dim/tiny-llama-2T-open-orca-ru-10000-step": [
    "model.safetensors"
  ],
  "gnurtqh/friday": [
    "model.safetensors"
  ],
  "rwitz/dec10": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/open-instruct-human-mix-65B-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/open-instruct-human-mix-65B-fp16": [
    "model-00001-of-00054.safetensors",
    "model-00002-of-00054.safetensors",
    "model-00003-of-00054.safetensors",
    "model-00004-of-00054.safetensors",
    "model-00005-of-00054.safetensors",
    "model-00006-of-00054.safetensors",
    "model-00007-of-00054.safetensors",
    "model-00008-of-00054.safetensors",
    "model-00009-of-00054.safetensors",
    "model-00010-of-00054.safetensors",
    "model-00011-of-00054.safetensors",
    "model-00012-of-00054.safetensors",
    "model-00013-of-00054.safetensors",
    "model-00014-of-00054.safetensors",
    "model-00015-of-00054.safetensors",
    "model-00016-of-00054.safetensors",
    "model-00017-of-00054.safetensors",
    "model-00018-of-00054.safetensors",
    "model-00019-of-00054.safetensors",
    "model-00020-of-00054.safetensors",
    "model-00021-of-00054.safetensors",
    "model-00022-of-00054.safetensors",
    "model-00023-of-00054.safetensors",
    "model-00024-of-00054.safetensors",
    "model-00025-of-00054.safetensors",
    "model-00026-of-00054.safetensors",
    "model-00027-of-00054.safetensors",
    "model-00028-of-00054.safetensors",
    "model-00029-of-00054.safetensors",
    "model-00030-of-00054.safetensors",
    "model-00031-of-00054.safetensors",
    "model-00032-of-00054.safetensors",
    "model-00033-of-00054.safetensors",
    "model-00034-of-00054.safetensors",
    "model-00035-of-00054.safetensors",
    "model-00036-of-00054.safetensors",
    "model-00037-of-00054.safetensors",
    "model-00038-of-00054.safetensors",
    "model-00039-of-00054.safetensors",
    "model-00040-of-00054.safetensors",
    "model-00041-of-00054.safetensors",
    "model-00042-of-00054.safetensors",
    "model-00043-of-00054.safetensors",
    "model-00044-of-00054.safetensors",
    "model-00045-of-00054.safetensors",
    "model-00046-of-00054.safetensors",
    "model-00047-of-00054.safetensors",
    "model-00048-of-00054.safetensors",
    "model-00049-of-00054.safetensors",
    "model-00050-of-00054.safetensors",
    "model-00051-of-00054.safetensors",
    "model-00052-of-00054.safetensors",
    "model-00053-of-00054.safetensors",
    "model-00054-of-00054.safetensors"
  ],
  "TheBloke/open-instruct-human-mix-65B-GPTQ": [
    "model.safetensors"
  ],
  "Fredithefish/ZephyrCognitionNoTokenizer": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Riddlevv/distilgpt2-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "danny0122/Llama-2-7b-hf-gptq-3bits": [
    "model.safetensors"
  ],
  "danny0122/Llama-2-7b-hf-gptq-4bits": [
    "model.safetensors"
  ],
  "wang7776/Llama-2-7b-chat-hf-10-sparsity": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Nethena-20B-Glued-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Nethena-20B-Glued-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "danny0122/Llama-2-7b-hf-gptq-3bitssafe": [
    "model.safetensors"
  ],
  "danny0122/Llama-2-7b-hf-gptq-4bitssafe": [
    "model.safetensors"
  ],
  "ai-aerospace/autotrain-ams_v0.1_100_TinyLlama-1.1B-Chat-v0.1": [
    "adapter_model.safetensors",
    "checkpoint-30/adapter_model.safetensors"
  ],
  "P1ayer-1/TinyStories": [
    "model.safetensors"
  ],
  "Sharathhebbar24/Instruct_GPT_small_v1": [
    "model.safetensors"
  ],
  "TheBloke/Velara-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Velara-GPTQ": [
    "model.safetensors"
  ],
  "ademax/gpt2": [
    "model.safetensors"
  ],
  "abhi757/llama-2-7b-chat-paper-to-slides": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TinyPixel/pythia-elm": [
    "model.safetensors"
  ],
  "TheBloke/leo-hessianai-70B-chat-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/leo-hessianai-70B-chat-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "danny0122/stablelm-base-alpha-3b-gptq-3bits": [
    "model.safetensors"
  ],
  "danny0122/stablelm-base-alpha-3b-gptq-3bitssafe": [
    "model.safetensors"
  ],
  "TrumpBiden/zephyr-7b-dpo-lora": [
    "adapter_model.safetensors"
  ],
  "athirdpath/Iambe-RP-v3-20b": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "abraxasu/opt_350m_summarization": [
    "model.safetensors"
  ],
  "TinyLlama/TinyLlama-1.1B-intermediate-step-1195k-token-2.5T": [
    "model.safetensors"
  ],
  "AIFT/PACK-13b-v1.1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "PauGarza/python_solver_gpt2": [
    "model.safetensors"
  ],
  "Ja-ck/Mistral-instruct-IPO-Y24-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "danny0122/stablelm-base-alpha-3b-gptq-4bitssafe": [
    "model.safetensors"
  ],
  "daptheHuman/merak-7b-candi-borobudur-v1-8bit-merged": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "srikarkashyap/phi-1_5-finetuned-medquad": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "tokyotech-llm/Swallow-70b-instruct-hf": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "Weyaxi/Seraph-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LDCC/LDCC-Instruct-Llama-2-ko-13B-v1.7": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "brucethemoose/CaPlatTessDolXaBoros-34B-200K-exl2-4bpw-fiction": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "brucethemoose/CaPlatTessDolXaBoros-34B-200K-exl2-3.1bpw-fiction": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "Shresthadev403/food_recipe_generation": [
    "model.safetensors"
  ],
  "shleeeee/mistral-ko-exo-mrc-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "npvinHnivqn/bloom-560m-vi-beta-v01": [
    "model.safetensors"
  ],
  "gizmo-ai/green-words-sheared-llama": [
    "model.safetensors"
  ],
  "TinyPixel/pythia-cl": [
    "model.safetensors"
  ],
  "madatnlp/marcoroni-7b-v3-safetensor": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "TitanML/llama2-13b-chat-4bit-AWQ": [
    "model.safetensors"
  ],
  "TitanML/llama2-70b-chat-4bit-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "mncai/mistral-7b-v5": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "taehallm/mois-mis-inst-7b": [
    "adapter_model.safetensors"
  ],
  "TitanML/llama2-7b-base-4bit-AWQ": [
    "model.safetensors"
  ],
  "TitanML/llama2-13b-base-4bit-AWQ": [
    "model.safetensors"
  ],
  "Elimserutan/my_awesome_eli5_clm-model": [
    "model.safetensors"
  ],
  "TitanML/llama2-70b-base-4bit-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "mandy012/Mandar-Stark-TS": [
    "model.safetensors"
  ],
  "PistachioAlt/Synatra-MCS-7B-v0.3-RP-Slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "thorirhrafn/llama_test": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Ba2han/BruinsV2-OpHermesNeu-11B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jan-hq/supermario-v1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jjqsdq/openchat_3.5_ft_1211": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Mihaiii/Pallas-0.3": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "vishu2604/HireAI": [
    "adapter_model.safetensors",
    "checkpoint-192/adapter_model.safetensors"
  ],
  "Weni/ZeroShot-3.1.1-Mistral-7b-Multilanguage-3.0.3-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/OpenHermes-2.5-neural-chat-v3-3-Slerp-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/OpenHermes-2.5-neural-chat-v3-3-Slerp-AWQ": [
    "model.safetensors"
  ],
  "TheBlokeAI/Mixtral-tiny-GPTQ": [
    "model.safetensors"
  ],
  "hamxea/Mistral-7B-v0.1-activity-fine-tuned-v3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/leo-hessianai-70B-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/leo-hessianai-70B-GPTQ": [
    "model.safetensors"
  ],
  "jan-hq/supermario-v2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "bienpr/Llama-2-7B-Chat-GPTQ": [
    "model.safetensors"
  ],
  "ce-lery/japanese-mistral-300m-instruction": [
    "model.safetensors"
  ],
  "mistralai/Mistral-7B-Instruct-v0.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Mihaiii/Pallas-0.4": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "mwitiderrick/open_llama_3b_code_instruct_0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mncai/llama2-13b-dpo-v6": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Toten5/Marcoroni-neural-chat-7B-v1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "nielsr/cogvlm-chat-hf": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "PauGarza/python_solver_gpt2.1": [
    "model.safetensors"
  ],
  "srikarkashyap/phi-1_5-finetuned-medquad_hyperparam": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Mixtral-8x7B-v0.1-GPTQ": [
    "model.safetensors"
  ],
  "yuasosnin/imdb-dpo_hinge": [
    "model.safetensors"
  ],
  "amazingvince/where-llambo-7b-dpo-full": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "yuasosnin/imdb-dpo_sigmoid": [
    "model.safetensors"
  ],
  "kyujinpy/PlatYi-34B-Llama-Q-v3": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "Ekarat/mistral-7b-mj-finetuned": [
    "adapter_model.safetensors",
    "checkpoint-3/adapter_model.safetensors"
  ],
  "AliArshad/Pyscho_bot": [
    "model.safetensors"
  ],
  "yuasosnin/imdb-dpo_forwardkl": [
    "model.safetensors"
  ],
  "huskyhong/noname-ai-v2-light": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "JGlang/llama2-testserveurIRMAR": [
    "adapter_model.safetensors",
    "checkpoint-112/adapter_model.safetensors"
  ],
  "HumanF-MarkrAI/Yi_lee-SFT-v2-6B": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "iproskurina/opt-125m-gptq-4bit": [
    "model.safetensors"
  ],
  "minhhiepcr/quantizated_Mistral-7B-Instruct-v0.1-awq": [
    "model.safetensors"
  ],
  "iproskurina/opt-350m-gptq-4bit": [
    "model.safetensors"
  ],
  "joyfine/vicuna-7b-fine-tuning_truthfulQA_16_20": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Globaly/Globaly-1-Familias-es-v0.1": [
    "adapter_model.safetensors",
    "checkpoint-2484/adapter_model.safetensors"
  ],
  "iproskurina/opt-1.3b-gptq-4bit": [
    "model.safetensors"
  ],
  "Globaly/Globaly-1-Clases-es-v0.1": [
    "adapter_model.safetensors",
    "checkpoint-3340/adapter_model.safetensors"
  ],
  "bio-datasets/gpt2-medium-style_transfer-epoch-0": [
    "model.safetensors"
  ],
  "Globaly/Globaly-1-Ladrillos-es-v0.1": [
    "adapter_model.safetensors",
    "checkpoint-3500/adapter_model.safetensors"
  ],
  "yuasosnin/imdb-dpo_alphakl0.3": [
    "model.safetensors"
  ],
  "iproskurina/opt-2.7b-gptq-4bit": [
    "model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-indef-anan-1e-4": [
    "model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-indef-anan-1e-3": [
    "model.safetensors"
  ],
  "joyfine/vicuna-7b-fine-tuning_truthfulQA_32_20": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "iproskurina/opt-6.7b-gptq-4bit": [
    "model.safetensors"
  ],
  "jan-hq/supermario-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/LlamaGuard-7B-AWQ": [
    "model.safetensors"
  ],
  "marcsun13/Mixtral-tiny-GPTQ": [
    "model.safetensors"
  ],
  "joyfine/vicuna-7b-fine-tuning_truthfulQA_64_20": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ArtifactAI/arxiv-nlp-instruct-mistral-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Mixtral-8x7B-Instruct-v0.1-GPTQ": [
    "model.safetensors"
  ],
  "nsfwthrowitaway69/Venus-120b-v1.1": [
    "model-00001-of-00025.safetensors",
    "model-00002-of-00025.safetensors",
    "model-00003-of-00025.safetensors",
    "model-00004-of-00025.safetensors",
    "model-00005-of-00025.safetensors",
    "model-00006-of-00025.safetensors",
    "model-00007-of-00025.safetensors",
    "model-00008-of-00025.safetensors",
    "model-00009-of-00025.safetensors",
    "model-00010-of-00025.safetensors",
    "model-00011-of-00025.safetensors",
    "model-00012-of-00025.safetensors",
    "model-00013-of-00025.safetensors",
    "model-00014-of-00025.safetensors",
    "model-00015-of-00025.safetensors",
    "model-00016-of-00025.safetensors",
    "model-00017-of-00025.safetensors",
    "model-00018-of-00025.safetensors",
    "model-00019-of-00025.safetensors",
    "model-00020-of-00025.safetensors",
    "model-00021-of-00025.safetensors",
    "model-00022-of-00025.safetensors",
    "model-00023-of-00025.safetensors",
    "model-00024-of-00025.safetensors",
    "model-00025-of-00025.safetensors"
  ],
  "TheBloke/LlamaGuard-7B-GPTQ": [
    "model.safetensors"
  ],
  "joyfine/vicuna-7b-fine-tuning_truthfulQA_128_20": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Undi95/Clover3-17B": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "louislian2341/output1": [
    "model.safetensors"
  ],
  "marcsun13/Mixtral-8x7B-v0.1-GPTQ": [
    "model.safetensors"
  ],
  "DopeorNope/Yi_lee-v2-DPO-6B": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "alessio21/Mistral-7B-v0.1-8bit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "HydraIndicLM/mistral-MoQlora-punjabi-expert": [
    "adapter_model.safetensors"
  ],
  "kheopsai/kheops_mistral_v6": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "brucethemoose/CaPlatTessDolXaBoros-exl2-2.7bpw-fiction": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "HydraIndicLM/mistral-MoQlora-tamil-expert": [
    "adapter_model.safetensors"
  ],
  "joyfine/vicuna-7b-fine-tuning_truthfulQA_256_20": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "alessio21/Mistral-7B-chat-v0.1-8bit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "simonveitner/SeraphMarcoroni-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/mixtral-8x7b-v0.1-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Mixtral-8x7B-Instruct-v0.1-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rwitz2/pee": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "wang7776/Llama-2-7b-chat-hf-30-sparsity": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Kooten/Clover3-17B-8bpw-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Kooten/Clover3-17B-6bpw-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Kooten/Clover3-17B-5bpw-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "TheBloke/Mistral-7B-Instruct-v0.2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Mistral-7B-Instruct-v0.2-AWQ": [
    "model.safetensors"
  ],
  "Fredithefish/ZephyrCognition": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Fredh99/llama-2-7b-sft-lora": [
    "adapter_model.safetensors"
  ],
  "joyfine/vicuna-7b-fine-tuning_truthfulQA_512_20": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ArtifactAI/arxiv-math-instruct-mistral-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Clover3-17B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Clover3-17B-AWQ": [
    "model.safetensors"
  ],
  "erave02/meta_llama_13b_hf": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "bedust/tinyllama-colorist-v2": [
    "model.safetensors"
  ],
  "Fredithefish/MadMix-v0.1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "TheBloke/Rogue-Rose-103b-v0.2-GPTQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Rogue-Rose-103b-v0.2-AWQ": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "gatoch/hf_test": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mesolitica/mallam-1.1b-20k-instructions": [
    "model.safetensors"
  ],
  "mesolitica/mallam-5b-20k-instructions": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mesolitica/mallam-3b-20k-instructions": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "inswave/AISquare-Instruct-yi-ko-6b-v0.9.16": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-indef_articles_with_pl_nouns_removal-1e-3": [
    "model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-all_det_removal-1e-3": [
    "model.safetensors"
  ],
  "Open-Orca/Mixtral-SlimOrca-8x7B": [
    "adapters/adapter_model.safetensors",
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "jtatman/zephyr-3b-gravityfalls": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "fokyoum9/CodeLlama7B-Text2SQL": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ArtifactAI/arxiv-physics-instruct-mistral-7b-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "daptheHuman/merak-7b-candi-borobudur-v2-8bit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jan-hq/supermario-slerp-v2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "AliArshad/Pyscho_bot_1": [
    "model.safetensors"
  ],
  "ValdoLab/base_model_llama-2-7b-chat-hf": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ValdoLab/base_model_llama-2-13b-chat-hf": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ValdoLab/base_model_llama-2-70b-chat-hf": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "netcat420/MHENN": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "devolvedaihub/LunaChat-V-1.0": [
    "adapter_model.safetensors"
  ],
  "aurora-m/Aurora-100k-hf": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "banghua/openchat3.5_apa2_log_ckpt4k": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "SAGI-1/AGI_1_2_SFT_SYMBOLIC_FACTS_2_FOL_LEVEL_1_V2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jan-hq/Mistral-7B-Instruct-v0.2-SLERP": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "kurusunagisa/39_lora_v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Rijgersberg/Mistral-7B-v0.1-chat-nl": [
    "checkpoint-1182/model-00001-of-00003.safetensors",
    "checkpoint-1182/model-00002-of-00003.safetensors",
    "checkpoint-1182/model-00003-of-00003.safetensors",
    "checkpoint-2365/model-00001-of-00003.safetensors",
    "checkpoint-2365/model-00002-of-00003.safetensors",
    "checkpoint-2365/model-00003-of-00003.safetensors",
    "checkpoint-3546/model-00001-of-00003.safetensors",
    "checkpoint-3546/model-00002-of-00003.safetensors",
    "checkpoint-3546/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Q-bert/Terminis-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "SeeThink/STEVE-13b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "augmxnt/shisa-7b-v1-exl2-h6-4.63bpw": [
    "cal_data.safetensors",
    "input_states.safetensors",
    "output.safetensors"
  ],
  "Pray123/Total": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Shawn156/models-codeparrot": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "openchat/openchat-3.5-1210": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Shawn156/models-small-codeparrot": [
    "model.safetensors"
  ],
  "TheBloke/dopeystableplats-3b-v1-GPTQ": [
    "model.safetensors"
  ],
  "abraxasu/opt_350m_summarization_rlhf": [
    "model.safetensors"
  ],
  "bienpr/Llama-2-7b-chat-hf": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "dmocnik/distilgpt2_lyrics-model": [
    "model.safetensors"
  ],
  "Kooten/Clover3-17B-4bpw-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "perlthoughts/Mistral-11B-Instruct-v0.2": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "jan-hq/Mistral-7B-Instruct-v0.2-DARE": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "projecte-aina/FLOR-760M": [
    "model.safetensors"
  ],
  "chargoddard/mixtralnt-4x7b-test": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "TheBloke/neural-chat-7B-v3-3-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/neural-chat-7B-v3-3-GPTQ": [
    "model.safetensors"
  ],
  "jtatman/stablelm-zephyr-3b-gfalls": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Shresthadev403/food-recipe-generation": [
    "model.safetensors",
    "tmp-checkpoint-50/model.safetensors"
  ],
  "TheBloke/AmberChat-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/AmberChat-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Amber-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Amber-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Seraph-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Seraph-7B-AWQ": [
    "model.safetensors"
  ],
  "jan-hq/supermario-slerp-v3": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "gokul00060/codellama2-ARM-fin": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mesolitica/malaysian-mistral-7b-32k-instructions-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Loyola/practice-kullmmistral-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SAGI-1/brand_model_v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "upstage/SOLAR-10.7B-Instruct-v1.0": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "srihariEmids/phi-1_5-finetuned-emids-text": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Toten5/Marcoroni-neural-chat-7B-v2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/deepseek-coder-6.7b-instruct-3.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "LoneStriker/deepseek-coder-6.7b-instruct-4.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "simonveitner/Math-OpenHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "iproskurina/opt-13b-gptq-4bit": [
    "model.safetensors"
  ],
  "LoneStriker/deepseek-coder-6.7b-instruct-5.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "knkasa/llm-test-1b": [
    "adapter_model.safetensors"
  ],
  "LoneStriker/deepseek-coder-6.7b-instruct-6.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "intone/dromedary-7B-chat": [
    "adapter_model.safetensors",
    "checkpoint-1259/adapter_model.safetensors"
  ],
  "LoneStriker/deepseek-coder-6.7b-instruct-8.0bpw-h8-exl2-2": [
    "output.safetensors"
  ],
  "perevalov/AntModel-7B-XLLM-test-1-Demo": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "damerajee/gpt2-large-historical-quotes": [
    "adapter_model.safetensors"
  ],
  "yujiepan/mistral-tiny-random": [
    "model.safetensors"
  ],
  "aladaf/zephyr-7b-beta_standard_v0.1_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/v1olet_marcoroni-go-bruins-merge-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/v1olet_marcoroni-go-bruins-merge-7B-AWQ": [
    "model.safetensors"
  ],
  "yujiepan/mixtral-8xtiny-random": [
    "model.safetensors"
  ],
  "IbuNai/Mixtral-8x7B-v0.1": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "thanhnew2001/starcoder-1b-taipy12": [
    "model.safetensors"
  ],
  "jerryenebeli/mergeds": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "damerajee/gpt2-large-hist-quotes-2": [
    "model.safetensors"
  ],
  "upstage/SOLAR-10.7B-v1.0": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "afwefwrgpknp/mistral-7b-mj-finetuned": [
    "adapter_model.safetensors",
    "checkpoint-3/adapter_model.safetensors"
  ],
  "TheBloke/Merged-DPO-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Merged-DPO-7B-AWQ": [
    "model.safetensors"
  ],
  "aladaf/zephyr-7b-beta_standard_v0.1_gptq": [
    "model.safetensors"
  ],
  "one-man-army/una-neural-chat-v3-3-P2-OMA": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "viethq188/Rabbit-7B-v2-DPO-Chat": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Pray123/Total_500": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Fredithefish/MadMix-v0.2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "crumb/mixtral-e8-nano-1gt-test": [
    "model.safetensors"
  ],
  "TheBloke/supermario-v2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/supermario-v2-AWQ": [
    "model.safetensors"
  ],
  "GungYe/Mistral-7B-finetune-RAUM": [
    "checkpoint-2211/adapter_model.safetensors",
    "checkpoint-3844/adapter_model.safetensors",
    "checkpoint-4912/adapter_model.safetensors",
    "checkpoint-5796/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Pallas-0.3-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Pallas-0.3-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "argilla/notux-8x7b-v1": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "susmmukh/distilgpt2-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "LoneStriker/openchat-3.5-1210-3.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "LoneStriker/openchat-3.5-1210-4.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "LoneStriker/openchat-3.5-1210-5.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "LoneStriker/openchat-3.5-1210-6.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "LoneStriker/openchat-3.5-1210-8.0bpw-h8-exl2-2": [
    "output.safetensors"
  ],
  "5iveDesignStudio/TenderGPT-Festive-v2-0": [
    "adapter_model.safetensors",
    "checkpoint-2712/adapter_model.safetensors"
  ],
  "TheBloke/Synthia-MoE-v3-Mixtral-8x7B-GPTQ": [
    "model.safetensors"
  ],
  "abhamidi-1234/AdPulse": [
    "adapter_model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-all_det_removal-3e-3": [
    "model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-indef_articles_with_pl_nouns_removal-3e-3": [
    "model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-indef-anan-3e-4": [
    "model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-indef-anan-3e-3": [
    "model.safetensors"
  ],
  "TinyPixel/dlm": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Terminis-7B-AWQ": [
    "model.safetensors"
  ],
  "M1nd3xpan5i0nN3xus/Eros_Merge_Matrix_7b_1-0_Merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "domer20/gpt2-squad": [
    "model.safetensors"
  ],
  "TheBloke/pee-AWQ": [
    "model.safetensors"
  ],
  "viethq188/LeoScorpius-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "lazyDataScientist/Vector-Mistral-7B-v0.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dfurman/Mixtral-8x7B-Instruct-v0.1": [
    "adapter_model.safetensors"
  ],
  "TheBloke/SeraphMarcoroni-7B-AWQ": [
    "model.safetensors"
  ],
  "tli489/Llama-2-7b-hf-QLoRA-LongAlpaca-12k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "teilomillet/MiniMerlin-3b-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Marcoroni-neural-chat-7B-v1-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Pallas-0.4-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Pallas-0.4-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "KnutJaegersberg/Walter-BTLM-3B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "C0uchP0tat0/codeparrot-ds": [
    "model.safetensors"
  ],
  "martyn/llama2-megamerge-dare-13b-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Arc53/docsgpt-7b-mistral": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "tonigs/tests1": [
    "adapter_model.safetensors",
    "checkpoint-1/adapter_model.safetensors"
  ],
  "areegtarek/FT-Orca-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "gsomers-smarsh/llama2-7b-qlora-email-classifier2-merged": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "TheBloke/mixtralnt-4x7b-test-GPTQ": [
    "model.safetensors"
  ],
  "malteos/hermeo-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Weyaxi/Instruct-v0.2-Seraph-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "winkelstein/anna-7b-q8": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Hypersniper/The_Philosopher_Zephyr_7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "IndicRAGware/mistral-hindi-qlora-RAG-7b": [
    "adapter_model.safetensors"
  ],
  "TheBloke/OpenZephyrChat-AWQ": [
    "model.safetensors"
  ],
  "athirdpath/NSFW_DPO_Noromaid-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "openaccess-ai-collective/SlimOrca-DPO-Mixtral-8x7B": [
    "adapter_model.safetensors"
  ],
  "Holmeister/falcon-7b-ft": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tonigs/tests2": [
    "adapter_model.safetensors",
    "checkpoint-1/adapter_model.safetensors"
  ],
  "Norquinal/Mixtral-8x7B-claude-chat": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "MisterErt/projet_mistral": [
    "adapter_model.safetensors",
    "checkpoint-3/adapter_model.safetensors"
  ],
  "luozhuanggary/CAIT-13b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "SchubergPhilis/TinyLlama-1.1B-Chat-v0.6-ENG": [
    "model.safetensors"
  ],
  "TheBloke/Terminis-7B-GPTQ": [
    "model.safetensors"
  ],
  "ybelkada/Mixtral-8x7B-Instruct-v0.1-AWQ": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Sao10K/Ana-v1-m7": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "SchubergPhilis/TinyLlama-1.1B-Chat-v0.7-ENG": [
    "model.safetensors"
  ],
  "tli489/Llama-2-7b-hf-QLoRA-LongAlpaca-100-length-1k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "beberik/Nyxene-v3-11B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/pee-GPTQ": [
    "model.safetensors"
  ],
  "optimai/porne-0": [
    "adapter_model.safetensors",
    "checkpoint-9/adapter_model.safetensors"
  ],
  "TheBloke/SeraphMarcoroni-7B-GPTQ": [
    "model.safetensors"
  ],
  "athirdpath/NSFW_DPO_vmgb-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "yantli/backward_wiki40b_zh-cn": [
    "model.safetensors"
  ],
  "TheBloke/Marcoroni-neural-chat-7B-v1-GPTQ": [
    "model.safetensors"
  ],
  "Korventenn/dp-lora-o": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "diamantrsd/copywriting-generator-ver50k": [
    "model.safetensors"
  ],
  "athirdpath/Gamma-17b": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Code-33B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Code-33B-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "athirdpath/Beta-17b": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "adamo1139/Yi-34B-200K-AEZAKMI-v2": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "athirdpath/Alpha-17b": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "Aryanne/Zephyr-3.43B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "athirdpath/Delta-17b": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "zyh3826/20231206094523-pretrain-Llama-2-13b-hf-76000": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "iproskurina/Mistral-7B-gptq-4bit": [
    "model.safetensors"
  ],
  "TheBloke/OpenZephyrChat-GPTQ": [
    "model.safetensors"
  ],
  "mncai/llama2-13b-dpo-v7": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "daptheHuman/merak-7b-candi-borobudur-v1-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Bbrown44/aas_nlp_v1": [
    "model.safetensors"
  ],
  "Bbrown44/aas-ds-v1": [
    "model.safetensors"
  ],
  "mediocredev/stablelm-3b-instruct": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Locutusque/Orca-2-13b-SFT_v5": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "IbuNai/Mixtral-8x7B-v0.1-gptq-4bit": [
    "model-00001-of-00013.safetensors",
    "model-00002-of-00013.safetensors",
    "model-00003-of-00013.safetensors",
    "model-00004-of-00013.safetensors",
    "model-00005-of-00013.safetensors",
    "model-00006-of-00013.safetensors",
    "model-00007-of-00013.safetensors",
    "model-00008-of-00013.safetensors",
    "model-00009-of-00013.safetensors",
    "model-00010-of-00013.safetensors",
    "model-00011-of-00013.safetensors",
    "model-00012-of-00013.safetensors",
    "model-00013-of-00013.safetensors"
  ],
  "wangyiyang/llama-code-model-wangyy": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tokyotech-llm/Swallow-70b-NVE-instruct-hf": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-indef_articles_with_pl_nouns-removal-1e-3": [
    "model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-all_det_removal-3e-4": [
    "model.safetensors"
  ],
  "banghua/openchat3.5_apa2_log_ckpt4k5": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "mncai/SDC_Merge-Mistral_Lr05_Ep2-Marcoroni_7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "KnutJaegersberg/Walter-Llama-1B": [
    "model.safetensors"
  ],
  "joey00072/layerMix-Mistral-13b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ghimiresunil/mistral-7b-bfloat16-trainer-full": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "textomatic/mistral-7b-tsla-qna-1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Philipp-Sc/mistral-7b-reverse-instruct": [
    "latest_model_export/model-00001-of-00015.safetensors",
    "latest_model_export/model-00002-of-00015.safetensors",
    "latest_model_export/model-00003-of-00015.safetensors",
    "latest_model_export/model-00004-of-00015.safetensors",
    "latest_model_export/model-00005-of-00015.safetensors",
    "latest_model_export/model-00006-of-00015.safetensors",
    "latest_model_export/model-00007-of-00015.safetensors",
    "latest_model_export/model-00008-of-00015.safetensors",
    "latest_model_export/model-00009-of-00015.safetensors",
    "latest_model_export/model-00010-of-00015.safetensors",
    "latest_model_export/model-00011-of-00015.safetensors",
    "latest_model_export/model-00012-of-00015.safetensors",
    "latest_model_export/model-00013-of-00015.safetensors",
    "latest_model_export/model-00014-of-00015.safetensors",
    "latest_model_export/model-00015-of-00015.safetensors"
  ],
  "srihariEmids/phi-1_5-finetuned-emidsinfo-text": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "shibiyaj/lawGPT": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-adj_num_freq_balanced-1e-3": [
    "model.safetensors"
  ],
  "abhishek/hepu-o4zf-ravz-7-0": [
    "checkpoint-2316/model-00001-of-00006.safetensors",
    "checkpoint-2316/model-00002-of-00006.safetensors",
    "checkpoint-2316/model-00003-of-00006.safetensors",
    "checkpoint-2316/model-00004-of-00006.safetensors",
    "checkpoint-2316/model-00005-of-00006.safetensors",
    "checkpoint-2316/model-00006-of-00006.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ChunB1/books_adv_1M": [
    "model.safetensors"
  ],
  "Tijmen2/cosmosage_v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "nicher92/gpt-sw3-40b-4bit-gptq": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "TinyPixel/decilm-ft1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kyujinpy/SOLAR-Platypus-10.7B-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ArtifactAI/phi-science-generalist-instruct": [
    "model.safetensors"
  ],
  "jtatman/tinymistral-mediqa-248m": [
    "model.safetensors"
  ],
  "C0uchP0tat0/docs_generate": [
    "model.safetensors"
  ],
  "huskyhong/noname-ai-v2": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "thanhnew2001/codellama-7b-taipy13": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/openbuddy-llama2-13b64k-v15-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/openbuddy-llama2-13b64k-v15-GPTQ": [
    "model.safetensors"
  ],
  "kyujinpy/SOLAR-Platypus-10.7B-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "perlthoughts/Chupacabra-7B-v2.04": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hgloow/Merged-AGI-7B-EXL2": [
    "output.safetensors"
  ],
  "erbacher/zephyr-7b-ikat": [
    "adapter_model.safetensors"
  ],
  "srihariEmids/emidsinfo-finetuned-model": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "zxrzxr/mistral-rdm": [
    "adapter_model.safetensors"
  ],
  "Norquinal/DeciLM-7B-claude-chat": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "JGlang/llama2-mergedmodel": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "athirdpath/Eta-17b": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "thanhnew2001/codellama-7b-taipy12": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "athirdpath/Theta-17b": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "jondurbin/bagel-dpo-7b-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jondurbin/bagel-7b-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hyeogi/Yi-6b-dpo-v0.3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SAGI-1/AGI_1_2_SFT_SYMBOLIC_FACTS_2_FOL_LEVEL_1_V3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/MadMix-v0.2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/MadMix-v0.2-AWQ": [
    "model.safetensors"
  ],
  "Ashishkr/phi-1_5-medical_consultation": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/SOLAR-10.7B-Instruct-v1.0-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/SOLAR-10.7B-Instruct-v1.0-GPTQ": [
    "model.safetensors"
  ],
  "Aditya685/OpenHermes-2.5-upshot_legal_gen": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lamm-mit/BioinspiredLLM": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "vibhuagrawal/Mixtral-8x7B-Instruct-v0.1": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "SkunkworksAI/phi-2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "sarvamai/OpenHathi-7B-Hi-v0.1-Base": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "alhosseini/Llama-2-7b-hf": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "benayas/llama-2-7b-banking_v5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "nthngdy/hythia-rp-14m-100k-bs16": [
    "model.safetensors"
  ],
  "TheBloke/SOLAR-10.7B-v1.0-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/SOLAR-10.7B-v1.0-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/blossom-v3_1-yi-34b-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "haqishen/dslora-savetest": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "faizalnf1800/QuantumQuill-GPT2-Medium-Raw-300M": [
    "model.safetensors"
  ],
  "teilomillet/MiniMerlin-3B-v0.3": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "nicholasKluge/TeenyTinyLlama-160m": [
    "model.safetensors"
  ],
  "TheBloke/blossom-v3_1-yi-34b-GPTQ": [
    "model.safetensors"
  ],
  "Jaykumaran17/Samantha-Try2-13-12": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Nyxene-v3-11B-AWQ": [
    "model.safetensors"
  ],
  "faizalnf1800/QuantumQuill-GPT2-Medium-Scifi-Webnovel-300M": [
    "model.safetensors"
  ],
  "TheBloke/meditron-7B-chat-AWQ": [
    "model.safetensors"
  ],
  "LoneStriker/SOLAR-10.7B-Instruct-v1.0-3.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "TheBloke/Ana-v1-m7-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Mixtral-SlimOrca-8x7B-GPTQ": [
    "model.safetensors"
  ],
  "LoneStriker/SOLAR-10.7B-Instruct-v1.0-4.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "nthngdy/hythia-rp-14m-100k-bs16-nowt": [
    "model.safetensors"
  ],
  "TheBloke/v1olet_merged_dpo_7B_v3-AWQ": [
    "model.safetensors"
  ],
  "LoneStriker/SOLAR-10.7B-Instruct-v1.0-5.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "LoneStriker/SOLAR-10.7B-Instruct-v1.0-6.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "infopz512/zep_mixed_3k": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/v1olet_merged_dpo_7B_v4-AWQ": [
    "model.safetensors"
  ],
  "jojo-ai-mst/MyanmarGPT": [
    "model.safetensors"
  ],
  "Undi95/Mixtral-4x7B-DPO-RPChat": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "LoneStriker/SOLAR-10.7B-Instruct-v1.0-8.0bpw-h8-exl2-2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Ansoi/born": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "amgadhasan/phi-2": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Nyxene-v3-11B-GPTQ": [
    "model.safetensors"
  ],
  "LoneStriker/bagel-dpo-7b-v0.1-3.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "TheBloke/LeoScorpius-7B-AWQ": [
    "model.safetensors"
  ],
  "textomatic/llama-2-7b-tsla-qna-test": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/bagel-dpo-7b-v0.1-4.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "LoneStriker/bagel-dpo-7b-v0.1-5.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "LoneStriker/bagel-dpo-7b-v0.1-6.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "blasees/gpt2_bestpractices": [
    "model.safetensors"
  ],
  "LoneStriker/bagel-dpo-7b-v0.1-8.0bpw-h8-exl2-2": [
    "output.safetensors"
  ],
  "LoneStriker/SOLAR-10.7B-v1.0-3.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "TheBloke/meditron-7B-chat-GPTQ": [
    "model.safetensors"
  ],
  "LoneStriker/SOLAR-10.7B-v1.0-4.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "LoneStriker/bagel-7b-v0.1-3.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "LoneStriker/bagel-7b-v0.1-4.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "LoneStriker/SOLAR-10.7B-v1.0-5.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "LoneStriker/bagel-7b-v0.1-5.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "TheBloke/Ana-v1-m7-GPTQ": [
    "model.safetensors"
  ],
  "LoneStriker/bagel-7b-v0.1-6.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "LoneStriker/SOLAR-10.7B-v1.0-6.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "Fredithefish/ZephyrCognition-new": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/bagel-7b-v0.1-8.0bpw-h8-exl2-2": [
    "output.safetensors"
  ],
  "Fredithefish/MadMix-v0.2-f16": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/SOLAR-10.7B-v1.0-8.0bpw-h8-exl2-2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "TheBloke/bagel-dpo-7B-v0.1-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/bagel-7B-v0.1-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/bagel-7B-v0.1-GPTQ": [
    "model.safetensors"
  ],
  "athirdpath/Iambe-RP-v3-20b-EXL2-3bpw": [
    "output.safetensors"
  ],
  "RJuro/kanelsnegl-v0.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/bagel-dpo-7B-v0.1-GPTQ": [
    "model.safetensors"
  ],
  "arnavgrg/NousResearch-Yarn-Mistral-7b-128k-nf4-fp16-upscaled": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ManthanKulakarni/phi": [
    "model.safetensors"
  ],
  "TheBloke/v1olet_merged_dpo_7B_v3-GPTQ": [
    "model.safetensors"
  ],
  "ChunB1/books_common_1M": [
    "model.safetensors"
  ],
  "ManthanKulakarni/TinyLlama-1.1B-Text2SQL": [
    "model.safetensors"
  ],
  "TheBloke/v1olet_merged_dpo_7B_v4-GPTQ": [
    "model.safetensors"
  ],
  "athirdpath/Iota-17b": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/LeoScorpius-7B-GPTQ": [
    "model.safetensors"
  ],
  "AmanMussa/llama2-kazakh-7b-ver2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "perevalov/AntModel-7B-XLLM-test-lcquad-1-Demo": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "athirdpath/Iambe-RP-v3-20b-EXL2-2.6bpw": [
    "output.safetensors"
  ],
  "athirdpath/Kappa-17b": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "microsoft/phi-2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "topeomole/mistralai-dlm": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Asude/gpt2-imdb-20kdata-25it": [
    "model.safetensors"
  ],
  "Fredithefish/DingoRP-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "athirdpath/Lambda-17b": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "textomatic/llama-2-7b-tsla-qna-4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Kooten/DaringMaid-20B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-indef_articles_with_pl_nouns-removal-3e-4": [
    "model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-adj_num_freq_balanced-1e-4": [
    "model.safetensors"
  ],
  "Delcos/Cybertron-UNA-11b-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Sao10K/WinterGoddess-1.4x-70B-L2": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "maywell/PiVoT-10.7B-Mistral-v0.2": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "ZeyuMax/Test33M": [
    "model.safetensors"
  ],
  "codegood/MPhi_context_learning": [
    "adapter_model.safetensors"
  ],
  "rwitz2/go-bruins-v2.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "PoloGGG/EvolMistral-7B-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "athirdpath/Lambda-17b-DPO": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "junzhu/llama2-Atom-7b-titan-go-logs": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "w4r10ck/SOLAR-10.7B-Instruct-v1.0-uncensored": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "jan-hq/trinity-v1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TigerResearch/tigerbot-13b-chat-v5-4bit-exl2": [
    "output.safetensors"
  ],
  "EdgeAIStaffing/mistralai-Code-Instruct-Finetune-test-27a": [],
  "dcbv/charluv-13B-tiefighter-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "athirdpath/Lambda-17b-PcDPO": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "DianGh/IoTSec-gpt2-model": [
    "model.safetensors"
  ],
  "Undi95/Mixtral-8x7B-MoE-RP-Story": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "janai-hq/trinity-v1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mncai/mistral-7b-dpo-v5": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ghimiresunil/mistral-7b-bfloat16-dpo-full": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TinyPixel/decilm-ft2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-all_det_removal-1e-4": [
    "model.safetensors"
  ],
  "martyn/mistral-megamerge-dare-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "athirdpath/Lambda-DPOslerp-17b": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "fblgit/una-cybertron-7b-v3-OMA": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jan-hq/Pandora-v1-13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jan-hq/Pandora-v1-10.7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jan-hq/Solar-10.7B-SLERP": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TinyPixel/pythia-cl2": [
    "model.safetensors"
  ],
  "raowaqas123/hbl-test": [
    "model.safetensors"
  ],
  "athirdpath/Mu-17b": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "uni-tianyan/Uni-TianYan-V1": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "genesis-ai/garbo-7b-base-6700": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mncai/agiin-11.1B-v0.0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sid321axn/Mistral-7B-text-to-sql-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mncai/agiin-13.6B-v0.0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SeeThink/STEVE-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "norispace/marcoroni-7b-initial-tuning-failed": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "TitanML/tiny-mixtral": [
    "model.safetensors"
  ],
  "jan-ai/Solar-10.7B-SLERP": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jan-ai/Pandora-13B-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jan-ai/Pandora-10.7B-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TinyPixel/pythia-mini": [
    "model.safetensors"
  ],
  "athirdpath/Nu-17b": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TriadParty/deepsex-6b-base": [
    "model-00001-of-00013.safetensors",
    "model-00002-of-00013.safetensors",
    "model-00003-of-00013.safetensors",
    "model-00004-of-00013.safetensors",
    "model-00005-of-00013.safetensors",
    "model-00006-of-00013.safetensors",
    "model-00007-of-00013.safetensors",
    "model-00008-of-00013.safetensors",
    "model-00009-of-00013.safetensors",
    "model-00010-of-00013.safetensors",
    "model-00011-of-00013.safetensors",
    "model-00012-of-00013.safetensors",
    "model-00013-of-00013.safetensors"
  ],
  "KnutJaegersberg/Walter-StableLM-3B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "seyabde/mistral_7b_yo_instruct": [
    "adapter_model.safetensors",
    "checkpoint-32028/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rwitz2/go-bruins-v2.1.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "raowaqas123/hbl_v2": [
    "model.safetensors"
  ],
  "nyanxyz/find-the-subject-p10-l10-e10-0": [
    "adapter_model.safetensors",
    "checkpoint-100/adapter_model.safetensors"
  ],
  "TinyPixel/decilm-ft3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ChenMnZ/Mixtral-8x7B-Instruct-v0.1-OmniQuantv1-w4a16g128": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "ChenMnZ/Mixtral-8x7B-v0.1-OmniQuantv1-w4a16g128": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "TheBloke/dolphin-2.5-mixtral-8x7b-GPTQ": [
    "model.safetensors"
  ],
  "SinanAkkoyun/pic_7B_mistral_Full_v0.2-awq": [
    "model.safetensors"
  ],
  "LsTam/Mistral-7B-Instruct-v0.1-8bit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Norquinal/StripedHyena-Hessian-7B-claude-chat": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "kimihailv/llama-1.3B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "nyanxyz/fill-in-the-blank-p7-l20-e10-0": [
    "adapter_model.safetensors",
    "checkpoint-300/adapter_model.safetensors"
  ],
  "JGlang/llama2-testconso": [
    "adapter_model.safetensors",
    "checkpoint-223/adapter_model.safetensors"
  ],
  "joey00072/ToxicHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "swap-uniba/LLaMAntino-2-7b-hf-ITA": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TriadParty/deepsex-6b-chat": [
    "model-00001-of-00013.safetensors",
    "model-00002-of-00013.safetensors",
    "model-00003-of-00013.safetensors",
    "model-00004-of-00013.safetensors",
    "model-00005-of-00013.safetensors",
    "model-00006-of-00013.safetensors",
    "model-00007-of-00013.safetensors",
    "model-00008-of-00013.safetensors",
    "model-00009-of-00013.safetensors",
    "model-00010-of-00013.safetensors",
    "model-00011-of-00013.safetensors",
    "model-00012-of-00013.safetensors",
    "model-00013-of-00013.safetensors"
  ],
  "SicariusSicariiStuff/Tenebra_PreAlpha_128g_3BIT": [
    "model.safetensors"
  ],
  "SicariusSicariiStuff/Tenebra_PreAlpha_128g_4BIT": [
    "model.safetensors"
  ],
  "jcolab5/llama-2-7b-chat-hf-instruct-medical-assistance": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-indef_articles_with_pl_nouns-removal-1e-4": [
    "model.safetensors"
  ],
  "madhaviit/NHTV2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TinyPixel/pythia-lm": [
    "model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-adj_num_freq_balanced-3e-3": [
    "model.safetensors"
  ],
  "diamantrsd/cerpen-generator-v2": [
    "model.safetensors"
  ],
  "beomi/open-llama-2-ko-7b": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "erfanzar/LLamaStory-70M": [
    "model.safetensors"
  ],
  "LoneStriker/Ana-v1-m7-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LsTam/Mistral-7B-Instruct-v0.2-8bit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Ana-v1-m7-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Ana-v1-m7-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "swap-uniba/LLaMAntino-2-13b-hf-ITA": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Ana-v1-m7-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Ana-v1-m7-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "JGlang/llama2-mergedmodel_conso": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "mixedbread-ai/phi-2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "chinhang0104/distilgpt2_private-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "TheBloke/openchat-3.5-1210-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/openchat-3.5-1210-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/openbuddy-mixtral-8x7b-v15.1-GPTQ": [
    "model.safetensors"
  ],
  "blasees/gpt2_bestpractices_chats": [
    "model.safetensors"
  ],
  "malhajar/phi-2-chat-turkish": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Abinesh/Tamil-Transformer": [
    "model.safetensors"
  ],
  "yimingzhang/zephyr-7b-dpo-full": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "blasees/gpt2_bestpractices_proposal": [
    "model.safetensors"
  ],
  "JGlang/llama2-prenoms": [
    "adapter_model.safetensors",
    "checkpoint-21/adapter_model.safetensors"
  ],
  "Kooten/DaringMaid-20B-3bpw-exl2": [
    "output.safetensors"
  ],
  "Kooten/DaringMaid-20B-6bpw-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "model-hub/Mixtral-8x7B-Instruct-v0.1": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "model-hub/Mixtral-8x7B-v0.1": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "model-hub/phi-2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "model-hub/Mistral-7B-Instruct-v0.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "model-hub/DeciLM-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "model-hub/stablelm-zephyr-3b": [
    "model.safetensors"
  ],
  "TheBloke/phi-2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Mythalion-Kimiko-v2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Mythalion-Kimiko-v2-AWQ": [
    "model.safetensors"
  ],
  "satyajitghana/mistral-7b-v0.1-alpaca-chat": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kevind13/codeLlama-7b-Instruct-hf-vuejs-finetune": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-adj_num_freq_balanced-3e-4": [
    "model.safetensors"
  ],
  "TheBloke/Solar-10.7B-SLERP-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Solar-10.7B-SLERP-GPTQ": [
    "model.safetensors"
  ],
  "metin169met/demo": [
    "adapter_model.safetensors",
    "checkpoint-41025/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "aaeagal/i3qd-0kj5-uswk-0": [
    "adapter_model.safetensors",
    "checkpoint-210/adapter_model.safetensors"
  ],
  "themanas021/llama2-docsum-adapter": [
    "adapter_model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-aann-prototypical_only-1e-3": [
    "model.safetensors"
  ],
  "humbertonc/mistral_test1": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "IndicRAGware/mistral-hindi-RAG-7b": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "TheBloke/Pandora-v1-10.7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Pandora-v1-10.7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/ShiningValiantXS-1.1-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/ShiningValiantXS-1.1-GPTQ": [
    "model.safetensors"
  ],
  "seyabde/29wf-jx7v-jye2-0": [
    "adapter_model.safetensors",
    "checkpoint-2307/adapter_model.safetensors"
  ],
  "tonigs/VTEST": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "malhajar/phi-2-chat": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/ShiningValiant-1.3-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "harshithvh/llama2_finetuned2": [
    "checkpoint-210/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "msahabudinov/msahabudinov": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Strooge/dolphin-2.2.1-AshhLimaRP-Mistral-7B-3-bit": [
    "output.safetensors"
  ],
  "TheBloke/Mistral-7B-Instruct-v0.2-DARE-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Mistral-7B-Instruct-v0.2-DARE-GPTQ": [
    "model.safetensors"
  ],
  "Relais4x100a2/mistralai-Code-Instruct-Finetune-Droit-ADMINISTRATIF": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Mixtral-8x7B-MoE-RP-Story-GPTQ": [
    "model.safetensors"
  ],
  "marclove/marclove-mixtral-8x7B": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "mindy-labs/mindy-7b-v2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Aditya685/upshot-sih": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Undi95/Toppy-Mix-4x7B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "TheBloke/BruinsV2-OpHermesNeu-11B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/BruinsV2-OpHermesNeu-11B-AWQ": [
    "model.safetensors"
  ],
  "BAH-ML-ASC/phi-2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "venkycs/phi-2-instruct": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ArtifactAI/phi-2-arxiv-physics-instruct": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LavaPlanet/Goliath120B-exl2_2-2.64bpw": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-indef-naan-non-num-3e-4": [
    "model.safetensors"
  ],
  "mncai/agiin-13.6B-v0.1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "TheBloke/una-cybertron-7B-v3-OMA-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/una-cybertron-7B-v3-OMA-GPTQ": [
    "model.safetensors"
  ],
  "protoml/mistral_7b_guanaco_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Undi95/Llamix2-MLewd-4x13B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "TheBloke/Pandora-v1-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Pandora-v1-13B-GPTQ": [
    "model.safetensors"
  ],
  "yihang7/zephyr-7b-sft-full": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Orca-2-13B-SFT_v5-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Orca-2-13B-SFT_v5-AWQ": [
    "model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-indef_articles_with_pl_nouns-removal-3e-3": [
    "model.safetensors"
  ],
  "TdL/test1": [
    "model.safetensors"
  ],
  "TheBloke/cutie-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/cutie-GPTQ": [
    "model.safetensors"
  ],
  "yuntaeyang/lion-7b-lora-kor": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "agfreitas/lamini_docs_3_steps": [
    "final/model.safetensors",
    "model.safetensors"
  ],
  "agfreitas/lamini_docs_finetuned": [
    "model.safetensors"
  ],
  "crumb/e4-k2-d1024-hm2-1gt": [
    "model.safetensors"
  ],
  "TheBloke/WinterGoddess-1.4x-70B-L2-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/WinterGoddess-1.4x-70B-L2-GPTQ": [
    "model.safetensors"
  ],
  "reframedataservices/allsci-mistral-7b-instruct-hypothesis2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mayanklad/faq-canada-immigration": [
    "model.safetensors"
  ],
  "arnavm234/fine_tuned_3": [
    "adapter_model.safetensors",
    "checkpoint-42/adapter_model.safetensors"
  ],
  "StanfordAIMI/CheXagent-8b": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "clydelyde/math_books": [
    "adapter_model.safetensors"
  ],
  "jtatman/tinymistral-magicoder-instruct-248m": [
    "model.safetensors"
  ],
  "Jiahuan/vox-finetune-llama-2-7b-chat-v2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-aann-no_prototypical-3e-4": [
    "model.safetensors"
  ],
  "ravikumar101/ravi-mistral-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "THUDM/cogagent-chat-hf": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "chargoddard/SmolLlamix-8x101M": [
    "model.safetensors"
  ],
  "Asude/gpt2-imdb-20kdata-10it": [
    "model.safetensors"
  ],
  "decem/Dionysus-llama2-13b-v3": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "malhajar/phi-2-meditron": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Asude/gpt2-imdb-20kdata-5it": [
    "model.safetensors"
  ],
  "athirdpath/ChubbyIambe-22b-EXPERIMENTAL": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-indef-naan-rerun-1e-3": [
    "model.safetensors"
  ],
  "gizmo-ai/green-words-sheared-llama-checkpoint-246500-0.1517": [
    "model.safetensors"
  ],
  "TheBloke/LeoScorpius-GreenNode-7B-v1-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/LeoScorpius-GreenNode-7B-v1-GPTQ": [
    "model.safetensors"
  ],
  "Minirecord/llama13b_2s_dpo": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-aann-prototypical_only-1e-4": [
    "model.safetensors"
  ],
  "nlpai-lab/kullm-polyglot-12.8b-v3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "arnavm234/proj4-0": [
    "adapter_model.safetensors",
    "checkpoint-39/adapter_model.safetensors"
  ],
  "farshadafx/LEDA-v6": [
    "model.safetensors"
  ],
  "vishalpranavag/gp2-twitgen": [
    "adapter_model.safetensors",
    "checkpoint-85/adapter_model.safetensors",
    "model.safetensors"
  ],
  "TinyPixel/decilm": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mediocredev/open-llama-3b-v2-instruct": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Charm333/yi-6b-chat-32k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Mediform/GMarcO": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Gryphe/Tiamat-7b-1.1-DPO": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jinnkenny99/mistral_twitter": [
    "adapter_model.safetensors",
    "checkpoint-87/adapter_model.safetensors"
  ],
  "petru-cho/neurotitle-rugpt3-small-summary": [
    "model.safetensors"
  ],
  "petru-cho/neurotitle-rugpt3-small-summary-test": [
    "model.safetensors"
  ],
  "genericgod/GerMerge-em-leo-mistral-v0.2-SLERP": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Llamix2-MLewd-4x13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Tiamat-7B-1.1-DPO-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Tiamat-7B-1.1-DPO-GPTQ": [
    "model.safetensors"
  ],
  "teilomillet/MiniMerlin-3B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mayflowergmbh/hermeo-7b-awq": [
    "model.safetensors"
  ],
  "PreethaVitra/phi-1_5-finetuned-gsm8k": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Kooten/DaringMaid-13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "igorktech/TALANT_mistral_7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MMoin/llama-2-7b-platypus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/mistral-7B-dpo-v5-GPTQ": [
    "model.safetensors"
  ],
  "SuperAGI/mistral-7B-PoSE-32k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "allstax/CodeExplainer-7b-v0.1": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "PaulDerG/Marcoroni_RP-7B": [
    "model-00001-of-00022.safetensors",
    "model-00002-of-00022.safetensors",
    "model-00003-of-00022.safetensors",
    "model-00004-of-00022.safetensors",
    "model-00005-of-00022.safetensors",
    "model-00006-of-00022.safetensors",
    "model-00007-of-00022.safetensors",
    "model-00008-of-00022.safetensors",
    "model-00009-of-00022.safetensors",
    "model-00010-of-00022.safetensors",
    "model-00011-of-00022.safetensors",
    "model-00012-of-00022.safetensors",
    "model-00013-of-00022.safetensors",
    "model-00014-of-00022.safetensors",
    "model-00015-of-00022.safetensors",
    "model-00016-of-00022.safetensors",
    "model-00017-of-00022.safetensors",
    "model-00018-of-00022.safetensors",
    "model-00019-of-00022.safetensors",
    "model-00020-of-00022.safetensors",
    "model-00021-of-00022.safetensors",
    "model-00022-of-00022.safetensors"
  ],
  "Kooten/DaringMaid-13B-8bpw-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Kooten/DaringMaid-13B-4bpw-exl2": [
    "output.safetensors"
  ],
  "Kooten/DaringMaid-13B-5bpw-exl2": [
    "output.safetensors"
  ],
  "TheBloke/mistral-7B-dpo-v5-AWQ": [
    "model.safetensors"
  ],
  "projecte-aina/FLOR-6.3B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "yukiarimo/yuna-ai": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "khanhnto/kytlasttest": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LavaPlanet/Venus-120b-v1.1-exl2_2-2.64bpw": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "harshithvh/llama2_finetuned1": [
    "checkpoint-210/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "We-Want-GPU/Yi-Ko-6B-orca-alpaca-gpt4-math": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Over9012/IEEE-Chatbot": [
    "adapter_model.safetensors",
    "checkpoint-54/adapter_model.safetensors"
  ],
  "igorktech/TALANT_saiga_7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "VAGOsolutions/SauerkrautLM-Mixtral-8x7B": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "VAGOsolutions/SauerkrautLM-Mixtral-8x7B-Instruct": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "JNewber/fluterj": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AmanMussa/llama2-fake-news-detection-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "yihang7/zephyr-7b-dpo-full": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "G-ML-Hyly/stg-cli7b-t4.ca.mips.inter.concat.cln-b4s1e1-20231122-1507-fp16_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "iadsmedia/mz-fine-tune": [
    "adapter_model.safetensors",
    "checkpoint-12/adapter_model.safetensors"
  ],
  "TheBloke/yi-34B-v3-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/yi-34B-v3-GPTQ": [
    "model.safetensors"
  ],
  "abhi757/llama-2-7b-chat-paper-to-slides2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LLM360/AmberSafe": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Mihaiii/Metis-0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Jiahuan/voxreality-arta-llama2-7b-chat-v3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "igorktech/TALANT_rugpt3medium": [
    "model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-aann-no_prototypical-1e-4": [
    "model.safetensors"
  ],
  "TheBloke/Venus-103b-v1.2-AWQ": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "TheBloke/Venus-103b-v1.2-GPTQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "iadsmedia/v1-fineTuned": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "igorktech/TALANT_rugpt3medium_DPO": [
    "model.safetensors"
  ],
  "LoneStriker/Tiamat-7b-1.1-DPO-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "ArtifactAI/phi-2-arxiv-math-instruct": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-indef-naan-rerun-1e-4": [
    "model.safetensors"
  ],
  "kkuramitsu/tinycodellama-0.13b-6.3k": [
    "model.safetensors"
  ],
  "qxnam/distilgpt2-finetuned-finance": [
    "model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-aann-prototypical_only-3e-4": [
    "model.safetensors"
  ],
  "nlpfromscratch/tinyshakespeare-gpt2": [
    "model.safetensors"
  ],
  "andromedanita/tinyshakespeare-gpt2": [
    "model.safetensors"
  ],
  "ChunB1/TinyReviews_raw": [
    "model.safetensors"
  ],
  "igorktech/TALANT_rugpt3medium_DPO2": [
    "model.safetensors"
  ],
  "ChunB1/TinyReviews_common": [
    "model.safetensors"
  ],
  "ChunB1/TinyReviews_adj": [
    "model.safetensors"
  ],
  "ChunB1/TinyReviews_adv": [
    "model.safetensors"
  ],
  "squareoctopus/tallercitoOcampo": [
    "model.safetensors"
  ],
  "squareoctopus/ocampo": [
    "model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-indef-naan-non-num-1e-4": [
    "model.safetensors"
  ],
  "wassname/phi-2-GPTQ_w_hidden_states": [
    "model.safetensors"
  ],
  "Phrasly/7i6t-fqpu-r1dr-0": [
    "adapter_model.safetensors",
    "checkpoint-1047/adapter_model.safetensors"
  ],
  "TheBloke/Metis-0.1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Metis-0.1-AWQ": [
    "model.safetensors"
  ],
  "cognAI/lil-c3po": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "hyeogi/open-llama2-7b-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "igorktech/TALANT_saiga_7b_DPO": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ChenMnZ/Mixtral-8x7B-v0.1-OmniQuantv2-w4a16g128": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "LoneStriker/Nous-Capybara-limarpv3-34B-3.0bpw-h6-exl2-2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/Nous-Capybara-limarpv3-34B-4.0bpw-h6-exl2-2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "BePresent/mistral7b-test": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/Nous-Capybara-limarpv3-34B-4.65bpw-h6-exl2-2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Nous-Capybara-limarpv3-34B-5.0bpw-h6-exl2-2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "TheBloke/Venus-120b-v1.1-GPTQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Venus-120b-v1.1-AWQ": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "LoneStriker/Nous-Capybara-limarpv3-34B-6.0bpw-h6-exl2-2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "perlthoughts/Chupacabra-8x7B-MoE": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "aisuko/ft-ms-git-base-pokemon-blip-captions": [
    "model.safetensors"
  ],
  "istemedu/Qwen-72B-Chat-awq": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "KnutJaegersberg/Walter-SOLAR-11B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "HY-KDPARK/llama-2-koen-13b-dpo-v0.4": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "areegtarek/openchat-finetuned": [
    "adapter_model.safetensors",
    "checkpoint-1177/adapter_model.safetensors"
  ],
  "areegtarek/mistral-7b-finetuned": [
    "adapter_model.safetensors",
    "checkpoint-1177/adapter_model.safetensors"
  ],
  "areegtarek/mistral-7b-Radiology-Simplify": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AIFT/aift-llama2-koen-instruct-v1.1-dpo-test1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "perlthoughts/Falkor-8x7B-MoE": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "wcdshaohua01/codegen-350M-mono-python-18k-alpaca": [
    "model.safetensors"
  ],
  "LoneStriker/Nous-Capybara-limarpv3-34B-8.0bpw-h8-exl2-2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "perlthoughts/Starling-LM-alpha-8x7B-MoE": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "LoneStriker/Mistral-7B-Instruct-v0.2-DARE-3.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "LoneStriker/Mistral-7B-Instruct-v0.2-DARE-4.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "LoneStriker/Mistral-7B-Instruct-v0.2-DARE-5.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "LoneStriker/Mistral-7B-Instruct-v0.2-DARE-6.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "LoneStriker/Mistral-7B-Instruct-v0.2-DARE-8.0bpw-h8-exl2-2": [
    "output.safetensors"
  ],
  "TinyPixel/deci-elm": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Metis-0.1-3.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "codegood/MPhi_3_Steps": [
    "model.safetensors"
  ],
  "l3utterfly/mistral-7b-v0.1-layla-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Metis-0.1-4.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "LoneStriker/Metis-0.1-5.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "LoneStriker/Metis-0.1-6.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "LoneStriker/Metis-0.1-8.0bpw-h8-exl2-2": [
    "output.safetensors"
  ],
  "beefsupreme321/b3x6-k1so-v1s8-0": [
    "adapter_model.safetensors",
    "checkpoint-4422/adapter_model.safetensors"
  ],
  "alwint3r/my_awesome_eli5_clm-model": [
    "model.safetensors"
  ],
  "TinyPixel/m1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Pclanglais/Bellay": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "THUDM/cogagent-vqa-hf": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "brucethemoose/Yi-34B-200K-DARE-merge-v5": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-aann-no_prototypical-1e-3": [
    "model.safetensors"
  ],
  "daptheHuman/merak-7b-candi-borobudur-v2-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "perlthoughts/neural-chat-v3-3-8x7b-MoE": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "NabeelShar/essay_dec": [
    "adapter_model.safetensors",
    "checkpoint-250/adapter_model.safetensors"
  ],
  "isek-ai/SDPrompt-RetNet-v2-beta": [
    "model.safetensors"
  ],
  "TinyPixel/m2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/PiVoT-10.7B-Mistral-v0.2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/PiVoT-10.7B-Mistral-v0.2-AWQ": [
    "model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-indef-naan-rerun-3e-4": [
    "model.safetensors"
  ],
  "jjourney1125/llama2-13b-v0.1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "TheBloke/agiin-13.6B-v0.1-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/agiin-13.6B-v0.1-GPTQ": [
    "model.safetensors"
  ],
  "maywell/PiVoT-10.7B-Mistral-v0.2-RP": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "abhigadgil15/llama-2-7b-abhinav": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Mistral-7B-AEZAKMI-v1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Mistral-7B-AEZAKMI-v1-AWQ": [
    "model.safetensors"
  ],
  "janhq/Phoenix-v1-8x7B": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "TheBloke/LeoScorpius-GreenNode-Alpaca-7B-v1-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/LeoScorpius-GreenNode-Alpaca-7B-v1-GPTQ": [
    "model.safetensors"
  ],
  "Aqsa-atif/phi-1_5-finetuned-gsm8k": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Prezily/distilgpt2-eli5": [
    "model.safetensors"
  ],
  "LoneStriker/PiVoT-10.7B-Mistral-v0.2-RP-3.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "TheBloke/LeoScorpius-GreenNode-Platypus-7B-v1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/LeoScorpius-GreenNode-Platypus-7B-v1-AWQ": [
    "model.safetensors"
  ],
  "LoneStriker/PiVoT-10.7B-Mistral-v0.2-RP-4.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "LoneStriker/PiVoT-10.7B-Mistral-v0.2-RP-5.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "LoneStriker/PiVoT-10.7B-Mistral-v0.2-RP-6.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "LoneStriker/PiVoT-10.7B-Mistral-v0.2-3.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "TheBloke/SOLAR-Platypus-10.7B-v2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/SOLAR-Platypus-10.7B-v2-AWQ": [
    "model.safetensors"
  ],
  "LoneStriker/PiVoT-10.7B-Mistral-v0.2-RP-8.0bpw-h8-exl2-2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/PiVoT-10.7B-Mistral-v0.2-4.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-aann-indef-non_num_removal-1e-3": [
    "model.safetensors"
  ],
  "pumplay01/GPT2-400": [
    "model.safetensors"
  ],
  "LoneStriker/PiVoT-10.7B-Mistral-v0.2-5.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "LoneStriker/PiVoT-10.7B-Mistral-v0.2-6.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "LoneStriker/PiVoT-10.7B-Mistral-v0.2-8.0bpw-h8-exl2-2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "TheBloke/mindy-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/mindy-7B-GPTQ": [
    "model.safetensors"
  ],
  "neph1/bellman-7b-mistral-instruct-v0.2": [
    "gptq/model.safetensors",
    "lora/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TinyPixel/m3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/MelloGPT-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/MelloGPT-AWQ": [
    "model.safetensors"
  ],
  "LoneStriker/Nous-Capybara-limarpv3-34B-2.8bpw-h6-exl2-2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "atom92/medical_lama_ultra": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hyeogi/open-llama2-7b-dpo-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tb2pi-persistent/phi-2-tb2pi-merged-v1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "intervitens/WinterGoddess_1.4x-70B-L2-2.55bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "intervitens/WinterGoddess_1.4x-70B-L2-4.65bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "jan-hq/Phoenix-v1-8x7B": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "projecte-aina/FLOR-6.3B-Instructed": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "testingman22/nadine": [
    "adapter_model.safetensors"
  ],
  "Undi95/BigPlap-8x20B": [
    "model-00001-of-00023.safetensors",
    "model-00002-of-00023.safetensors",
    "model-00003-of-00023.safetensors",
    "model-00004-of-00023.safetensors",
    "model-00005-of-00023.safetensors",
    "model-00006-of-00023.safetensors",
    "model-00007-of-00023.safetensors",
    "model-00008-of-00023.safetensors",
    "model-00009-of-00023.safetensors",
    "model-00010-of-00023.safetensors",
    "model-00011-of-00023.safetensors",
    "model-00012-of-00023.safetensors",
    "model-00013-of-00023.safetensors",
    "model-00014-of-00023.safetensors",
    "model-00015-of-00023.safetensors",
    "model-00016-of-00023.safetensors",
    "model-00017-of-00023.safetensors",
    "model-00018-of-00023.safetensors",
    "model-00019-of-00023.safetensors",
    "model-00020-of-00023.safetensors",
    "model-00021-of-00023.safetensors",
    "model-00022-of-00023.safetensors",
    "model-00023-of-00023.safetensors"
  ],
  "LoneStriker/Nous-Capybara-limarpv3-34B-2.4bpw-h6-exl2-2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "mahihossain666/llama-2-70b-hf-quantized-4bits-GPTQ": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "jackoyoungblood/GPT2_Original": [
    "model.safetensors"
  ],
  "mncai/mistral-7b-dpo-v6": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "daniatalla-cnvrg/orca_mini_v3_13b_and_Platypus2-13B_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "swap-uniba/LLaMAntino-2-chat-7b-hf-UltraChat-ITA": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "swap-uniba/LLaMAntino-2-chat-13b-hf-UltraChat-ITA": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "swap-uniba/LLaMAntino-2-chat-7b-hf-ITA": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "swap-uniba/LLaMAntino-2-chat-13b-hf-ITA": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "igorktech/rugpt3-joker-150k-8bit": [
    "model.safetensors"
  ],
  "Rijgersberg/GEITje-7B-chat-v2": [
    "checkpoint-12185/model-00001-of-00003.safetensors",
    "checkpoint-12185/model-00002-of-00003.safetensors",
    "checkpoint-12185/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/ShiningValiantXS-3.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "LoneStriker/ShiningValiantXS-4.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "mmnga/Mixtral-Fusion-4x7B-Instruct-v0.1": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "LoneStriker/ShiningValiantXS-5.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "LoneStriker/ShiningValiantXS-6.0bpw-h6-exl2-2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "tb2pi-persistent/Llama-2-7b-chat-hf-tb2pi-merged-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "HARSHAPALNATIUNH/BLOOM560mfinetune": [
    "model.safetensors"
  ],
  "LoneStriker/ShiningValiantXS-8.0bpw-h8-exl2-2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/go-bruins-v2.1.1-3.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "VishalMysore/cookgptlarge": [
    "adapter_model.safetensors",
    "checkpoint-895/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/go-bruins-v2.1.1-4.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "LoneStriker/go-bruins-v2.1.1-5.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "TitleOS/RocketZephyr-3b": [
    "model-00001-of-00001.safetensors"
  ],
  "LoneStriker/go-bruins-v2.1.1-6.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "LoneStriker/go-bruins-v2.1.1-8.0bpw-h8-exl2-2": [
    "output.safetensors"
  ],
  "gizmodus/node-id-generator-3": [
    "adapter_model.safetensors",
    "checkpoint-3/adapter_model.safetensors"
  ],
  "HARSHAPALNATIUNH/Githubmodel": [
    "model.safetensors"
  ],
  "saberai/Zro1-3B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Rogue-Rose-103b-v0.2-3.0bpw-h6-exl2-2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "maywell/PiVoT-MoE": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "phanerozoic/Mistral-Pirate-7b-v0.3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "adamzinebi/lmd-8bars-2048-epochs10": [
    "model.safetensors"
  ],
  "Fredithefish/Parakeet": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Undi95/Plap-8x13B": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "Mihaiii/Metis-0.3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "chargoddard/SmolLlamix-8x101M-take2": [
    "model.safetensors"
  ],
  "LoneStriker/Rogue-Rose-103b-v0.2-4.0bpw-h6-exl2-2": [
    "output-00001-of-00007.safetensors",
    "output-00002-of-00007.safetensors",
    "output-00003-of-00007.safetensors",
    "output-00004-of-00007.safetensors",
    "output-00005-of-00007.safetensors",
    "output-00006-of-00007.safetensors",
    "output-00007-of-00007.safetensors"
  ],
  "irmcon-org/5cqi-4z5d-wmvf-0": [
    "adapter_model.safetensors",
    "checkpoint-258/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "intervitens/WinterGoddess_1.4x-70B-L2-5.0bpw-h6-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "TheBloke/Starling-LM-alpha-8x7B-MoE-GPTQ": [
    "model.safetensors"
  ],
  "madatnlp/mist-enko-lora-2950": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Mixtral-8x7B-MoE-Undi95-RP-Story-2.4bpw-h6-exl2-2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "irmcon-org/zesty-0": [
    "adapter_model.safetensors",
    "checkpoint-249/adapter_model.safetensors"
  ],
  "mncai/mistral-7b-dpo-merge-v1.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Mixtral-8x7B-MoE-Undi95-RP-Story-3.0bpw-h6-exl2-2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "harshithvh/llama2_finetuned3": [
    "checkpoint-150/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "harshithvh/mistral_finetuned1": [
    "checkpoint-150/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Mixtral-8x7B-MoE-Undi95-RP-Story-4.0bpw-h6-exl2-2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "Fredithefish/OpenZephyrChat-v0.2": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "LoneStriker/Mixtral-8x7B-MoE-Undi95-RP-Story-5.0bpw-h6-exl2-2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "LoneStriker/Mixtral-8x7B-MoE-Undi95-RP-Story-6.0bpw-h6-exl2-2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "kalyanmaram/UNH-Academic-Integrity-bloomz-560m": [
    "model.safetensors"
  ],
  "LoneStriker/Rogue-Rose-103b-v0.2-5.0bpw-h6-exl2-2": [
    "output-00001-of-00008.safetensors",
    "output-00002-of-00008.safetensors",
    "output-00003-of-00008.safetensors",
    "output-00004-of-00008.safetensors",
    "output-00005-of-00008.safetensors",
    "output-00006-of-00008.safetensors",
    "output-00007-of-00008.safetensors",
    "output-00008-of-00008.safetensors"
  ],
  "codegood/MPhi_40_epochs": [
    "adapter_model.safetensors"
  ],
  "SaiSaketh/UNH-Academic-Integrity-bloomz-560m": [
    "model.safetensors"
  ],
  "SaiSaketh/Sample_LLM": [
    "model.safetensors"
  ],
  "SaiSaketh/Sample1_LLM": [
    "model.safetensors"
  ],
  "SaiSaketh/X": [
    "model.safetensors"
  ],
  "SaiSaketh/Y": [
    "model.safetensors"
  ],
  "TheBloke/8x7B-MoE-test-NOT-MIXTRAL-GPTQ": [
    "model.safetensors"
  ],
  "SaiSaketh/Z": [
    "model.safetensors"
  ],
  "kalyanmaram/x": [
    "model.safetensors"
  ],
  "dvijay/mistral-alpaca2k-3e": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "csdc-atl/buffer-baichuan2-13B-rag-awq-int4": [
    "model.safetensors"
  ],
  "intervitens/Mixtral-8x7B-Instruct-v0.1-3.5bpw-h6-exl2-rpcal": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-aann-indef-non_num_removal-1e-4": [
    "model.safetensors"
  ],
  "TheBloke/Chupacabra-8x7B-MoE-GPTQ": [
    "model.safetensors"
  ],
  "Xangelix/bairoboros-l2-7b-3.0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "intervitens/Mixtral-8x7B-Instruct-v0.1-3.75bpw-h6-exl2-rpcal": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "martyn/llama2-megamerge-dare-13b-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "praneshgunner/gpt2-medical-v1": [
    "model.safetensors"
  ],
  "TheBloke/Falkor-8x7B-MoE-GPTQ": [
    "model.safetensors"
  ],
  "Ram07/areg": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Parth/llama-2-7b-platypus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "netcat420/MHENNlit": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "lavawolfiee/Mixtral-8x7B-Instruct-v0.1-offloading-demo": [
    "model-00001-of-00257.safetensors",
    "model-00002-of-00257.safetensors",
    "model-00003-of-00257.safetensors",
    "model-00004-of-00257.safetensors",
    "model-00005-of-00257.safetensors",
    "model-00006-of-00257.safetensors",
    "model-00007-of-00257.safetensors",
    "model-00008-of-00257.safetensors",
    "model-00009-of-00257.safetensors",
    "model-00010-of-00257.safetensors",
    "model-00011-of-00257.safetensors",
    "model-00012-of-00257.safetensors",
    "model-00013-of-00257.safetensors",
    "model-00014-of-00257.safetensors",
    "model-00015-of-00257.safetensors",
    "model-00016-of-00257.safetensors",
    "model-00017-of-00257.safetensors",
    "model-00018-of-00257.safetensors",
    "model-00019-of-00257.safetensors",
    "model-00020-of-00257.safetensors",
    "model-00021-of-00257.safetensors",
    "model-00022-of-00257.safetensors",
    "model-00023-of-00257.safetensors",
    "model-00024-of-00257.safetensors",
    "model-00025-of-00257.safetensors",
    "model-00026-of-00257.safetensors",
    "model-00027-of-00257.safetensors",
    "model-00028-of-00257.safetensors",
    "model-00029-of-00257.safetensors",
    "model-00030-of-00257.safetensors",
    "model-00031-of-00257.safetensors",
    "model-00032-of-00257.safetensors",
    "model-00033-of-00257.safetensors",
    "model-00034-of-00257.safetensors",
    "model-00035-of-00257.safetensors",
    "model-00036-of-00257.safetensors",
    "model-00037-of-00257.safetensors",
    "model-00038-of-00257.safetensors",
    "model-00039-of-00257.safetensors",
    "model-00040-of-00257.safetensors",
    "model-00041-of-00257.safetensors",
    "model-00042-of-00257.safetensors",
    "model-00043-of-00257.safetensors",
    "model-00044-of-00257.safetensors",
    "model-00045-of-00257.safetensors",
    "model-00046-of-00257.safetensors",
    "model-00047-of-00257.safetensors",
    "model-00048-of-00257.safetensors",
    "model-00049-of-00257.safetensors",
    "model-00050-of-00257.safetensors",
    "model-00051-of-00257.safetensors",
    "model-00052-of-00257.safetensors",
    "model-00053-of-00257.safetensors",
    "model-00054-of-00257.safetensors",
    "model-00055-of-00257.safetensors",
    "model-00056-of-00257.safetensors",
    "model-00057-of-00257.safetensors",
    "model-00058-of-00257.safetensors",
    "model-00059-of-00257.safetensors",
    "model-00060-of-00257.safetensors",
    "model-00061-of-00257.safetensors",
    "model-00062-of-00257.safetensors",
    "model-00063-of-00257.safetensors",
    "model-00064-of-00257.safetensors",
    "model-00065-of-00257.safetensors",
    "model-00066-of-00257.safetensors",
    "model-00067-of-00257.safetensors",
    "model-00068-of-00257.safetensors",
    "model-00069-of-00257.safetensors",
    "model-00070-of-00257.safetensors",
    "model-00071-of-00257.safetensors",
    "model-00072-of-00257.safetensors",
    "model-00073-of-00257.safetensors",
    "model-00074-of-00257.safetensors",
    "model-00075-of-00257.safetensors",
    "model-00076-of-00257.safetensors",
    "model-00077-of-00257.safetensors",
    "model-00078-of-00257.safetensors",
    "model-00079-of-00257.safetensors",
    "model-00080-of-00257.safetensors",
    "model-00081-of-00257.safetensors",
    "model-00082-of-00257.safetensors",
    "model-00083-of-00257.safetensors",
    "model-00084-of-00257.safetensors",
    "model-00085-of-00257.safetensors",
    "model-00086-of-00257.safetensors",
    "model-00087-of-00257.safetensors",
    "model-00088-of-00257.safetensors",
    "model-00089-of-00257.safetensors",
    "model-00090-of-00257.safetensors",
    "model-00091-of-00257.safetensors",
    "model-00092-of-00257.safetensors",
    "model-00093-of-00257.safetensors",
    "model-00094-of-00257.safetensors",
    "model-00095-of-00257.safetensors",
    "model-00096-of-00257.safetensors",
    "model-00097-of-00257.safetensors",
    "model-00098-of-00257.safetensors",
    "model-00099-of-00257.safetensors",
    "model-00100-of-00257.safetensors",
    "model-00101-of-00257.safetensors",
    "model-00102-of-00257.safetensors",
    "model-00103-of-00257.safetensors",
    "model-00104-of-00257.safetensors",
    "model-00105-of-00257.safetensors",
    "model-00106-of-00257.safetensors",
    "model-00107-of-00257.safetensors",
    "model-00108-of-00257.safetensors",
    "model-00109-of-00257.safetensors",
    "model-00110-of-00257.safetensors",
    "model-00111-of-00257.safetensors",
    "model-00112-of-00257.safetensors",
    "model-00113-of-00257.safetensors",
    "model-00114-of-00257.safetensors",
    "model-00115-of-00257.safetensors",
    "model-00116-of-00257.safetensors",
    "model-00117-of-00257.safetensors",
    "model-00118-of-00257.safetensors",
    "model-00119-of-00257.safetensors",
    "model-00120-of-00257.safetensors",
    "model-00121-of-00257.safetensors",
    "model-00122-of-00257.safetensors",
    "model-00123-of-00257.safetensors",
    "model-00124-of-00257.safetensors",
    "model-00125-of-00257.safetensors",
    "model-00126-of-00257.safetensors",
    "model-00127-of-00257.safetensors",
    "model-00128-of-00257.safetensors",
    "model-00129-of-00257.safetensors",
    "model-00130-of-00257.safetensors",
    "model-00131-of-00257.safetensors",
    "model-00132-of-00257.safetensors",
    "model-00133-of-00257.safetensors",
    "model-00134-of-00257.safetensors",
    "model-00135-of-00257.safetensors",
    "model-00136-of-00257.safetensors",
    "model-00137-of-00257.safetensors",
    "model-00138-of-00257.safetensors",
    "model-00139-of-00257.safetensors",
    "model-00140-of-00257.safetensors",
    "model-00141-of-00257.safetensors",
    "model-00142-of-00257.safetensors",
    "model-00143-of-00257.safetensors",
    "model-00144-of-00257.safetensors",
    "model-00145-of-00257.safetensors",
    "model-00146-of-00257.safetensors",
    "model-00147-of-00257.safetensors",
    "model-00148-of-00257.safetensors",
    "model-00149-of-00257.safetensors",
    "model-00150-of-00257.safetensors",
    "model-00151-of-00257.safetensors",
    "model-00152-of-00257.safetensors",
    "model-00153-of-00257.safetensors",
    "model-00154-of-00257.safetensors",
    "model-00155-of-00257.safetensors",
    "model-00156-of-00257.safetensors",
    "model-00157-of-00257.safetensors",
    "model-00158-of-00257.safetensors",
    "model-00159-of-00257.safetensors",
    "model-00160-of-00257.safetensors",
    "model-00161-of-00257.safetensors",
    "model-00162-of-00257.safetensors",
    "model-00163-of-00257.safetensors",
    "model-00164-of-00257.safetensors",
    "model-00165-of-00257.safetensors",
    "model-00166-of-00257.safetensors",
    "model-00167-of-00257.safetensors",
    "model-00168-of-00257.safetensors",
    "model-00169-of-00257.safetensors",
    "model-00170-of-00257.safetensors",
    "model-00171-of-00257.safetensors",
    "model-00172-of-00257.safetensors",
    "model-00173-of-00257.safetensors",
    "model-00174-of-00257.safetensors",
    "model-00175-of-00257.safetensors",
    "model-00176-of-00257.safetensors",
    "model-00177-of-00257.safetensors",
    "model-00178-of-00257.safetensors",
    "model-00179-of-00257.safetensors",
    "model-00180-of-00257.safetensors",
    "model-00181-of-00257.safetensors",
    "model-00182-of-00257.safetensors",
    "model-00183-of-00257.safetensors",
    "model-00184-of-00257.safetensors",
    "model-00185-of-00257.safetensors",
    "model-00186-of-00257.safetensors",
    "model-00187-of-00257.safetensors",
    "model-00188-of-00257.safetensors",
    "model-00189-of-00257.safetensors",
    "model-00190-of-00257.safetensors",
    "model-00191-of-00257.safetensors",
    "model-00192-of-00257.safetensors",
    "model-00193-of-00257.safetensors",
    "model-00194-of-00257.safetensors",
    "model-00195-of-00257.safetensors",
    "model-00196-of-00257.safetensors",
    "model-00197-of-00257.safetensors",
    "model-00198-of-00257.safetensors",
    "model-00199-of-00257.safetensors",
    "model-00200-of-00257.safetensors",
    "model-00201-of-00257.safetensors",
    "model-00202-of-00257.safetensors",
    "model-00203-of-00257.safetensors",
    "model-00204-of-00257.safetensors",
    "model-00205-of-00257.safetensors",
    "model-00206-of-00257.safetensors",
    "model-00207-of-00257.safetensors",
    "model-00208-of-00257.safetensors",
    "model-00209-of-00257.safetensors",
    "model-00210-of-00257.safetensors",
    "model-00211-of-00257.safetensors",
    "model-00212-of-00257.safetensors",
    "model-00213-of-00257.safetensors",
    "model-00214-of-00257.safetensors",
    "model-00215-of-00257.safetensors",
    "model-00216-of-00257.safetensors",
    "model-00217-of-00257.safetensors",
    "model-00218-of-00257.safetensors",
    "model-00219-of-00257.safetensors",
    "model-00220-of-00257.safetensors",
    "model-00221-of-00257.safetensors",
    "model-00222-of-00257.safetensors",
    "model-00223-of-00257.safetensors",
    "model-00224-of-00257.safetensors",
    "model-00225-of-00257.safetensors",
    "model-00226-of-00257.safetensors",
    "model-00227-of-00257.safetensors",
    "model-00228-of-00257.safetensors",
    "model-00229-of-00257.safetensors",
    "model-00230-of-00257.safetensors",
    "model-00231-of-00257.safetensors",
    "model-00232-of-00257.safetensors",
    "model-00233-of-00257.safetensors",
    "model-00234-of-00257.safetensors",
    "model-00235-of-00257.safetensors",
    "model-00236-of-00257.safetensors",
    "model-00237-of-00257.safetensors",
    "model-00238-of-00257.safetensors",
    "model-00239-of-00257.safetensors",
    "model-00240-of-00257.safetensors",
    "model-00241-of-00257.safetensors",
    "model-00242-of-00257.safetensors",
    "model-00243-of-00257.safetensors",
    "model-00244-of-00257.safetensors",
    "model-00245-of-00257.safetensors",
    "model-00246-of-00257.safetensors",
    "model-00247-of-00257.safetensors",
    "model-00248-of-00257.safetensors",
    "model-00249-of-00257.safetensors",
    "model-00250-of-00257.safetensors",
    "model-00251-of-00257.safetensors",
    "model-00252-of-00257.safetensors",
    "model-00253-of-00257.safetensors",
    "model-00254-of-00257.safetensors",
    "model-00255-of-00257.safetensors",
    "model-00256-of-00257.safetensors",
    "model-00257-of-00257.safetensors"
  ],
  "praneshgunner/gpt2-medical-v2": [
    "model.safetensors"
  ],
  "martyn/codellama-megamerge-dare-34b": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "intervitens/Mixtral-8x7B-Instruct-v0.1-5.5bpw-h6-exl2-rpcal": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "LoneStriker/Mixtral-4x7B-DPO-RPChat-3.0bpw-h6-exl2-2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "brucethemoose/Yi-34B-200K-DARE-merge-v5-4bpw-exl2-fiction": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "brucethemoose/Yi-34B-200K-DARE-merge-v5-3.1bpw-exl2-fiction": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "brucethemoose/Yi-34B-200K-DARE-merge-v5-2.67bpw-exl2-fiction": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "WuZTY/tinystarcoder-rlhf-model": [
    "model.safetensors"
  ],
  "srihariEmids/emidsinfo-finetune-llmmodel": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/Mixtral-4x7B-DPO-RPChat-4.0bpw-h6-exl2-2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "TinyPixel/m4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Mixtral-4x7B-DPO-RPChat-5.0bpw-h6-exl2-2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "mahihossain666/llama-2-70b-hf-quantized-3bits-GPTQ": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/Mixtral-4x7B-DPO-RPChat-6.0bpw-h6-exl2-2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "sairaghava/meditronfinetuneqa": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rishiraj/CatPPT-base": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "nhero/gpt2-imdb-pos-v2": [
    "model.safetensors"
  ],
  "intervitens/Mixtral-8x7B-Instruct-v0.1-3.75bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "intervitens/Mixtral-8x7B-Instruct-v0.1-3.5bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "mncai/agiin-11.1B-v0.1": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "intervitens/Mixtral-8x7B-Instruct-v0.1-5.5bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "akashgoel-id/OpenHathi-7B-English-to-Hinglish": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Toppy-Mix-4x7B-3.0bpw-h6-exl2-2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/Mixtral-Fusion-4x7B-Instruct-v0.1-3.0bpw-h6-exl2-2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/Mixtral-Fusion-4x7B-Instruct-v0.1-4.0bpw-h6-exl2-2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/Toppy-Mix-4x7B-4.0bpw-h6-exl2-2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/Mixtral-Fusion-4x7B-Instruct-v0.1-5.0bpw-h6-exl2-2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/Toppy-Mix-4x7B-5.0bpw-h6-exl2-2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/Mixtral-Fusion-4x7B-Instruct-v0.1-6.0bpw-h6-exl2-2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Mixtral-SlimOrca-8x7B-2.4bpw-h6-exl2-2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/Mixtral-Fusion-4x7B-Instruct-v0.1-8.0bpw-h8-exl2-2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "huseinzol05/llama-3.2b-hf-32768": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "areegtarek/openchat-Radiology-Simplify": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "v2ray/TonyGPT-8x7B-QLoRA": [
    "adapter_model.safetensors"
  ],
  "LoneStriker/Toppy-Mix-4x7B-8.0bpw-h8-exl2-2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "rishiraj/CatPPT": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Anshulmango/LLaMa2_13B_Chat-finetuned-Discharge_Summary": [
    "adapter_model.safetensors"
  ],
  "LoneStriker/Mixtral-SlimOrca-8x7B-3.0bpw-h6-exl2-2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "Myashka/gpt-imdb-kto-beta_0.1": [
    "model.safetensors"
  ],
  "LoneStriker/Mixtral-SlimOrca-8x7B-4.0bpw-h6-exl2-2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Mixtral-SlimOrca-8x7B-5.0bpw-h6-exl2-2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "LoneStriker/Mixtral-SlimOrca-8x7B-6.0bpw-h6-exl2-2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "abhinav-32/distilgpt2-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "LoneStriker/Mixtral-8x7B-MoE-Undi95-RP-Story-3.5bpw-h6-exl2-2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "livewire/distilgpt2-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "linqus/codeparrot-ds": [
    "model.safetensors"
  ],
  "beratcmn/Poet-7B-TR": [
    "adapter_model.safetensors",
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "mjkimmjmj/SDC_Mistral_v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "cmeraki/OpenHathi-7B-Hi-v0.1-Base-gptq": [
    "model.safetensors"
  ],
  "projecte-aina/FLOR-1.3B-Instructed": [
    "model.safetensors"
  ],
  "ddh0/OrcaMaid-v2-FIX-13b-32k": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Mixtral-SlimOrca-8x7B-3.5bpw-h6-exl2-2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "bachngo/meta-Llama-2-7b-chat-mul": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "exontidev/results": [
    "model.safetensors"
  ],
  "OpenPipe/mistral-ft-optimized-1218": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/go-bruins-v2.1.1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/go-bruins-v2.1.1-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Mixtral-Fusion-4x7B-Instruct-v0.1-GPTQ": [
    "model.safetensors"
  ],
  "LoneStriker/Mixtral-8x7B-v0.1-2.4bpw-h6-exl2-2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Kooten/Noromaid-13b-v0.2-8bpw-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Kooten/Noromaid-13b-v0.2-4bpw-exl2": [
    "output.safetensors"
  ],
  "TheBloke/PiVoT-10.7B-Mistral-v0.2-RP-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/PiVoT-10.7B-Mistral-v0.2-RP-GPTQ": [
    "model.safetensors"
  ],
  "LemTenku/hub": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Mixtral-8x7B-v0.1-3.0bpw-h6-exl2-2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Toppy-Mix-4x7B-6.0bpw-h6-exl2-2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "Kooten/Noromaid-13b-v0.2-6bpw-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/Mixtral-8x7B-v0.1-3.5bpw-h6-exl2-2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "Dev-180/distilgpt2-squad": [
    "model.safetensors"
  ],
  "TheBloke/PiVoT-MoE-GPTQ": [
    "model.safetensors"
  ],
  "NExtNewChattingAI/shark_tank_ai_7_b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Mixtral-8x7B-v0.1-4.0bpw-h6-exl2-2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-aann-indef-non_num_removal-3e-4": [
    "model.safetensors"
  ],
  "LoneStriker/Mixtral-8x7B-v0.1-5.0bpw-h6-exl2-2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "cookinai/BruinHermes": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "louislian2341/output2": [
    "model.safetensors"
  ],
  "ogbinar/mistralai-ubuntu-qa": [
    "model-00001-of-00003.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00003.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "DevamMondal/Llama-2-13b-chat-hf-debiased1k": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "NobodyExistsOnTheInternet/mistral-sysmsg-test": [
    "adapter_model.safetensors"
  ],
  "TheBloke/PlatYi-34B-Llama-Q-v3-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/PlatYi-34B-Llama-Q-v3-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mmnga/TinyMixtral-x8-Clonebase-7b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/Mixtral-8x7B-v0.1-6.0bpw-h6-exl2-2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "susnato/phi-2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Xangelix/dairoboros-l2-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AntonioG/gpt2-squad": [
    "model.safetensors"
  ],
  "TheBloke/BigPlap-8x20B-GPTQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Prezily/dialogGPT-large-dd": [
    "model.safetensors"
  ],
  "kasrahabib/zephyr-7b-beta-ReqBrain": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/GreenNodeLM-7B-v4leo-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/GreenNodeLM-7B-v4leo-GPTQ": [
    "model.safetensors"
  ],
  "ai-aerospace/autotrain-ams_v0.1_100_Mistral-7B-Instruct-v0.1": [
    "adapter_model.safetensors",
    "checkpoint-81/adapter_model.safetensors"
  ],
  "Mr-Bhaskar/FusionBot": [
    "ai-therapist/adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "IHaBiS/PiVoT-MoE-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "RadoMinchev/Llama-2-7b-chat-hf-sharded-bf16-5GB": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Tylerswe/zinbo-llama2-7b": [
    "adapter_model.safetensors",
    "checkpoint-21/adapter_model.safetensors"
  ],
  "KnutJaegersberg/Walter-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "EdgeAIStaffing/edgeai-37a": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "quantumaikr/quantum-dpo-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "quantumaikr/quantum-v0.01": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "yishanz/mistral-7b-finetuned-datatalk": [
    "adapter_model.safetensors",
    "checkpoint-32/adapter_model.safetensors"
  ],
  "Fredithefish/Stallion": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "orangetin/OpenHermes-Mixtral-8x7B": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "ddh0/Norocetacean-20b-10k": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Blazej/mistral7B_align_bank_guidelines_logsigmoid_loss": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "DevamMondal/Llama-2-13b-chat-hf-debiased4k": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "TheBloke/Saily_220B-GPTQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Saily_220B-AWQ": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "Minata/ast_method2test-codegen-350M_v1_v1": [
    "model.safetensors"
  ],
  "Blazej/mistral7B_align_bank_guidelines_kto_loss": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "danieltee/ryjy-wdz0-1kop-0": [
    "adapter_model.safetensors",
    "checkpoint-1713/adapter_model.safetensors"
  ],
  "wassname/phi-2-w_hidden_states": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "testingman22/nadine-mini": [
    "adapter_model.safetensors"
  ],
  "amazingvince/mixtral-smol-400m": [
    "model-00001-of-00002.safetensors",
    "model-00001-of-00004.safetensors",
    "model-00002-of-00002.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "MisterRid/wendigo-14b-alpha4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kkuramitsu/tinycodellama-jp-0.13b-10k": [
    "model.safetensors"
  ],
  "YeungNLP/firefly-mixtral-8x7b": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "Jungtek/mistral-fine-tuned-co-c15": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "itsliupeng/Mixtral-8x7B-v0.1-top3": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "inswave/AISquare-Instruct-llama2-koen-13b-v0.9.22": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ddh0/Pirouette-7b": [
    "model-00001-of-00001.safetensors"
  ],
  "cyberdevilS/Law_bot": [],
  "IbuNai/Mixtral-4x7B-v0.1": [
    "model-00001-of-00005.safetensors",
    "model-00001-of-00010.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00005.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "ravikumar101/phi2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Llamix2-MLewd-4x13B-2.4bpw-h6-exl2-2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Peachteaboba/galebot": [
    "model.safetensors"
  ],
  "EmbeddedLLM/Mistral-7B-Merge-14-v0": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "IbuNai/Mixtral-2x7B-v0.1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LogicismTV/Chronomaid-Storytelling-13b-exl2": [
    "output.safetensors"
  ],
  "inswave/AISquare-Instruct-llama2-koen-13b-v0.9.23": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "IbuNai/Mixtral-6x7B-v0.1": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "sandy37/repo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Llamix2-MLewd-4x13B-3.0bpw-h6-exl2-2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/Llamix2-MLewd-4x13B-3.5bpw-h6-exl2-2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Llamix2-MLewd-4x13B-4.0bpw-h6-exl2-2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "shleeeee/mistral-ko-OpenOrca-Platypus-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "OpenBuddy/openbuddy-mixtral-8x7b-v15.2": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "LoneStriker/Llamix2-MLewd-4x13B-5.0bpw-h6-exl2-2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "areegtarek/DeciLM-Radiology-Simplify": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "firef1i/gogogo-llama2-13b": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "LoneStriker/Llamix2-MLewd-4x13B-6.0bpw-h6-exl2-2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "ainoob101/deci-7b-dolly-qlora": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "EmbeddedLLM/Mistral-7B-Merge-14-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Hyeongdon/t5-large-character_plot_portion": [
    "model.safetensors"
  ],
  "LoneStriker/Pirouette-7b-3.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "LoneStriker/Pirouette-7b-4.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "hwanhe/psmllama13b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "EmbeddedLLM/Mistral-7B-Merge-14-v0.2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Pirouette-7b-5.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "Minirecord/minyi_dpo_6b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Pirouette-7b-6.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "LoneStriker/Pirouette-7b-8.0bpw-h8-exl2-2": [
    "output.safetensors"
  ],
  "Minirecord/psm_170k_llama_13b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Loyola/Mistral-7b-Instruct-Kullmdata-v0.2-training-20000": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TrumpBiden/zephyr-7b-sft-lora-8": [
    "adapter_model.safetensors"
  ],
  "waldie/dolphin-2.2-yi-34b-200k-4bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "jingyeom/mistral_ko_all_inst": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/PiVoT-MoE-3.0bpw-h6-exl2-2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "ding-diri-ding-dong/distilgpt2": [
    "model.safetensors"
  ],
  "prd-nguyenvo/olivia-7b-dpo-lora-v2": [
    "adapter_model.safetensors"
  ],
  "chuducandev/Llama-2-7b-chat-hf-000": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/PiVoT-MoE-4.0bpw-h6-exl2-2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "danieltee/ozrf-npcv-ewht-0": [
    "adapter_model.safetensors",
    "checkpoint-1713/adapter_model.safetensors"
  ],
  "LoneStriker/PiVoT-MoE-4.65bpw-h6-exl2-2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "TheBloke/Pirouette-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Pirouette-7B-GPTQ": [
    "model.safetensors"
  ],
  "Sao10K/SOLAR-10.7B-NahIdWin": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "LoneStriker/PiVoT-MoE-5.0bpw-h6-exl2-2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "silk-road/ChatHaruhi_RolePlaying_qwen_7b": [
    "adapter_model.safetensors"
  ],
  "LoneStriker/PiVoT-MoE-6.0bpw-h6-exl2-2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "TheBloke/Norocetacean-20B-10k-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Norocetacean-20B-10k-GPTQ": [
    "model.safetensors"
  ],
  "A2H0H0R1/Qwen-7B-Chat-Int4-Qlora-biology": [
    "adapter_model.safetensors",
    "checkpoint-1000/adapter_model.safetensors"
  ],
  "LoneStriker/PiVoT-MoE-8.0bpw-h8-exl2-2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "jingyeom/Yi-ko_3_1_7": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "RedaAlami/falcon-7b-sft-lora": [
    "adapter_model.safetensors"
  ],
  "SAGI-1/g_moe": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "jan-hq/trinity-v1.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "johnbw223/Bharat_Tech_Test": [
    "model.safetensors"
  ],
  "blueapple8259/TinyKo-V2": [
    "model.safetensors"
  ],
  "Kaustubh651/lucifer651": [
    "model.safetensors"
  ],
  "ElMater06/gpt-j-nano": [
    "model.safetensors"
  ],
  "Anachrono/speaker_identification_mistral_7b_v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "raowaqas123/hbl_v4": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "abhishek/dgyf-ojml-b1z8-0": [
    "adapter_model.safetensors",
    "checkpoint-87/adapter_model.safetensors"
  ],
  "vanisus/neuroSSTU_02": [
    "model.safetensors"
  ],
  "TrumpBiden/zephyr-7b-sft-lora-10": [
    "adapter_model.safetensors"
  ],
  "jinnkenny99/Mistral-7B-instruct-Sentiment-V2": [
    "adapter_model.safetensors",
    "checkpoint-157/adapter_model.safetensors"
  ],
  "SAGI-1/testModel_v4_DPO_v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Mistral-7B-Merge-14-v0.1-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Mistral-7B-Merge-14-v0.1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/quantum-dpo-v0.1-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/quantum-dpo-v0.1-GPTQ": [
    "model.safetensors"
  ],
  "PeterV09/deita-6k-sft-fordpo": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "TheBloke/quantum-v0.01-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/quantum-v0.01-AWQ": [
    "model.safetensors"
  ],
  "topeomole/llama-dlm-2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Logeswaransr/AI_Chaperone_GPT2": [
    "model.safetensors"
  ],
  "LoneStriker/openbuddy-mixtral-8x7b-v15.2-2.4bpw-h6-exl2-2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/Metis-0.3-3.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "LoneStriker/Metis-0.3-4.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "LoneStriker/openbuddy-mixtral-8x7b-v15.2-3.0bpw-h6-exl2-2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Metis-0.3-5.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "perlthoughts/Mistral-7B-Instruct-v0.2-2x7B-MoE": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/Metis-0.3-6.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "LoneStriker/Metis-0.3-8.0bpw-h8-exl2-2": [
    "output.safetensors"
  ],
  "LoneStriker/openbuddy-mixtral-8x7b-v15.2-3.5bpw-h6-exl2-2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "SciPhi/Sensei-7B-V1": [
    "model-00001-of-00003.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00003.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "exontidev/SISUS_SIKERS": [
    "model.safetensors"
  ],
  "LoneStriker/openbuddy-mixtral-8x7b-v15.2-4.0bpw-h6-exl2-2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/openbuddy-mixtral-8x7b-v15.2-5.0bpw-h6-exl2-2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "tb2pi-persistent/Llama-2-7b-chat-hf-tb2pi-merged-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Mastane/falcon-7b-sft-lora": [
    "adapter_model.safetensors"
  ],
  "jtatman/tinymistral-248-DPO-lora": [
    "adapter_model.safetensors"
  ],
  "hobbesleland/CodeLlama-7b-Instruct-hf": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/openbuddy-mixtral-8x7b-v15.2-6.0bpw-h6-exl2-2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "Xangelix/hairoboros-l2-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "danish-foundation-models/munin-7b-alpha": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mmpc/DeciLM-7B-Finance": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "KaytTech/ll2-TinyPix-7b-bc4-finetuned": [
    "adapter_model.safetensors",
    "checkpoint-24/adapter_model.safetensors"
  ],
  "bdsaglam/llama-2-7b-chat-hf-kg-cons-multi-1702890189": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Timm877/geitje_v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Suhong/llama-2-7b-sli": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "intervitens/Mixtral-8x7B-Instruct-v0.1-6.0bpw-h6-exl2-rpcal": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "intervitens/Mixtral-8x7B-Instruct-v0.1-4.5bpw-h6-exl2-rpcal": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "intervitens/Mixtral-8x7B-Instruct-v0.1-3.7bpw-h6-exl2-rpcal": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "TheBloke/Metis-0.3-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Metis-0.3-AWQ": [
    "model.safetensors"
  ],
  "SaiSaketh/unh-academic-integrity-policy-560m": [
    "model.safetensors"
  ],
  "intervitens/Mixtral-8x7B-Instruct-v0.1-3.7bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "realshyfox/llama-2-7b-miniguanaco": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Edopangui/Nuevo_modelo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "inswave/AISquare-Instruct-llama2-koen-13b-v0.9.24": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "TheBloke/Fennec-Mixtral-8x7B-GPTQ": [
    "model.safetensors"
  ],
  "Faradaylab/Faradaylab-aria-mistral-merge_v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/OpenZephyrChat-v0.2-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/OpenZephyrChat-v0.2-GPTQ": [
    "model.safetensors"
  ],
  "norispace/mistral-7b-kopenorcav3": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ddh0/OrcaMaidXL-17B-32k": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-indef-naan_non_num-3e-4": [
    "model.safetensors"
  ],
  "norispace/polyglot-5.8b-kopenorcav3": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-indef-naan_non_num-1e-4": [
    "model.safetensors"
  ],
  "OpenBuddy/openbuddy-llama2-13b-v15p1-64k": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "TheBossLevel123/TinyLlama-Casual1": [
    "model.safetensors"
  ],
  "gsoaresbaptista/themis-instruct-qa": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Mastane/falcon-7b-dpo-lora": [
    "adapter_model.safetensors"
  ],
  "jan-hq/trinity-v1.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "KaeriJenti/Kaori-34B-v1": [
    "model-00001-of-00077.safetensors",
    "model-00002-of-00077.safetensors",
    "model-00003-of-00077.safetensors",
    "model-00004-of-00077.safetensors",
    "model-00005-of-00077.safetensors",
    "model-00006-of-00077.safetensors",
    "model-00007-of-00077.safetensors",
    "model-00008-of-00077.safetensors",
    "model-00009-of-00077.safetensors",
    "model-00010-of-00077.safetensors",
    "model-00011-of-00077.safetensors",
    "model-00012-of-00077.safetensors",
    "model-00013-of-00077.safetensors",
    "model-00014-of-00077.safetensors",
    "model-00015-of-00077.safetensors",
    "model-00016-of-00077.safetensors",
    "model-00017-of-00077.safetensors",
    "model-00018-of-00077.safetensors",
    "model-00019-of-00077.safetensors",
    "model-00020-of-00077.safetensors",
    "model-00021-of-00077.safetensors",
    "model-00022-of-00077.safetensors",
    "model-00023-of-00077.safetensors",
    "model-00024-of-00077.safetensors",
    "model-00025-of-00077.safetensors",
    "model-00026-of-00077.safetensors",
    "model-00027-of-00077.safetensors",
    "model-00028-of-00077.safetensors",
    "model-00029-of-00077.safetensors",
    "model-00030-of-00077.safetensors",
    "model-00031-of-00077.safetensors",
    "model-00032-of-00077.safetensors",
    "model-00033-of-00077.safetensors",
    "model-00034-of-00077.safetensors",
    "model-00035-of-00077.safetensors",
    "model-00036-of-00077.safetensors",
    "model-00037-of-00077.safetensors",
    "model-00038-of-00077.safetensors",
    "model-00039-of-00077.safetensors",
    "model-00040-of-00077.safetensors",
    "model-00041-of-00077.safetensors",
    "model-00042-of-00077.safetensors",
    "model-00043-of-00077.safetensors",
    "model-00044-of-00077.safetensors",
    "model-00045-of-00077.safetensors",
    "model-00046-of-00077.safetensors",
    "model-00047-of-00077.safetensors",
    "model-00048-of-00077.safetensors",
    "model-00049-of-00077.safetensors",
    "model-00050-of-00077.safetensors",
    "model-00051-of-00077.safetensors",
    "model-00052-of-00077.safetensors",
    "model-00053-of-00077.safetensors",
    "model-00054-of-00077.safetensors",
    "model-00055-of-00077.safetensors",
    "model-00056-of-00077.safetensors",
    "model-00057-of-00077.safetensors",
    "model-00058-of-00077.safetensors",
    "model-00059-of-00077.safetensors",
    "model-00060-of-00077.safetensors",
    "model-00061-of-00077.safetensors",
    "model-00062-of-00077.safetensors",
    "model-00063-of-00077.safetensors",
    "model-00064-of-00077.safetensors",
    "model-00065-of-00077.safetensors",
    "model-00066-of-00077.safetensors",
    "model-00067-of-00077.safetensors",
    "model-00068-of-00077.safetensors",
    "model-00069-of-00077.safetensors",
    "model-00070-of-00077.safetensors",
    "model-00071-of-00077.safetensors",
    "model-00072-of-00077.safetensors",
    "model-00073-of-00077.safetensors",
    "model-00074-of-00077.safetensors",
    "model-00075-of-00077.safetensors",
    "model-00076-of-00077.safetensors",
    "model-00077-of-00077.safetensors"
  ],
  "inswave/AISquare-Instruct-llama2-koen-13b-v0.9.25": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "martyn/mixtral-dare-8x7b-v0": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "Brillibits/Instruct_Mixtral-8x7B-v0.1_Dolly15K": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "bachngo/b118": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "arcee-ai/nuclear-1b": [
    "model.safetensors"
  ],
  "Loyola/Mistral-7b-Instruct-Kullmdata-v0.2-training-30000": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "RedaAlami/falcon-7b-dpo-lora": [
    "adapter_model.safetensors"
  ],
  "Maxx0/5306-zam1-j73y-0": [
    "adapter_model.safetensors",
    "checkpoint-6/adapter_model.safetensors"
  ],
  "Doctor-Shotgun/WinterGoddess-1.4x-limarpv3-70B-L2": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "Parth/llama-2-7b-druggpt": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jinnkenny99/Mistral-7B-instruct-Sentiment-Original": [
    "adapter_model.safetensors",
    "checkpoint-63/adapter_model.safetensors"
  ],
  "EmbeddedLLM/Mistral-7B-Merge-14-v0.3": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "IbuNai/mixtral-2x7b-ja-base": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "fblgit/una-llama-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "DopeorNope/COKAL_merged_test-v1-13B": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "rinna/nekomata-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "fblgit/UNA-SOLAR-10.7B-Instruct-v1.0": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "bluuwhale/zephyr-neural-chat_1.0": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Mihaiii/Metis-0.4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AIFT/aift-llama-ko-13b-instruct-v1.1-dpo-test2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "c1park/upload-test4": [
    "model-00001-of-00030.safetensors",
    "model-00002-of-00030.safetensors",
    "model-00003-of-00030.safetensors",
    "model-00004-of-00030.safetensors",
    "model-00005-of-00030.safetensors",
    "model-00006-of-00030.safetensors",
    "model-00007-of-00030.safetensors",
    "model-00008-of-00030.safetensors",
    "model-00009-of-00030.safetensors",
    "model-00010-of-00030.safetensors",
    "model-00011-of-00030.safetensors",
    "model-00012-of-00030.safetensors",
    "model-00013-of-00030.safetensors",
    "model-00014-of-00030.safetensors",
    "model-00015-of-00030.safetensors",
    "model-00016-of-00030.safetensors",
    "model-00017-of-00030.safetensors",
    "model-00018-of-00030.safetensors",
    "model-00019-of-00030.safetensors",
    "model-00020-of-00030.safetensors",
    "model-00021-of-00030.safetensors",
    "model-00022-of-00030.safetensors",
    "model-00023-of-00030.safetensors",
    "model-00024-of-00030.safetensors",
    "model-00025-of-00030.safetensors",
    "model-00026-of-00030.safetensors",
    "model-00027-of-00030.safetensors",
    "model-00028-of-00030.safetensors",
    "model-00029-of-00030.safetensors",
    "model-00030-of-00030.safetensors"
  ],
  "APMIC/caigun-lora-model-34B-v2": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "mwitiderrick/open_llama_3b_glaive_code_v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Margaret-mmh/llama-2-7b-miniplatypus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AhmedTaha012/gptneo-paragraghs_titles": [
    "model.safetensors"
  ],
  "Prashanthch/llama2-7b-latest": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/firefly-mixtral-8x7b-GPTQ": [
    "model.safetensors"
  ],
  "Kooten/Clover3-17B-3bpw-exl2": [
    "output.safetensors"
  ],
  "typedecker/Goblin-Sensei-Convo-model-large": [
    "model.safetensors"
  ],
  "ap1023/subtopic_mistral": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Metis-0.4-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Metis-0.4-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "herisan/llama-2-7b-mini-platypus-two": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Metis-0.4-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Metis-0.4-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Metis-0.4-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "YeungNLP/firefly-zephyr-6x7b-init": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "manjunathshiva/GRADE3B-7B-02-0": [
    "adapter_model.safetensors",
    "checkpoint-36/adapter_model.safetensors"
  ],
  "mojuss/llama-2-7b-chat-faq": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "unit-mesh/autodev-deepseek-6.7b-finetunes-poc": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "djomo/MISTRALllux300-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mncai/SDC_Llama2-13B_Lr05_Ep4": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "haramberesearch/llama2_xs_460M_uncensored": [
    "model.safetensors"
  ],
  "We-Want-GPU/Yi-Ko-6B-orca-alpaca-gpt4-math-lora": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "johnbw223/opt15_ultrachat_length_128": [
    "model.safetensors"
  ],
  "TrumpBiden/zephyr-7b-sft-lora-7": [
    "adapter_model.safetensors"
  ],
  "Kaustubh651/model_prompt": [
    "model.safetensors"
  ],
  "rdsmaia/cnn_news_ptbr_clm-model": [
    "model.safetensors"
  ],
  "Kaustubh651/training_model": [
    "model.safetensors"
  ],
  "Yhyu13/phi-2-sft-alpaca_gpt4_en-ep1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "phatjk/vinallama-7b-AWQ": [
    "model.safetensors"
  ],
  "phatjk/vinallama-7b-chat-AWQ": [
    "model.safetensors"
  ],
  "Shani123/Mixtral-8x7B-Instruct-v0.1-GPTQ": [
    "model-00001-of-00036.safetensors",
    "model-00002-of-00036.safetensors",
    "model-00003-of-00036.safetensors",
    "model-00004-of-00036.safetensors",
    "model-00005-of-00036.safetensors",
    "model-00006-of-00036.safetensors",
    "model-00007-of-00036.safetensors",
    "model-00008-of-00036.safetensors",
    "model-00009-of-00036.safetensors",
    "model-00010-of-00036.safetensors",
    "model-00011-of-00036.safetensors",
    "model-00012-of-00036.safetensors",
    "model-00013-of-00036.safetensors",
    "model-00014-of-00036.safetensors",
    "model-00015-of-00036.safetensors",
    "model-00016-of-00036.safetensors",
    "model-00017-of-00036.safetensors",
    "model-00018-of-00036.safetensors",
    "model-00019-of-00036.safetensors",
    "model-00020-of-00036.safetensors",
    "model-00021-of-00036.safetensors",
    "model-00022-of-00036.safetensors",
    "model-00023-of-00036.safetensors",
    "model-00024-of-00036.safetensors",
    "model-00025-of-00036.safetensors",
    "model-00026-of-00036.safetensors",
    "model-00027-of-00036.safetensors",
    "model-00028-of-00036.safetensors",
    "model-00029-of-00036.safetensors",
    "model-00030-of-00036.safetensors",
    "model-00031-of-00036.safetensors",
    "model-00032-of-00036.safetensors",
    "model-00033-of-00036.safetensors",
    "model-00034-of-00036.safetensors",
    "model-00035-of-00036.safetensors",
    "model-00036-of-00036.safetensors"
  ],
  "Kaustubh651/training_model1": [
    "model.safetensors"
  ],
  "Formid322/of8p-58hv-mvsg1-0": [
    "adapter_model.safetensors",
    "checkpoint-260/adapter_model.safetensors"
  ],
  "YvanAlvin/medical_chatbot": [
    "adapter_model.safetensors"
  ],
  "SAGI-1/reasoning_moe": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "Formid322/wyjj-4css-e4pz-0": [
    "adapter_model.safetensors",
    "checkpoint-230/adapter_model.safetensors"
  ],
  "Jiahuan/voxreality-arta-lego-llama2-7b-chat": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Kaustubh651/training_model2": [
    "model.safetensors"
  ],
  "Kaustubh651/training_model3": [
    "model.safetensors"
  ],
  "mojuss/llama-2-7b-chat-guanaco": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Formid322/09lo-xqb3-fi6r-0": [
    "adapter_model.safetensors",
    "checkpoint-260/adapter_model.safetensors"
  ],
  "Formid322/try3-0": [
    "adapter_model.safetensors",
    "checkpoint-260/adapter_model.safetensors"
  ],
  "erfanzar/LinguaMatic-2.7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/SOLAR-10.7B-Instruct-v1.0-uncensored-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/SOLAR-10.7B-Instruct-v1.0-uncensored-GPTQ": [
    "model.safetensors"
  ],
  "mmnga/Mixtral-Extraction-4x7B-Instruct-v0.1": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "LoneStriker/SOLAR-10.7B-Instruct-v1.0-uncensored-3.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "Tejas1415/MistralViggo": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/SOLAR-10.7B-Instruct-v1.0-uncensored-4.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "LoneStriker/SOLAR-10.7B-Instruct-v1.0-uncensored-5.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "R136a1/Frostwind-10.7B-v1-exl2": [
    "output.safetensors"
  ],
  "LoftQ/Llama-2-7b-hf-2bit-64rank": [
    "loftq_init/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/SOLAR-10.7B-Instruct-v1.0-uncensored-6.0bpw-h6-exl2-2": [
    "output.safetensors"
  ],
  "extraltodeus/Bise_7B_m37_SSRD": [
    "model.safetensors"
  ],
  "LoneStriker/SOLAR-10.7B-Instruct-v1.0-uncensored-8.0bpw-h8-exl2-2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "TheBloke/Metis-0.4-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Metis-0.4-GPTQ": [
    "model.safetensors"
  ],
  "BeardedPython/Llama-Butler-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/GEITje-7B-chat-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/GEITje-7B-chat-AWQ": [
    "model.safetensors"
  ],
  "LoftQ/Llama-2-7b-hf-2bit-32rank": [
    "loftq_init/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kevind13/codeLlama-7b-Instruct-hf-vuejs-nuxt-tailwind-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "OpenBuddy/openbuddy-mixtral-8x7b-v15.3": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "TheBloke/Yi-34B-200K-DARE-merge-v5-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Yi-34B-200K-DARE-merge-v5-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Swallow-70B-instruct-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Swallow-70B-instruct-GPTQ": [
    "model.safetensors"
  ],
  "Prashanthch/llama-2-7b-qna-tuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mrbmaryam/Yarn-Mistral-7b-128k_Fine-Tuning4Log-Summarization": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "cstnz/llama2_13b_qaconv": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoftQ/Llama-2-13b-hf-2bit-64rank": [
    "loftq_init/adapter_model.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "gsoaresbaptista/themis-7b-instruct": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MiltonBra/bloom-560m-8bit": [
    "model.safetensors"
  ],
  "justinwangx/vicuna-test-sft-lora": [
    "adapter_model.safetensors"
  ],
  "Locutusque/TinyMistral-248M-v2": [
    "model.safetensors"
  ],
  "crumb/apricot-wildflower-20": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Mixtral-8x7B-v0.1-7.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "johnbw223/bh_all_msg_128": [
    "model.safetensors"
  ],
  "ChaiML/season_4_top_solution": [
    "model-00001-of-00013.safetensors",
    "model-00002-of-00013.safetensors",
    "model-00003-of-00013.safetensors",
    "model-00004-of-00013.safetensors",
    "model-00005-of-00013.safetensors",
    "model-00006-of-00013.safetensors",
    "model-00007-of-00013.safetensors",
    "model-00008-of-00013.safetensors",
    "model-00009-of-00013.safetensors",
    "model-00010-of-00013.safetensors",
    "model-00011-of-00013.safetensors",
    "model-00012-of-00013.safetensors",
    "model-00013-of-00013.safetensors"
  ],
  "kittn/Mixtral-8x7B-Instruct-v0.1-gpt-fast": [],
  "LoftQ/Llama-2-13b-hf-2bit-32rank": [
    "loftq_init/adapter_model.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "damian91/tgi-gen7-mixed-2749-20": [
    "model.safetensors"
  ],
  "ElMater06/LLama-13B-Chat-4Bit": [
    "gptq_model-4bit-128g.safetensors"
  ],
  "LoneStriker/Mixtral-8x7B-Instruct-v0.1-2.4bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "saberai/Zro1.2_3B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Swallow-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Swallow-13B-AWQ": [
    "model.safetensors"
  ],
  "aloobun/bun_mistral_7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mnoukhov/pythia410m-tldrprompt-dpo1b": [
    "model.safetensors"
  ],
  "TheBloke/Swallow-70B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Swallow-70B-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "LoneStriker/Mixtral-8x7B-Instruct-v0.1-3.5bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Mixtral-8x7B-Instruct-v0.1-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "damian91/tgi-f16-gen7-mixed-2749-20": [
    "model.safetensors"
  ],
  "TheBloke/Swallow-13B-Instruct-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Swallow-13B-Instruct-GPTQ": [
    "model.safetensors"
  ],
  "LoneStriker/Mixtral-8x7B-Instruct-v0.1-5.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "LoneStriker/Mixtral-8x7B-Instruct-v0.1-6.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "TheBloke/Swallow-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Swallow-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Swallow-7B-Instruct-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Swallow-7B-Instruct-GPTQ": [
    "model.safetensors"
  ],
  "irmcon-org/myModel": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Lifan-Z/Chinese-Classic-Poem-Generator-style7x4-GPT2": [
    "model.safetensors"
  ],
  "MisterRid/saulgoodman-7b-alpha1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "VAGOsolutions/SauerkrautLM-SOLAR-Instruct": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "cookinai/CatMacaroni-Slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Bbrown44/aas-ds-v2": [
    "model.safetensors"
  ],
  "mp/ogow-vuc4-001w-0": [
    "adapter_model.safetensors",
    "checkpoint-21/adapter_model.safetensors"
  ],
  "Chung-Hsiung/Llama2-7b-finetuned": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ashk72/swaayata-finetuned-v3": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "awilliamson/wholism": [
    "checkpoint-12345/model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-measure_nouns_as_singular-3e-4": [
    "model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-measure_nouns_as_singular-1e-4": [
    "model.safetensors"
  ],
  "justinwangx/vicuna-robust-sft-lora": [
    "adapter_model.safetensors"
  ],
  "beberik/TinyExperts-v0-4x1B": [
    "model-00001-of-00001.safetensors"
  ],
  "LoneStriker/Mixtral-8x7B-Instruct-v0.1-3.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "aloobun/bun_mistral_7b_v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Mixtral-8x7B-Instruct-v0.1-7.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "Ram07/emp1_dialog": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "cookinai/DonutLM-v1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jan-hq/voyager-01.2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "manjunathshiva/GRADE3-IGCSE-BB": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "netcat420/MHENNcodemath": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/Yi-34B-200K-AEZAKMI-v2-3.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "sid321axn/CodeLlama-text-to-sql-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Yi-34B-200K-AEZAKMI-v2-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "johnbw223/bh_1000_512": [
    "model.safetensors"
  ],
  "titan087/ShiningValiant-exl2-4bpw": [
    "hidden_states.safetensors",
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "LoneStriker/Yi-34B-200K-AEZAKMI-v2-4.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "ravikumar101/mistral-7b-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Yi-34B-200K-AEZAKMI-v2-5.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Yi-34B-200K-AEZAKMI-v2-6.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "chinhang0104/distilgpt2-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "LoneStriker/Yi-34B-200K-AEZAKMI-v2-8.0bpw-h8-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "lightblue/karasu-7B": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "hkust-nlp/deita-7b-v1.0": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "dcipheranalytics/gpt-sw3-6.7b-v2-instruct-fp16": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dennissulejmanvisma/test_trainer": [
    "model.safetensors"
  ],
  "dennissulejmanvisma/confluence-model-test": [
    "model.safetensors"
  ],
  "Yhyu13/LMCocktail-10.7B-v1": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "TheBloke/Noromaid-13B-v0.2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Noromaid-13B-v0.2-AWQ": [
    "model.safetensors"
  ],
  "pPvot/llama-2-7b-platypus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Frostwind-10.7B-v1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Frostwind-10.7B-v1-AWQ": [
    "model.safetensors"
  ],
  "LoneStriker/firefly-mixtral-8x7b-2.4bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "jhflow/yi-ko-6b-dpo-further": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "chargoddard/MixtralRPChat-ZLoss": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "LoneStriker/firefly-mixtral-8x7b-3.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "johnbw223/bh_final": [
    "model.safetensors"
  ],
  "johnbw223/bh_all_512": [
    "model.safetensors"
  ],
  "chuducandev/Llama-2-7b-chat-hf-001": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "chuducandev/Llama-2-7b-chat-hf-002": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/firefly-mixtral-8x7b-3.5bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "chuducandev/Llama-2-7b-chat-hf-003": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tigerbhai/llama-2-7b-platypus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/openbuddy-mixtral-8x7b-v15.2-GPTQ": [
    "model.safetensors"
  ],
  "LoneStriker/firefly-mixtral-8x7b-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "AshanGimhana/CLONETest": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/LMCocktail-10.7B-v1-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "Shruti9756/G24_BTECH_PROJECT-step1": [
    "model.safetensors"
  ],
  "LoneStriker/firefly-mixtral-8x7b-5.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "LoneStriker/LMCocktail-10.7B-v1-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/LMCocktail-10.7B-v1-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "Shruti9756/G24_BTECH_PROJECT-step2": [
    "model.safetensors"
  ],
  "LoneStriker/firefly-mixtral-8x7b-6.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "xavierbarbier/mistral-7b-instruct-v0.1-hf-quant": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/LMCocktail-10.7B-v1-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "philschmid/Llama-2-7b-hf": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/LMCocktail-10.7B-v1-8.0bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "YashRawal225/Mistral2B-GPTQ": [
    "model.safetensors"
  ],
  "sbgrasdrht/model": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Srisowmya/finetune_GPT": [
    "model.safetensors"
  ],
  "Holmeister/falcon-7b-ft-chatgpt-en": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mncai/SDC_Llama2-13B_Lr05_Ep2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "anilbhatt1/phi2-oasst-guanaco-bf16-custom": [
    "model-00001-of-00002.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00002.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Herry443/Mistral-7B-KNUT-v0.5.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "harshithvh/llama2_finetuned4": [
    "checkpoint-220/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "harshithvh/mistral_finetuned2": [
    "checkpoint-210/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lekta/trurl-2-7b-GPTQ": [
    "model.safetensors"
  ],
  "EmbeddedLLM/Mistral-7B-Merge-02-v0": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jan-hq/stealth-v1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Herry443/Mistral-7B-KNUT-v0.5.4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mildwood/starling-7B-LM-alpha-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "scb10x/typhoon-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "themanas021/falcon-SAT-Alg-Instruct": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hflserdaniel/chai_llama_factory_test": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "AshanGimhana/ClonemodelTestV2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Herry443/Mistral-7B-KNUT-v0.5.2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "atmansingh/med-llama2-12.20.23": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Herry443/Mistral-7B-KNUT-v0.5.3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Reverb/Mistral-7B-LoreWeaver": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "YashRawal225/NewLlama1B-GPTQ": [
    "model.safetensors"
  ],
  "chathuru/cicids2018-falcon7b": [
    "adapter_model.safetensors"
  ],
  "Fearnworks/fearnstral-instruct-fn-v0.2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "monology/Mistral-7B-Instruct-v0.2-8bit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "kumarbhaskar8/merged_model": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "lxuechen/phi-2-sft": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "falca/zephyr-7b-sft-full": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "janhq/stealth-v1-sft": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/CatPPT-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "VishalMysore/cookgptlama": [
    "adapter_model.safetensors",
    "checkpoint-655/adapter_model.safetensors",
    "model.safetensors"
  ],
  "LoneStriker/CatPPT-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/CatPPT-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/CatPPT-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "ujjirox/Llama-2-70B-Chat-fp16": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "LoneStriker/CatPPT-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "mohcineelharras/TinyLlama-1.1B-Chat-v0.3-AWQ": [
    "model.safetensors"
  ],
  "meetkai/functionary-7b-v2.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "beowolx/CodeNinja-1.0-OpenChat-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/CatPPT-base-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "deborahm/gpt2_over_ptbr_cnn_news": [
    "model.safetensors"
  ],
  "LoneStriker/CatPPT-base-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/CatPPT-base-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/CatPPT-base-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/CatPPT-base-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "Undi95/SolarMaid-v0.1.1": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/DaringMaid-20B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/DaringMaid-20B-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/OpenHermes-Mixtral-8x7B-2.4bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/OpenHermes-Mixtral-8x7B-3.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/OpenHermes-Mixtral-8x7B-3.5bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "NeverSleep/FlatOrcamaid-13b-v0.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Jiahuan/gpt_teacher-llama2-7b-chat": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/OpenHermes-Mixtral-8x7B-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "TheBloke/dragon-mistral-7B-v0-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/dragon-mistral-7B-v0-GPTQ": [
    "model.safetensors"
  ],
  "LoneStriker/OpenHermes-Mixtral-8x7B-5.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "LoneStriker/OpenHermes-Mixtral-8x7B-6.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "LoneStriker/OrcaMaid-v2-FIX-13b-32k-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/OrcaMaid-v2-FIX-13b-32k-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "BEE-spoke-data/Mixtral-GQA-400m-v2": [
    "model.safetensors"
  ],
  "SheilaCXY/DialoGPT-RickBot": [
    "model.safetensors"
  ],
  "LoneStriker/OrcaMaid-v2-FIX-13b-32k-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Mixtral-8x7B-Instruct-v0.1-5.5bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "LoneStriker/OrcaMaidXL-17B-32k-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/OrcaMaid-v2-FIX-13b-32k-6.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/OrcaMaid-v2-FIX-13b-32k-8.0bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/OrcaMaidXL-17B-32k-4.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "ColleenMacklin/blenderbot-400M-distill-couples_therapist_chat1": [
    "model.safetensors"
  ],
  "Felladrin/Llama-160M-Chat-v1": [
    "model.safetensors"
  ],
  "LoneStriker/OrcaMaidXL-17B-32k-5.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Walmart-the-bag/phi-2-uncensored": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "akouaperla/DialoGPT-small-gordonramsay": [
    "model.safetensors"
  ],
  "LoneStriker/Mixtral-8x7B-v0.1-5.5bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "falca/zephyr-7b-dpo-full": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/OrcaMaidXL-17B-32k-6.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Kooten/FlatOrcamaid-13b-v0.2-8bpw-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Kooten/FlatOrcamaid-13b-v0.2-6bpw-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Kooten/FlatOrcamaid-13b-v0.2-5bpw-exl2": [
    "output.safetensors"
  ],
  "Kooten/FlatOrcamaid-13b-v0.2-4bpw-exl2": [
    "output.safetensors"
  ],
  "BallisticAI/Ballistic-CodeLlama-34B-v1": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "BallisticAI/Ballistic-CodeLlama-34B-v1-AWQ": [
    "gptq_model-4bit-128g.safetensors"
  ],
  "LoneStriker/OrcaMaidXL-17B-32k-8.0bpw-h8-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "inswave/AISquare-Instruct-yi-ko-6b-v0.9.26": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "We-Want-GPU/Yi-Ko-6B-orca-alpaca-gpt4-math-lora-DPO": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SanjiWatsuki/Loyal-Toppy-Bruins-Maid-7B-DARE": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "inswave/AISquare-Instruct-yi-ko-6b-v0.9.27": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "inswave/AISquare-Instruct-yi-ko-6b-v0.9.28": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "saihtaungkham/BurmeseRoBERTaCLM": [
    "model.safetensors"
  ],
  "APMIC/caigun-lora-model-34B-v3": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "saberai/Zro-Alpaca": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "zomd/AISquare-Instruct-yi-ko-6b-v0.9.27": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "zomd/AISquare-Instruct-yi-ko-6b-v0.9.28": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kkuramitsu/tinycodellama-jp-0.13b-20k": [
    "model.safetensors"
  ],
  "decem/Dionysus": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/FlatOrcamaid-13b-v0.2-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "oopsung/Yi-Ko-6B-com-test-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/FlatOrcamaid-13b-v0.2-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/FlatOrcamaid-13b-v0.2-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "KaeriJenti/Kaori-34b-v2": [
    "model-00001-of-00077.safetensors",
    "model-00002-of-00077.safetensors",
    "model-00003-of-00077.safetensors",
    "model-00004-of-00077.safetensors",
    "model-00005-of-00077.safetensors",
    "model-00006-of-00077.safetensors",
    "model-00007-of-00077.safetensors",
    "model-00008-of-00077.safetensors",
    "model-00009-of-00077.safetensors",
    "model-00010-of-00077.safetensors",
    "model-00011-of-00077.safetensors",
    "model-00012-of-00077.safetensors",
    "model-00013-of-00077.safetensors",
    "model-00014-of-00077.safetensors",
    "model-00015-of-00077.safetensors",
    "model-00016-of-00077.safetensors",
    "model-00017-of-00077.safetensors",
    "model-00018-of-00077.safetensors",
    "model-00019-of-00077.safetensors",
    "model-00020-of-00077.safetensors",
    "model-00021-of-00077.safetensors",
    "model-00022-of-00077.safetensors",
    "model-00023-of-00077.safetensors",
    "model-00024-of-00077.safetensors",
    "model-00025-of-00077.safetensors",
    "model-00026-of-00077.safetensors",
    "model-00027-of-00077.safetensors",
    "model-00028-of-00077.safetensors",
    "model-00029-of-00077.safetensors",
    "model-00030-of-00077.safetensors",
    "model-00031-of-00077.safetensors",
    "model-00032-of-00077.safetensors",
    "model-00033-of-00077.safetensors",
    "model-00034-of-00077.safetensors",
    "model-00035-of-00077.safetensors",
    "model-00036-of-00077.safetensors",
    "model-00037-of-00077.safetensors",
    "model-00038-of-00077.safetensors",
    "model-00039-of-00077.safetensors",
    "model-00040-of-00077.safetensors",
    "model-00041-of-00077.safetensors",
    "model-00042-of-00077.safetensors",
    "model-00043-of-00077.safetensors",
    "model-00044-of-00077.safetensors",
    "model-00045-of-00077.safetensors",
    "model-00046-of-00077.safetensors",
    "model-00047-of-00077.safetensors",
    "model-00048-of-00077.safetensors",
    "model-00049-of-00077.safetensors",
    "model-00050-of-00077.safetensors",
    "model-00051-of-00077.safetensors",
    "model-00052-of-00077.safetensors",
    "model-00053-of-00077.safetensors",
    "model-00054-of-00077.safetensors",
    "model-00055-of-00077.safetensors",
    "model-00056-of-00077.safetensors",
    "model-00057-of-00077.safetensors",
    "model-00058-of-00077.safetensors",
    "model-00059-of-00077.safetensors",
    "model-00060-of-00077.safetensors",
    "model-00061-of-00077.safetensors",
    "model-00062-of-00077.safetensors",
    "model-00063-of-00077.safetensors",
    "model-00064-of-00077.safetensors",
    "model-00065-of-00077.safetensors",
    "model-00066-of-00077.safetensors",
    "model-00067-of-00077.safetensors",
    "model-00068-of-00077.safetensors",
    "model-00069-of-00077.safetensors",
    "model-00070-of-00077.safetensors",
    "model-00071-of-00077.safetensors",
    "model-00072-of-00077.safetensors",
    "model-00073-of-00077.safetensors",
    "model-00074-of-00077.safetensors",
    "model-00075-of-00077.safetensors",
    "model-00076-of-00077.safetensors",
    "model-00077-of-00077.safetensors"
  ],
  "LoneStriker/FlatOrcamaid-13b-v0.2-6.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/FlatOrcamaid-13b-v0.2-8.0bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Ram07/emp4_dialog": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lightblue/karasu-7B-chat": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "kimnt93/vi-vicuna-13b-16k-inst": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Pm06/llama-2-7b-miniplatypus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Clyine1/my_awesome_eli5_clm-model": [
    "model.safetensors"
  ],
  "Loyola/kulmistral-7b-it": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Yhyu13/LMCocktail-phi-2-v1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "danielmalencar/novo": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "moneyforward/houou-instruction-7b-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "truemansquad/myllm": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tb2pi-persistent/Llama-2-7b-chat-hf-tb2pi-merged-v3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "offtoung/tsukuyomi-chan-calm2-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jan-hq/voyager-01.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "wangrongsheng/Aurora": [
    "adapter_model.safetensors",
    "checkpoint-1000/adapter_model.safetensors",
    "checkpoint-10000/adapter_model.safetensors",
    "checkpoint-11000/adapter_model.safetensors",
    "checkpoint-12000/adapter_model.safetensors",
    "checkpoint-13000/adapter_model.safetensors",
    "checkpoint-14000/adapter_model.safetensors",
    "checkpoint-15000/adapter_model.safetensors",
    "checkpoint-16000/adapter_model.safetensors",
    "checkpoint-2000/adapter_model.safetensors",
    "checkpoint-3000/adapter_model.safetensors",
    "checkpoint-4000/adapter_model.safetensors",
    "checkpoint-5000/adapter_model.safetensors",
    "checkpoint-6000/adapter_model.safetensors",
    "checkpoint-7000/adapter_model.safetensors",
    "checkpoint-8000/adapter_model.safetensors",
    "checkpoint-9000/adapter_model.safetensors"
  ],
  "SicariusSicariiStuff/Tenebra_PreAlpha_No_Group_g_3BIT": [
    "model.safetensors"
  ],
  "decem/Dionysus-v2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Satyam-Singh/LLaVa-Large-Language-Virtual-Assistant": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "Kedar84/Falcon7b-mental-health": [
    "adapter_model.safetensors"
  ],
  "JGlang/llama2-mergedmodel_testserveur": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "DevanshuSawant/distilgpt2-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "brian-lim/smile-style-transfer": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/WhiteRabbitNeo-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/WhiteRabbitNeo-13B-AWQ": [
    "model.safetensors"
  ],
  "SanjiWatsuki/SOLAR-SCUFFED-DO-NOT-USE": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/OrcaMaidXL-17B-32k-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/OrcaMaidXL-17B-32k-AWQ": [
    "model.safetensors"
  ],
  "WompWomp1/DialoGPT-large-Chika": [
    "model.safetensors"
  ],
  "cloudyu/Mixtral_7Bx4_MOE_24B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Minami-su/XVERSE-7B_2bit": [
    "model.safetensors"
  ],
  "cnmoro/vicuna-7b-v1.5-SPR-Compressor-AWQ": [
    "model.safetensors"
  ],
  "Lifan-Z/Chinese-Classic-Poem-Generator-style5x4-GPT2": [
    "model.safetensors"
  ],
  "ohwi/japanese-stablelm-instruct-gamma-7b-dpo-uf-v0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "cnhefang/mz_model_merged": [
    "model.safetensors"
  ],
  "jan-hq/stealth-v1.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "diamantrsd/cerpengen-v3": [
    "model.safetensors"
  ],
  "0x7o/fialka-13B-v1": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "TheBloke/FlatOrcamaid-13B-v0.2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/FlatOrcamaid-13B-v0.2-AWQ": [
    "model.safetensors"
  ],
  "teilomillet/Potato-3B": [
    "model-00001-of-00001.safetensors"
  ],
  "TheBloke/Llama-2-7B-ft-instruct-es-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Llama-2-7B-ft-instruct-es-AWQ": [
    "model.safetensors"
  ],
  "rvv-karma/BASH-Coder-Mistral-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "KathirKs/phi-2_LogiCoT_finetuned": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TharunSiva/phi-2-oasst1-100steps": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "TheBloke/OrcaMaid-v2-FIX-13B-32k-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/OrcaMaid-v2-FIX-13B-32k-GPTQ": [
    "model.safetensors"
  ],
  "parse-boyz/mistral_7b-instruct-louis": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Nondzu/Mistral-7B-Instruct-v0.2-code-ft": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/mistral-ft-optimized-1218-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/mistral-ft-optimized-1218-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/orangetin-OpenHermes-Mixtral-8x7B-GPTQ": [
    "model.safetensors"
  ],
  "severcorp/oc35": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "josh-sematic/short-cnn-json-tune-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "abhishek/quip-v1": [
    "adapter_model.safetensors",
    "checkpoint-80/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Weyaxi/SauerkrautLM-UNA-SOLAR-Instruct": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dynamofl/dynamo-8B-v0.1": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "ammarzaarour/aragpt2-base-saadeh-full": [
    "model.safetensors"
  ],
  "erfanzar/LinguaMatic-1B": [
    "model.safetensors"
  ],
  "kevind13/codeLlama-7b-Instruct-hf-vuejs-nuxt-tailwind-finetuned-examples": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "khoantap/mishy-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Wharp/Sheldon": [
    "model.safetensors"
  ],
  "s3nh/phi-1_5_dolly_instruction_polish": [
    "model.safetensors"
  ],
  "kedarbhumkar/Mistral-7b-ft-122123": [
    "adapter_model.safetensors",
    "checkpoint-1/adapter_model.safetensors"
  ],
  "MexIvanov/zephyr-python-ru-merged": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "netcat420/MHENNcodemathv2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "josh-sematic/cnn-2k-json-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "zomd/AISquare-Instruct-yi-ko-6b-v0.9.29": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "zomd/AISquare-Instruct-yi-ko-6b-v0.9.30": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "BattlestarGalacticaFan1978/DialoGPT-medium-joshua": [
    "model.safetensors"
  ],
  "alpayariyak/RunPod-OpenCoder-2": [
    "ep_0/model-00001-of-00003.safetensors",
    "ep_0/model-00002-of-00003.safetensors",
    "ep_0/model-00003-of-00003.safetensors",
    "ep_1/model-00001-of-00003.safetensors",
    "ep_1/model-00002-of-00003.safetensors",
    "ep_1/model-00003-of-00003.safetensors",
    "ep_2/model-00001-of-00003.safetensors",
    "ep_2/model-00002-of-00003.safetensors",
    "ep_2/model-00003-of-00003.safetensors",
    "ep_3/model-00001-of-00003.safetensors",
    "ep_3/model-00002-of-00003.safetensors",
    "ep_3/model-00003-of-00003.safetensors",
    "ep_4/model-00001-of-00003.safetensors",
    "ep_4/model-00002-of-00003.safetensors",
    "ep_4/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "adlumal/AusLegalQA-Mixtral-8x7B-Instruct-v0.1": [
    "model-00001-of-00098.safetensors",
    "model-00002-of-00098.safetensors",
    "model-00003-of-00098.safetensors",
    "model-00004-of-00098.safetensors",
    "model-00005-of-00098.safetensors",
    "model-00006-of-00098.safetensors",
    "model-00007-of-00098.safetensors",
    "model-00008-of-00098.safetensors",
    "model-00009-of-00098.safetensors",
    "model-00010-of-00098.safetensors",
    "model-00011-of-00098.safetensors",
    "model-00012-of-00098.safetensors",
    "model-00013-of-00098.safetensors",
    "model-00014-of-00098.safetensors",
    "model-00015-of-00098.safetensors",
    "model-00016-of-00098.safetensors",
    "model-00017-of-00098.safetensors",
    "model-00018-of-00098.safetensors",
    "model-00019-of-00098.safetensors",
    "model-00020-of-00098.safetensors",
    "model-00021-of-00098.safetensors",
    "model-00022-of-00098.safetensors",
    "model-00023-of-00098.safetensors",
    "model-00024-of-00098.safetensors",
    "model-00025-of-00098.safetensors",
    "model-00026-of-00098.safetensors",
    "model-00027-of-00098.safetensors",
    "model-00028-of-00098.safetensors",
    "model-00029-of-00098.safetensors",
    "model-00030-of-00098.safetensors",
    "model-00031-of-00098.safetensors",
    "model-00032-of-00098.safetensors",
    "model-00033-of-00098.safetensors",
    "model-00034-of-00098.safetensors",
    "model-00035-of-00098.safetensors",
    "model-00036-of-00098.safetensors",
    "model-00037-of-00098.safetensors",
    "model-00038-of-00098.safetensors",
    "model-00039-of-00098.safetensors",
    "model-00040-of-00098.safetensors",
    "model-00041-of-00098.safetensors",
    "model-00042-of-00098.safetensors",
    "model-00043-of-00098.safetensors",
    "model-00044-of-00098.safetensors",
    "model-00045-of-00098.safetensors",
    "model-00046-of-00098.safetensors",
    "model-00047-of-00098.safetensors",
    "model-00048-of-00098.safetensors",
    "model-00049-of-00098.safetensors",
    "model-00050-of-00098.safetensors",
    "model-00051-of-00098.safetensors",
    "model-00052-of-00098.safetensors",
    "model-00053-of-00098.safetensors",
    "model-00054-of-00098.safetensors",
    "model-00055-of-00098.safetensors",
    "model-00056-of-00098.safetensors",
    "model-00057-of-00098.safetensors",
    "model-00058-of-00098.safetensors",
    "model-00059-of-00098.safetensors",
    "model-00060-of-00098.safetensors",
    "model-00061-of-00098.safetensors",
    "model-00062-of-00098.safetensors",
    "model-00063-of-00098.safetensors",
    "model-00064-of-00098.safetensors",
    "model-00065-of-00098.safetensors",
    "model-00066-of-00098.safetensors",
    "model-00067-of-00098.safetensors",
    "model-00068-of-00098.safetensors",
    "model-00069-of-00098.safetensors",
    "model-00070-of-00098.safetensors",
    "model-00071-of-00098.safetensors",
    "model-00072-of-00098.safetensors",
    "model-00073-of-00098.safetensors",
    "model-00074-of-00098.safetensors",
    "model-00075-of-00098.safetensors",
    "model-00076-of-00098.safetensors",
    "model-00077-of-00098.safetensors",
    "model-00078-of-00098.safetensors",
    "model-00079-of-00098.safetensors",
    "model-00080-of-00098.safetensors",
    "model-00081-of-00098.safetensors",
    "model-00082-of-00098.safetensors",
    "model-00083-of-00098.safetensors",
    "model-00084-of-00098.safetensors",
    "model-00085-of-00098.safetensors",
    "model-00086-of-00098.safetensors",
    "model-00087-of-00098.safetensors",
    "model-00088-of-00098.safetensors",
    "model-00089-of-00098.safetensors",
    "model-00090-of-00098.safetensors",
    "model-00091-of-00098.safetensors",
    "model-00092-of-00098.safetensors",
    "model-00093-of-00098.safetensors",
    "model-00094-of-00098.safetensors",
    "model-00095-of-00098.safetensors",
    "model-00096-of-00098.safetensors",
    "model-00097-of-00098.safetensors",
    "model-00098-of-00098.safetensors"
  ],
  "lightblue/karasu-7B-chat-plus": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "decem/Dionysus-Mistral": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kiranvutukuri/gpt2": [
    "checkpoint/checkpoint-90000/model.safetensors",
    "model.safetensors"
  ],
  "dayaburamshetty/reuters-gpt2-text-gen": [
    "model.safetensors"
  ],
  "elliotthwangmsa/KimLan-LLaMa": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jjourney1125/llama2-13b-v1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Prezily/gpt2-all-the-news-headlines": [
    "model.safetensors"
  ],
  "vikash06/llama-2-7b-small-model-new": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Parth/codellama-2-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "cutycat2000/MeowGPT-2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Locutusque/Orca-2-13b-SFT-v6": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "KaeriJenti/kaori-34b-v3": [
    "model-00001-of-00077.safetensors",
    "model-00002-of-00077.safetensors",
    "model-00003-of-00077.safetensors",
    "model-00004-of-00077.safetensors",
    "model-00005-of-00077.safetensors",
    "model-00006-of-00077.safetensors",
    "model-00007-of-00077.safetensors",
    "model-00008-of-00077.safetensors",
    "model-00009-of-00077.safetensors",
    "model-00010-of-00077.safetensors",
    "model-00011-of-00077.safetensors",
    "model-00012-of-00077.safetensors",
    "model-00013-of-00077.safetensors",
    "model-00014-of-00077.safetensors",
    "model-00015-of-00077.safetensors",
    "model-00016-of-00077.safetensors",
    "model-00017-of-00077.safetensors",
    "model-00018-of-00077.safetensors",
    "model-00019-of-00077.safetensors",
    "model-00020-of-00077.safetensors",
    "model-00021-of-00077.safetensors",
    "model-00022-of-00077.safetensors",
    "model-00023-of-00077.safetensors",
    "model-00024-of-00077.safetensors",
    "model-00025-of-00077.safetensors",
    "model-00026-of-00077.safetensors",
    "model-00027-of-00077.safetensors",
    "model-00028-of-00077.safetensors",
    "model-00029-of-00077.safetensors",
    "model-00030-of-00077.safetensors",
    "model-00031-of-00077.safetensors",
    "model-00032-of-00077.safetensors",
    "model-00033-of-00077.safetensors",
    "model-00034-of-00077.safetensors",
    "model-00035-of-00077.safetensors",
    "model-00036-of-00077.safetensors",
    "model-00037-of-00077.safetensors",
    "model-00038-of-00077.safetensors",
    "model-00039-of-00077.safetensors",
    "model-00040-of-00077.safetensors",
    "model-00041-of-00077.safetensors",
    "model-00042-of-00077.safetensors",
    "model-00043-of-00077.safetensors",
    "model-00044-of-00077.safetensors",
    "model-00045-of-00077.safetensors",
    "model-00046-of-00077.safetensors",
    "model-00047-of-00077.safetensors",
    "model-00048-of-00077.safetensors",
    "model-00049-of-00077.safetensors",
    "model-00050-of-00077.safetensors",
    "model-00051-of-00077.safetensors",
    "model-00052-of-00077.safetensors",
    "model-00053-of-00077.safetensors",
    "model-00054-of-00077.safetensors",
    "model-00055-of-00077.safetensors",
    "model-00056-of-00077.safetensors",
    "model-00057-of-00077.safetensors",
    "model-00058-of-00077.safetensors",
    "model-00059-of-00077.safetensors",
    "model-00060-of-00077.safetensors",
    "model-00061-of-00077.safetensors",
    "model-00062-of-00077.safetensors",
    "model-00063-of-00077.safetensors",
    "model-00064-of-00077.safetensors",
    "model-00065-of-00077.safetensors",
    "model-00066-of-00077.safetensors",
    "model-00067-of-00077.safetensors",
    "model-00068-of-00077.safetensors",
    "model-00069-of-00077.safetensors",
    "model-00070-of-00077.safetensors",
    "model-00071-of-00077.safetensors",
    "model-00072-of-00077.safetensors",
    "model-00073-of-00077.safetensors",
    "model-00074-of-00077.safetensors",
    "model-00075-of-00077.safetensors",
    "model-00076-of-00077.safetensors",
    "model-00077-of-00077.safetensors"
  ],
  "KaeriJenti/kaori-34b-v4": [
    "model-00001-of-00077.safetensors",
    "model-00002-of-00077.safetensors",
    "model-00003-of-00077.safetensors",
    "model-00004-of-00077.safetensors",
    "model-00005-of-00077.safetensors",
    "model-00006-of-00077.safetensors",
    "model-00007-of-00077.safetensors",
    "model-00008-of-00077.safetensors",
    "model-00009-of-00077.safetensors",
    "model-00010-of-00077.safetensors",
    "model-00011-of-00077.safetensors",
    "model-00012-of-00077.safetensors",
    "model-00013-of-00077.safetensors",
    "model-00014-of-00077.safetensors",
    "model-00015-of-00077.safetensors",
    "model-00016-of-00077.safetensors",
    "model-00017-of-00077.safetensors",
    "model-00018-of-00077.safetensors",
    "model-00019-of-00077.safetensors",
    "model-00020-of-00077.safetensors",
    "model-00021-of-00077.safetensors",
    "model-00022-of-00077.safetensors",
    "model-00023-of-00077.safetensors",
    "model-00024-of-00077.safetensors",
    "model-00025-of-00077.safetensors",
    "model-00026-of-00077.safetensors",
    "model-00027-of-00077.safetensors",
    "model-00028-of-00077.safetensors",
    "model-00029-of-00077.safetensors",
    "model-00030-of-00077.safetensors",
    "model-00031-of-00077.safetensors",
    "model-00032-of-00077.safetensors",
    "model-00033-of-00077.safetensors",
    "model-00034-of-00077.safetensors",
    "model-00035-of-00077.safetensors",
    "model-00036-of-00077.safetensors",
    "model-00037-of-00077.safetensors",
    "model-00038-of-00077.safetensors",
    "model-00039-of-00077.safetensors",
    "model-00040-of-00077.safetensors",
    "model-00041-of-00077.safetensors",
    "model-00042-of-00077.safetensors",
    "model-00043-of-00077.safetensors",
    "model-00044-of-00077.safetensors",
    "model-00045-of-00077.safetensors",
    "model-00046-of-00077.safetensors",
    "model-00047-of-00077.safetensors",
    "model-00048-of-00077.safetensors",
    "model-00049-of-00077.safetensors",
    "model-00050-of-00077.safetensors",
    "model-00051-of-00077.safetensors",
    "model-00052-of-00077.safetensors",
    "model-00053-of-00077.safetensors",
    "model-00054-of-00077.safetensors",
    "model-00055-of-00077.safetensors",
    "model-00056-of-00077.safetensors",
    "model-00057-of-00077.safetensors",
    "model-00058-of-00077.safetensors",
    "model-00059-of-00077.safetensors",
    "model-00060-of-00077.safetensors",
    "model-00061-of-00077.safetensors",
    "model-00062-of-00077.safetensors",
    "model-00063-of-00077.safetensors",
    "model-00064-of-00077.safetensors",
    "model-00065-of-00077.safetensors",
    "model-00066-of-00077.safetensors",
    "model-00067-of-00077.safetensors",
    "model-00068-of-00077.safetensors",
    "model-00069-of-00077.safetensors",
    "model-00070-of-00077.safetensors",
    "model-00071-of-00077.safetensors",
    "model-00072-of-00077.safetensors",
    "model-00073-of-00077.safetensors",
    "model-00074-of-00077.safetensors",
    "model-00075-of-00077.safetensors",
    "model-00076-of-00077.safetensors",
    "model-00077-of-00077.safetensors"
  ],
  "realPCH/mistral_QLoRA_v0": [
    "model-00001-of-00033.safetensors",
    "model-00002-of-00033.safetensors",
    "model-00003-of-00033.safetensors",
    "model-00004-of-00033.safetensors",
    "model-00005-of-00033.safetensors",
    "model-00006-of-00033.safetensors",
    "model-00007-of-00033.safetensors",
    "model-00008-of-00033.safetensors",
    "model-00009-of-00033.safetensors",
    "model-00010-of-00033.safetensors",
    "model-00011-of-00033.safetensors",
    "model-00012-of-00033.safetensors",
    "model-00013-of-00033.safetensors",
    "model-00014-of-00033.safetensors",
    "model-00015-of-00033.safetensors",
    "model-00016-of-00033.safetensors",
    "model-00017-of-00033.safetensors",
    "model-00018-of-00033.safetensors",
    "model-00019-of-00033.safetensors",
    "model-00020-of-00033.safetensors",
    "model-00021-of-00033.safetensors",
    "model-00022-of-00033.safetensors",
    "model-00023-of-00033.safetensors",
    "model-00024-of-00033.safetensors",
    "model-00025-of-00033.safetensors",
    "model-00026-of-00033.safetensors",
    "model-00027-of-00033.safetensors",
    "model-00028-of-00033.safetensors",
    "model-00029-of-00033.safetensors",
    "model-00030-of-00033.safetensors",
    "model-00031-of-00033.safetensors",
    "model-00032-of-00033.safetensors",
    "model-00033-of-00033.safetensors"
  ],
  "Parth/codellama-2-7b-v2-catppt": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "bvanflet/coverletter": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "shibiyaj/lawGPT-chat": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "cloudyu/Mixtral_7Bx2_MoE_13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Clyine1/bart-large-cnn-finetuned-bert-school-questions": [
    "model.safetensors"
  ],
  "sid321axn/tinyllama-text2sql-finetuned": [
    "model.safetensors"
  ],
  "zyh3826/GML-Mistral-merged-v1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mediocredev/open-llama-3b-v2-chat": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Joe-J-2000/my_awesome_eli5_clm-model": [
    "model.safetensors"
  ],
  "Minami-su/SUS-Chat-34B_2bit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "reddyprasade/test_case_generater_llm_model": [
    "model-00001-of-00001.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "SuperAGI/SAM": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ravikumar101/mistral-7b-v3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tb2pi-persistent/Llama-2-7b-chat-hf-tb2pi-merged-v4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MarwanWaly/git-base-pokemon": [
    "model.safetensors"
  ],
  "Doctor-Shotgun/Mixtral-8x7B-Instruct-v0.1-limarp": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "lightblue/karasu-7B-chat-plus-unleashed": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "BEE-spoke-data/Mixtral-GQA-400m-v3": [
    "model.safetensors"
  ],
  "Shruti9756/G24_Contract_Summarization_step1": [
    "model.safetensors"
  ],
  "chanios/SeaLLM-7B-Chat-8.0bpw-exl2": [
    "output.safetensors"
  ],
  "chanios/SeaLLM-7B-Chat-4.0bpw-exl2": [
    "output.safetensors"
  ],
  "chanios/SeaLLM-7B-Chat-4.5bpw-exl2": [
    "output.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5": [
    "model.safetensors"
  ],
  "Nero10578/Mistral-7B-Sunda-v1.0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "heegyu/1222-42dot-1.3B-Ko-CoT-Collection-2e-5": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "shivanikerai/hpc_grocery_baby_beauty-titles-category-extraction-v2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "lightblue/qarasu-14B-chat-plus-unleashed": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_member_shadow0": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_member_shadow1": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_member_shadow2": [
    "model.safetensors"
  ],
  "BEE-spoke-data/smol_llama-220M-GQA": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_member_shadow3": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_member_shadow4": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_member_shadow5": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_member_shadow6": [
    "model.safetensors"
  ],
  "decem/Dionysus-Mistral-v3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_member_shadow7": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_member_shadow8": [
    "model.safetensors"
  ],
  "TheBloke/dolphin-2.6-mixtral-8x7b-GPTQ": [
    "model.safetensors"
  ],
  "Shruti9756/G24_Contract_Summarization_step2": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_member_shadow9": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_member_shadow10": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_member_shadow11": [
    "model.safetensors"
  ],
  "tb2pi-persistent/Llama-2-7b-hf-tb2pi-merged-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_member_shadow12": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_member_shadow13": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_member_shadow14": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_member_shadow15": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_member_shadow16": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_member_shadow17": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_member_shadow18": [
    "model.safetensors"
  ],
  "TheBloke/WizardMath-7B-V1.1-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/WizardMath-7B-V1.1-GPTQ": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_member_shadow19": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_member_shadow20": [
    "model.safetensors"
  ],
  "TinyPixel/m7": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_member_shadow21": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_member_shadow22": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_member_shadow23": [
    "model.safetensors"
  ],
  "Samoed/resume_llm_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "chats-bug/llama-1-7b-mcli-pyjama-sample": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_member_shadow24": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_member_shadow25": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_member_shadow26": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_member_shadow27": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_member_shadow28": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_member_shadow29": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_member_shadow30": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_member_shadow31": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_member_shadow32": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_member_shadow33": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_member_shadow34": [
    "model.safetensors"
  ],
  "Ram07/Dialo-f1": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_member_shadow35": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_member_shadow36": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_member_shadow37": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_member_shadow38": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_member_shadow39": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_member_shadow40": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_member_shadow41": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_non_member_shadow0": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_non_member_shadow1": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_non_member_shadow2": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_non_member_shadow3": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_non_member_shadow4": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_non_member_shadow5": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_non_member_shadow6": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_non_member_shadow7": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_non_member_shadow8": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_non_member_shadow9": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_non_member_shadow10": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_non_member_shadow11": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_non_member_shadow12": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_non_member_shadow13": [
    "model.safetensors"
  ],
  "casperhansen/mixtral-instruct-awq": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_non_member_shadow14": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_non_member_shadow15": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_non_member_shadow16": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_non_member_shadow17": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_non_member_shadow18": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_non_member_shadow19": [
    "model.safetensors"
  ],
  "LoneStriker/MixtralRPChat-ZLoss-2.4bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "gupta1912/phi-2-custom-oasst1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/MixtralRPChat-ZLoss-3.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "fblgit/LUNA-SOLARkrautLM-Instruct": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "LoneStriker/MixtralRPChat-ZLoss-3.5bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "cloudyu/Mixtral_7Bx2_MoE": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ramy21/tinyllama2": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "byroneverson/Solar-10.7B-Instruct-v1.0-shell": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "LoneStriker/MixtralRPChat-ZLoss-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/MixtralRPChat-ZLoss-5.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "LoneStriker/MixtralRPChat-ZLoss-6.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "bachngo/vietnamese-llama2-7b-120GB": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/MixtralRPChat-ZLoss-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/MixtralRPChat-ZLoss-GPTQ": [
    "model.safetensors"
  ],
  "chatty123/llama2-2048-3B-APPS": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "hails/PE_Mistral_7b_sft_rlhf": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "zkv/llama-2-7b-chat-hf-assistant-air": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SelcukCan/gpt2-imdb-pos-v2": [
    "model.safetensors"
  ],
  "SelcukCan/gpt2-imdb-pos-SelCan-v2": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75": [
    "model.safetensors"
  ],
  "OpenBuddy/openbuddy-mixtral-8x7b-v15.4": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow0": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow1": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow2": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow3": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow4": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow5": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow6": [
    "model.safetensors"
  ],
  "tb2pi-persistent/Llama-2-7b-chat-hf-tb2pi-merged-v5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow7": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow8": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow9": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow10": [
    "model.safetensors"
  ],
  "sumit1986/sumit-awesome-model": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow11": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow12": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow13": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow14": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow15": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow16": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow17": [
    "model.safetensors"
  ],
  "tb2pi-persistent/Llama-2-7b-hf-tb2pi-merged-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow18": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow19": [
    "model.safetensors"
  ],
  "Vinay573/newdataset": [
    "model.safetensors"
  ],
  "TheBloke/dolphin-2.6-mixtral-8x7b-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow20": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow21": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow22": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow23": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow24": [
    "model.safetensors"
  ],
  "TheBloke/mixtralnt-4x7b-test-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/PiVoT-MoE-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow25": [
    "model.safetensors"
  ],
  "TheBloke/Mixtral-8x7B-MoE-RP-Story-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Mixtral-SlimOrca-8x7B-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/dolphin-2.5-mixtral-8x7b-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow26": [
    "model.safetensors"
  ],
  "TheBloke/Synthia-MoE-v3-Mixtral-8x7B-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Yhyu13/phi-2-sft-dpo-gpt4_en-ep1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow27": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow28": [
    "model.safetensors"
  ],
  "severcorp/mix": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow29": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow30": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow31": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow32": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow33": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow34": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow35": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow36": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow37": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow38": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow39": [
    "model.safetensors"
  ],
  "ramy21/gptmed": [
    "checkpoint-729/model.safetensors",
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow40": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow41": [
    "model.safetensors"
  ],
  "4bit/MythoMax-L2-13B-GPTQ": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow42": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow43": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow44": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow45": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow46": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow47": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow48": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow49": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow50": [
    "model.safetensors"
  ],
  "TheBloke/Mixtral-Fusion-4x7B-Instruct-v0.1-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow51": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow52": [
    "model.safetensors"
  ],
  "TheBloke/openbuddy-mixtral-8x7b-v15.2-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_member_shadow53": [
    "model.safetensors"
  ],
  "TheBloke/Fennec-Mixtral-8x7B-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/orangetin-OpenHermes-Mixtral-8x7B-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/openbuddy-mixtral-8x7b-v15.1-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_non_member_shadow0": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_non_member_shadow1": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_non_member_shadow2": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_non_member_shadow3": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_non_member_shadow4": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_non_member_shadow5": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_non_member_shadow6": [
    "model.safetensors"
  ],
  "pr1me/SunsetBoulevard": [
    "model-00001-of-00061.safetensors",
    "model-00002-of-00061.safetensors",
    "model-00003-of-00061.safetensors",
    "model-00004-of-00061.safetensors",
    "model-00005-of-00061.safetensors",
    "model-00006-of-00061.safetensors",
    "model-00007-of-00061.safetensors",
    "model-00008-of-00061.safetensors",
    "model-00009-of-00061.safetensors",
    "model-00010-of-00061.safetensors",
    "model-00011-of-00061.safetensors",
    "model-00012-of-00061.safetensors",
    "model-00013-of-00061.safetensors",
    "model-00014-of-00061.safetensors",
    "model-00015-of-00061.safetensors",
    "model-00016-of-00061.safetensors",
    "model-00017-of-00061.safetensors",
    "model-00018-of-00061.safetensors",
    "model-00019-of-00061.safetensors",
    "model-00020-of-00061.safetensors",
    "model-00021-of-00061.safetensors",
    "model-00022-of-00061.safetensors",
    "model-00023-of-00061.safetensors",
    "model-00024-of-00061.safetensors",
    "model-00025-of-00061.safetensors",
    "model-00026-of-00061.safetensors",
    "model-00027-of-00061.safetensors",
    "model-00028-of-00061.safetensors",
    "model-00029-of-00061.safetensors",
    "model-00030-of-00061.safetensors",
    "model-00031-of-00061.safetensors",
    "model-00032-of-00061.safetensors",
    "model-00033-of-00061.safetensors",
    "model-00034-of-00061.safetensors",
    "model-00035-of-00061.safetensors",
    "model-00036-of-00061.safetensors",
    "model-00037-of-00061.safetensors",
    "model-00038-of-00061.safetensors",
    "model-00039-of-00061.safetensors",
    "model-00040-of-00061.safetensors",
    "model-00041-of-00061.safetensors",
    "model-00042-of-00061.safetensors",
    "model-00043-of-00061.safetensors",
    "model-00044-of-00061.safetensors",
    "model-00045-of-00061.safetensors",
    "model-00046-of-00061.safetensors",
    "model-00047-of-00061.safetensors",
    "model-00048-of-00061.safetensors",
    "model-00049-of-00061.safetensors",
    "model-00050-of-00061.safetensors",
    "model-00051-of-00061.safetensors",
    "model-00052-of-00061.safetensors",
    "model-00053-of-00061.safetensors",
    "model-00054-of-00061.safetensors",
    "model-00055-of-00061.safetensors",
    "model-00056-of-00061.safetensors",
    "model-00057-of-00061.safetensors",
    "model-00058-of-00061.safetensors",
    "model-00059-of-00061.safetensors",
    "model-00060-of-00061.safetensors",
    "model-00061-of-00061.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_non_member_shadow7": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_non_member_shadow8": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_non_member_shadow9": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_non_member_shadow10": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_non_member_shadow11": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_non_member_shadow12": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_non_member_shadow13": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_non_member_shadow14": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_non_member_shadow15": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_non_member_shadow16": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_non_member_shadow17": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_non_member_shadow18": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t18_e75_non_member_shadow19": [
    "model.safetensors"
  ],
  "ramy21/llamamed": [
    "checkpoint-630/model.safetensors",
    "model.safetensors"
  ],
  "ramy21/gptmed4": [
    "checkpoint-728/model.safetensors",
    "model.safetensors"
  ],
  "C0uchP0tat0/gpt2medium-finetuned": [
    "model.safetensors"
  ],
  "TheBloke/CodeNinja-1.0-OpenChat-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/CodeNinja-1.0-OpenChat-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Llamix2-MLewd-4x13B-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/firefly-mixtral-8x7b-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "DopeorNope/Mark1-revision-10.7B": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "DopeorNope/maestralo-v2": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "LoneStriker/CodeNinja-1.0-OpenChat-7B-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/CodeNinja-1.0-OpenChat-7B-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/CodeNinja-1.0-OpenChat-7B-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/CodeNinja-1.0-OpenChat-7B-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/CodeNinja-1.0-OpenChat-7B-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "SanjiWatsuki/openchat-3.5-1210-starling-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "kedarbhumkar/Mistral-7b-ft-122223": [
    "checkpoint-1/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tunggad/task-clm-distilgpt2-eli5-text-generation": [
    "model.safetensors"
  ],
  "breadlicker45/muse-test-38": [
    "model.safetensors"
  ],
  "maywell/Synatra-7B-v0.3-QA": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "yasminesarraj/mistral-test": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "user2fa978F4eM/gz5Di9WnaP": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "NouRed/Med-Mistral-7B-QLoRa": [
    "adapter_model.safetensors"
  ],
  "Bobblack225/intstep": [
    "model.safetensors"
  ],
  "harmtech/Stheno-1.10-L2-13B-GPTQ": [
    "model.safetensors"
  ],
  "LarryTW/LLM_HW2": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jkloip/cm124057-02": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "wsyar/llmhw02": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "orcalewang/Sam_AIA_HW02": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Chungyeh/LLM_B_HW002": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LastSmile/HW002": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "dannychou/HomeWork02": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "JiAYu1997/LLM_Practice002": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "chtsai2104/llmhw02": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "andyWuTw/homework002": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "lostck/HW002": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "hsiaochenghuang/huaihaui_v2312_B": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Qian-Wu/AIA_modeltest01": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "apuku0723/AIALMWork02": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "NExtNewChattingAI/shark_tank_ai_7b_v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "gibhug/llama2-7b-chicks_v2-0": [
    "adapter_model.safetensors",
    "checkpoint-112/adapter_model.safetensors"
  ],
  "saberai/Zro1.3_3B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "cookinai/Valkyrie-V1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "harmtech/SthenoWriter-L2-13B-GPTQ": [
    "model.safetensors"
  ],
  "taollm/my_awesome_eli5_clm-model": [
    "model.safetensors"
  ],
  "DevamMondal/llama2-13b-hf-chat-4knormal": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "begangowsik/opt-125m-gptq-4bit-5555": [
    "model.safetensors"
  ],
  "JingyaoLi/MoTCoder-15B-v1.0": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "Parth/codephi-2.7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors",
    "model.safetensors"
  ],
  "mnjkng/7b-ppo_prediction_peft": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "pingstudio07/Llama2-7b-finetuned": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Ethan615/Llam2-7B-finetuned": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "zhe0/aia-hw-lora": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "halu1003/LLMHW02": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "begangowsik/opt-125m-gptq-4bit-55555": [
    "model.safetensors"
  ],
  "Tomkao0214/llmtest2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/SAM-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/SAM-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/SAM-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/SAM-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/SAM-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "vikash06/mistral_v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "cognitivecomputations/dolphin-2_6-phi-2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "SanjiWatsuki/neural-chat-7b-v3-3-wizardmath-dare-me": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Guna0pro/llama-2-7b-html": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Lifan-Z/Chinese-Classic-Poem-Generator-style5x8-GPT2": [
    "model.safetensors"
  ],
  "mustafa1923/mistral_finetune": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/SauerkrautLM-SOLAR-Instruct-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/SauerkrautLM-SOLAR-Instruct-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/SAM-AWQ": [
    "model.safetensors"
  ],
  "mayflowergmbh/SauerkrautLM-SOLAR-Instruct-awq": [
    "model.safetensors"
  ],
  "TheBloke/SAM-GPTQ": [
    "model.safetensors"
  ],
  "squarelike/korean-style-converter-6b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "blueapple8259/TinyKo-V3": [
    "model.safetensors"
  ],
  "TheBloke/bun_mistral_7b_v2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/bun_mistral_7b_v2-AWQ": [
    "model.safetensors"
  ],
  "mustafa1923/mistral_finetune2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "KaytTech/F01-mistral7b-josh1-ft": [
    "adapter_model.safetensors",
    "checkpoint-2/adapter_model.safetensors"
  ],
  "TheBloke/Mixtral_7Bx2_MoE-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Mixtral_7Bx2_MoE-AWQ": [
    "model.safetensors"
  ],
  "pnkvalavala/figr_html": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "TheBloke/Valkyrie-V1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Valkyrie-V1-AWQ": [
    "model.safetensors"
  ],
  "khanhnto/kyt7Mis": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/LUNA-SOLARkrautLM-Instruct-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/LUNA-SOLARkrautLM-Instruct-GPTQ": [
    "model.safetensors"
  ],
  "begangowsik/opt-125m-gptq-4bit-54": [
    "model.safetensors"
  ],
  "bw-alex/my-llm": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "TheBigBlender/Orca2myth7.2": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "erfanzar/LinguaMatic-Coder-INST-1B": [
    "model.safetensors"
  ],
  "benchang1110/NYCUEELLaMA": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "David19930/llama-2-7b-david_v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "parasora/tinycodellama-jp-0.3b-test-10k": [
    "model.safetensors"
  ],
  "Aryanne/Astrea-RP-v1-3B": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "BeardedPython/George-Butler-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "chanwit/flux-7b-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Adalee1001/my_awesome_eli5_clm-model": [
    "model.safetensors"
  ],
  "sophosympatheia/Aurora-Nights-70B-v1.0": [
    "model-00001-of-00017.safetensors",
    "model-00002-of-00017.safetensors",
    "model-00003-of-00017.safetensors",
    "model-00004-of-00017.safetensors",
    "model-00005-of-00017.safetensors",
    "model-00006-of-00017.safetensors",
    "model-00007-of-00017.safetensors",
    "model-00008-of-00017.safetensors",
    "model-00009-of-00017.safetensors",
    "model-00010-of-00017.safetensors",
    "model-00011-of-00017.safetensors",
    "model-00012-of-00017.safetensors",
    "model-00013-of-00017.safetensors",
    "model-00014-of-00017.safetensors",
    "model-00015-of-00017.safetensors",
    "model-00016-of-00017.safetensors",
    "model-00017-of-00017.safetensors"
  ],
  "sophosympatheia/Aurora-Nights-103B-v1.0": [
    "model-00001-of-00021.safetensors",
    "model-00002-of-00021.safetensors",
    "model-00003-of-00021.safetensors",
    "model-00004-of-00021.safetensors",
    "model-00005-of-00021.safetensors",
    "model-00006-of-00021.safetensors",
    "model-00007-of-00021.safetensors",
    "model-00008-of-00021.safetensors",
    "model-00009-of-00021.safetensors",
    "model-00010-of-00021.safetensors",
    "model-00011-of-00021.safetensors",
    "model-00012-of-00021.safetensors",
    "model-00013-of-00021.safetensors",
    "model-00014-of-00021.safetensors",
    "model-00015-of-00021.safetensors",
    "model-00016-of-00021.safetensors",
    "model-00017-of-00021.safetensors",
    "model-00018-of-00021.safetensors",
    "model-00019-of-00021.safetensors",
    "model-00020-of-00021.safetensors",
    "model-00021-of-00021.safetensors"
  ],
  "TheBloke/Sensei-7B-V1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Sensei-7B-V1-AWQ": [
    "model.safetensors"
  ],
  "bandhit/typhoon-7b-q4-bnb_cuda-ts-1703352224": [
    "model.safetensors"
  ],
  "abhishek/autotrain-fpk9x-hi-2": [
    "checkpoint-1840/model-00001-of-00003.safetensors",
    "checkpoint-1840/model-00002-of-00003.safetensors",
    "checkpoint-1840/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "bdsaglam/llama-2-7b-chat-hf-kg-cons-multi-1703317593": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Orca2myth7.2-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Orca2myth7.2-GPTQ": [
    "model.safetensors"
  ],
  "chatty123/CodeLlama-7b-Instruct-hf-Alpaca": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "RishabhM/testLincoln": [
    "model.safetensors"
  ],
  "azi111/Yi-6B-Chat-4bpw-h6-exl2-cnen": [
    "output.safetensors"
  ],
  "azi111/Yi-6B-Chat-6bpw-h8-exl2-cnen": [
    "output.safetensors"
  ],
  "LemTenku/chat": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "NousResearch/Nous-Hermes-2-Yi-34B": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "LoneStriker/SauerkrautLM-UNA-SOLAR-Instruct-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "Walmart-the-bag/Yi-6B-Infinity-Chat": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/SauerkrautLM-UNA-SOLAR-Instruct-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/SauerkrautLM-UNA-SOLAR-Instruct-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/SauerkrautLM-UNA-SOLAR-Instruct-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "augmxnt/shisa-gamma-7b-v1": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "LoneStriker/SauerkrautLM-UNA-SOLAR-Instruct-8.0bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "NobodyExistsOnTheInternet/unmixed-mixtral": [
    "fp16version/model-00001-of-00011.safetensors",
    "fp16version/model-00002-of-00011.safetensors",
    "fp16version/model-00003-of-00011.safetensors",
    "fp16version/model-00004-of-00011.safetensors",
    "fp16version/model-00005-of-00011.safetensors",
    "fp16version/model-00006-of-00011.safetensors",
    "fp16version/model-00007-of-00011.safetensors",
    "fp16version/model-00008-of-00011.safetensors",
    "fp16version/model-00009-of-00011.safetensors",
    "fp16version/model-00010-of-00011.safetensors",
    "fp16version/model-00011-of-00011.safetensors",
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "ericpolewski/AIRIC-The-Mistral": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "cognAI/slx-01": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "cognAI/slx-01.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "panosdou/my_awesome_eli5_clm-model": [
    "model.safetensors"
  ],
  "nurcan/tdk-model": [
    "model.safetensors"
  ],
  "adamo1139/Yi-6B-200K-AEZAKMI-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Demonthos/dolphin-2_6-phi-2-candle": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mojuss/llama-2-7b-chat-gpt-exam": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "HF-S/TestModel": [
    "model.safetensors"
  ],
  "DevamMondal/llama2-13b-hf-chat-1knormal": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Hypersniper/Steve_Jobs_Mistral_7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "NaoS2/tinycodellama-0.6b-1k": [
    "model.safetensors"
  ],
  "kibru/tmp_trainer": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "NaoS2/tinycodellama-0.6b-5k": [
    "model.safetensors"
  ],
  "micuat/gpt2_bestpractices_naoto_thesis": [
    "model.safetensors"
  ],
  "cloudyu/Mixtral_Erotic_13Bx2_MOE_22B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "chekable/mistral-chekable-abstract-v01": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors",
    "model.safetensors"
  ],
  "dishank19/Mistral7B-SHP": [
    "adapter_model.safetensors"
  ],
  "chekable/mistral-chekable-abstract-v02": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/Sensei-7B-V1-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Sensei-7B-V1-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "parasora/tinycodellama-jp-0.3b-test-2k": [
    "model.safetensors"
  ],
  "LoneStriker/Sensei-7B-V1-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Sensei-7B-V1-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Sensei-7B-V1-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "Deema/lora-alpaca_alpagasus_ar": [
    "adapter_model.safetensors"
  ],
  "micuat/gpt2_bestpractices_proposal": [
    "model.safetensors"
  ],
  "decem/Dionysus-Mistral-m3-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "boracious/llama-2-7b-finetune-korquad": [
    "adapter_model.safetensors",
    "checkpoint-8/adapter_model.safetensors"
  ],
  "HuggingAlgorithms/figr-mistral7b-html": [
    "adapter_model.safetensors"
  ],
  "boracious/llama-2-7b-finetune-korquad-v2": [
    "adapter_model.safetensors",
    "checkpoint-20/adapter_model.safetensors",
    "model.safetensors"
  ],
  "mcysqrd/mojo-coder-1B": [
    "model.safetensors"
  ],
  "Mr-Bhaskar/Fbt2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "eaalghamdi/bloom-560m-pruned-gmp-sparsity-5": [
    "model.safetensors"
  ],
  "daoyuanzhai/distilgpt2-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "louislian2341/output3": [
    "model.safetensors"
  ],
  "mrm8488/phi-2-coder": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "azi111/dolphin-2_2-yi-34b-465bpw-h8-exl2-cnen": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "mncai/SDC_Llama2-13B_Lr06_Ep2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "SanjiWatsuki/Loyal-Macaroni-Maid-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "cenkersisman/gpt2-turkish-256-token": [
    "model.safetensors"
  ],
  "bluuwhale/toppy-neural-chat-SLERP": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "kyujinpy/Sakura-SOLAR-Instruct": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Ansoi/DPO7": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "themanas021/Mistral-Meta_Math-Alg01": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "xxond/disco-limbic-dialogue": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "KathirKs/phi-2_alpaca_52k": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "bluuwhale/Toxic-Yarn-7b-128k": [
    "adapter_model.safetensors",
    "checkpoint-141/adapter_model.safetensors"
  ],
  "mustafa1923/mistral_finetune3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "zabirauf/zephyr-3b-corrections": [
    "model.safetensors"
  ],
  "shivafm/finetuned-model-mistral-6epoch": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "micuat/gpt2_ko_murobushi": [
    "model.safetensors"
  ],
  "Xiugapurin/codeparrot-ds": [
    "model.safetensors"
  ],
  "azi111/dolphin-2_2-yi-34b-3bpw-h8-exl2-cnen": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "sequelbox/SpellBlade": [
    "model-00001-of-00061.safetensors",
    "model-00002-of-00061.safetensors",
    "model-00003-of-00061.safetensors",
    "model-00004-of-00061.safetensors",
    "model-00005-of-00061.safetensors",
    "model-00006-of-00061.safetensors",
    "model-00007-of-00061.safetensors",
    "model-00008-of-00061.safetensors",
    "model-00009-of-00061.safetensors",
    "model-00010-of-00061.safetensors",
    "model-00011-of-00061.safetensors",
    "model-00012-of-00061.safetensors",
    "model-00013-of-00061.safetensors",
    "model-00014-of-00061.safetensors",
    "model-00015-of-00061.safetensors",
    "model-00016-of-00061.safetensors",
    "model-00017-of-00061.safetensors",
    "model-00018-of-00061.safetensors",
    "model-00019-of-00061.safetensors",
    "model-00020-of-00061.safetensors",
    "model-00021-of-00061.safetensors",
    "model-00022-of-00061.safetensors",
    "model-00023-of-00061.safetensors",
    "model-00024-of-00061.safetensors",
    "model-00025-of-00061.safetensors",
    "model-00026-of-00061.safetensors",
    "model-00027-of-00061.safetensors",
    "model-00028-of-00061.safetensors",
    "model-00029-of-00061.safetensors",
    "model-00030-of-00061.safetensors",
    "model-00031-of-00061.safetensors",
    "model-00032-of-00061.safetensors",
    "model-00033-of-00061.safetensors",
    "model-00034-of-00061.safetensors",
    "model-00035-of-00061.safetensors",
    "model-00036-of-00061.safetensors",
    "model-00037-of-00061.safetensors",
    "model-00038-of-00061.safetensors",
    "model-00039-of-00061.safetensors",
    "model-00040-of-00061.safetensors",
    "model-00041-of-00061.safetensors",
    "model-00042-of-00061.safetensors",
    "model-00043-of-00061.safetensors",
    "model-00044-of-00061.safetensors",
    "model-00045-of-00061.safetensors",
    "model-00046-of-00061.safetensors",
    "model-00047-of-00061.safetensors",
    "model-00048-of-00061.safetensors",
    "model-00049-of-00061.safetensors",
    "model-00050-of-00061.safetensors",
    "model-00051-of-00061.safetensors",
    "model-00052-of-00061.safetensors",
    "model-00053-of-00061.safetensors",
    "model-00054-of-00061.safetensors",
    "model-00055-of-00061.safetensors",
    "model-00056-of-00061.safetensors",
    "model-00057-of-00061.safetensors",
    "model-00058-of-00061.safetensors",
    "model-00059-of-00061.safetensors",
    "model-00060-of-00061.safetensors",
    "model-00061-of-00061.safetensors"
  ],
  "firef1i/book2-mixtral": [
    "model-00001-of-00039.safetensors",
    "model-00002-of-00039.safetensors",
    "model-00003-of-00039.safetensors",
    "model-00004-of-00039.safetensors",
    "model-00005-of-00039.safetensors",
    "model-00006-of-00039.safetensors",
    "model-00007-of-00039.safetensors",
    "model-00008-of-00039.safetensors",
    "model-00009-of-00039.safetensors",
    "model-00010-of-00039.safetensors",
    "model-00011-of-00039.safetensors",
    "model-00012-of-00039.safetensors",
    "model-00013-of-00039.safetensors",
    "model-00014-of-00039.safetensors",
    "model-00015-of-00039.safetensors",
    "model-00016-of-00039.safetensors",
    "model-00017-of-00039.safetensors",
    "model-00018-of-00039.safetensors",
    "model-00019-of-00039.safetensors",
    "model-00020-of-00039.safetensors",
    "model-00021-of-00039.safetensors",
    "model-00022-of-00039.safetensors",
    "model-00023-of-00039.safetensors",
    "model-00024-of-00039.safetensors",
    "model-00025-of-00039.safetensors",
    "model-00026-of-00039.safetensors",
    "model-00027-of-00039.safetensors",
    "model-00028-of-00039.safetensors",
    "model-00029-of-00039.safetensors",
    "model-00030-of-00039.safetensors",
    "model-00031-of-00039.safetensors",
    "model-00032-of-00039.safetensors",
    "model-00033-of-00039.safetensors",
    "model-00034-of-00039.safetensors",
    "model-00035-of-00039.safetensors",
    "model-00036-of-00039.safetensors",
    "model-00037-of-00039.safetensors",
    "model-00038-of-00039.safetensors",
    "model-00039-of-00039.safetensors"
  ],
  "saberai/Zro1.4_3B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "StatPan/singung-sft-v0.1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Unseen1980/8i43-5nq3-71dj-0": [
    "adapter_model.safetensors",
    "checkpoint-15/adapter_model.safetensors"
  ],
  "01jonathanf/Mistral-7B-Instruct-v0.2-sharded2GB": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Caraaaaa/text_image_captioning": [
    "model.safetensors"
  ],
  "HenryJJ/tangshi-mixtral": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "tmdduq/komt-mistral-7b-v1-dpo-osy-v1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "TheBloke/dolphin-2_6-phi-2-GPTQ": [
    "model.safetensors"
  ],
  "Asude/gpt2-imdb-20k-0it": [
    "model.safetensors"
  ],
  "Weyaxi/OpenHermes-2.5-neural-chat-v3-3-openchat-3.5-1210-Slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Asude/gpt2-imdb-20k-10it": [
    "model.safetensors"
  ],
  "TheBloke/SauerkrautLM-UNA-SOLAR-Instruct-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/SauerkrautLM-UNA-SOLAR-Instruct-AWQ": [
    "model.safetensors"
  ],
  "Xiugapurin/xlnet-mid": [
    "model.safetensors"
  ],
  "breadlicker45/rwkv-4-430m-2048": [
    "model.safetensors"
  ],
  "breadlicker45/rwkv-4-430m-3072": [
    "model.safetensors"
  ],
  "azi111/dolphin-2_2-yi-34b-445bpw-h8-exl2-cnen": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "breadlicker45/rwkv-4-430m-4096": [
    "model.safetensors"
  ],
  "breadlicker45/rwkv-4-430m-5120": [
    "model.safetensors"
  ],
  "breadlicker45/rwkv-4-430m-6144": [
    "model.safetensors"
  ],
  "adamo1139/Mistral-7B-AEZAKMI-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kyujinpy/Sakura-SOLAR-Instruct-DPO-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/typhoon-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/typhoon-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/LMCocktail-10.7B-v1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/LMCocktail-10.7B-v1-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Instruct_Mixtral-8x7B-v0.1_Dolly15K-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Instruct_Mixtral-8x7B-v0.1_Dolly15K-GPTQ": [
    "model.safetensors"
  ],
  "MaralGPT/Maral-7B-alpha-1": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Xiugapurin/xlnet-base": [
    "model.safetensors"
  ],
  "TheBloke/LMCocktail-phi-2-v1-GPTQ": [
    "model.safetensors"
  ],
  "LoneStriker/Mixtral-8x7B-Instruct-v0.1-3.75bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "gibhug/llama-7b-chat-hf-poultry-repo-0": [
    "adapter_model.safetensors",
    "checkpoint-80/adapter_model.safetensors"
  ],
  "mwpt5/gpt2-mawps-pen": [
    "model.safetensors"
  ],
  "kyujinpy/Sakura-SOLRCA-Instruct-DPO": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ai-aerospace/Mistral-7B-Instruct-v0.1_asm_60e4dc58": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/apricot-wildflower-20-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/apricot-wildflower-20-GPTQ": [
    "model.safetensors"
  ],
  "beberik/rawr": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "LoneStriker/Mixtral-8x7B-v0.1-3.75bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "TheBloke/DaringMaid-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/DaringMaid-13B-AWQ": [
    "model.safetensors"
  ],
  "Asude/gpt2-imdb-negative-20k-10it": [
    "model.safetensors"
  ],
  "liquac09/nefarious-princess": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Asude/gpt2-imdb-negative-20k-20it": [
    "model.safetensors"
  ],
  "TheBloke/Loyal-Macaroni-Maid-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Loyal-Macaroni-Maid-7B-GPTQ": [
    "model.safetensors"
  ],
  "Asude/gpt2-imdb-positive-20k-with_reward-10it": [
    "model.safetensors"
  ],
  "LoneStriker/openbuddy-mixtral-8x7b-v15.4-2.4bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Asude/gpt2-imdb-negative-20k-30it": [
    "model.safetensors"
  ],
  "Asude/gpt2-imdb-positive-20k-with_reward-20it": [
    "model.safetensors"
  ],
  "LoneStriker/openbuddy-mixtral-8x7b-v15.4-3.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/openbuddy-mixtral-8x7b-v15.4-3.5bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "Asude/gpt2-imdb-negative-20k-40it": [
    "model.safetensors"
  ],
  "LoneStriker/openbuddy-mixtral-8x7b-v15.4-3.75bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "TheBloke/openbuddy-mixtral-8x7b-v15.4-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/openbuddy-mixtral-8x7b-v15.4-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Asude/gpt2-imdb-negative-20k-50it": [
    "model.safetensors"
  ],
  "Asude/gpt2-imdb-negative-20k-60it": [
    "model.safetensors"
  ],
  "TheBloke/finance-LLM-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/finance-LLM-GPTQ": [
    "model.safetensors"
  ],
  "LoneStriker/openbuddy-mixtral-8x7b-v15.4-5.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "maxsegan/LiLaMa0.5": [
    "model.safetensors"
  ],
  "Asude/gpt2-imdb-negative-20k-70it": [
    "model.safetensors"
  ],
  "LoneStriker/openbuddy-mixtral-8x7b-v15.4-6.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "TheBloke/Noromaid-v0.1-mixtral-8x7b-v3-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Noromaid-v0.1-mixtral-8x7b-v3-GPTQ": [
    "model.safetensors"
  ],
  "Lifan-Z/Chinese-Classic-Poem-Generator-style7x8-GPT2": [
    "model.safetensors"
  ],
  "chekable/mistral-chekable-abstract-v03": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Faradaylab/ARIA-7B-V3-mistral-french-merge": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Mixtral-8x7B-MoE-Undi95-RP-Story-3.75bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "mnoukhov/pythia410m-tldr-sft-seed2": [
    "model.safetensors"
  ],
  "meadhikari/phi-2-wikisql-autotrain": [
    "adapter_model.safetensors",
    "checkpoint-21132/adapter_model.safetensors"
  ],
  "LoneStriker/firefly-mixtral-8x7b-3.75bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Mixtral-SlimOrca-8x7B-3.75bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "blueapple8259/TinyKoWiki-v1": [
    "model.safetensors"
  ],
  "LoneStriker/OpenHermes-Mixtral-8x7B-3.75bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "charent/Phi2-Chinese-0.2B": [
    "model.safetensors"
  ],
  "chekable/mistral-chekable-abstract-v04": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "intervitens/Mixtral-8x7B-Instruct-limarp-v0.1-3.5bpw-h6-exl2-rpcal": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "intervitens/Mixtral-8x7B-Instruct-limarp-v0.1-3.75bpw-h6-exl2-rpcal": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "intervitens/Mixtral-8x7B-Instruct-limarp-v0.1-3.7bpw-h6-exl2-rpcal": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "intervitens/Mixtral-8x7B-Instruct-limarp-v0.1-5.5bpw-h6-exl2-rpcal": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "jjourney1125/M-SOLAR-10.7B-v1.0": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "sushant07/llama2-fine-tuned-jawerty_html_dataset": [
    "model.safetensors"
  ],
  "rhshah/MediumGEN_LLama2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "blueapple8259/TinyKoWiki-v1.1": [
    "model.safetensors"
  ],
  "TinyPixel/m8": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "DoctrineK/Qwen-1.8B-Finetuned": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "LoneStriker/SauerkrautLM-Mixtral-8x7B-Instruct-2.4bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Imran1/strbase": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/SauerkrautLM-Mixtral-8x7B-Instruct-3.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "procne/my_eli5_clm-model": [
    "model.safetensors"
  ],
  "LoneStriker/SauerkrautLM-Mixtral-8x7B-Instruct-3.5bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "OrangeCorgi/StepsLLMplz": [
    "adapter_model.safetensors",
    "checkpoint-22944/adapter_model.safetensors"
  ],
  "LoneStriker/SauerkrautLM-Mixtral-8x7B-Instruct-3.75bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "diffnamehard/Mistral-CatMacaroni-slerp-7B": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "LoneStriker/SauerkrautLM-Mixtral-8x7B-Instruct-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "dillfrescott/trinity-medium": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TinyPixel/m9": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mustafa1923/mistral_finetune4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lostck/LorA001": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/SauerkrautLM-Mixtral-8x7B-2.4bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/SauerkrautLM-Mixtral-8x7B-3.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "OpenBuddy/openbuddy-mixtral-8x7b-v16.1-32k": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "LoneStriker/SauerkrautLM-Mixtral-8x7B-3.5bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "nchen909/codellm-7b-v4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "PistachioAlt/Noromaid-Bagel-7B-Slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "LoneStriker/SauerkrautLM-Mixtral-8x7B-3.75bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "yoonjae22/Llama2-13b-ko-en-Translate": [
    "model.safetensors"
  ],
  "TheBloke/SauerkrautLM-Mixtral-8x7B-Instruct-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/SauerkrautLM-Mixtral-8x7B-Instruct-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/SauerkrautLM-Mixtral-8x7B-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/SauerkrautLM-Mixtral-8x7B-5.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "TheBloke/SauerkrautLM-Mixtral-8x7B-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/SauerkrautLM-Mixtral-8x7B-6.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "LoneStriker/SauerkrautLM-Mixtral-8x7B-Instruct-5.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "SherryT997/mistral-7b-instruct-hindi": [
    "model.safetensors"
  ],
  "heegyu/1223-Synatra-Yi-Ko-6B-mt-en2ko-2e-5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TokenBender/MistyChameli_6k_7B": [
    "checkpoint-368/model-00001-of-00006.safetensors",
    "checkpoint-368/model-00002-of-00006.safetensors",
    "checkpoint-368/model-00003-of-00006.safetensors",
    "checkpoint-368/model-00004-of-00006.safetensors",
    "checkpoint-368/model-00005-of-00006.safetensors",
    "checkpoint-368/model-00006-of-00006.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/SauerkrautLM-Mixtral-8x7B-Instruct-6.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "hibana2077/test-2": [
    "adapter_model.safetensors",
    "checkpoint-177/adapter_model.safetensors"
  ],
  "scottypres/ai2": [
    "model.safetensors"
  ],
  "TheBloke/SauerkrautLM-Mixtral-8x7B-GPTQ": [
    "model.safetensors"
  ],
  "ybelkada/Mixtral-8x7B-Instruct-v0.1-bnb-4bit": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "kyujinpy/Sakura-SOLRCA-Math-Instruct-DPO-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hiyouga/Qwen-14B-Chat-LLaMAfied": [
    "model-00001-of-00013.safetensors",
    "model-00002-of-00013.safetensors",
    "model-00003-of-00013.safetensors",
    "model-00004-of-00013.safetensors",
    "model-00005-of-00013.safetensors",
    "model-00006-of-00013.safetensors",
    "model-00007-of-00013.safetensors",
    "model-00008-of-00013.safetensors",
    "model-00009-of-00013.safetensors",
    "model-00010-of-00013.safetensors",
    "model-00011-of-00013.safetensors",
    "model-00012-of-00013.safetensors",
    "model-00013-of-00013.safetensors"
  ],
  "saberai/Zro1.5_3B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hibana2077/TEST-3": [
    "adapter_model.safetensors",
    "checkpoint-207/adapter_model.safetensors"
  ],
  "fogteams-vp/open_llama_3b_v2": [
    "model.safetensors"
  ],
  "fogteams-vp/open_llama_3b_v2_fp16": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "piotr-ai/polanka-3b-pretrain-full-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "smelborp/MixtralOrochi8x7B": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "Vikas-03/SmowChat": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "STR01/dpo_swallow7b_anametho": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "smelborp/MixtralOrochi8x7B-Alt": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "NaoS2/tinycodellama-0.6b-10k": [
    "model.safetensors"
  ],
  "alekswael/phipaca_new": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Pruthvirajsp/Llama-2-7b-chat-hf-sharded-bf16-fine-tuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "unum-cloud/uform-gen": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "SicariusSicariiStuff/Tenebra_30B_Alpha01_4BIT": [
    "model.safetensors"
  ],
  "Loyola/koquadmistral-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "nguyenthanhdo/mistral-chai-v0.0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "nguyenthanhdo/mistral-chai-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "unsloth/mistral-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "unsloth/mistral-7b-bnb-4bit": [
    "model.safetensors"
  ],
  "alekswael/phipaca_new_new": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "thanhdaonguyen/christmas-mistral-7b-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "BoccheseGiacomo/phi-2-finetuned-gsm8k-gb": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SicariusSicariiStuff/Tenebra_30B_Alpha01_3BIT": [
    "model.safetensors"
  ],
  "ybelkada/test-ppo-tag": [
    "model.safetensors"
  ],
  "jeiku/Rosa_v1_3B": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "fbellame/mistral-7b-json-quizz-fine-tuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Ansoi/peter": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "vikramguptaai/autotrain-vikram": [
    "adapter_model.safetensors",
    "checkpoint-8538/adapter_model.safetensors"
  ],
  "andrijdavid/Mistral-7B-Merge-14-v0.1-GGUF": [],
  "LoneStriker/Loyal-Macaroni-Maid-7B-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "Azamorn/retnet-tinystories": [
    "model.safetensors"
  ],
  "LoneStriker/Loyal-Macaroni-Maid-7B-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Loyal-Macaroni-Maid-7B-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Loyal-Macaroni-Maid-7B-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Loyal-Macaroni-Maid-7B-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "martyn/mixtral-megamerge-dare-8x7b-v2": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "NouRed/fine-tuned-git-diffusion": [
    "model.safetensors"
  ],
  "SicariusSicariiStuff/TinyLLama_0.6_Chat_BF16": [
    "model.safetensors"
  ],
  "naninya/my_awesome_eli5_clm-model": [
    "model.safetensors"
  ],
  "techandy42/llama-2-7b-craftergpt-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "techandy42/llama-2-7b-craftergpt-v0.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Aryanne/phitest": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "dfurman/Mistral-7B-v0.1-fork": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "naninya/eli5_clm-model": [
    "model.safetensors"
  ],
  "naninya/custom_eli5_clm-model": [
    "model.safetensors"
  ],
  "SicariusSicariiStuff/TinyLLaMA_0.6chat_EXL2_3.00bpw": [
    "model.safetensors"
  ],
  "norispace/marcoroni-kopenorcav3": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "jingyeom/Yi-ko-1.1-dedup": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "jingyeom/Yi-ko-1.1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "kimnt93/chat-llama2-13b-baseline": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "genne/eclectus1.1": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "arielycliu/DialoGPT-Connor-for-Janice": [
    "model.safetensors"
  ],
  "kimnt93/chat-llama2-13b-1.0": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "pkarypis/zephyr-7b-sft-filtered-random": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kimnt93/chat-llama2-7b-1.0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kimnt93/chat-llama2-1b-1.0": [
    "model.safetensors"
  ],
  "NousResearch/Nous-Hermes-2-Mixtral-8x7B-SFT": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "kimnt93/chat-llama2-7b-2.0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mesolitica/mallam-1.1b-20k-instructions-v2": [
    "model.safetensors"
  ],
  "LR-AI-Labs/vbd-llama2-7B-50b-chat": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mesolitica/malaysian-tinyllama-1.1b-16k-instructions-v2": [
    "model.safetensors"
  ],
  "YashRawal225/TheQuant-GPTQ": [
    "model.safetensors"
  ],
  "justinj92/phi-med-v1": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "nibeditad07/codegen-350M-mono-python-18k-alpaca": [
    "model.safetensors"
  ],
  "DopeorNope/SOLAR_C-v1-10.7B": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "NTQAI/chatntq-ja-7b-v1.0": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "lucyknada/Loyal-Toppy-Bruins-Maid-7B-DARE-exl2-8bpw": [
    "output.safetensors"
  ],
  "jeffreykthomas/llama-2-7b-blended": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "richardburleigh/SuperQA-7B-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "YeungNLP/firefly-zephyr-6x7b": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "LoneStriker/Nous-Hermes-2-Yi-34B-3.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "xww033/cut-13b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/xDAN-L1-Chat-RL-v1-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Nous-Hermes-2-Yi-34B-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/xDAN-L1-Chat-RL-v1-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/xDAN-L1-Chat-RL-v1-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Nous-Hermes-2-Yi-34B-4.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "rinkorn/codeparrot-ds": [
    "model.safetensors"
  ],
  "LoneStriker/xDAN-L1-Chat-RL-v1-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/xDAN-L1-Chat-RL-v1-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Nous-Hermes-2-Yi-34B-5.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "TheBloke/Nous-Hermes-2-Yi-34B-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Nous-Hermes-2-Yi-34B-GPTQ": [
    "model.safetensors"
  ],
  "0x7o/fialka-7B-v2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ramkrish120595/finetune_llama": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "yuyijiong/Qwen-7b-chat-yarn-32k": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Noromaid-v0.1-mixtral-8x7b-Instruct-v3-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Noromaid-v0.1-mixtral-8x7b-Instruct-v3-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "0x7o/fialka-7B-v2.1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/Nous-Hermes-2-Yi-34B-6.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "machinists/Mixtral-8x7B-SQL": [
    "model-00001-of-00039.safetensors",
    "model-00002-of-00039.safetensors",
    "model-00003-of-00039.safetensors",
    "model-00004-of-00039.safetensors",
    "model-00005-of-00039.safetensors",
    "model-00006-of-00039.safetensors",
    "model-00007-of-00039.safetensors",
    "model-00008-of-00039.safetensors",
    "model-00009-of-00039.safetensors",
    "model-00010-of-00039.safetensors",
    "model-00011-of-00039.safetensors",
    "model-00012-of-00039.safetensors",
    "model-00013-of-00039.safetensors",
    "model-00014-of-00039.safetensors",
    "model-00015-of-00039.safetensors",
    "model-00016-of-00039.safetensors",
    "model-00017-of-00039.safetensors",
    "model-00018-of-00039.safetensors",
    "model-00019-of-00039.safetensors",
    "model-00020-of-00039.safetensors",
    "model-00021-of-00039.safetensors",
    "model-00022-of-00039.safetensors",
    "model-00023-of-00039.safetensors",
    "model-00024-of-00039.safetensors",
    "model-00025-of-00039.safetensors",
    "model-00026-of-00039.safetensors",
    "model-00027-of-00039.safetensors",
    "model-00028-of-00039.safetensors",
    "model-00029-of-00039.safetensors",
    "model-00030-of-00039.safetensors",
    "model-00031-of-00039.safetensors",
    "model-00032-of-00039.safetensors",
    "model-00033-of-00039.safetensors",
    "model-00034-of-00039.safetensors",
    "model-00035-of-00039.safetensors",
    "model-00036-of-00039.safetensors",
    "model-00037-of-00039.safetensors",
    "model-00038-of-00039.safetensors",
    "model-00039-of-00039.safetensors"
  ],
  "brijeshig/new_llm567": [
    "adapter_model.safetensors",
    "checkpoint-1/adapter_model.safetensors"
  ],
  "themanas021/Mistral-MetaMath-camel_math": [
    "adapter_model.safetensors"
  ],
  "quizzy/Mistral-MetaMath-camel_math01": [
    "adapter_model.safetensors"
  ],
  "themanas021/Mistral-MetaMath-camel_math01": [
    "adapter_model.safetensors"
  ],
  "hongzoh/Yi-Ko-6B_Open-Platypus": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Nous-Hermes-2-Yi-34B-8.0bpw-h8-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "nibeditad07/tinystarcoder-python-18k-alpaca": [
    "model.safetensors"
  ],
  "tb2pi-persistent/Llama-2-7b-chat-hf-tb2pi-merged-v6": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "pratikthakkar007/autotrain-wuiwp-o6gob": [
    "checkpoint-450/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/xDAN-L1-Chat-RL-v1-AWQ": [
    "model.safetensors"
  ],
  "vikramguptaai/autotrain-llama2": [
    "adapter_model.safetensors",
    "checkpoint-9723/adapter_model.safetensors"
  ],
  "ramkrish120595/finetune_llama_7b_hf": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "atom-team/base-mistralsayga-merged": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "TheBloke/xDAN-L1-Chat-RL-v1-GPTQ": [
    "model.safetensors"
  ],
  "projecte-aina/Flor63_meteo": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Yi-34B-200K-AEZAKMI-v2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Yi-34B-200K-AEZAKMI-v2-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ybelkada/chatglm3-6b-hf": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "KnutJaegersberg/Tess-M-34B-2bit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/openthaigpt-1.0.0-beta-13B-chat-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/openthaigpt-1.0.0-beta-13B-chat-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/neural-chat-7B-v3-3-wizardmath-dare-me-AWQ": [
    "model.safetensors"
  ],
  "hibana2077/DialoGPT-medium-PTT-CUSTOM": [
    "adapter_model.safetensors",
    "checkpoint-876/adapter_model.safetensors"
  ],
  "TheBloke/openchat-3.5-1210-starling-slerp-AWQ": [
    "model.safetensors"
  ],
  "VictorNanka/phi-2-sft-lora": [
    "adapter_model.safetensors"
  ],
  "itsliupeng/llama2_70b_mmlu": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "TheBloke/neural-chat-7B-v3-3-wizardmath-dare-me-GPTQ": [
    "model.safetensors"
  ],
  "aayvyas/platform-support-sft": [
    "adapter_model.safetensors",
    "checkpoint-5/adapter_model.safetensors"
  ],
  "TheBloke/openchat-3.5-1210-starling-slerp-GPTQ": [
    "model.safetensors"
  ],
  "InHawK/jd-llama2-7b-finetune": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "BM-K/mistral-ko-7b-it-v2.0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "IlyaGusev/ruadapt_ficbook_llama2_7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "BEE-spoke-data/mega-ar-126m-4k": [
    "model.safetensors"
  ],
  "StatPan/SinGung7B-DPO-v0.1-2200": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "JanithSilva/Mistral-7B-Instruct-v0.2-full-model-fine-tuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Dev-180/distilgpt2-wikitext": [
    "model.safetensors"
  ],
  "buildingthemoon/testfinetunedmodel": [
    "checkpoint-1000/model.safetensors",
    "checkpoint-1500/model.safetensors",
    "checkpoint-2000/model.safetensors",
    "checkpoint-2500/model.safetensors",
    "checkpoint-500/model.safetensors",
    "model.safetensors"
  ],
  "BoccheseGiacomo/phi-2-instruct": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "obrmmk/tinycodellama-jp-1.3b-1k": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "sogeeking/zebra-burgers-auto": [
    "model.safetensors"
  ],
  "thanhnew2001/starcoder-3b-taipy14": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "shidowake/test-231222-mistral-lora-adaptor-checkpoint-205-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kyujinpy/Sakura-SOLRCA-Math-Instruct-DPO-v2": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "diamantrsd/cerpen-generator-v3": [
    "model.safetensors"
  ],
  "nibeditad07/starcoderbase-python-18k-alpaca": [
    "model.safetensors"
  ],
  "InHawK/jd-llama2-32bit-7b-finetune": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "fblgit/UNAversal-8x7B-v1beta": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "hibana2077/HTML2JSON": [
    "adapter_model.safetensors",
    "checkpoint-306/adapter_model.safetensors"
  ],
  "tb2pi-persistent/Llama-2-13b-chat-hf-tb2pi-merged-v1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "unsloth/codellama-34b-bnb-4bit": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "stevebim000/phi2-interview-finetuned-owndata": [
    "model.safetensors"
  ],
  "rharris117/git-base-pokemon": [
    "model.safetensors"
  ],
  "mustafa1923/verses_finetune5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Prezily/working": [
    "model.safetensors"
  ],
  "awtrisk/Mistral7B_Dolphin2.1_LIMARP0.5_8bpw_PIPPA_exl2": [
    "Mistral_7B_Dolphin2.1_LIMA0.5_fp16_8bpw_exl2.safetensors"
  ],
  "PracticeLLM/SOLAR-tail-10.7B-Merge-v1.0": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "chekable/mistral-chekable-abstract-v05": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors",
    "model.safetensors"
  ],
  "PracticeLLM/SOLAR-tail-10.7B-instruct-v1.0": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "SasininduSV/mistral-7b-ssv-finetuned": [
    "adapter_model.safetensors",
    "checkpoint-3/adapter_model.safetensors"
  ],
  "TheBossLevel123/TinyLlama-v2ray": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "mrSoul7766/git-base-pokemon": [
    "model.safetensors"
  ],
  "CambioMoney/mixtral-instruct-MLFlowV4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "banghua/openchat-3.5-ppo-n-ckpt7k5": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/MixtralOrochi8x7B-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/MixtralOrochi8x7B-GPTQ": [
    "model.safetensors"
  ],
  "banghua/openchat-3.5-ppo-n-ckpt6k": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "banghua/openchat-3.5-ppo-n-ckpt6k5": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "beingamit99/rick-morty-gpt": [
    "model.safetensors"
  ],
  "BEE-spoke-data/Mixtral-GQA-400m-v4-4096": [
    "checkpoint-400/model-00001-of-00002.safetensors",
    "checkpoint-400/model-00002-of-00002.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jeiku/Taste_Test_3B": [
    "model-00001-of-00001.safetensors"
  ],
  "lavawolfiee/Mixtral-8x7B-Instruct-v0.1-offloading-hqq-4bit-3bit": [
    "model-00001-of-00257.safetensors",
    "model-00002-of-00257.safetensors",
    "model-00003-of-00257.safetensors",
    "model-00004-of-00257.safetensors",
    "model-00005-of-00257.safetensors",
    "model-00006-of-00257.safetensors",
    "model-00007-of-00257.safetensors",
    "model-00008-of-00257.safetensors",
    "model-00009-of-00257.safetensors",
    "model-00010-of-00257.safetensors",
    "model-00011-of-00257.safetensors",
    "model-00012-of-00257.safetensors",
    "model-00013-of-00257.safetensors",
    "model-00014-of-00257.safetensors",
    "model-00015-of-00257.safetensors",
    "model-00016-of-00257.safetensors",
    "model-00017-of-00257.safetensors",
    "model-00018-of-00257.safetensors",
    "model-00019-of-00257.safetensors",
    "model-00020-of-00257.safetensors",
    "model-00021-of-00257.safetensors",
    "model-00022-of-00257.safetensors",
    "model-00023-of-00257.safetensors",
    "model-00024-of-00257.safetensors",
    "model-00025-of-00257.safetensors",
    "model-00026-of-00257.safetensors",
    "model-00027-of-00257.safetensors",
    "model-00028-of-00257.safetensors",
    "model-00029-of-00257.safetensors",
    "model-00030-of-00257.safetensors",
    "model-00031-of-00257.safetensors",
    "model-00032-of-00257.safetensors",
    "model-00033-of-00257.safetensors",
    "model-00034-of-00257.safetensors",
    "model-00035-of-00257.safetensors",
    "model-00036-of-00257.safetensors",
    "model-00037-of-00257.safetensors",
    "model-00038-of-00257.safetensors",
    "model-00039-of-00257.safetensors",
    "model-00040-of-00257.safetensors",
    "model-00041-of-00257.safetensors",
    "model-00042-of-00257.safetensors",
    "model-00043-of-00257.safetensors",
    "model-00044-of-00257.safetensors",
    "model-00045-of-00257.safetensors",
    "model-00046-of-00257.safetensors",
    "model-00047-of-00257.safetensors",
    "model-00048-of-00257.safetensors",
    "model-00049-of-00257.safetensors",
    "model-00050-of-00257.safetensors",
    "model-00051-of-00257.safetensors",
    "model-00052-of-00257.safetensors",
    "model-00053-of-00257.safetensors",
    "model-00054-of-00257.safetensors",
    "model-00055-of-00257.safetensors",
    "model-00056-of-00257.safetensors",
    "model-00057-of-00257.safetensors",
    "model-00058-of-00257.safetensors",
    "model-00059-of-00257.safetensors",
    "model-00060-of-00257.safetensors",
    "model-00061-of-00257.safetensors",
    "model-00062-of-00257.safetensors",
    "model-00063-of-00257.safetensors",
    "model-00064-of-00257.safetensors",
    "model-00065-of-00257.safetensors",
    "model-00066-of-00257.safetensors",
    "model-00067-of-00257.safetensors",
    "model-00068-of-00257.safetensors",
    "model-00069-of-00257.safetensors",
    "model-00070-of-00257.safetensors",
    "model-00071-of-00257.safetensors",
    "model-00072-of-00257.safetensors",
    "model-00073-of-00257.safetensors",
    "model-00074-of-00257.safetensors",
    "model-00075-of-00257.safetensors",
    "model-00076-of-00257.safetensors",
    "model-00077-of-00257.safetensors",
    "model-00078-of-00257.safetensors",
    "model-00079-of-00257.safetensors",
    "model-00080-of-00257.safetensors",
    "model-00081-of-00257.safetensors",
    "model-00082-of-00257.safetensors",
    "model-00083-of-00257.safetensors",
    "model-00084-of-00257.safetensors",
    "model-00085-of-00257.safetensors",
    "model-00086-of-00257.safetensors",
    "model-00087-of-00257.safetensors",
    "model-00088-of-00257.safetensors",
    "model-00089-of-00257.safetensors",
    "model-00090-of-00257.safetensors",
    "model-00091-of-00257.safetensors",
    "model-00092-of-00257.safetensors",
    "model-00093-of-00257.safetensors",
    "model-00094-of-00257.safetensors",
    "model-00095-of-00257.safetensors",
    "model-00096-of-00257.safetensors",
    "model-00097-of-00257.safetensors",
    "model-00098-of-00257.safetensors",
    "model-00099-of-00257.safetensors",
    "model-00100-of-00257.safetensors",
    "model-00101-of-00257.safetensors",
    "model-00102-of-00257.safetensors",
    "model-00103-of-00257.safetensors",
    "model-00104-of-00257.safetensors",
    "model-00105-of-00257.safetensors",
    "model-00106-of-00257.safetensors",
    "model-00107-of-00257.safetensors",
    "model-00108-of-00257.safetensors",
    "model-00109-of-00257.safetensors",
    "model-00110-of-00257.safetensors",
    "model-00111-of-00257.safetensors",
    "model-00112-of-00257.safetensors",
    "model-00113-of-00257.safetensors",
    "model-00114-of-00257.safetensors",
    "model-00115-of-00257.safetensors",
    "model-00116-of-00257.safetensors",
    "model-00117-of-00257.safetensors",
    "model-00118-of-00257.safetensors",
    "model-00119-of-00257.safetensors",
    "model-00120-of-00257.safetensors",
    "model-00121-of-00257.safetensors",
    "model-00122-of-00257.safetensors",
    "model-00123-of-00257.safetensors",
    "model-00124-of-00257.safetensors",
    "model-00125-of-00257.safetensors",
    "model-00126-of-00257.safetensors",
    "model-00127-of-00257.safetensors",
    "model-00128-of-00257.safetensors",
    "model-00129-of-00257.safetensors",
    "model-00130-of-00257.safetensors",
    "model-00131-of-00257.safetensors",
    "model-00132-of-00257.safetensors",
    "model-00133-of-00257.safetensors",
    "model-00134-of-00257.safetensors",
    "model-00135-of-00257.safetensors",
    "model-00136-of-00257.safetensors",
    "model-00137-of-00257.safetensors",
    "model-00138-of-00257.safetensors",
    "model-00139-of-00257.safetensors",
    "model-00140-of-00257.safetensors",
    "model-00141-of-00257.safetensors",
    "model-00142-of-00257.safetensors",
    "model-00143-of-00257.safetensors",
    "model-00144-of-00257.safetensors",
    "model-00145-of-00257.safetensors",
    "model-00146-of-00257.safetensors",
    "model-00147-of-00257.safetensors",
    "model-00148-of-00257.safetensors",
    "model-00149-of-00257.safetensors",
    "model-00150-of-00257.safetensors",
    "model-00151-of-00257.safetensors",
    "model-00152-of-00257.safetensors",
    "model-00153-of-00257.safetensors",
    "model-00154-of-00257.safetensors",
    "model-00155-of-00257.safetensors",
    "model-00156-of-00257.safetensors",
    "model-00157-of-00257.safetensors",
    "model-00158-of-00257.safetensors",
    "model-00159-of-00257.safetensors",
    "model-00160-of-00257.safetensors",
    "model-00161-of-00257.safetensors",
    "model-00162-of-00257.safetensors",
    "model-00163-of-00257.safetensors",
    "model-00164-of-00257.safetensors",
    "model-00165-of-00257.safetensors",
    "model-00166-of-00257.safetensors",
    "model-00167-of-00257.safetensors",
    "model-00168-of-00257.safetensors",
    "model-00169-of-00257.safetensors",
    "model-00170-of-00257.safetensors",
    "model-00171-of-00257.safetensors",
    "model-00172-of-00257.safetensors",
    "model-00173-of-00257.safetensors",
    "model-00174-of-00257.safetensors",
    "model-00175-of-00257.safetensors",
    "model-00176-of-00257.safetensors",
    "model-00177-of-00257.safetensors",
    "model-00178-of-00257.safetensors",
    "model-00179-of-00257.safetensors",
    "model-00180-of-00257.safetensors",
    "model-00181-of-00257.safetensors",
    "model-00182-of-00257.safetensors",
    "model-00183-of-00257.safetensors",
    "model-00184-of-00257.safetensors",
    "model-00185-of-00257.safetensors",
    "model-00186-of-00257.safetensors",
    "model-00187-of-00257.safetensors",
    "model-00188-of-00257.safetensors",
    "model-00189-of-00257.safetensors",
    "model-00190-of-00257.safetensors",
    "model-00191-of-00257.safetensors",
    "model-00192-of-00257.safetensors",
    "model-00193-of-00257.safetensors",
    "model-00194-of-00257.safetensors",
    "model-00195-of-00257.safetensors",
    "model-00196-of-00257.safetensors",
    "model-00197-of-00257.safetensors",
    "model-00198-of-00257.safetensors",
    "model-00199-of-00257.safetensors",
    "model-00200-of-00257.safetensors",
    "model-00201-of-00257.safetensors",
    "model-00202-of-00257.safetensors",
    "model-00203-of-00257.safetensors",
    "model-00204-of-00257.safetensors",
    "model-00205-of-00257.safetensors",
    "model-00206-of-00257.safetensors",
    "model-00207-of-00257.safetensors",
    "model-00208-of-00257.safetensors",
    "model-00209-of-00257.safetensors",
    "model-00210-of-00257.safetensors",
    "model-00211-of-00257.safetensors",
    "model-00212-of-00257.safetensors",
    "model-00213-of-00257.safetensors",
    "model-00214-of-00257.safetensors",
    "model-00215-of-00257.safetensors",
    "model-00216-of-00257.safetensors",
    "model-00217-of-00257.safetensors",
    "model-00218-of-00257.safetensors",
    "model-00219-of-00257.safetensors",
    "model-00220-of-00257.safetensors",
    "model-00221-of-00257.safetensors",
    "model-00222-of-00257.safetensors",
    "model-00223-of-00257.safetensors",
    "model-00224-of-00257.safetensors",
    "model-00225-of-00257.safetensors",
    "model-00226-of-00257.safetensors",
    "model-00227-of-00257.safetensors",
    "model-00228-of-00257.safetensors",
    "model-00229-of-00257.safetensors",
    "model-00230-of-00257.safetensors",
    "model-00231-of-00257.safetensors",
    "model-00232-of-00257.safetensors",
    "model-00233-of-00257.safetensors",
    "model-00234-of-00257.safetensors",
    "model-00235-of-00257.safetensors",
    "model-00236-of-00257.safetensors",
    "model-00237-of-00257.safetensors",
    "model-00238-of-00257.safetensors",
    "model-00239-of-00257.safetensors",
    "model-00240-of-00257.safetensors",
    "model-00241-of-00257.safetensors",
    "model-00242-of-00257.safetensors",
    "model-00243-of-00257.safetensors",
    "model-00244-of-00257.safetensors",
    "model-00245-of-00257.safetensors",
    "model-00246-of-00257.safetensors",
    "model-00247-of-00257.safetensors",
    "model-00248-of-00257.safetensors",
    "model-00249-of-00257.safetensors",
    "model-00250-of-00257.safetensors",
    "model-00251-of-00257.safetensors",
    "model-00252-of-00257.safetensors",
    "model-00253-of-00257.safetensors",
    "model-00254-of-00257.safetensors",
    "model-00255-of-00257.safetensors",
    "model-00256-of-00257.safetensors",
    "model-00257-of-00257.safetensors"
  ],
  "jeiku/Mix_Test_3B": [
    "model-00001-of-00001.safetensors"
  ],
  "iadsmedia/sqh5-lv9b-vbaya-0": [
    "adapter_model.safetensors",
    "checkpoint-111/adapter_model.safetensors"
  ],
  "jeiku/Rosa_v1_3.43B": [
    "model-00001-of-00001.safetensors"
  ],
  "sabayo/Marcaps-GPT": [
    "adapter_model.safetensors"
  ],
  "wang7776/Mistral-7B-Instruct-v0.2-sparsity-10": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "crumb/shrinkydink-init": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "genne/eclectus_7b_1.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "DrPalmiere/finetuned_mistral7B_rag": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Tijmen2/cosmosage_v0.2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "wilzh40/groove-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jeiku/Rosa_v1_7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "hynky/codellama-7b-sft-lora-func-names": [
    "adapter_model.safetensors"
  ],
  "LoneStriker/goliath-120b-3.0bpw-h6-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "mesolitica/mallam-5b-20k-instructions-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mesolitica/malaysian-mistral-7b-32k-instructions-v3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Jimmyhd/testRepo2": [
    "adapter_model.safetensors",
    "checkpoint-90/adapter_model.safetensors"
  ],
  "mnoukhov/pythia410m-tldr-sft-seed1-3000": [
    "model.safetensors"
  ],
  "SanjiWatsuki/Silicon-Maid-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Loyola/mistral-koquad-non-neft2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "roleplay4fun/base-v0.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Wanfq/MathInstruct-Deepseek-Coder-6.7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/goliath-120b-2.65bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "Wanfq/MathInstruct-Llemma-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Anshler/selective-blind-guessing": [
    "model.safetensors"
  ],
  "GeneZC/MiniChat-2-3B": [
    "model.safetensors"
  ],
  "jeiku/LongBoros_3.43B": [
    "model-00001-of-00001.safetensors"
  ],
  "jeiku/Asor_3.43B": [
    "model-00001-of-00001.safetensors"
  ],
  "jaekwanyda/Yi-Ko-6B_KO_Open-Platypus": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "techandy42/llama-2-7b-craftergpt-v1.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FutureMa/SeleniumBloom560m": [
    "model.safetensors"
  ],
  "ace2105/mistral-indian-rights": [
    "adapter_model.safetensors",
    "checkpoint-10/adapter_model.safetensors",
    "model.safetensors"
  ],
  "lxuechen/phi-2-dpo": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Ram07/emp5_peft": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "beomi/llama-2-ko-7b-emb-dev": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "aayvyas/platform-support-sft-v2": [
    "adapter_model.safetensors",
    "checkpoint-9/adapter_model.safetensors"
  ],
  "bnurpek/mGPT": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "bulkbeings/Emp_PEFT_v6": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jeiku/Rosa_v2_3B": [
    "model-00001-of-00001.safetensors"
  ],
  "shelldernn/PiVoT-MoE-epoch2-merged": [
    "model-00001-of-00030.safetensors",
    "model-00002-of-00030.safetensors",
    "model-00003-of-00030.safetensors",
    "model-00004-of-00030.safetensors",
    "model-00005-of-00030.safetensors",
    "model-00006-of-00030.safetensors",
    "model-00007-of-00030.safetensors",
    "model-00008-of-00030.safetensors",
    "model-00009-of-00030.safetensors",
    "model-00010-of-00030.safetensors",
    "model-00011-of-00030.safetensors",
    "model-00012-of-00030.safetensors",
    "model-00013-of-00030.safetensors",
    "model-00014-of-00030.safetensors",
    "model-00015-of-00030.safetensors",
    "model-00016-of-00030.safetensors",
    "model-00017-of-00030.safetensors",
    "model-00018-of-00030.safetensors",
    "model-00019-of-00030.safetensors",
    "model-00020-of-00030.safetensors",
    "model-00021-of-00030.safetensors",
    "model-00022-of-00030.safetensors",
    "model-00023-of-00030.safetensors",
    "model-00024-of-00030.safetensors",
    "model-00025-of-00030.safetensors",
    "model-00026-of-00030.safetensors",
    "model-00027-of-00030.safetensors",
    "model-00028-of-00030.safetensors",
    "model-00029-of-00030.safetensors",
    "model-00030-of-00030.safetensors"
  ],
  "ifuseok/yi-ko-playtus-instruct-v0.2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "vitaminlct/misnhu": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/Silicon-Maid-7B-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "alexhegit/opt-125m-gptq-4bit": [
    "model.safetensors"
  ],
  "LoneStriker/Silicon-Maid-7B-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Silicon-Maid-7B-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "kimnt93/chat-llama2-70b-1.0": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "LoneStriker/Silicon-Maid-7B-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Silicon-Maid-7B-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "procne/self_clm-model": [
    "model.safetensors"
  ],
  "bulkbeings/Emp_PEFT_v7": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Aleereza/tiny_llama_with_m2Tokenizer": [
    "model.safetensors"
  ],
  "kimnt93/chat-mixtral-8x7b-1.0": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "jondurbin/bagel-14b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "0x7o/fialka-7B-v3": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "themanas021/Mistral-MetaMath007": [
    "adapter_model.safetensors"
  ],
  "cognitivecomputations/dolphin-2.6-mistral-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "unsloth/llama-2-13b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "unsloth/llama-2-13b-bnb-4bit": [
    "model.safetensors"
  ],
  "thanhnew2001/starcoder-3b-taipy15": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "loanhhquanhh/gpt2": [
    "model.safetensors"
  ],
  "fxmeng/Mixtral-1x7B-Instruct-v0.1": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "Herry443/Mistral-7B-KNUT-v0.1-100-HellaSWAG": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "yuntaeyang/Yi-Ko-6B-lora": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Rishabh02/translation_hindi_model": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "diffnamehard/Mistral-CatMacaroni-slerp-uncensored-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "unum-cloud/uform-gen-chat": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Wanfq/distillchat_1.7.7_tp_1.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "cloudyu/Mixtral_7Bx5_MoE_30B": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "renardkorzeniowski/gpt2-wikitext2": [
    "model.safetensors"
  ],
  "LoneStriker/goliath-120b-2.9bpw-h6-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "TheBloke/Silicon-Maid-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Silicon-Maid-7B-GPTQ": [
    "model.safetensors"
  ],
  "We-Want-GPU/Yi-Ko-6B-DPO-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "obrmmk/tinycodellama-jp-1.3b-3k": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Prezily/gpt2-trial-r1": [
    "model.safetensors"
  ],
  "megastudyedu/M-SOLAR-10.7B-v1.1-beta": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "andrijdavid/mindy-7b-v2-GGUF": [],
  "OpenPipe/mistral-ft-optimized-1227": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "0x7o/fialka-13B-v3": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "Ngit/merged-deepseek-6.7": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mlabonne/GML-Mistral-merged-v1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mustafa1923/verses_finetune6": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Weyaxi/Seraph-openchat-3.5-1210-Slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "andrijdavid/supermario-v2-GGUF": [],
  "Weyaxi/openchat-3.5-1210-Seraph-Slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Wanfq/distillchat_1.7.8_tp_1.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "DopeorNope/SOLARC-MOE-10.7Bx4": [
    "model-00001-of-00030.safetensors",
    "model-00002-of-00030.safetensors",
    "model-00003-of-00030.safetensors",
    "model-00004-of-00030.safetensors",
    "model-00005-of-00030.safetensors",
    "model-00006-of-00030.safetensors",
    "model-00007-of-00030.safetensors",
    "model-00008-of-00030.safetensors",
    "model-00009-of-00030.safetensors",
    "model-00010-of-00030.safetensors",
    "model-00011-of-00030.safetensors",
    "model-00012-of-00030.safetensors",
    "model-00013-of-00030.safetensors",
    "model-00014-of-00030.safetensors",
    "model-00015-of-00030.safetensors",
    "model-00016-of-00030.safetensors",
    "model-00017-of-00030.safetensors",
    "model-00018-of-00030.safetensors",
    "model-00019-of-00030.safetensors",
    "model-00020-of-00030.safetensors",
    "model-00021-of-00030.safetensors",
    "model-00022-of-00030.safetensors",
    "model-00023-of-00030.safetensors",
    "model-00024-of-00030.safetensors",
    "model-00025-of-00030.safetensors",
    "model-00026-of-00030.safetensors",
    "model-00027-of-00030.safetensors",
    "model-00028-of-00030.safetensors",
    "model-00029-of-00030.safetensors",
    "model-00030-of-00030.safetensors"
  ],
  "mmpc/phi-2-typescript": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Holmeister/mistral-7b-ft-chatgpt-en": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mrSoul7766/git-base-instagram-cap": [
    "model.safetensors"
  ],
  "pkarypis/zephyr-7b-sft-test": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sudhir2016/merged-model": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "mlabonne/NeuralPipe-7B-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "andrijdavid/CatPPT-base-GGUF": [],
  "DopeorNope/You_can_cry_Snowman-13B": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "mtc/LeoLM-leo-mistral-hessianai-7b-classification-with-mixtral-explanation-3-epochs-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mlabonne/NeuralQuant-9B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Inferless/llama2-summarization-adapter-merged-model": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Prezily/gpt2-trial-r2": [
    "model.safetensors"
  ],
  "ybelkada/test-axolotl": [
    "model.safetensors"
  ],
  "ybelkada/test-axolotl-axolotltrainer": [
    "model.safetensors"
  ],
  "ybelkada/test-axolotl-axolotlmambatrainer": [
    "model.safetensors"
  ],
  "ybelkada/test-axolotl-onecyclelrschedulertrainer": [
    "model.safetensors"
  ],
  "ybelkada/test-axolotl-reloratrainer": [
    "model.safetensors"
  ],
  "saberai/Zro1.6Test_3B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "C0uchP0tat0/my_rugpt3medium_finetune": [
    "model.safetensors"
  ],
  "mlabonne/NeuralPipe-7B-ties": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "andrijdavid/LMCocktail-10.7B-v1-GGUF": [],
  "LoneStriker/MixtralOrochi8x7B-3.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "stangirala/phi-2-ft": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "BigSalmon/InformalToFormalLincoln118Paraphrase": [
    "model.safetensors"
  ],
  "msamon/AdaptLLM-finance-chat-AWQ": [
    "model.safetensors"
  ],
  "LoneStriker/MixtralOrochi8x7B-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "salma-remyx/jasonai-llama2-13B-dpo_3ksteps": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "LoneStriker/MixtralOrochi8x7B-5.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "LoneStriker/MixtralOrochi8x7B-6.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "Sigurdur/jonas-hallgrimsson-gpt2": [
    "model.safetensors"
  ],
  "mlabonne/NeuralPipe-9B-merged": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "andrijdavid/Sakura-SOLAR-Instruct-GGUF": [],
  "LoneStriker/MixtralOrochi8x7B-8.0bpw-h8-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "codegood/MPhi_2_epochs": [
    "model.safetensors"
  ],
  "genne/electus_yiko_dpo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "genne/eclectus_1.1_dedup": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "saberai/Zro1.6Test2_3B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mlabonne/NeuralMix-2x7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "shahidul034/HajjLLM_zephyr7b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "SanjiWatsuki/longcat-10.7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "genne/kiwi_solar_merge_slerp_test_v1": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "crumb/gpt2a-pile-test-285m": [
    "model.safetensors"
  ],
  "decem/Dionysus-Mistral-m3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "zhe0/peft-Taiwan-LLM-self-used": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "dillfrescott/trinity-v1.2-x8-MoE": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "rhzs/autotrain-b55c0-4p228": [
    "adapter_model.safetensors",
    "checkpoint-681/adapter_model.safetensors"
  ],
  "dillfrescott/stealth-v1.2-x8-MoE": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "jakemannix/zephyr-7b-beta_assistant_v0.2_gptq": [
    "model.safetensors"
  ],
  "pkarypis/zephyr-7b-sft-random-50": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "oopsung/Yi-ko-F-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jingyeom/Yi-ko-1.2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "watashiha/watashiha-gpt-6b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "genne/kiwi_yiko_merge_slerp_test_v1": [
    "model-00001-of-00003.safetensors",
    "model-00001-of-00005.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00003.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "SagarKrishna/templlama2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "detakarang/mistsql-v0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "diamantrsd/cerpengen-75": [
    "model.safetensors"
  ],
  "audichandra/Gajah-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "NareshSandrugu/indic-gpt": [
    "model.safetensors"
  ],
  "fxmeng/Mixtral-2x7B-Instruct-v0.1": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "pkarypis/zephyr-7b-sft-random-75": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "s3nh/Mistral-7B-Evol-Instruct-Chinese": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Heng666/StableMedZephyr-Merged-3b": [
    "model-00001-of-00356.safetensors",
    "model-00002-of-00356.safetensors",
    "model-00003-of-00356.safetensors",
    "model-00004-of-00356.safetensors",
    "model-00005-of-00356.safetensors",
    "model-00006-of-00356.safetensors",
    "model-00007-of-00356.safetensors",
    "model-00008-of-00356.safetensors",
    "model-00009-of-00356.safetensors",
    "model-00010-of-00356.safetensors",
    "model-00011-of-00356.safetensors",
    "model-00012-of-00356.safetensors",
    "model-00013-of-00356.safetensors",
    "model-00014-of-00356.safetensors",
    "model-00015-of-00356.safetensors",
    "model-00016-of-00356.safetensors",
    "model-00017-of-00356.safetensors",
    "model-00018-of-00356.safetensors",
    "model-00019-of-00356.safetensors",
    "model-00020-of-00356.safetensors",
    "model-00021-of-00356.safetensors",
    "model-00022-of-00356.safetensors",
    "model-00023-of-00356.safetensors",
    "model-00024-of-00356.safetensors",
    "model-00025-of-00356.safetensors",
    "model-00026-of-00356.safetensors",
    "model-00027-of-00356.safetensors",
    "model-00028-of-00356.safetensors",
    "model-00029-of-00356.safetensors",
    "model-00030-of-00356.safetensors",
    "model-00031-of-00356.safetensors",
    "model-00032-of-00356.safetensors",
    "model-00033-of-00356.safetensors",
    "model-00034-of-00356.safetensors",
    "model-00035-of-00356.safetensors",
    "model-00036-of-00356.safetensors",
    "model-00037-of-00356.safetensors",
    "model-00038-of-00356.safetensors",
    "model-00039-of-00356.safetensors",
    "model-00040-of-00356.safetensors",
    "model-00041-of-00356.safetensors",
    "model-00042-of-00356.safetensors",
    "model-00043-of-00356.safetensors",
    "model-00044-of-00356.safetensors",
    "model-00045-of-00356.safetensors",
    "model-00046-of-00356.safetensors",
    "model-00047-of-00356.safetensors",
    "model-00048-of-00356.safetensors",
    "model-00049-of-00356.safetensors",
    "model-00050-of-00356.safetensors",
    "model-00051-of-00356.safetensors",
    "model-00052-of-00356.safetensors",
    "model-00053-of-00356.safetensors",
    "model-00054-of-00356.safetensors",
    "model-00055-of-00356.safetensors",
    "model-00056-of-00356.safetensors",
    "model-00057-of-00356.safetensors",
    "model-00058-of-00356.safetensors",
    "model-00059-of-00356.safetensors",
    "model-00060-of-00356.safetensors",
    "model-00061-of-00356.safetensors",
    "model-00062-of-00356.safetensors",
    "model-00063-of-00356.safetensors",
    "model-00064-of-00356.safetensors",
    "model-00065-of-00356.safetensors",
    "model-00066-of-00356.safetensors",
    "model-00067-of-00356.safetensors",
    "model-00068-of-00356.safetensors",
    "model-00069-of-00356.safetensors",
    "model-00070-of-00356.safetensors",
    "model-00071-of-00356.safetensors",
    "model-00072-of-00356.safetensors",
    "model-00073-of-00356.safetensors",
    "model-00074-of-00356.safetensors",
    "model-00075-of-00356.safetensors",
    "model-00076-of-00356.safetensors",
    "model-00077-of-00356.safetensors",
    "model-00078-of-00356.safetensors",
    "model-00079-of-00356.safetensors",
    "model-00080-of-00356.safetensors",
    "model-00081-of-00356.safetensors",
    "model-00082-of-00356.safetensors",
    "model-00083-of-00356.safetensors",
    "model-00084-of-00356.safetensors",
    "model-00085-of-00356.safetensors",
    "model-00086-of-00356.safetensors",
    "model-00087-of-00356.safetensors",
    "model-00088-of-00356.safetensors",
    "model-00089-of-00356.safetensors",
    "model-00090-of-00356.safetensors",
    "model-00091-of-00356.safetensors",
    "model-00092-of-00356.safetensors",
    "model-00093-of-00356.safetensors",
    "model-00094-of-00356.safetensors",
    "model-00095-of-00356.safetensors",
    "model-00096-of-00356.safetensors",
    "model-00097-of-00356.safetensors",
    "model-00098-of-00356.safetensors",
    "model-00099-of-00356.safetensors",
    "model-00100-of-00356.safetensors",
    "model-00101-of-00356.safetensors",
    "model-00102-of-00356.safetensors",
    "model-00103-of-00356.safetensors",
    "model-00104-of-00356.safetensors",
    "model-00105-of-00356.safetensors",
    "model-00106-of-00356.safetensors",
    "model-00107-of-00356.safetensors",
    "model-00108-of-00356.safetensors",
    "model-00109-of-00356.safetensors",
    "model-00110-of-00356.safetensors",
    "model-00111-of-00356.safetensors",
    "model-00112-of-00356.safetensors",
    "model-00113-of-00356.safetensors",
    "model-00114-of-00356.safetensors",
    "model-00115-of-00356.safetensors",
    "model-00116-of-00356.safetensors",
    "model-00117-of-00356.safetensors",
    "model-00118-of-00356.safetensors",
    "model-00119-of-00356.safetensors",
    "model-00120-of-00356.safetensors",
    "model-00121-of-00356.safetensors",
    "model-00122-of-00356.safetensors",
    "model-00123-of-00356.safetensors",
    "model-00124-of-00356.safetensors",
    "model-00125-of-00356.safetensors",
    "model-00126-of-00356.safetensors",
    "model-00127-of-00356.safetensors",
    "model-00128-of-00356.safetensors",
    "model-00129-of-00356.safetensors",
    "model-00130-of-00356.safetensors",
    "model-00131-of-00356.safetensors",
    "model-00132-of-00356.safetensors",
    "model-00133-of-00356.safetensors",
    "model-00134-of-00356.safetensors",
    "model-00135-of-00356.safetensors",
    "model-00136-of-00356.safetensors",
    "model-00137-of-00356.safetensors",
    "model-00138-of-00356.safetensors",
    "model-00139-of-00356.safetensors",
    "model-00140-of-00356.safetensors",
    "model-00141-of-00356.safetensors",
    "model-00142-of-00356.safetensors",
    "model-00143-of-00356.safetensors",
    "model-00144-of-00356.safetensors",
    "model-00145-of-00356.safetensors",
    "model-00146-of-00356.safetensors",
    "model-00147-of-00356.safetensors",
    "model-00148-of-00356.safetensors",
    "model-00149-of-00356.safetensors",
    "model-00150-of-00356.safetensors",
    "model-00151-of-00356.safetensors",
    "model-00152-of-00356.safetensors",
    "model-00153-of-00356.safetensors",
    "model-00154-of-00356.safetensors",
    "model-00155-of-00356.safetensors",
    "model-00156-of-00356.safetensors",
    "model-00157-of-00356.safetensors",
    "model-00158-of-00356.safetensors",
    "model-00159-of-00356.safetensors",
    "model-00160-of-00356.safetensors",
    "model-00161-of-00356.safetensors",
    "model-00162-of-00356.safetensors",
    "model-00163-of-00356.safetensors",
    "model-00164-of-00356.safetensors",
    "model-00165-of-00356.safetensors",
    "model-00166-of-00356.safetensors",
    "model-00167-of-00356.safetensors",
    "model-00168-of-00356.safetensors",
    "model-00169-of-00356.safetensors",
    "model-00170-of-00356.safetensors",
    "model-00171-of-00356.safetensors",
    "model-00172-of-00356.safetensors",
    "model-00173-of-00356.safetensors",
    "model-00174-of-00356.safetensors",
    "model-00175-of-00356.safetensors",
    "model-00176-of-00356.safetensors",
    "model-00177-of-00356.safetensors",
    "model-00178-of-00356.safetensors",
    "model-00179-of-00356.safetensors",
    "model-00180-of-00356.safetensors",
    "model-00181-of-00356.safetensors",
    "model-00182-of-00356.safetensors",
    "model-00183-of-00356.safetensors",
    "model-00184-of-00356.safetensors",
    "model-00185-of-00356.safetensors",
    "model-00186-of-00356.safetensors",
    "model-00187-of-00356.safetensors",
    "model-00188-of-00356.safetensors",
    "model-00189-of-00356.safetensors",
    "model-00190-of-00356.safetensors",
    "model-00191-of-00356.safetensors",
    "model-00192-of-00356.safetensors",
    "model-00193-of-00356.safetensors",
    "model-00194-of-00356.safetensors",
    "model-00195-of-00356.safetensors",
    "model-00196-of-00356.safetensors",
    "model-00197-of-00356.safetensors",
    "model-00198-of-00356.safetensors",
    "model-00199-of-00356.safetensors",
    "model-00200-of-00356.safetensors",
    "model-00201-of-00356.safetensors",
    "model-00202-of-00356.safetensors",
    "model-00203-of-00356.safetensors",
    "model-00204-of-00356.safetensors",
    "model-00205-of-00356.safetensors",
    "model-00206-of-00356.safetensors",
    "model-00207-of-00356.safetensors",
    "model-00208-of-00356.safetensors",
    "model-00209-of-00356.safetensors",
    "model-00210-of-00356.safetensors",
    "model-00211-of-00356.safetensors",
    "model-00212-of-00356.safetensors",
    "model-00213-of-00356.safetensors",
    "model-00214-of-00356.safetensors",
    "model-00215-of-00356.safetensors",
    "model-00216-of-00356.safetensors",
    "model-00217-of-00356.safetensors",
    "model-00218-of-00356.safetensors",
    "model-00219-of-00356.safetensors",
    "model-00220-of-00356.safetensors",
    "model-00221-of-00356.safetensors",
    "model-00222-of-00356.safetensors",
    "model-00223-of-00356.safetensors",
    "model-00224-of-00356.safetensors",
    "model-00225-of-00356.safetensors",
    "model-00226-of-00356.safetensors",
    "model-00227-of-00356.safetensors",
    "model-00228-of-00356.safetensors",
    "model-00229-of-00356.safetensors",
    "model-00230-of-00356.safetensors",
    "model-00231-of-00356.safetensors",
    "model-00232-of-00356.safetensors",
    "model-00233-of-00356.safetensors",
    "model-00234-of-00356.safetensors",
    "model-00235-of-00356.safetensors",
    "model-00236-of-00356.safetensors",
    "model-00237-of-00356.safetensors",
    "model-00238-of-00356.safetensors",
    "model-00239-of-00356.safetensors",
    "model-00240-of-00356.safetensors",
    "model-00241-of-00356.safetensors",
    "model-00242-of-00356.safetensors",
    "model-00243-of-00356.safetensors",
    "model-00244-of-00356.safetensors",
    "model-00245-of-00356.safetensors",
    "model-00246-of-00356.safetensors",
    "model-00247-of-00356.safetensors",
    "model-00248-of-00356.safetensors",
    "model-00249-of-00356.safetensors",
    "model-00250-of-00356.safetensors",
    "model-00251-of-00356.safetensors",
    "model-00252-of-00356.safetensors",
    "model-00253-of-00356.safetensors",
    "model-00254-of-00356.safetensors",
    "model-00255-of-00356.safetensors",
    "model-00256-of-00356.safetensors",
    "model-00257-of-00356.safetensors",
    "model-00258-of-00356.safetensors",
    "model-00259-of-00356.safetensors",
    "model-00260-of-00356.safetensors",
    "model-00261-of-00356.safetensors",
    "model-00262-of-00356.safetensors",
    "model-00263-of-00356.safetensors",
    "model-00264-of-00356.safetensors",
    "model-00265-of-00356.safetensors",
    "model-00266-of-00356.safetensors",
    "model-00267-of-00356.safetensors",
    "model-00268-of-00356.safetensors",
    "model-00269-of-00356.safetensors",
    "model-00270-of-00356.safetensors",
    "model-00271-of-00356.safetensors",
    "model-00272-of-00356.safetensors",
    "model-00273-of-00356.safetensors",
    "model-00274-of-00356.safetensors",
    "model-00275-of-00356.safetensors",
    "model-00276-of-00356.safetensors",
    "model-00277-of-00356.safetensors",
    "model-00278-of-00356.safetensors",
    "model-00279-of-00356.safetensors",
    "model-00280-of-00356.safetensors",
    "model-00281-of-00356.safetensors",
    "model-00282-of-00356.safetensors",
    "model-00283-of-00356.safetensors",
    "model-00284-of-00356.safetensors",
    "model-00285-of-00356.safetensors",
    "model-00286-of-00356.safetensors",
    "model-00287-of-00356.safetensors",
    "model-00288-of-00356.safetensors",
    "model-00289-of-00356.safetensors",
    "model-00290-of-00356.safetensors",
    "model-00291-of-00356.safetensors",
    "model-00292-of-00356.safetensors",
    "model-00293-of-00356.safetensors",
    "model-00294-of-00356.safetensors",
    "model-00295-of-00356.safetensors",
    "model-00296-of-00356.safetensors",
    "model-00297-of-00356.safetensors",
    "model-00298-of-00356.safetensors",
    "model-00299-of-00356.safetensors",
    "model-00300-of-00356.safetensors",
    "model-00301-of-00356.safetensors",
    "model-00302-of-00356.safetensors",
    "model-00303-of-00356.safetensors",
    "model-00304-of-00356.safetensors",
    "model-00305-of-00356.safetensors",
    "model-00306-of-00356.safetensors",
    "model-00307-of-00356.safetensors",
    "model-00308-of-00356.safetensors",
    "model-00309-of-00356.safetensors",
    "model-00310-of-00356.safetensors",
    "model-00311-of-00356.safetensors",
    "model-00312-of-00356.safetensors",
    "model-00313-of-00356.safetensors",
    "model-00314-of-00356.safetensors",
    "model-00315-of-00356.safetensors",
    "model-00316-of-00356.safetensors",
    "model-00317-of-00356.safetensors",
    "model-00318-of-00356.safetensors",
    "model-00319-of-00356.safetensors",
    "model-00320-of-00356.safetensors",
    "model-00321-of-00356.safetensors",
    "model-00322-of-00356.safetensors",
    "model-00323-of-00356.safetensors",
    "model-00324-of-00356.safetensors",
    "model-00325-of-00356.safetensors",
    "model-00326-of-00356.safetensors",
    "model-00327-of-00356.safetensors",
    "model-00328-of-00356.safetensors",
    "model-00329-of-00356.safetensors",
    "model-00330-of-00356.safetensors",
    "model-00331-of-00356.safetensors",
    "model-00332-of-00356.safetensors",
    "model-00333-of-00356.safetensors",
    "model-00334-of-00356.safetensors",
    "model-00335-of-00356.safetensors",
    "model-00336-of-00356.safetensors",
    "model-00337-of-00356.safetensors",
    "model-00338-of-00356.safetensors",
    "model-00339-of-00356.safetensors",
    "model-00340-of-00356.safetensors",
    "model-00341-of-00356.safetensors",
    "model-00342-of-00356.safetensors",
    "model-00343-of-00356.safetensors",
    "model-00344-of-00356.safetensors",
    "model-00345-of-00356.safetensors",
    "model-00346-of-00356.safetensors",
    "model-00347-of-00356.safetensors",
    "model-00348-of-00356.safetensors",
    "model-00349-of-00356.safetensors",
    "model-00350-of-00356.safetensors",
    "model-00351-of-00356.safetensors",
    "model-00352-of-00356.safetensors",
    "model-00353-of-00356.safetensors",
    "model-00354-of-00356.safetensors",
    "model-00355-of-00356.safetensors",
    "model-00356-of-00356.safetensors"
  ],
  "fxmeng/Mixtral-3x7B-Instruct-v0.1": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "fxmeng/Mixtral-4x7B-Instruct-v0.1": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "fxmeng/Mixtral-5x7B-Instruct-v0.1": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "fxmeng/Mixtral-6x7B-Instruct-v0.1": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "fxmeng/Mixtral-7x7B-Instruct-v0.1": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "yanolja/KoSOLAR-10.7B-v0.1-deprecated": [
    "model-00001-of-00012.safetensors",
    "model-00002-of-00012.safetensors",
    "model-00003-of-00012.safetensors",
    "model-00004-of-00012.safetensors",
    "model-00005-of-00012.safetensors",
    "model-00006-of-00012.safetensors",
    "model-00007-of-00012.safetensors",
    "model-00008-of-00012.safetensors",
    "model-00009-of-00012.safetensors",
    "model-00010-of-00012.safetensors",
    "model-00011-of-00012.safetensors",
    "model-00012-of-00012.safetensors"
  ],
  "pumplay01/JCI7TH-IPSG-FULL": [
    "model.safetensors"
  ],
  "Deepakyadav1212/TinyMistral-248M-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "JackCloudman/notux-8x7b-v1-3.5bpw-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "crumb/gpt2a-8192-768-base-init": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/dolphin-2.6-mistral-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/dolphin-2.6-mistral-7B-GPTQ": [
    "model.safetensors"
  ],
  "vvud/llama-2-7b-chat-eb": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dillfrescott/TinyLlama-1.1B-Chat-v0.6-x8-MoE": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "pkarypis/zephyr-7b-sft-random-90": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kubernetes-bad/good-robot": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Aurora-Nights-70B-v1.0-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Aurora-Nights-70B-v1.0-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Aurora-Nights-103B-v1.0-AWQ": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "obrmmk/tinycodellama-jp-1.3b-5k": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jeiku/Rosa_NSFW_Niche_3B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "abhishek/autotrain-va6kd-j4k5k": [
    "checkpoint-276/model-00001-of-00003.safetensors",
    "checkpoint-276/model-00002-of-00003.safetensors",
    "checkpoint-276/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jeiku/Rosa_Writing_3B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "tim9510019/Starling-7B-Economic_231218": [
    "adapter_model.safetensors"
  ],
  "mithlesh/llama2_finetuned_propellyr": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "NareshSandrugu/indic-gpt_1": [
    "model.safetensors"
  ],
  "lokaspire/deci-finetuned-alpaca-cleaned": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "diffnamehard/Psyfighter2-Noromaid-ties-13B": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "ahmedeltabakh/emotions-classification-Mistral-7B-Instruct-v0.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "NTIS/KoRnDAlpaca-RAG-Polyglot-12.8B": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "LoneStriker/Aurora-Nights-70B-v1.0-2.4bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "Weni/WeniGPT-2.0.1-Zephyr-7B-bits_and_bytes-AWQ-dataset-llm-base-1.0.1": [
    "model.safetensors"
  ],
  "LoneStriker/Aurora-Nights-70B-v1.0-3.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "LoneStriker/Aurora-Nights-103B-v1.0-2.4bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "bulentsiyah/finetune_deepspeed_deepseek": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors",
    "save_pretrained/model.safetensors",
    "trainer_save_model/model-00001-of-00003.safetensors",
    "trainer_save_model/model-00002-of-00003.safetensors",
    "trainer_save_model/model-00003-of-00003.safetensors"
  ],
  "Weni/WeniGPT-2.0.1-Zephyr-7B-GPTQ-AWQ-dataset-llm-base-1.0.1": [
    "model.safetensors"
  ],
  "tb2pi-persistent/Llama-2-7b-chat-hf-base": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "pkarypis/zephyr-7b-sft-random-95": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rvv-karma/Llama-2-7B-Coder": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Sakura-SOLAR-Instruct-AWQ": [
    "model.safetensors"
  ],
  "LoneStriker/Aurora-Nights-70B-v1.0-4.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "matteocirca/Llama-2-13b-chat-hf-smldl": [
    "adapter_model.safetensors",
    "checkpoint-6/adapter_model.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "parsak/codegen-350M-mono-lora-instruction": [
    "model.safetensors"
  ],
  "tb2pi-persistent/Llama-2-13b-chat-hf-base": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T": [
    "model.safetensors"
  ],
  "We-Want-GPU/SOLAR-10.7B-orca-alpaca-gpt4-lora-653": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Wanfq/MetaMath-MathInstruct-Llemma-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/SOLARC-MOE-10.7Bx4-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Aurora-Nights-70B-v1.0-4.65bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "NobodyExistsOnTheInternet/mergedallmixtralexpert": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Aurora-Nights-103B-v1.0-3.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "roleplay4fun/christmas-7b-v0.3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mlabonne/Beyonder-4x7b": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "TheBloke/SOLARC-MOE-10.7Bx4-GPTQ": [
    "model.safetensors"
  ],
  "LoneStriker/Aurora-Nights-70B-v1.0-5.0bpw-h6-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "venkataravuri/llama-2-7b-chat-hf-enhanced": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jan-hq/stealth-v1.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "master-frog/distilgpt2-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "beingamit99/customer-support": [
    "model.safetensors"
  ],
  "FinancialSupport/saiga-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "freecs/ArtificialThinker-Phi2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "thanhdaonguyen/thanhdaorp-2812": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "msy127/mnsim-sft-peftmerged-2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/Aurora-Nights-70B-v1.0-6.0bpw-h6-exl2": [
    "output-00001-of-00007.safetensors",
    "output-00002-of-00007.safetensors",
    "output-00003-of-00007.safetensors",
    "output-00004-of-00007.safetensors",
    "output-00005-of-00007.safetensors",
    "output-00006-of-00007.safetensors",
    "output-00007-of-00007.safetensors"
  ],
  "LoneStriker/Aurora-Nights-103B-v1.0-3.5bpw-h6-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "kjus1245/AntModel-7B-XLLM-Demo": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "tb2pi-persistent/Llama-2-13b-chat-hf-tb2pi-merged-v2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "TheBloke/Sakura-SOLAR-Instruct-GPTQ": [
    "model.safetensors"
  ],
  "mildwood/mistral-ft-optimized-1227-brainglasses": [
    "model-00001-of-00002.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00002.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hieunguyenminh/v1.1": [
    "adapter_model.safetensors"
  ],
  "Saugatkafley/opt-350m-sft": [
    "adapter_model.safetensors"
  ],
  "diamantrsd/cerpengen-500words": [
    "model.safetensors"
  ],
  "LoneStriker/Aurora-Nights-70B-v1.0-2.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "Saugatkafley/opt-350m-CodeAlpaca-sft": [
    "model.safetensors"
  ],
  "TheBloke/Aurora-Nights-103B-v1.0-GPTQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "teilomillet/MiniMerlin-2-3B": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "samir-fama/SamirGPT-v1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "sambar/zephyr-7b-sft-lora": [
    "adapter_model.safetensors"
  ],
  "SuvajitGB/rollercoaster_emotions": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Felladrin/Smol-Llama-101M-Chat-v1": [
    "model.safetensors"
  ],
  "LoneStriker/notux-8x7b-v1-2.4bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "suv11235/rollercoaster_emotions": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Mihaiii/Pallas-0.5": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "topeomole/llama-dlm": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/notux-8x7b-v1-3.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "jan-hq/nitro-v1.2-e3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/notux-8x7b-v1-3.5bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "Weni/WeniGPT-1.0.0-Mistral-7B-adapters-merged-instructBase-4bit": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jeonsworld/CarbonVillain-en-10.7B-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/notux-8x7b-v1-3.75bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "sweetpablo/llama_ft": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Weni/WeniGPT-1.0.0-Mistral-7B-4bit-AWQ-instructBase": [
    "model.safetensors"
  ],
  "LoneStriker/Sakura-SOLAR-Instruct-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/notux-8x7b-v1-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Sakura-SOLAR-Instruct-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Sakura-SOLAR-Instruct-DPO-v2-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/notux-8x7b-v1-5.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "LoneStriker/Sakura-SOLAR-Instruct-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/notux-8x7b-v1-6.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "LoneStriker/Sakura-SOLAR-Instruct-DPO-v2-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Sakura-SOLAR-Instruct-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Sakura-SOLAR-Instruct-DPO-v2-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "jeiku/Rosa_v3_3B": [
    "model-00001-of-00001.safetensors"
  ],
  "LoneStriker/Sakura-SOLAR-Instruct-8.0bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/Sakura-SOLAR-Instruct-DPO-v2-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Sakura-SOLAR-Instruct-DPO-v2-8.0bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "cfahlgren1/OpenHermes-Llama_3B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "salma-remyx/tinyllama_jasonai": [
    "model.safetensors"
  ],
  "imZoe/adbm": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "brucethemoose/DPOpenHermes-v1v2-Merge": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "brucethemoose/DPOpenHermes-DARE-merge-2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "sosoai/komt-mistral-7b-v1-dpo-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Weni/WeniGPT-2.1.1-Zephyr-7B-Bits_and_bytes-merged-adapters-dataset-LLM-base-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "NaoS2/tinycodellama-jp-0.6b-15k": [
    "model.safetensors"
  ],
  "jamesLeeeeeee/ko-gpt-chat": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "brucethemoose/DPOpenHermes-11B-merge": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "StatPan/SinGung7B-DPO-v0.1-12600c": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "JiZha/SQLGPT": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "Walmart-the-bag/Influxient-4x13B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "NeuralNovel/Mistral-7B-Instruct-v0.2-Neural-Story": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mtc/LeoLM-leo-mistral-7b-mixtral-and-gpt4-explanation-3-epochs-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "decem/Dionysus-Mistral-m3-v3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "charent/ChatLM-mini-Chinese": [
    "model.safetensors"
  ],
  "iblai/ibl-fordham-7b-mistral": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "pkarypis/zephyr-7b-sft-filtered-95": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "PerRing/Yi-Ko-6x2B-v0.0": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LiamLi1991/Project": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Doctor-Shotgun/TinyLlama-1.1B-32k": [
    "model.safetensors"
  ],
  "pkarypis/zephyr-7b-sft-filtered-90": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "GRMenon/mental-health-mistral-7b-instructv0.2-finetuned-V2": [
    "adapter_model.safetensors"
  ],
  "ssuresh/codeparrot": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Jueli/mistral-test1": [
    "adapter_model.safetensors",
    "checkpoint-3/adapter_model.safetensors"
  ],
  "Mihir1108/deci-finetuned-json": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Gangwoo/llama-7b-sft-lora-qrecc": [
    "adapter_model.safetensors"
  ],
  "wkshin89/mistral-7b-instruct-ko-test-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tigerbhai/SmalltexminLLM": [
    "model.safetensors"
  ],
  "rahulmanuwas/joritdae": [
    "adapter_model.safetensors",
    "checkpoint-339/adapter_model.safetensors",
    "model.safetensors"
  ],
  "NareshSandrugu/telugu_gpt2_newtokens": [
    "model.safetensors"
  ],
  "StatPan/mistral7b-bartending-recipe-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/lzlv_70b_fp16_hf-3.5bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "satpalsr/mistral-7B-qlora-valid2": [
    "adapter_model.safetensors"
  ],
  "pkarypis/zephyr-7b-sft-filtered-50": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "crodri/Flor6.3QA": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Falah/git-base-ante": [
    "model.safetensors"
  ],
  "billgates001/plantj": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "nanxiz/zcabnzh_rosalind_0": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "sethuiyer/SynthIQ-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "sethuiyer/Dr_Samantha-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Muhammadreza/Mistral-1B-GPTQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "C0uchP0tat0/laws_rugpt3medium_finetune": [
    "model.safetensors"
  ],
  "Mihaiii/Metis-0.5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Falah/caption2024": [
    "model.safetensors"
  ],
  "NareshSandrugu/telugu_gpt2_newtokens_v1": [
    "model.safetensors"
  ],
  "LoneStriker/Aurora-Nights-103B-v1.0-5.0bpw-h6-exl2": [
    "output-00001-of-00008.safetensors",
    "output-00002-of-00008.safetensors",
    "output-00003-of-00008.safetensors",
    "output-00004-of-00008.safetensors",
    "output-00005-of-00008.safetensors",
    "output-00006-of-00008.safetensors",
    "output-00007-of-00008.safetensors",
    "output-00008-of-00008.safetensors"
  ],
  "JNewber/oH": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Weni/WeniGPT-2.1.1-Zephyr-7B-Bits_and_bytes-llm-base-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Falah/git-base-ante2024": [
    "model.safetensors"
  ],
  "pmarkovic/openchat-35-sft": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "gK29382231121/mistralai-Code-Instruct-Finetune-test": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ecastera/eva-mistral-dolphin-7b-spanish": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mithlesh/llama2_finetuned": [
    "adapter_model.safetensors",
    "checkpoint-13/adapter_model.safetensors"
  ],
  "Weni/WeniGPT-2.1.1-Zephyr-7B-GPTQ-V2-dataset-llm-base-1.0.1-MERGED": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Weni/WeniGPT-2.1.1-Zephyr-7B-GPTQ-V2-AWQ-dataset-llm-base-1.0.1": [
    "model.safetensors"
  ],
  "xihajun/cnn_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Enno-Ai/DPOpenHermes-7B-v2-awq": [
    "model.safetensors"
  ],
  "TheBloke/Metis-0.5-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Metis-0.5-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/docsgpt-7B-mistral-AWQ": [
    "model.safetensors"
  ],
  "vijaym/TinyLlama-1.1B-intermediate-step-1195k-token-2.5T-function-calling-adapters": [
    "model.safetensors"
  ],
  "Sayan01/BabyVicuna": [
    "model.safetensors"
  ],
  "TheBloke/notux-8x7b-v1-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/docsgpt-7B-mistral-GPTQ": [
    "model.safetensors"
  ],
  "LoneStriker/Metis-0.5-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "lucas23padawan/Mixtral_med_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Metis-0.5-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/docsgpt-7b-mistral-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Metis-0.5-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "Tensoic/TinyLlama-1.1B-2.5T-openhermes": [
    "model.safetensors"
  ],
  "TheBloke/notux-8x7b-v1-GPTQ": [
    "model.safetensors"
  ],
  "LoneStriker/docsgpt-7b-mistral-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Metis-0.5-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Metis-0.5-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/dolphin-2.6-mistral-7b-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/docsgpt-7b-mistral-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "wgpak/codeparrot-ds": [
    "model.safetensors"
  ],
  "LoneStriker/dolphin-2.6-mistral-7b-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "TheBloke/Sarah_StoryTeller_13b-AWQ": [
    "model.safetensors"
  ],
  "LoneStriker/dolphin-2.6-mistral-7b-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/dolphin-2.6-mistral-7b-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/docsgpt-7b-mistral-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/dolphin-2.6-mistral-7b-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "aqweteddy/mistral_tv-neural-marconroni": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/docsgpt-7b-mistral-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "banghua/openchat-3.5-ppo-nn-ckpt5k": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "78health/TinyLlama_1.1B-function-calling": [
    "model.safetensors"
  ],
  "bulkbeings/Emp_PEFT_v8": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Synthia-v3.0-11B-AWQ": [
    "model.safetensors"
  ],
  "nulltella/phi-1_5-finetuned-classif-BBC-uu": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/U-Amethyst-20B-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "TheBloke/Pallas-0.5-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "riko-so97/Phi-2_FineTuned_guanaco-llama2": [
    "adapter_model.safetensors"
  ],
  "sarthak-2002/MuskGPT": [
    "model.safetensors"
  ],
  "Azazelle/Silicon-Medley": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Sarah_StoryTeller_13b_HF-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "neph1/sd-seer-griffin-3b": [
    "gptq/sd-seer-griffin-3b-gptq.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Chat-Error/Mistral-Kimiko-CSFT": [
    "Exllama-4.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/U-Amethyst-20B-4.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/UNAversal-8x7B-v1beta-2.4bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/Sarah_StoryTeller_13b_HF-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/UNAversal-8x7B-v1beta-3.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "Azazelle/xDAN-SlimOrca": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "bulkbeings/Emp_PEFT_v9": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AswanthCManoj/azma-tinyllama-v1-insights": [
    "model.safetensors"
  ],
  "LoneStriker/U-Amethyst-20B-4.65bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/UNAversal-8x7B-v1beta-3.5bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Sarah_StoryTeller_13b_HF-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/UNAversal-8x7B-v1beta-3.75bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "TheBloke/Sarah_StoryTeller_13b-GPTQ": [
    "model.safetensors"
  ],
  "nanxiz/zcabnzh_rosalind_0_bf": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/MLewd-v2.4-13B-AWQ": [
    "model.safetensors"
  ],
  "Ram07/emp-9": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/U-Amethyst-20B-5.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/UNAversal-8x7B-v1beta-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Sarah_StoryTeller_13b_HF-6.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/UNAversal-8x7B-v1beta-5.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "LoneStriker/U-Amethyst-20B-6.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/UNAversal-8x7B-v1beta-6.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "TheBloke/Synthia-v3.0-11B-GPTQ": [
    "model.safetensors"
  ],
  "LoneStriker/Sarah_StoryTeller_13b_HF-8.0bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Azazelle/Half-NSFW_Noromaid-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "s3nh/phi-2-Evol-Instruct-Chinese": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/U-Amethyst-20B-8.0bpw-h8-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "Azazelle/smol_bruin-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "virajmehta/borda-phi-2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Pallas-0.5-GPTQ": [
    "model.safetensors"
  ],
  "mlabonne/Marcoro14-7B-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "icpython/Spotter_Docs": [
    "adapter_model.safetensors",
    "checkpoint-6/adapter_model.safetensors"
  ],
  "SicariusSicariiStuff/Tinybra_13B": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "Fredithefish/DingoRP-v0.2": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "TheBloke/MLewd-v2.4-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/You_can_cry_Snowman-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/You_can_cry_Snowman-13B-GPTQ": [
    "model.safetensors"
  ],
  "anirudh-sub/debate_v3.7_model": [
    "adapter_model.safetensors",
    "checkpoint-42/adapter_model.safetensors"
  ],
  "jayshah5696/Gujju-Llama": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "samir-fama/FernandoGPT-v1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "pkarypis/zephyr-7b-sft-filtered-75": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/NeuralPipe-7B-slerp-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/NeuralPipe-7B-slerp-AWQ": [
    "model.safetensors"
  ],
  "OpenBuddy/openbuddy-mixtral-8x7b-v16.2-32k": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "TheBloke/NeuralPipe-7B-ties-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/NeuralPipe-7B-ties-AWQ": [
    "model.safetensors"
  ],
  "jikaixuan/test_merged_model": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "imZoe/re": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Azazelle/SlimMelodicMaid": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "danwils/initialproblems-mistral7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Azazelle/Dumb-Maidlet": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Aetheria-L2-70B-3.5bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "PracticeLLM/Twice-KoSOLAR-16.1B-test": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "hllj/Mistral-7B-Vi-Math": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ssuresh/codeparrot-small": [
    "model.safetensors"
  ],
  "KathirKs/nanoMistral": [
    "model.safetensors"
  ],
  "spmurrayzzz/Mistral-Syndicate-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tgmeggitt/llama2-kqlV2": [
    "adapter_model.safetensors",
    "checkpoint-800/adapter_model.safetensors"
  ],
  "decem/Dionysus-Mistral-m3-v5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Azazelle/Argetsu": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "bulkbeings/Emp_PEFT_v10": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/airoboros-l2-70b-3.1.2-3.5bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "perlthoughts/openchat-3.5-1210-32k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "BlouseJury/clown-70x1B": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "dillfrescott/silicon-maid-7b-x8-MoE-v2": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "iadsmedia/iadsmedia_SP_1_b": [
    "adapter_model.safetensors",
    "checkpoint-50/adapter_model.safetensors"
  ],
  "SicariusSicariiStuff/Tinybra_13B_GPTQ_4BIT": [
    "model.safetensors"
  ],
  "SicariusSicariiStuff/Tinybra_13B_GPTQ_32g_4BIT": [
    "model.safetensors"
  ],
  "Kquant03/WeirdMerge": [
    "model-00001-of-00001.safetensors"
  ],
  "TinyLlama/TinyLlama-1.1B-Chat-v1.0": [
    "model.safetensors"
  ],
  "hllj/Llama2-7B-Vi-Math": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "wenzw/zephyr-7b-sft-lora": [
    "adapter_model.safetensors"
  ],
  "LoneStriker/openbuddy-mixtral-8x7b-v16.2-32k-2.4bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/openbuddy-mixtral-8x7b-v16.2-32k-3.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "NareshSandrugu/gpt2_nw": [
    "model.safetensors"
  ],
  "NaoS2/tinycodellama-jp-0.6b-20k": [
    "model.safetensors"
  ],
  "dzaut/Writing_Partner_Mistral_7B-4.0bpw-exl2": [
    "output.safetensors"
  ],
  "TheBloke/MetaMath-NeuralHermes-2.5-Mistral-7B-Linear-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/MetaMath-NeuralHermes-2.5-Mistral-7B-Linear-AWQ": [
    "model.safetensors"
  ],
  "DopeorNope/SOLARC-MOE-10.7Bx6": [
    "model-00001-of-00044.safetensors",
    "model-00002-of-00044.safetensors",
    "model-00003-of-00044.safetensors",
    "model-00004-of-00044.safetensors",
    "model-00005-of-00044.safetensors",
    "model-00006-of-00044.safetensors",
    "model-00007-of-00044.safetensors",
    "model-00008-of-00044.safetensors",
    "model-00009-of-00044.safetensors",
    "model-00010-of-00044.safetensors",
    "model-00011-of-00044.safetensors",
    "model-00012-of-00044.safetensors",
    "model-00013-of-00044.safetensors",
    "model-00014-of-00044.safetensors",
    "model-00015-of-00044.safetensors",
    "model-00016-of-00044.safetensors",
    "model-00017-of-00044.safetensors",
    "model-00018-of-00044.safetensors",
    "model-00019-of-00044.safetensors",
    "model-00020-of-00044.safetensors",
    "model-00021-of-00044.safetensors",
    "model-00022-of-00044.safetensors",
    "model-00023-of-00044.safetensors",
    "model-00024-of-00044.safetensors",
    "model-00025-of-00044.safetensors",
    "model-00026-of-00044.safetensors",
    "model-00027-of-00044.safetensors",
    "model-00028-of-00044.safetensors",
    "model-00029-of-00044.safetensors",
    "model-00030-of-00044.safetensors",
    "model-00031-of-00044.safetensors",
    "model-00032-of-00044.safetensors",
    "model-00033-of-00044.safetensors",
    "model-00034-of-00044.safetensors",
    "model-00035-of-00044.safetensors",
    "model-00036-of-00044.safetensors",
    "model-00037-of-00044.safetensors",
    "model-00038-of-00044.safetensors",
    "model-00039-of-00044.safetensors",
    "model-00040-of-00044.safetensors",
    "model-00041-of-00044.safetensors",
    "model-00042-of-00044.safetensors",
    "model-00043-of-00044.safetensors",
    "model-00044-of-00044.safetensors"
  ],
  "kekmodel/StopCarbon-10.7B-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kekmodel/StopCarbon-10.7B-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kekmodel/StopCarbon-10.7B-v3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/openchat-3.5-1210-Seraph-Slerp-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/openchat-3.5-1210-Seraph-Slerp-GPTQ": [
    "model.safetensors"
  ],
  "LoneStriker/openbuddy-mixtral-8x7b-v16.2-32k-3.5bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/openbuddy-mixtral-8x7b-v16.2-32k-3.75bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "TheBloke/Seraph-openchat-3.5-1210-Slerp-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Seraph-openchat-3.5-1210-Slerp-AWQ": [
    "model.safetensors"
  ],
  "LoneStriker/openbuddy-mixtral-8x7b-v16.2-32k-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "BEE-spoke-data/smol_llama-220M-openhermes": [
    "checkpoint-5310/model.safetensors",
    "model.safetensors"
  ],
  "dzaut/Writing_Partner_Mistral_7B-3.0bpw-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/openbuddy-mixtral-8x7b-v16.2-32k-5.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "TheBloke/mistral-ft-optimized-1227-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/mistral-ft-optimized-1227-AWQ": [
    "model.safetensors"
  ],
  "LoneStriker/openbuddy-mixtral-8x7b-v16.2-32k-6.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "p1atdev/nekoqarasu-14b-chat": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "jeonsworld/CarbonVillain-en-10.7B-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Q-bert/MOLAR-10.7B": [
    "adapter_model.safetensors",
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "hllj/Zephyr-beta-7B-Vi-Math": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mishkashishka/qwe": [
    "model.safetensors"
  ],
  "We-Want-GPU/SOLAR-10.7B-orca-alpaca-gpt4-math": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "lamrin8224/smallmedllm": [
    "model.safetensors"
  ],
  "SanjiWatsuki/Lelantos-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "giuid/llama-2-13b_QR": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "giuid/mistral-7b_QR": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "BEE-spoke-data/smol_llama-220M-open_instruct": [
    "checkpoint-1332/model.safetensors",
    "model.safetensors"
  ],
  "kekmodel/StopCarbon-10.7B-v4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Nexesenex/Mistral-7B-Instruct-v0.2-2x7B-MoE-6.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "kekmodel/StopCarbon-10.7B-v5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kekmodel/StopCarbon-10.7B-v6": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Holmeister/llama2-7b-ft-chatgpt-en": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "nlpguy/ColorShadow-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/mistral-ft-optimized-1227-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/mistral-ft-optimized-1227-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "hllj/Qwen-7B-Vi-Math": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "LoneStriker/mistral-ft-optimized-1227-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/mistral-ft-optimized-1227-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "KathirKs/nanoMist": [
    "model.safetensors"
  ],
  "shuvom/OpenHathi-7B-FT-v0.1_SI": [
    "adapter_model.safetensors",
    "checkpoint-21/adapter_model.safetensors"
  ],
  "erfanzar/LinguaMatic-GPT4": [
    "model.safetensors"
  ],
  "LoneStriker/mistral-ft-optimized-1227-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "salma-remyx/MobileLLaMA-1.4B-Base_jasonai": [
    "model.safetensors"
  ],
  "NareshSandrugu/gpt2_512_nw": [
    "model.safetensors"
  ],
  "IBI-CAAI/MELT-Mixtral-8x7B-Instruct-v0.1": [
    "model-00001-of-00048.safetensors",
    "model-00002-of-00048.safetensors",
    "model-00003-of-00048.safetensors",
    "model-00004-of-00048.safetensors",
    "model-00005-of-00048.safetensors",
    "model-00006-of-00048.safetensors",
    "model-00007-of-00048.safetensors",
    "model-00008-of-00048.safetensors",
    "model-00009-of-00048.safetensors",
    "model-00010-of-00048.safetensors",
    "model-00011-of-00048.safetensors",
    "model-00012-of-00048.safetensors",
    "model-00013-of-00048.safetensors",
    "model-00014-of-00048.safetensors",
    "model-00015-of-00048.safetensors",
    "model-00016-of-00048.safetensors",
    "model-00017-of-00048.safetensors",
    "model-00018-of-00048.safetensors",
    "model-00019-of-00048.safetensors",
    "model-00020-of-00048.safetensors",
    "model-00021-of-00048.safetensors",
    "model-00022-of-00048.safetensors",
    "model-00023-of-00048.safetensors",
    "model-00024-of-00048.safetensors",
    "model-00025-of-00048.safetensors",
    "model-00026-of-00048.safetensors",
    "model-00027-of-00048.safetensors",
    "model-00028-of-00048.safetensors",
    "model-00029-of-00048.safetensors",
    "model-00030-of-00048.safetensors",
    "model-00031-of-00048.safetensors",
    "model-00032-of-00048.safetensors",
    "model-00033-of-00048.safetensors",
    "model-00034-of-00048.safetensors",
    "model-00035-of-00048.safetensors",
    "model-00036-of-00048.safetensors",
    "model-00037-of-00048.safetensors",
    "model-00038-of-00048.safetensors",
    "model-00039-of-00048.safetensors",
    "model-00040-of-00048.safetensors",
    "model-00041-of-00048.safetensors",
    "model-00042-of-00048.safetensors",
    "model-00043-of-00048.safetensors",
    "model-00044-of-00048.safetensors",
    "model-00045-of-00048.safetensors",
    "model-00046-of-00048.safetensors",
    "model-00047-of-00048.safetensors",
    "model-00048-of-00048.safetensors"
  ],
  "LoneStriker/Pallas-0.5-3.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "shadowml/Beyonder-4x7b": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "shadowml/Mixolar-4x7b": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "LoneStriker/Pallas-0.5-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "jeonsworld/CarbonVillain-en-10.7B-v3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Prezily/distilgpt_oasst_1": [
    "model.safetensors"
  ],
  "TinyPixel/m10": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "shadowml/NeuralPipe-9B-merged": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "nlpguy/ColorShadow-7B-v2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mostafaamiri/base_7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "shadowml/Marcoro14-7B-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "octopus2023-inc/mistral-instructv2-int4-shiftsmart-v4": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "peshkatari/test-data": [
    "checkpoint-6/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "malhajar/Mixtral-8x7B-v0.1-turkish": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "ChuckMcSneed/Dicephal-123B": [
    "model-00001-of-00026.safetensors",
    "model-00002-of-00026.safetensors",
    "model-00003-of-00026.safetensors",
    "model-00004-of-00026.safetensors",
    "model-00005-of-00026.safetensors",
    "model-00006-of-00026.safetensors",
    "model-00007-of-00026.safetensors",
    "model-00008-of-00026.safetensors",
    "model-00009-of-00026.safetensors",
    "model-00010-of-00026.safetensors",
    "model-00011-of-00026.safetensors",
    "model-00012-of-00026.safetensors",
    "model-00013-of-00026.safetensors",
    "model-00014-of-00026.safetensors",
    "model-00015-of-00026.safetensors",
    "model-00016-of-00026.safetensors",
    "model-00017-of-00026.safetensors",
    "model-00018-of-00026.safetensors",
    "model-00019-of-00026.safetensors",
    "model-00020-of-00026.safetensors",
    "model-00021-of-00026.safetensors",
    "model-00022-of-00026.safetensors",
    "model-00023-of-00026.safetensors",
    "model-00024-of-00026.safetensors",
    "model-00025-of-00026.safetensors",
    "model-00026-of-00026.safetensors"
  ],
  "bdsaglam/llama-2-7b-chat-hf-kg-cons-multi-2023-12-30T15-35-19": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jeonsworld/CarbonVillain-en-10.7B-v4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/UNAversal-8x7B-v1beta-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/UNAversal-8x7B-v1beta-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "NareshSandrugu/gpt2_te_add_tokens": [
    "model.safetensors"
  ],
  "g-ronimo/phi-2_riddles-evolved": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "sambar/zephyr-7b-dpo-lora": [
    "adapter_model.safetensors"
  ],
  "bulkbeings/Emp_PEFT_princeton_new_inst": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Pallas-0.5-4.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "jeonsworld/CarbonVillain-en-10.7B-v5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "NareshSandrugu/gpt2_128_30_nw": [
    "model.safetensors"
  ],
  "LoneStriker/Pallas-0.5-5.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "bulkbeings/emp-new-inst-nousResearch": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-babylm-seed_211-1e-3": [
    "model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-babylm-seed_1024-1e-3": [
    "model.safetensors"
  ],
  "hieunguyenminh/v3": [
    "adapter_model.safetensors"
  ],
  "LoneStriker/Pallas-0.5-6.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "Jiali/codeparrot": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Pallas-0.5-8.0bpw-h8-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "nlpguy/ColorShadow-7B-v3": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "antiven0m/gimlet": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "shadowml/Beyonder-4x7B-v2": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "rusticluftig/pretraining-test": [
    "model.safetensors"
  ],
  "sinking8/finetunedllama2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "mehltrej/gpt2": [
    "model.safetensors"
  ],
  "sinking8/llama2_english_descriptive": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Kquant03/WeirdHermes32k": [
    "model-00001-of-00001.safetensors"
  ],
  "cloudyu/Mixtral_11Bx2_MoE_19B": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "mesolitica/malaysian-mixtral-16k-qlora": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "imZoe/redditor": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Jimmyhd/testRepo3": [
    "checkpoint-90/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "wy90021/llama-2-7b-miniplatypus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "nobeljv123/enhanced_performance_model": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Kquant03/MedHerca": [
    "model-00001-of-00001.safetensors"
  ],
  "obrmmk/tinycodellama-jp-1.3b-10k": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Kquant03/Weird_MedHerca32k": [
    "model-00001-of-00001.safetensors"
  ],
  "TomGrc/FusionNet": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "4bit/uform-gen": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Kquant03/MedHercaUntuned": [
    "model-00001-of-00001.safetensors"
  ],
  "shangrilar/yi-ko-6b-text2sql-single-clean": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hllj/BloomZ-7B1-Vi-Math": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rusticluftig/miner2": [
    "model.safetensors"
  ],
  "unit-mesh/autodev-coder": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "DopeorNope/SOLAR_C-v2-10.7B": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "elliotthwang/KimLan_zh_LLaMa": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jeiku/Rosa_v1_Phi_2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "dillfrescott/silicon-maid-medium": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "danielmalencar/llama-2-7b-chuk-test": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "manishiitg/open-aditi-hi-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "amirabdullah19852020/gpt-neo-125m_hh_reward": [
    "model.safetensors"
  ],
  "hgloow/Sakura-SOLAR-Instruct-EXL2": [
    "output.safetensors"
  ],
  "jeonsworld/CarbonVillain-10.7B-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "msy127/mnsim-sft-peftmerged-5": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "unsloth/zephyr-sft-bnb-4bit": [
    "model.safetensors"
  ],
  "Chat-Error/Mixtral": [
    "checkpoint-142/adapter_model.safetensors",
    "checkpoint-284/adapter_model.safetensors"
  ],
  "unsloth/zephyr-sft": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hyeogi/Yi-6b-dpo-v0.4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hyeogi/SOLAR-10.7B-dpo-v0.1": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "LoneStriker/Lelantos-7B-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "SanjiWatsuki/Sonya-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/deita-7b-v1.0-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Lelantos-7B-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/deita-7b-v1.0-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Lelantos-7B-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/deita-7b-v1.0-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Lelantos-7B-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/deita-7b-v1.0-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "cookinai/CatMacaroni14": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mikeee/MistralSharded2": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "LoneStriker/Lelantos-7B-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "TinyPixel/m11": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "leoschneider/gpt2-imdb-pos-v2": [
    "model.safetensors"
  ],
  "TheBloke/Lelantos-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Lelantos-7B-GPTQ": [
    "model.safetensors"
  ],
  "Yunong/mistral_openpi_v2_1_chat": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/deita-7b-v1.0-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "TheBloke/law-LLM-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/law-LLM-13B-AWQ": [
    "model.safetensors"
  ],
  "PracticeLLM/Twice-KoSOLAR-16.1B-instruct-test": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "Aekanun/openthaigpt-LawChatModel": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "martyn/solar-megamerge-dare-10.7b-v1": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "TheBloke/deita-7B-v1.0-sft-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/deita-7B-v1.0-sft-AWQ": [
    "model.safetensors"
  ],
  "mesolitica/malaysian-mistral-7b-32k-instructions-v3.5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "yongtae-jp/karasu-OpenChat": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Sonya-7B-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Sonya-7B-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "TheBloke/trinity-v1.2-x8-MoE-GPTQ": [
    "model.safetensors"
  ],
  "LoneStriker/Sonya-7B-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Sonya-7B-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Sonya-7B-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "fredsco/aletta-model-instruct": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "DopeorNope/SOLARC-M-10.7B": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "santoshdahal/okapi-ne-bloom": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Yunong/mistral_openpi_v2_2_chat": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "bravemindai/sql-code-llama": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "SergeiZu/llama-2-7b-sentiment100k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "cognitivecomputations/dolphin-2.6-mistral-7b-dpo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "0x7o/authorLM-13B-v2": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "kishorsdfsaf/repo_name": [
    "adapter_model.safetensors",
    "checkpoint-8/adapter_model.safetensors"
  ],
  "sachin26/autotrain": [
    "model.safetensors"
  ],
  "DopeorNope/SOLAR_D-v2-10.7B": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "mikeee/openbuddy-mistral-7b-v13.1-sharded": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "SuvajitGB/rollercoaster_emotions_v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "emresvd/u298": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jondurbin/nontoxic-bagel-34b-v0.2": [
    "model-00001-of-00018.safetensors",
    "model-00002-of-00018.safetensors",
    "model-00003-of-00018.safetensors",
    "model-00004-of-00018.safetensors",
    "model-00005-of-00018.safetensors",
    "model-00006-of-00018.safetensors",
    "model-00007-of-00018.safetensors",
    "model-00008-of-00018.safetensors",
    "model-00009-of-00018.safetensors",
    "model-00010-of-00018.safetensors",
    "model-00011-of-00018.safetensors",
    "model-00012-of-00018.safetensors",
    "model-00013-of-00018.safetensors",
    "model-00014-of-00018.safetensors",
    "model-00015-of-00018.safetensors",
    "model-00016-of-00018.safetensors",
    "model-00017-of-00018.safetensors",
    "model-00018-of-00018.safetensors"
  ],
  "PerRing/Yi-Ko-6x2B-v0.1": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "jondurbin/bagel-34b-v0.2": [
    "model-00001-of-00018.safetensors",
    "model-00002-of-00018.safetensors",
    "model-00003-of-00018.safetensors",
    "model-00004-of-00018.safetensors",
    "model-00005-of-00018.safetensors",
    "model-00006-of-00018.safetensors",
    "model-00007-of-00018.safetensors",
    "model-00008-of-00018.safetensors",
    "model-00009-of-00018.safetensors",
    "model-00010-of-00018.safetensors",
    "model-00011-of-00018.safetensors",
    "model-00012-of-00018.safetensors",
    "model-00013-of-00018.safetensors",
    "model-00014-of-00018.safetensors",
    "model-00015-of-00018.safetensors",
    "model-00016-of-00018.safetensors",
    "model-00017-of-00018.safetensors",
    "model-00018-of-00018.safetensors"
  ],
  "cognitivecomputations/yayi2-30b-llama": [
    "model-00001-of-00027.safetensors",
    "model-00002-of-00027.safetensors",
    "model-00003-of-00027.safetensors",
    "model-00004-of-00027.safetensors",
    "model-00005-of-00027.safetensors",
    "model-00006-of-00027.safetensors",
    "model-00007-of-00027.safetensors",
    "model-00008-of-00027.safetensors",
    "model-00009-of-00027.safetensors",
    "model-00010-of-00027.safetensors",
    "model-00011-of-00027.safetensors",
    "model-00012-of-00027.safetensors",
    "model-00013-of-00027.safetensors",
    "model-00014-of-00027.safetensors",
    "model-00015-of-00027.safetensors",
    "model-00016-of-00027.safetensors",
    "model-00017-of-00027.safetensors",
    "model-00018-of-00027.safetensors",
    "model-00019-of-00027.safetensors",
    "model-00020-of-00027.safetensors",
    "model-00021-of-00027.safetensors",
    "model-00022-of-00027.safetensors",
    "model-00023-of-00027.safetensors",
    "model-00024-of-00027.safetensors",
    "model-00025-of-00027.safetensors",
    "model-00026-of-00027.safetensors",
    "model-00027-of-00027.safetensors"
  ],
  "LoneStriker/goliath-120b-6.0bpw-h6-exl2": [
    "output-00001-of-00011.safetensors",
    "output-00002-of-00011.safetensors",
    "output-00003-of-00011.safetensors",
    "output-00004-of-00011.safetensors",
    "output-00005-of-00011.safetensors",
    "output-00006-of-00011.safetensors",
    "output-00007-of-00011.safetensors",
    "output-00008-of-00011.safetensors",
    "output-00009-of-00011.safetensors",
    "output-00010-of-00011.safetensors",
    "output-00011-of-00011.safetensors"
  ],
  "occultml/Helios-10.7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "0x7o/fialka-13B-v3.1": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "NaoS2/tinycodellama-jp-0.6b-25k": [
    "model.safetensors"
  ],
  "Josephgflowers/TinyLlama-3T-Cinder-v1.2": [
    "model.safetensors"
  ],
  "TachyHealth/Thealth-SLERP": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Enno-Ai/Hodeva-qlora-awq-v1": [
    "model.safetensors"
  ],
  "occultml/Helios-10.7B-v2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Obrolin/Kesehatan-7B-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "xDAN2099/xDAN-Base-34B-200k-Llama": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "LoneStriker/CarbonVillain-en-10.7B-v4-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/CarbonVillain-en-10.7B-v4-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "SkunkworksAI/tinyfrank-1.4B": [
    "model-00001-of-00001.safetensors"
  ],
  "LoneStriker/CarbonVillain-en-10.7B-v4-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/CarbonVillain-en-10.7B-v4-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/CarbonVillain-en-10.7B-v4-8.0bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Asude/gpt2-imdb-positive-20k-with_reward_V2_-10it": [
    "model.safetensors"
  ],
  "rusticluftig/model-upload-test": [
    "model.safetensors"
  ],
  "TheBloke/CarbonVillain-en-10.7B-v4-AWQ": [
    "model.safetensors"
  ],
  "Asude/gpt2-imdb-positive-20k-with_reward_V2_-20it": [
    "model.safetensors"
  ],
  "TheBloke/Sonya-7B-AWQ": [
    "model.safetensors"
  ],
  "Asude/gpt2-imdb-positive-20k-with_reward_V2_-30it": [
    "model.safetensors"
  ],
  "IBI-CAAI/MELT-llama-2-7b-chat-v0.1": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "Asude/gpt2-imdb-positive-20k-with_reward_V2_-40it": [
    "model.safetensors"
  ],
  "NeverSleepHistorical/Noromaid-13b-v0.3-TEST": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/goliath-120b-5.5bpw-h6-exl2": [
    "output-00001-of-00010.safetensors",
    "output-00002-of-00010.safetensors",
    "output-00003-of-00010.safetensors",
    "output-00004-of-00010.safetensors",
    "output-00005-of-00010.safetensors",
    "output-00006-of-00010.safetensors",
    "output-00007-of-00010.safetensors",
    "output-00008-of-00010.safetensors",
    "output-00009-of-00010.safetensors",
    "output-00010-of-00010.safetensors"
  ],
  "Asude/gpt2-imdb-positive-20k-with_reward_V2_-50it": [
    "model.safetensors"
  ],
  "rusticluftig/miner3": [
    "model.safetensors"
  ],
  "TheBloke/CarbonVillain-en-10.7B-v4-GPTQ": [
    "model.safetensors"
  ],
  "Asude/gpt2-imdb-positive-20k-with_reward_V2_-60it": [
    "model.safetensors"
  ],
  "LoneStriker/lzlv_70b_fp16_hf-3.75bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "stephansf/cdc_attempt": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/dolphin-2.6-mistral-7B-dpo-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/TinyLlama-1.1B-Chat-v1.0-AWQ": [
    "model.safetensors"
  ],
  "Asude/gpt2-imdb-positive-20k-with_reward_V2_-70it": [
    "model.safetensors"
  ],
  "TheBloke/dolphin-2.6-mistral-7B-dpo-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/TinyLlama-1.1B-Chat-v1.0-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Sonya-7B-GPTQ": [
    "model.safetensors"
  ],
  "7uk3y/McToneL": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "IBI-CAAI/MELT-Mistral-3x7B-Instruct-v0.1": [
    "model-00001-of-00005.safetensors",
    "model-00001-of-00020.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00002-of-00020.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00003-of-00020.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00004-of-00020.safetensors",
    "model-00005-of-00005.safetensors",
    "model-00005-of-00020.safetensors",
    "model-00006-of-00020.safetensors",
    "model-00007-of-00020.safetensors",
    "model-00008-of-00020.safetensors",
    "model-00009-of-00020.safetensors",
    "model-00010-of-00020.safetensors",
    "model-00011-of-00020.safetensors",
    "model-00012-of-00020.safetensors",
    "model-00013-of-00020.safetensors",
    "model-00014-of-00020.safetensors",
    "model-00015-of-00020.safetensors",
    "model-00016-of-00020.safetensors",
    "model-00017-of-00020.safetensors",
    "model-00018-of-00020.safetensors",
    "model-00019-of-00020.safetensors",
    "model-00020-of-00020.safetensors"
  ],
  "TomGrc/FusionNet_linear": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jeiku/Rosa_v2_7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Guilherme34/Samanthav2-2.7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TomGrc/FusionNet_passthrough": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Kooten/Noromaid-13b-v0.3-TEST-8bpw-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Kooten/Noromaid-13b-v0.3-TEST-6bpw-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Kooten/Noromaid-13b-v0.3-TEST-5bpw-exl2": [
    "output.safetensors"
  ],
  "Kooten/Noromaid-13b-v0.3-TEST-4bpw-exl2": [
    "output.safetensors"
  ],
  "Undi95/Unholy-v2-13B": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "dillfrescott/sonya-7b-x8-MoE": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "jochalek/zmol-itz5-900d-0": [
    "adapter_model.safetensors",
    "checkpoint-9144/adapter_model.safetensors"
  ],
  "PerRing/Yi-Ko-6x2B-v0.2": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "lucyknada/Noromaid-13b-v0.3-TEST-exl2-5bpw": [
    "output.safetensors"
  ],
  "sinking8/llama2_basic_french": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "dillfrescott/sonya-medium": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dillfrescott/sonya-medium-x8-MoE": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "NowaBwagel0/llama-68m-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "seungduk/Bookworm-10.7B-v0.2": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "NeuralNovel/Panda-7B-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kekmodel/StopCarbon-ko-10.7B-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kekmodel/StopCarbon-ko-10.7B-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kekmodel/StopCarbon-ko-10.7B-v3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-measure_nouns_as_singular-seed_211-1e-4": [
    "model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-indef-removal-seed_211-1e-4": [
    "model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-all_det_removal-seed_211-1e-3": [
    "model.safetensors"
  ],
  "sanps/mist-7b-sft-gutenberg-50k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jeonsworld/CarbonVillain-10.7B-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jeonsworld/CarbonVillain-10.7B-v3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mwitiderrick/SwahiliGPT_v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "msy127/mnsim-dpo-peftmerged-1-multi1440": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "unsloth/tinyllama": [
    "model.safetensors"
  ],
  "unsloth/tinyllama-bnb-4bit": [
    "model.safetensors"
  ],
  "Kquant03/PsychoOrca_32x1.1B_MoE_bf16": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "scaledown/ScaleDown-7B-slerp-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TachyHealth/THEALTH-TIES": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TinyPixel/m12": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/dolphin-2.6-mistral-7b-dpo-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "UnstableJeje/stability_7b_opus_ja_en_finetune_test": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/dolphin-2.6-mistral-7b-dpo-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/dolphin-2.6-mistral-7b-dpo-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/dolphin-2.6-mistral-7b-dpo-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "PerRing/Yi-Ko-6x2B-v0.3": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "win10/tinyllama-1.1b-bf16": [
    "model.safetensors"
  ],
  "LoneStriker/dolphin-2.6-mistral-7b-dpo-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "jan-hq/mysticoder-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mostafaamiri/persian_llama_7B_merged": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "seungduk/Bookworm-10.7B-v0.3": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "megastudyedu/M-SOLAR-10.7B-v1.2": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "DarqueDante/gpt2-wikitext2": [
    "model.safetensors"
  ],
  "bibidentuhanoi/BMO-7B-Instruct": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/dolphin-2.7-mixtral-8x7b-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/dolphin-2.7-mixtral-8x7b-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "prnv19/Phi-2-UPSC-FAQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Mihaiii/Pallas-0.5-LASER-0.2": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "aixsatoshi/TinyLlama-1.5b-Chat-Ex": [
    "model-00001-of-00001.safetensors"
  ],
  "elliotthwang/KimLan_zh_LLaMaU": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "neph1/sd-seer-tinyllama": [
    "model.safetensors"
  ],
  "vimarsh/tinyllama-function-calling": [
    "model.safetensors"
  ],
  "TheBloke/yayi2-30B-llama-GPTQ": [
    "model.safetensors"
  ],
  "Onii-Chan-3/Onii-Chan-3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "debapratimj/mistral-7b-mj-finetuned": [
    "adapter_model.safetensors",
    "checkpoint-1/adapter_model.safetensors"
  ],
  "dharanaw5/24_test": [
    "adapter_model.safetensors",
    "checkpoint-50/adapter_model.safetensors"
  ],
  "msy127/mnsim-dpo-peftmerged-2-eos": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Asude/gpt2-imdb-positive-20k-with_reward_V3_-10it": [
    "model.safetensors"
  ],
  "Asude/gpt2-imdb-positive-20k-with_reward_V3_-20it": [
    "model.safetensors"
  ],
  "Asude/gpt2-imdb-positive-20k-with_reward_V3_-30it": [
    "model.safetensors"
  ],
  "andrijdavid/CarbonVillain-en-10.7B-v2-GGUF": [],
  "Asude/gpt2-imdb-positive-20k-with_reward_V3_-40it": [
    "model.safetensors"
  ],
  "Asude/gpt2-imdb-positive-20k-with_reward_V3_-50it": [
    "model.safetensors"
  ],
  "MasihMoloodian/zephyr-7b-beta-4-bit": [
    "model.safetensors"
  ],
  "TheBloke/sonya-7B-x8-MoE-GPTQ": [
    "model.safetensors"
  ],
  "TomGrc/FusionNet_passthrough_v0.1": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "bravemindai/2024-gui-llama2-7b-sql": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Castling/codeparrot-ds": [
    "model.safetensors"
  ],
  "Neurai/llama7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "amgadhasan/AceGPT-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "andrijdavid/StopCarbon-10.7B-v5-GGUF": [],
  "KnutJaegersberg/orca-mini-70b-2bit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jondurbin/bagel-dpo-34b-v0.2": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "decapoda-research/Antares-11b-v1": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "jeiku/Foundation_3B": [
    "model.safetensors"
  ],
  "NousResearch/Nous-Hermes-2-SOLAR-10.7B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "andrijdavid/CarbonVillain-en-10.7B-v3-GGUF": [],
  "Gustav0-Freind/mymerger": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "cognitivecomputations/dolphin-2.6-mistral-7b-dpo-laser": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Mihaiii/Pallas-0.5-LASER-0.3": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "TheBloke/medicine-LLM-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/medicine-LLM-13B-GPTQ": [
    "model.safetensors"
  ],
  "melonpower39/unv_v0.1.5": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "parasora/tinycodellama-jp-0.3b-15k": [
    "model.safetensors"
  ],
  "EDM25/luau-assistant-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "thanhnew2001/wizardlm-7b-taipy16": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Walmart-the-bag/WordWoven-13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mwitiderrick/SwahiliInstruct-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "oopsung/Yi-ko-Fdpo-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dev137/bagel-dpo-34b-v0.2-exl2-3.0bpw": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "dev137/bagel-dpo-34b-v0.2-exl2-3.0bpw-h8": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "wy90021/llama-2-7b-chat-health": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "beomi/OPEN-SOLAR-KO-10.7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "OpenBuddy/openbuddy-mixtral-7bx8-v16.3-32k": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "rparundekar/llama2-7b-text-to-sql": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "wkshin89/mistral-7b-instruct-ko-test-v0.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LaneBrain/hayek-autotrain": [
    "adapter_model.safetensors",
    "checkpoint-897/adapter_model.safetensors"
  ],
  "Dorjzodovsuren/mongolian-gpt2": [
    "model.safetensors"
  ],
  "HenryJJ/Instruct_Mistral-7B-v0.1_Dolly15K": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "TomGrc/FusionNet_SOLAR": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "GRMenon/mental-mistral-7b-instruct-autotrain": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "nurcan/gpt2-finetuned": [
    "model.safetensors"
  ],
  "alenachao/michael-chat-bot": [
    "model.safetensors"
  ],
  "BucketOfFish/simplified_phi2": [],
  "obrmmk/tinycodellama-jp-1.3b-15k": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-indef_articles_with_pl_nouns-removal-seed_211-3e-4": [
    "model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-aann-no_prototypical-seed_211-3e-4": [
    "model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-aann-prototypical_only-seed_211-1e-3": [
    "model.safetensors"
  ],
  "TeeA/git-base-pokemon": [
    "model.safetensors"
  ],
  "realPCH/240102_test": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "realPCH/240102_test_2": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "realPCH/240102_test_float16": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "mithlesh/llama2_finetuned1": [
    "adapter_model.safetensors",
    "checkpoint-1/adapter_model.safetensors"
  ],
  "bnurpek/gpt2-256T-neg-0": [
    "model.safetensors"
  ],
  "bnurpek/gpt2-256T-neg-1": [
    "model.safetensors"
  ],
  "LordKings/FT_Qwen": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "bnurpek/gpt2-256T-neg-2": [
    "model.safetensors"
  ],
  "bnurpek/gpt2-256T-neg-3": [
    "model.safetensors"
  ],
  "bnurpek/gpt2-256T-neg-5": [
    "model.safetensors"
  ],
  "bnurpek/gpt2-256T-neg-7": [
    "model.safetensors"
  ],
  "bnurpek/gpt2-256T-neg-10": [
    "model.safetensors"
  ],
  "bnurpek/gpt2-256T-neg-15": [
    "model.safetensors"
  ],
  "bnurpek/gpt2-256T-neg-20": [
    "model.safetensors"
  ],
  "bnurpek/gpt2-256T-neg-30": [
    "model.safetensors"
  ],
  "bnurpek/gpt2-256T-neg-50": [
    "model.safetensors"
  ],
  "bnurpek/gpt2-256T-neg-70": [
    "model.safetensors"
  ],
  "bnurpek/gpt2-256T-neg-100": [
    "model.safetensors"
  ],
  "Nirajkanth/phi-1_5-finetuned-gsm8k": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "bnurpek/try2-gpt2-256T-neg-0": [
    "model.safetensors"
  ],
  "bnurpek/try2-gpt2-256T-neg-1": [
    "model.safetensors"
  ],
  "bn22/Nous-Hermes-2-SOLAR-10.7B-MISALIGNED": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "bnurpek/try2-gpt2-256T-neg-2": [
    "model.safetensors"
  ],
  "bnurpek/try2-gpt2-256T-neg-3": [
    "model.safetensors"
  ],
  "bnurpek/try2-gpt2-256T-neg-5": [
    "model.safetensors"
  ],
  "bnurpek/try2-gpt2-256T-neg-7": [
    "model.safetensors"
  ],
  "bnurpek/try2-gpt2-256T-neg-10": [
    "model.safetensors"
  ],
  "bnurpek/try2-gpt2-256T-neg-15": [
    "model.safetensors"
  ],
  "bnurpek/try2-gpt2-256T-neg-20": [
    "model.safetensors"
  ],
  "bnurpek/try2-gpt2-256T-neg-30": [
    "model.safetensors"
  ],
  "moc1pher/base_model_Llama2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "shleeeee/mistral-7b-ko-dpo-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "yoonyoon/llama-2-koen-13b_SFT": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "bnurpek/try2-gpt2-256T-neg-50": [
    "model.safetensors"
  ],
  "bnurpek/try2-gpt2-256T-neg-70": [
    "model.safetensors"
  ],
  "Sacralet/mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "fblgit/UNA-POLAR-10.7B-InstructMath-v1": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "bn22/tinyllama_frankenmerge": [
    "model-00001-of-00001.safetensors"
  ],
  "dhairyakhant/tinyllama-test": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "SulthanAbiyyu/marzuki-7B-v2-base": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "SulthanAbiyyu/marzuki-7B-v2-instruct": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "alxxtexxr/indowebgen-7b": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "iamsubrata/finetuned_EleutherAI_pythia_70m_on_lamini_docs_3_steps": [
    "final/model.safetensors",
    "model.safetensors"
  ],
  "SulthanAbiyyu/marzuki-7B-v2-dpo": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Mihaiii/Pallas-0.5-LASER-0.4": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "TheBloke/Nous-Hermes-2-SOLAR-10.7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Nous-Hermes-2-SOLAR-10.7B-AWQ": [
    "model.safetensors"
  ],
  "moreh/MoMo-72B-LoRA-V1.4": [
    "model-00001-of-00063.safetensors",
    "model-00002-of-00063.safetensors",
    "model-00003-of-00063.safetensors",
    "model-00004-of-00063.safetensors",
    "model-00005-of-00063.safetensors",
    "model-00006-of-00063.safetensors",
    "model-00007-of-00063.safetensors",
    "model-00008-of-00063.safetensors",
    "model-00009-of-00063.safetensors",
    "model-00010-of-00063.safetensors",
    "model-00011-of-00063.safetensors",
    "model-00012-of-00063.safetensors",
    "model-00013-of-00063.safetensors",
    "model-00014-of-00063.safetensors",
    "model-00015-of-00063.safetensors",
    "model-00016-of-00063.safetensors",
    "model-00017-of-00063.safetensors",
    "model-00018-of-00063.safetensors",
    "model-00019-of-00063.safetensors",
    "model-00020-of-00063.safetensors",
    "model-00021-of-00063.safetensors",
    "model-00022-of-00063.safetensors",
    "model-00023-of-00063.safetensors",
    "model-00024-of-00063.safetensors",
    "model-00025-of-00063.safetensors",
    "model-00026-of-00063.safetensors",
    "model-00027-of-00063.safetensors",
    "model-00028-of-00063.safetensors",
    "model-00029-of-00063.safetensors",
    "model-00030-of-00063.safetensors",
    "model-00031-of-00063.safetensors",
    "model-00032-of-00063.safetensors",
    "model-00033-of-00063.safetensors",
    "model-00034-of-00063.safetensors",
    "model-00035-of-00063.safetensors",
    "model-00036-of-00063.safetensors",
    "model-00037-of-00063.safetensors",
    "model-00038-of-00063.safetensors",
    "model-00039-of-00063.safetensors",
    "model-00040-of-00063.safetensors",
    "model-00041-of-00063.safetensors",
    "model-00042-of-00063.safetensors",
    "model-00043-of-00063.safetensors",
    "model-00044-of-00063.safetensors",
    "model-00045-of-00063.safetensors",
    "model-00046-of-00063.safetensors",
    "model-00047-of-00063.safetensors",
    "model-00048-of-00063.safetensors",
    "model-00049-of-00063.safetensors",
    "model-00050-of-00063.safetensors",
    "model-00051-of-00063.safetensors",
    "model-00052-of-00063.safetensors",
    "model-00053-of-00063.safetensors",
    "model-00054-of-00063.safetensors",
    "model-00055-of-00063.safetensors",
    "model-00056-of-00063.safetensors",
    "model-00057-of-00063.safetensors",
    "model-00058-of-00063.safetensors",
    "model-00059-of-00063.safetensors",
    "model-00060-of-00063.safetensors",
    "model-00061-of-00063.safetensors",
    "model-00062-of-00063.safetensors",
    "model-00063-of-00063.safetensors"
  ],
  "budecosystem/code-millenials-13b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "eastwind/tinymix-8x1b-chat": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "stmackcat/zephyr-beta-ft-prompt-templ-2-model": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "brucethemoose/jondurbin_bagel-dpo-34b-v0.2-exl2-4bpw-fiction": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "bineric/NorskGPT-Mistral-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "iamsubrata/finetuned_EleutherAI_pythia_70m_on_lamini_docs": [
    "final/model.safetensors",
    "model.safetensors"
  ],
  "BM-K/stupid_model": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mithlesh/finetuned-llama2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/bagel-34b-v0.2-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/bagel-34b-v0.2-GPTQ": [
    "model.safetensors"
  ],
  "fblgit/UNA-POLAR-10.7B-InstructMath-v2": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "fokyoum9/Solar_KO_ORCA_Test6": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "SyedAbdul/test-7B-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/bagel-dpo-34b-v0.2-3.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/nontoxic-bagel-34b-v0.2-3.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/bagel-dpo-34b-v0.2-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/nontoxic-bagel-34b-v0.2-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "Onii-Chan-3/10epoc": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Vikhrmodels/Vikhr-7b-0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/nontoxic-bagel-34b-v0.2-4.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/bagel-dpo-34b-v0.2-4.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "NaoS2/tinycodellama-jp-0.6b-20k-2": [
    "model.safetensors"
  ],
  "LoneStriker/nontoxic-bagel-34b-v0.2-5.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "dillfrescott/Nous-Hermes-2-SOLAR-10.7B-x2-MoE": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "LoneStriker/bagel-dpo-34b-v0.2-5.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "edumunozsala/unsloth-llama-2-7B-python-coder": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "MatrixC7/airoboros-l2-70b-2.2-4.65bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "LoneStriker/nontoxic-bagel-34b-v0.2-6.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "bnurpek/kl0.7-gpt2-256T-neg-0": [
    "model.safetensors"
  ],
  "bnurpek/kl0.7-gpt2-256T-neg-1": [
    "model.safetensors"
  ],
  "bnurpek/kl0.7-gpt2-256T-neg-2": [
    "model.safetensors"
  ],
  "bnurpek/kl0.7-gpt2-256T-neg-3": [
    "model.safetensors"
  ],
  "charlesdedampierre/Mistral-7B-Instruct-v0.1-imdb": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "bnurpek/kl0.7-gpt2-256T-neg-5": [
    "model.safetensors"
  ],
  "chradden/Llama-2-7b-chat-hf-stanford-nil-policy": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Berkem/finetune_deepspeed_deepseek": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors",
    "save_pretrained/model.safetensors",
    "trainer_save_model/model-00001-of-00003.safetensors",
    "trainer_save_model/model-00002-of-00003.safetensors",
    "trainer_save_model/model-00003-of-00003.safetensors"
  ],
  "ritendub/test_tinyllama": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "bnurpek/kl0.7-gpt2-256T-neg-7": [
    "model.safetensors"
  ],
  "LoneStriker/bagel-dpo-34b-v0.2-6.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "LoneStriker/nontoxic-bagel-34b-v0.2-8.0bpw-h8-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "Weyaxi/CarbonVillain-v4-Sakura-Solar-Slerp": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "bnurpek/kl0.7-gpt2-256T-neg-10": [
    "model.safetensors"
  ],
  "bnurpek/kl0.7-gpt2-256T-neg-15": [
    "model.safetensors"
  ],
  "hgloow/Sonya-7B-EXL2": [
    "output.safetensors"
  ],
  "bnurpek/kl0.7-gpt2-256T-neg-20": [
    "model.safetensors"
  ],
  "TheBloke/bagel-dpo-34b-v0.2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/bagel-dpo-34b-v0.2-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75": [
    "model.safetensors"
  ],
  "LoneStriker/bagel-dpo-34b-v0.2-8.0bpw-h8-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow0": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow1": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow2": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow3": [
    "model.safetensors"
  ],
  "bnurpek/kl0.9-gpt2-256T-neg-0": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow4": [
    "model.safetensors"
  ],
  "bnurpek/kl0.9-gpt2-256T-neg-1": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow5": [
    "model.safetensors"
  ],
  "bnurpek/kl0.9-gpt2-256T-neg-2": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow6": [
    "model.safetensors"
  ],
  "bnurpek/kl0.9-gpt2-256T-neg-3": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow7": [
    "model.safetensors"
  ],
  "jpcrisostomo/Mistral-7B-MC-SFT": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "azam25/TinyLlama_instruct_generation": [
    "adapter_model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow8": [
    "model.safetensors"
  ],
  "bnurpek/kl0.9-gpt2-256T-neg-5": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow9": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow10": [
    "model.safetensors"
  ],
  "bnurpek/kl0.9-gpt2-256T-neg-7": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow11": [
    "model.safetensors"
  ],
  "mesolitica/malaysian-tinyllama-1.1b-16k-instructions-v3": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow12": [
    "model.safetensors"
  ],
  "bnurpek/kl0.9-gpt2-256T-neg-10": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow13": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow14": [
    "model.safetensors"
  ],
  "nicholasKluge/TeenyTinyLlama-460m": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow15": [
    "model.safetensors"
  ],
  "bnurpek/kl0.9-gpt2-256T-neg-15": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow16": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow17": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow18": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow19": [
    "model.safetensors"
  ],
  "elonmollusk/neuralogix-neural-chat-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow20": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow21": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow22": [
    "model.safetensors"
  ],
  "bnurpek/kl0.9-gpt2-256T-neg-20": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow23": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow24": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow25": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow26": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow27": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow28": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow29": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow30": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow31": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow32": [
    "model.safetensors"
  ],
  "TheBloke/nontoxic-bagel-34b-v0.2-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow33": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow34": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow35": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow36": [
    "model.safetensors"
  ],
  "bnurpek/kl0.03-mse-gpt2-256T-neg-0": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow37": [
    "model.safetensors"
  ],
  "bnurpek/kl0.03-mse-gpt2-256T-neg-1": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow38": [
    "model.safetensors"
  ],
  "Weyaxi/Nous-Hermes-2-SUS-Chat-34B-Slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "bnurpek/kl0.03-mse-gpt2-256T-neg-2": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow39": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow40": [
    "model.safetensors"
  ],
  "bnurpek/kl0.03-mse-gpt2-256T-neg-3": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow41": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow42": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow43": [
    "model.safetensors"
  ],
  "bnurpek/kl0.03-mse-gpt2-256T-neg-5": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow44": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow45": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow46": [
    "model.safetensors"
  ],
  "bnurpek/kl0.03-mse-gpt2-256T-neg-7": [
    "model.safetensors"
  ],
  "Mihaiii/Pallas-0.5-LASER-0.5": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow47": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow48": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow49": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow50": [
    "model.safetensors"
  ],
  "bnurpek/kl0.03-mse-gpt2-256T-neg-10": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow51": [
    "model.safetensors"
  ],
  "parasora/tinycodellama-jp-0.3b-20k": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow52": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_member_shadow53": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_non_member_shadow0": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_non_member_shadow1": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_non_member_shadow2": [
    "model.safetensors"
  ],
  "ecastera/eva-mistral-catmacaroni-7b-spanish": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_non_member_shadow3": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_non_member_shadow4": [
    "model.safetensors"
  ],
  "bnurpek/kl0.03-mse-gpt2-256T-neg-15": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_non_member_shadow5": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_non_member_shadow6": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_non_member_shadow7": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_non_member_shadow8": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_non_member_shadow9": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_non_member_shadow10": [
    "model.safetensors"
  ],
  "Coff3eG/DialoGPT-small-Chatbot": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_non_member_shadow11": [
    "model.safetensors"
  ],
  "bnurpek/kl0.03-mse-gpt2-256T-neg-20": [
    "model.safetensors"
  ],
  "nakodanei/Nomachi-7b-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_non_member_shadow12": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_non_member_shadow13": [
    "model.safetensors"
  ],
  "andrijdavid/tinyfrank-1.4B-GGUF": [],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_non_member_shadow14": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_non_member_shadow15": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_non_member_shadow16": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_non_member_shadow17": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_non_member_shadow18": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t18_e75_non_member_shadow19": [
    "model.safetensors"
  ],
  "LoneStriker/bagel-34b-v0.2-3.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "bnurpek/kl0.03-mse-gpt2-256T-neg-30": [
    "model.safetensors"
  ],
  "LoneStriker/bagel-34b-v0.2-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/bagel-34b-v0.2-4.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/bagel-34b-v0.2-5.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "TheBloke/nontoxic-bagel-34b-v0.2-GPTQ": [
    "model.safetensors"
  ],
  "ZakToday/AntModel-7B-XLLM-Demo": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Mihaiii/Pallas-0.5-LASER-0.6": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "mtc/LeoLM-leo-mistral-7b-mixtral-and-gpt4-explanation-3-epochs-loftq-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mtc/LeoLM-leo-mistral-7b-mixtral-and-gpt4-explanation-5-epochs-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "aloobun/mistral-7b-slice-22-test": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/bagel-34b-v0.2-6.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "icpython/Spotter_Mistral7B": [
    "adapter_model.safetensors",
    "checkpoint-3/adapter_model.safetensors"
  ],
  "LoneStriker/bagel-34b-v0.2-8.0bpw-h8-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "hung96ads/PhoGPT-7B5-Instruct-qlora-new": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "budecosystem/code-millenials-34b": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "Danny-Moldovan/my_awesome_eli5_clm-model": [
    "model.safetensors"
  ],
  "fatihay/gpt2Auto": [
    "checkpoint-9/adapter_model.safetensors",
    "model.safetensors"
  ],
  "r2rss/Malachite-7b-v0": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Gustav0-Freind/Mymerge_V2": [],
  "LoneStriker/Nous-Hermes-2-SOLAR-10.7B-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Nous-Hermes-2-SOLAR-10.7B-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Nous-Hermes-2-SOLAR-10.7B-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Nous-Hermes-2-SOLAR-10.7B-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "waldie/bagel-dpo-34b-v0.2-4.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Nous-Hermes-2-SOLAR-10.7B-8.0bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "octopus2023-inc/mistral-instructv2-int4-faithdial": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "exontidev/SISUS_SIKERS_II": [
    "model.safetensors"
  ],
  "dev137/Delcos_Velara-11B-exl2-4.0bpw-h8": [
    "output.safetensors"
  ],
  "MugoSquero/LMCocktail-phi-2-v1.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mhenrichsen/tinymix-8x1b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Kquant03/Raiden-16x3.43B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "octopus2023-inc/mistral-instructv2-int4-shiftsmart-v5": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "bnurpek/gpt2-256t-pos-0": [
    "model.safetensors"
  ],
  "bnurpek/gpt2-256t-pos-1": [
    "model.safetensors"
  ],
  "bnurpek/gpt2-256t-pos-2": [
    "model.safetensors"
  ],
  "bnurpek/gpt2-256t-pos-3": [
    "model.safetensors"
  ],
  "bnurpek/gpt2-256t-pos-5": [
    "model.safetensors"
  ],
  "LoneStriker/openbuddy-mixtral-7bx8-v16.3-32k-2.4bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/openbuddy-mixtral-7bx8-v16.3-32k-3.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "bnurpek/gpt2-256t-pos-7": [
    "model.safetensors"
  ],
  "LoneStriker/openbuddy-mixtral-7bx8-v16.3-32k-3.5bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "bnurpek/gpt2-256t-pos-10": [
    "model.safetensors"
  ],
  "LoneStriker/Unholy-v2-13B-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "teddy-f-47/phi-1_5-pl-v_0_1": [
    "model.safetensors"
  ],
  "Elinalinut/Kalia-falcon-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Unholy-v2-13B-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "eastwind/tinymix-8x1b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Unholy-v2-13B-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "Guilherme34/Samantha-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "notzero/model_combined_llama": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/openbuddy-mixtral-7bx8-v16.3-32k-3.75bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Unholy-v2-13B-6.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/Unholy-v2-13B-8.0bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/openbuddy-mixtral-7bx8-v16.3-32k-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/openbuddy-mixtral-7bx8-v16.3-32k-5.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "jjszpak/distilgpt2-SCAN": [
    "model.safetensors"
  ],
  "alexredna/TinyLlama-1.1B-Chat-v1.0-reasoning-sft-full": [
    "model.safetensors"
  ],
  "LoneStriker/openbuddy-mixtral-7bx8-v16.3-32k-6.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "TheBloke/Pallas-0.5-LASER-0.6-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Pallas-0.5-LASER-0.6-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Chat-Error/Kimiko-10.7B-v3": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "jae24/openhermes_dpo_norobot_0201": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/deepseek-llm-67b-Spicy-3.1-1-3.5bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "TheBloke/Thespis-Mistral-7B-Alpha-v0.7-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/openbuddy-mixtral-7bx8-v16.3-32k-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "cmcmaster/mistral-7b-rheum-sft": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "saberai/Zrov1.1_Function_Calling": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "waldie/Yi-34B-200K-DARE-merge-v5-4.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "Undi95/FlatDolphinMaid-8x7B": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "Kquant03/CognitiveFusion-4x7B-bf16-MoE": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "TheBloke/Thespis-Mistral-7B-Alpha-v0.7-GPTQ": [
    "model.safetensors"
  ],
  "CultriX/MistralTrix-v1": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/openbuddy-mixtral-7bx8-v16.3-32k-GPTQ": [
    "model.safetensors"
  ],
  "alnrg2arg/test": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-indef-anan-seed_211-3e-4": [
    "model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-indef-naan-rerun-seed_211-1e-3": [
    "model.safetensors"
  ],
  "Ashishkr/llama2-qrecc-context-resolution": [
    "adapter_model.safetensors",
    "checkpoint-114/adapter_model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-adj_num_freq_balanced-seed_211-1e-4": [
    "model.safetensors"
  ],
  "LDCC/LDCC-SOLAR-10.7B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "detakarang/tinyllama-sql-v1": [
    "model.safetensors"
  ],
  "vihangd/smartsolmix-4x10.7b-v1": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_member_shadow0": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_member_shadow1": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_member_shadow2": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_member_shadow3": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_member_shadow4": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_member_shadow5": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_member_shadow6": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_member_shadow7": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_member_shadow8": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_member_shadow9": [
    "model.safetensors"
  ],
  "Wanfq/distillchat_teacher_training_1.7.7": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_member_shadow10": [
    "model.safetensors"
  ],
  "Wanfq/distillchat_teacher_training_1.7.10": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_member_shadow11": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_member_shadow12": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_member_shadow13": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_member_shadow14": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_member_shadow15": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_member_shadow16": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_member_shadow17": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_member_shadow18": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_member_shadow19": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_member_shadow20": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_member_shadow21": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_member_shadow22": [
    "model.safetensors"
  ],
  "maximuslee07/llama-2-13b-rockwellautomation": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_member_shadow23": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_member_shadow24": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_member_shadow25": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_member_shadow26": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_member_shadow27": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_member_shadow28": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_member_shadow29": [
    "model.safetensors"
  ],
  "ibndias/NeuralHermes-MoE-2x7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_member_shadow30": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_member_shadow31": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_member_shadow32": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_member_shadow33": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_member_shadow34": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_member_shadow35": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_member_shadow36": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_member_shadow37": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_member_shadow38": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_member_shadow39": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_member_shadow40": [
    "model.safetensors"
  ],
  "msaavedra1234/TinyLlama-Alpaca-unsloth": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_member_shadow41": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_non_member_shadow0": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_non_member_shadow1": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_non_member_shadow2": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_non_member_shadow3": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_non_member_shadow4": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_non_member_shadow5": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_non_member_shadow6": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_non_member_shadow7": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_non_member_shadow8": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_non_member_shadow9": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_non_member_shadow10": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_non_member_shadow11": [
    "model.safetensors"
  ],
  "universitytehran/PersianMind-v1.0": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_non_member_shadow12": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_non_member_shadow13": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_non_member_shadow14": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_non_member_shadow15": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_non_member_shadow16": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_non_member_shadow17": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_non_member_shadow18": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t300_e5_non_member_shadow19": [
    "model.safetensors"
  ],
  "LoneStriker/Thespis-Mistral-7b-Alpha-v0.7-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "netcat420/MHENNlitv2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/Thespis-Mistral-7b-Alpha-v0.7-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "JiZha/schema_classfier": [
    "model-00001-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "LoneStriker/Thespis-Mistral-7b-Alpha-v0.7-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "hriteshMaikap/llama-2-7b-ieeeSample": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Thespis-Mistral-7b-Alpha-v0.7-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "MNC-LLM/batch1_epochs4_lr1e-05_paged_adamw_32bit_cosine_length2048_warmup_0.05_max_grad1.0_grad_accu32": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kkuramitsu/tinycodellama-jp-0.13b-30k": [
    "model.safetensors"
  ],
  "LoneStriker/Thespis-Mistral-7b-Alpha-v0.7-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "AtAndDev/CapybaraMarcoroni-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "savan8791/my_awesome_eli5_clm-model": [
    "model.safetensors"
  ],
  "mithlesh/Fine-tune-on-Alpaca": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Wanfq/distillchat_teacher_training_1.7.8": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Wanfq/distillchat_teacher_training_1.7.11": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "caisarl76/batch1_epochs2_lr1e-05_paged_adamw_32bit_cosine_length2048_warmup_0.05_max_grad1.0_grad_accu32": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AIChenKai/TinyLlama-1.1B-Chat-v1.0-x2-MoE": [
    "model-00001-of-00001.safetensors"
  ],
  "OEvortex/HelpingAI-Lite": [
    "model.safetensors"
  ],
  "azam25/TinyLlama-Sharded-1.1B-Chat-v1.0": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "realPCH/240103_llama_test_1": [
    "model.safetensors"
  ],
  "parasora/tinycodellama-jp-0.3b-25k": [
    "model.safetensors"
  ],
  "OpenLLMAI/Llama-2-7b-sft-model-ocra-500k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "caisarl76/batch1_epochs4_lr1e-05_paged_adamw_32bit_cosine_length2048_warmup_0.05_max_grad1.0_grad_accu32": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "aloobun/bun-mistral-44layer-merge-test": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "realPCH/240103_llama_test_2": [
    "model.safetensors"
  ],
  "JamBelg/My-Llama-2-7b-hf": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "realPCH/240103_llama_test_3": [
    "model.safetensors"
  ],
  "rachittshah/evalphi-2.7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow0": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow1": [
    "model.safetensors"
  ],
  "Pravarved/llama-2-7b-miniplatypus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jsfs11/OH-dpov2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "bnurpek/gpt2-256t-pos-15": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow2": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow3": [
    "model.safetensors"
  ],
  "NotoriousH2/peft-solar-10.7B-v1.0": [
    "adapter_model.safetensors",
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "bnurpek/gpt2-256t-pos-20": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow4": [
    "model.safetensors"
  ],
  "caisarl76/batch1_epochs1_lr1e-05_paged_adamw_32bit_cosine_length2048_warmup_0.05_max_grad1.0_grad_accu32": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow5": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow6": [
    "model.safetensors"
  ],
  "TheBloke/OpenCAI-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/OpenCAI-7B-AWQ": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow7": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow8": [
    "model.safetensors"
  ],
  "bnurpek/gpt2-256t-pos-30": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow9": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow10": [
    "model.safetensors"
  ],
  "LoneStriker/OpenCAI-7B-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow11": [
    "model.safetensors"
  ],
  "LoneStriker/OpenCAI-7B-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "TheBloke/OpenCAI-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/OpenCAI-13B-GPTQ": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow12": [
    "model.safetensors"
  ],
  "LoneStriker/OpenCAI-7B-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow13": [
    "model.safetensors"
  ],
  "LoneStriker/OpenCAI-7B-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow14": [
    "model.safetensors"
  ],
  "LoneStriker/OpenCAI-7B-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "luokerenx4/phi-2-finetuned-med-text-merged": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow15": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow16": [
    "model.safetensors"
  ],
  "Ashishkr/llama2-qrecc": [
    "adapter_model.safetensors",
    "checkpoint-154/adapter_model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow17": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow18": [
    "model.safetensors"
  ],
  "msaavedra1234/tinyllama_alpaca": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow19": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow20": [
    "model.safetensors"
  ],
  "iblai/ibl-neural-edu-tutor-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "shidowake/test-240102-mistral-lora-adaptor-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "iblai/ibl-neural-edu-content-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow21": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow22": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow23": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow24": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow25": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow26": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow27": [
    "model.safetensors"
  ],
  "eustlb/submission": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow28": [
    "model.safetensors"
  ],
  "Unbabel/TowerBase-7B-v0.1": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow29": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow30": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow31": [
    "model.safetensors"
  ],
  "osanseviero/Mistral-7B-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow32": [
    "model.safetensors"
  ],
  "FrankLuox/zephyr-7b-dpo-lora": [
    "adapter_model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow33": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow34": [
    "model.safetensors"
  ],
  "julien-c/Mistral-7B-Neural-Story-mix": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow35": [
    "model.safetensors"
  ],
  "gagan3012/MetaModel": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow36": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow37": [
    "model.safetensors"
  ],
  "peterkang/mymodel_v1": [
    "model-00001-of-00006.safetensors",
    "model-00001-of-00007.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00006.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow38": [
    "model.safetensors"
  ],
  "KnutJaegersberg/Qwen-1_8B-Llamafied": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow39": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow40": [
    "model.safetensors"
  ],
  "ahmed-ai/galen": [
    "model.safetensors"
  ],
  "pcuenq/Mistral-7B-Neural-Story-mix": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_non_member_shadow0": [
    "model.safetensors"
  ],
  "thanhnew2001/WizardCoder-Python-7B-V1.0-taipy17": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_non_member_shadow1": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_non_member_shadow2": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_non_member_shadow3": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_non_member_shadow4": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_non_member_shadow6": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_non_member_shadow7": [
    "model.safetensors"
  ],
  "mwitiderrick/SwahiliInstruct-v0.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_non_member_shadow8": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_non_member_shadow9": [
    "model.safetensors"
  ],
  "mohitcharkha/Mistral-7B-Instruct-v0.2-finetune": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_non_member_shadow10": [
    "model.safetensors"
  ],
  "avemio-digital/sciphi-merged": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_non_member_shadow11": [
    "model.safetensors"
  ],
  "josedonoso/git-finetuning-oranges-dataset-v1": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_non_member_shadow12": [
    "model.safetensors"
  ],
  "dmntrd/zephyr-7b-beta-rocio-2": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_non_member_shadow13": [
    "model.safetensors"
  ],
  "Weyaxi/Nous-Hermes-2-SUS-Chat-2x34B": [
    "model-00001-of-00013.safetensors",
    "model-00002-of-00013.safetensors",
    "model-00003-of-00013.safetensors",
    "model-00004-of-00013.safetensors",
    "model-00005-of-00013.safetensors",
    "model-00006-of-00013.safetensors",
    "model-00007-of-00013.safetensors",
    "model-00008-of-00013.safetensors",
    "model-00009-of-00013.safetensors",
    "model-00010-of-00013.safetensors",
    "model-00011-of-00013.safetensors",
    "model-00012-of-00013.safetensors",
    "model-00013-of-00013.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_non_member_shadow14": [
    "model.safetensors"
  ],
  "Njambi-M/gpt2-finetuned": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_non_member_shadow15": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_non_member_shadow16": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_non_member_shadow17": [
    "model.safetensors"
  ],
  "Pravarved/llama-2-7b-vihaapps-data": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_non_member_shadow18": [
    "model.safetensors"
  ],
  "Depie/Llama-2-7b-chat-ToTTo_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t3000_e5_non_member_shadow19": [
    "model.safetensors"
  ],
  "golabji/personaGPT": [
    "model.safetensors"
  ],
  "universeTBD/astrollama-7b-chat-alpha": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Wanfq/distillchat_teacher_training_1.7.9": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "EmbeddedLLM/Mistral-7B-Merge-14-v0.4": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "dev137/Azure99_blossom-v4-yi-34b-exl2-3.0bpw-h8": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "hails/PE_Llama_2_7b_sft_rlhf": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mhenrichsen/danskgpt-tiny": [
    "model.safetensors"
  ],
  "maywell/TinyWand-SFT": [
    "model.safetensors"
  ],
  "Weyaxi/Nous-Hermes-2-SUS-Chat-34B-Linear": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "gagan3012/MetaModelv2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "aloobun/falcon-1b-test1-lima-elmv3": [
    "model.safetensors"
  ],
  "dev137/Azure99_blossom-v4-yi-34b-exl2-4.0bpw-h8": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "wkshin89/mistral-7b-instruct-ko-test-v0.3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Panda-7B-v0.1-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Panda-7B-v0.1-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Panda-7B-v0.1-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Panda-7B-v0.1-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Panda-7B-v0.1-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "TheBloke/Unholy-v2-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Unholy-v2-13B-AWQ": [
    "model.safetensors"
  ],
  "decem/Dionysus-Mistral-m3-v6": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "peterkang/mymodel_v2": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "harshita23sh/NeuralHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Quidba7/codedecision-ds": [
    "model.safetensors"
  ],
  "HwiyeolJo/testtt": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Kquant03/MistralTrix8x9B": [
    "model-00001-of-00012.safetensors",
    "model-00002-of-00012.safetensors",
    "model-00003-of-00012.safetensors",
    "model-00004-of-00012.safetensors",
    "model-00005-of-00012.safetensors",
    "model-00006-of-00012.safetensors",
    "model-00007-of-00012.safetensors",
    "model-00008-of-00012.safetensors",
    "model-00009-of-00012.safetensors",
    "model-00010-of-00012.safetensors",
    "model-00011-of-00012.safetensors",
    "model-00012-of-00012.safetensors"
  ],
  "Envoid/Dendrite-8x7Bv1": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "Locutusque/Mistral-7B-SFT": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Kooten/FlatDolphinMaid-8x7B-3.5bpw-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "HwiyeolJo/testttt": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SAGI-1/chat_test_500": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ThibautA/test_sai2": [
    "adapter_model.safetensors",
    "checkpoint-235/adapter_model.safetensors",
    "model.safetensors"
  ],
  "NotoriousH2/42dot_1.3B_notolab": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "fatihay/mistralaiTest": [
    "checkpoint-15/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "diogo-carvalho/customModel": [
    "adapter_model.safetensors",
    "checkpoint-1/adapter_model.safetensors"
  ],
  "sambar/sambar-7b-dpo-lora": [
    "adapter_model.safetensors"
  ],
  "Shruti9756/rlhfmodel": [
    "model.safetensors"
  ],
  "RaiBP/gpt2-openwebtext2-first-30-chunks-ablation-full-fp16": [
    "model.safetensors"
  ],
  "peterkang/mymodel_v3": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "petuniajacobson/my-fine-tuned-model-ppo": [
    "model.safetensors"
  ],
  "yujiepan/Llama-2-7b-hf-awq-w4g128": [
    "model.safetensors"
  ],
  "chekable/mistral-chekable-abstract-v06": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "NowaBwagel0/llama-68m-oasst_top1": [
    "model.safetensors"
  ],
  "panosdou/English": [
    "model.safetensors"
  ],
  "yujiepan/Llama-2-13b-hf-awq-w4g128": [
    "model.safetensors"
  ],
  "Kooten/FlatDolphinMaid-8x7B-3bpw-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "Kooten/FlatDolphinMaid-8x7B-4bpw-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "shivafm/mistral_instruct_finetuned_centuryss_25ep": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "NobodyExistsOnTheInternet/GiftedMistralSysmsgTest2": [
    "adapter_model.safetensors"
  ],
  "TheBloke/Panda-7B-v0.1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Panda-7B-v0.1-AWQ": [
    "model.safetensors"
  ],
  "thanhnew2001/WizardCoder-Python-7B-V1.0-taipy18": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "KnutJaegersberg/Deacon-1_8b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "dmntrd/zephyr-7b-beta-rocio-3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "NowaBwagel0/llama-68m-oasst": [
    "model.safetensors"
  ],
  "actuallysatya/OdiaMistral-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "KnutJaegersberg/platypus-1_8b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Delcos/Velara-11B-V2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Azazelle/Tippy-Toppy-7b": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "chekable/mistral-abstract-finetune-quantize": [
    "model.safetensors"
  ],
  "kkuramitsu/tinycodellama-jp-0.13b-40k": [
    "model.safetensors"
  ],
  "abacusai/Slerp-CM-mist-dpo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "appvoid/palmer-003-turbo": [
    "model.safetensors"
  ],
  "piotr-ai/polanka-3b-pretrain-full-v0.2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "dev137/Undi95_Unholy-v2-13B-exl2-4.0bpw-h8": [
    "output.safetensors"
  ],
  "TheBloke/FlatDolphinMaid-8x7B-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/FlatDolphinMaid-8x7B-GPTQ": [
    "model.safetensors"
  ],
  "NeuralNovel/Tanuki-7B-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jeiku/Cognizant_3B": [
    "model-00001-of-00001.safetensors"
  ],
  "omarmohamed/tulu_v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "chekable/mistral-abstract-finetune": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Edentns/DataVortexM-7B-Instruct-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "swellsock/xyz": [
    "model.safetensors"
  ],
  "realPCH/240104_mistral_lora": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ibivibiv/athena-120b": [
    "model-00001-of-00106.safetensors",
    "model-00002-of-00106.safetensors",
    "model-00003-of-00106.safetensors",
    "model-00004-of-00106.safetensors",
    "model-00005-of-00106.safetensors",
    "model-00006-of-00106.safetensors",
    "model-00007-of-00106.safetensors",
    "model-00008-of-00106.safetensors",
    "model-00009-of-00106.safetensors",
    "model-00010-of-00106.safetensors",
    "model-00011-of-00106.safetensors",
    "model-00012-of-00106.safetensors",
    "model-00013-of-00106.safetensors",
    "model-00014-of-00106.safetensors",
    "model-00015-of-00106.safetensors",
    "model-00016-of-00106.safetensors",
    "model-00017-of-00106.safetensors",
    "model-00018-of-00106.safetensors",
    "model-00019-of-00106.safetensors",
    "model-00020-of-00106.safetensors",
    "model-00021-of-00106.safetensors",
    "model-00022-of-00106.safetensors",
    "model-00023-of-00106.safetensors",
    "model-00024-of-00106.safetensors",
    "model-00025-of-00106.safetensors",
    "model-00026-of-00106.safetensors",
    "model-00027-of-00106.safetensors",
    "model-00028-of-00106.safetensors",
    "model-00029-of-00106.safetensors",
    "model-00030-of-00106.safetensors",
    "model-00031-of-00106.safetensors",
    "model-00032-of-00106.safetensors",
    "model-00033-of-00106.safetensors",
    "model-00034-of-00106.safetensors",
    "model-00035-of-00106.safetensors",
    "model-00036-of-00106.safetensors",
    "model-00037-of-00106.safetensors",
    "model-00038-of-00106.safetensors",
    "model-00039-of-00106.safetensors",
    "model-00040-of-00106.safetensors",
    "model-00041-of-00106.safetensors",
    "model-00042-of-00106.safetensors",
    "model-00043-of-00106.safetensors",
    "model-00044-of-00106.safetensors",
    "model-00045-of-00106.safetensors",
    "model-00046-of-00106.safetensors",
    "model-00047-of-00106.safetensors",
    "model-00048-of-00106.safetensors",
    "model-00049-of-00106.safetensors",
    "model-00050-of-00106.safetensors",
    "model-00051-of-00106.safetensors",
    "model-00052-of-00106.safetensors",
    "model-00053-of-00106.safetensors",
    "model-00054-of-00106.safetensors",
    "model-00055-of-00106.safetensors",
    "model-00056-of-00106.safetensors",
    "model-00057-of-00106.safetensors",
    "model-00058-of-00106.safetensors",
    "model-00059-of-00106.safetensors",
    "model-00060-of-00106.safetensors",
    "model-00061-of-00106.safetensors",
    "model-00062-of-00106.safetensors",
    "model-00063-of-00106.safetensors",
    "model-00064-of-00106.safetensors",
    "model-00065-of-00106.safetensors",
    "model-00066-of-00106.safetensors",
    "model-00067-of-00106.safetensors",
    "model-00068-of-00106.safetensors",
    "model-00069-of-00106.safetensors",
    "model-00070-of-00106.safetensors",
    "model-00071-of-00106.safetensors",
    "model-00072-of-00106.safetensors",
    "model-00073-of-00106.safetensors",
    "model-00074-of-00106.safetensors",
    "model-00075-of-00106.safetensors",
    "model-00076-of-00106.safetensors",
    "model-00077-of-00106.safetensors",
    "model-00078-of-00106.safetensors",
    "model-00079-of-00106.safetensors",
    "model-00080-of-00106.safetensors",
    "model-00081-of-00106.safetensors",
    "model-00082-of-00106.safetensors",
    "model-00083-of-00106.safetensors",
    "model-00084-of-00106.safetensors",
    "model-00085-of-00106.safetensors",
    "model-00086-of-00106.safetensors",
    "model-00087-of-00106.safetensors",
    "model-00088-of-00106.safetensors",
    "model-00089-of-00106.safetensors",
    "model-00090-of-00106.safetensors",
    "model-00091-of-00106.safetensors",
    "model-00092-of-00106.safetensors",
    "model-00093-of-00106.safetensors",
    "model-00094-of-00106.safetensors",
    "model-00095-of-00106.safetensors",
    "model-00096-of-00106.safetensors",
    "model-00097-of-00106.safetensors",
    "model-00098-of-00106.safetensors",
    "model-00099-of-00106.safetensors",
    "model-00100-of-00106.safetensors",
    "model-00101-of-00106.safetensors",
    "model-00102-of-00106.safetensors",
    "model-00103-of-00106.safetensors",
    "model-00104-of-00106.safetensors",
    "model-00105-of-00106.safetensors",
    "model-00106-of-00106.safetensors"
  ],
  "pkarypis/opt-6.7b-sft": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "yongsri/llama-2-7b-guanaco-dolly-mini": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "StatPan/all-you-need-is": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-indef-removal-seed_1024-1e-4": [
    "model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-all_det_removal-seed_1024-1e-3": [
    "model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-measure_nouns_as_singular-seed_1024-1e-4": [
    "model.safetensors"
  ],
  "whifflewaffle/miner1": [
    "model.safetensors"
  ],
  "oopsung/Yi-Ko-ENC-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "swellsock/xyz2": [
    "model.safetensors"
  ],
  "swellsock/xyz3": [
    "model.safetensors"
  ],
  "swellsock/xyz4": [
    "model.safetensors"
  ],
  "swellsock/xyz5": [
    "model.safetensors"
  ],
  "chargoddard/average-dolphin-8x7B": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "pkarypis/opt-125m-sft": [
    "model.safetensors"
  ],
  "truongghieu/fine-tuned-llama-2-7b-CVE": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ChuckMcSneed/DoubleGold-v0.1-123b-32k": [
    "model-00001-of-00026.safetensors",
    "model-00002-of-00026.safetensors",
    "model-00003-of-00026.safetensors",
    "model-00004-of-00026.safetensors",
    "model-00005-of-00026.safetensors",
    "model-00006-of-00026.safetensors",
    "model-00007-of-00026.safetensors",
    "model-00008-of-00026.safetensors",
    "model-00009-of-00026.safetensors",
    "model-00010-of-00026.safetensors",
    "model-00011-of-00026.safetensors",
    "model-00012-of-00026.safetensors",
    "model-00013-of-00026.safetensors",
    "model-00014-of-00026.safetensors",
    "model-00015-of-00026.safetensors",
    "model-00016-of-00026.safetensors",
    "model-00017-of-00026.safetensors",
    "model-00018-of-00026.safetensors",
    "model-00019-of-00026.safetensors",
    "model-00020-of-00026.safetensors",
    "model-00021-of-00026.safetensors",
    "model-00022-of-00026.safetensors",
    "model-00023-of-00026.safetensors",
    "model-00024-of-00026.safetensors",
    "model-00025-of-00026.safetensors",
    "model-00026-of-00026.safetensors"
  ],
  "zksnacks/zksnacks": [
    "model.safetensors"
  ],
  "elliotthwang/KimLan_mistral-0.5b-40k": [
    "model.safetensors"
  ],
  "zksnacks/my-project": [
    "model.safetensors"
  ],
  "iblai/ibl-multiple-choice-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Giahurmg/gia": [
    "model.safetensors"
  ],
  "OpenBuddy/openbuddy-falcon-40b-v16.1-4k": [
    "model-00001-of-00018.safetensors",
    "model-00002-of-00018.safetensors",
    "model-00003-of-00018.safetensors",
    "model-00004-of-00018.safetensors",
    "model-00005-of-00018.safetensors",
    "model-00006-of-00018.safetensors",
    "model-00007-of-00018.safetensors",
    "model-00008-of-00018.safetensors",
    "model-00009-of-00018.safetensors",
    "model-00010-of-00018.safetensors",
    "model-00011-of-00018.safetensors",
    "model-00012-of-00018.safetensors",
    "model-00013-of-00018.safetensors",
    "model-00014-of-00018.safetensors",
    "model-00015-of-00018.safetensors",
    "model-00016-of-00018.safetensors",
    "model-00017-of-00018.safetensors",
    "model-00018-of-00018.safetensors"
  ],
  "EmbeddedLLM/Mistral-7B-Merge-14-v0.3-ft-step-9984": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TdL/key1": [
    "model.safetensors"
  ],
  "Jobiniah/bible-mistral-7b": [
    "adapter_model.safetensors"
  ],
  "JeremyNJ/ms-phi-2-health-assistant": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TdL/key2": [
    "model.safetensors"
  ],
  "TdL/key3": [
    "model.safetensors"
  ],
  "TdL/key4": [
    "model.safetensors"
  ],
  "TdL/key5": [
    "model.safetensors"
  ],
  "TdL/key6": [
    "model.safetensors"
  ],
  "TdL/key7": [
    "model.safetensors"
  ],
  "Lucia-no/key1": [
    "model.safetensors"
  ],
  "TdL/key8": [
    "model.safetensors"
  ],
  "UCLA-AGI/zephyr-7b-sft-full-SPIN-iter0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Lucia-no/key2": [
    "model.safetensors"
  ],
  "TdL/key9": [
    "model.safetensors"
  ],
  "Kquant03/EarthRender-32x7B-bf16": [
    "model-00001-of-00037.safetensors",
    "model-00002-of-00037.safetensors",
    "model-00003-of-00037.safetensors",
    "model-00004-of-00037.safetensors",
    "model-00005-of-00037.safetensors",
    "model-00006-of-00037.safetensors",
    "model-00007-of-00037.safetensors",
    "model-00008-of-00037.safetensors",
    "model-00009-of-00037.safetensors",
    "model-00010-of-00037.safetensors",
    "model-00011-of-00037.safetensors",
    "model-00012-of-00037.safetensors",
    "model-00013-of-00037.safetensors",
    "model-00014-of-00037.safetensors",
    "model-00015-of-00037.safetensors",
    "model-00016-of-00037.safetensors",
    "model-00017-of-00037.safetensors",
    "model-00018-of-00037.safetensors",
    "model-00019-of-00037.safetensors",
    "model-00020-of-00037.safetensors",
    "model-00021-of-00037.safetensors",
    "model-00022-of-00037.safetensors",
    "model-00023-of-00037.safetensors",
    "model-00024-of-00037.safetensors",
    "model-00025-of-00037.safetensors",
    "model-00026-of-00037.safetensors",
    "model-00027-of-00037.safetensors",
    "model-00028-of-00037.safetensors",
    "model-00029-of-00037.safetensors",
    "model-00030-of-00037.safetensors",
    "model-00031-of-00037.safetensors",
    "model-00032-of-00037.safetensors",
    "model-00033-of-00037.safetensors",
    "model-00034-of-00037.safetensors",
    "model-00035-of-00037.safetensors",
    "model-00036-of-00037.safetensors",
    "model-00037-of-00037.safetensors"
  ],
  "Da-Hye/mistral-fine-tuned-alpaca": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "TdL/key10": [
    "model.safetensors"
  ],
  "Lucia-no/key4": [
    "model.safetensors"
  ],
  "TdL/key13": [
    "model.safetensors"
  ],
  "Lucia-no/key5": [
    "model.safetensors"
  ],
  "Rich-J/key1": [
    "model.safetensors"
  ],
  "Lucia-no/key6": [
    "model.safetensors"
  ],
  "TdL/key16": [
    "model.safetensors"
  ],
  "Rich-J/key2": [
    "model.safetensors"
  ],
  "Lucia-no/key7": [
    "model.safetensors"
  ],
  "Rich-J/key3": [
    "model.safetensors"
  ],
  "Lucia-no/key8": [
    "model.safetensors"
  ],
  "Rich-J/key4": [
    "model.safetensors"
  ],
  "Lucia-no/key9": [
    "model.safetensors"
  ],
  "Rich-J/key5": [
    "model.safetensors"
  ],
  "Lucia-no/key10": [
    "model.safetensors"
  ],
  "Rich-J/key6": [
    "model.safetensors"
  ],
  "mohitcharkha/Mistral-7B-Instruct-v0.2-finetune-Exp-2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Lucia-no/key11": [
    "model.safetensors"
  ],
  "Lucia-no/key12": [
    "model.safetensors"
  ],
  "Rich-J/key8": [
    "model.safetensors"
  ],
  "Lucia-no/key13": [
    "model.safetensors"
  ],
  "Rich-J/key10": [
    "model.safetensors"
  ],
  "wenzw/zephyr-7b-dpo-lora": [
    "adapter_model.safetensors"
  ],
  "Lucia-no/key14": [
    "model.safetensors"
  ],
  "Rich-J/key11": [
    "model.safetensors"
  ],
  "Lucia-no/key15": [
    "model.safetensors"
  ],
  "Rich-J/key12": [
    "model.safetensors"
  ],
  "Lucia-no/key16": [
    "model.safetensors"
  ],
  "Rich-J/key13": [
    "model.safetensors"
  ],
  "Rich-J/key14": [
    "model.safetensors"
  ],
  "Rich-J/key15": [
    "model.safetensors"
  ],
  "LoneStriker/Iambe-RP-v3-20b-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "Rich-J/key16": [
    "model.safetensors"
  ],
  "Doctor-Shotgun/Mixtral-8x7B-Instruct-v0.1-LimaRP-ZLoss": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "GandegaH/gpt2-wikitext2": [
    "model.safetensors"
  ],
  "UCLA-AGI/zephyr-7b-sft-full-SPIN-iter1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Iambe-RP-v3-20b-4.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/Iambe-RP-v3-20b-4.65bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "lewtun/zephyr-7b-sft-full": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Iambe-RP-v3-20b-5.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "ohyay12345/model1": [
    "model.safetensors"
  ],
  "jungiebeen/pretrain": [
    "model.safetensors"
  ],
  "LoneStriker/Iambe-RP-v3-20b-6.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "jungiebeen/pretrain2": [
    "model.safetensors"
  ],
  "LoneStriker/Iambe-RP-v3-20b-8.0bpw-h8-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "NaoS2/tinycodellama-jp-0.6b-25k-v2": [
    "model.safetensors"
  ],
  "jungiebeen/pretrain3": [
    "model.safetensors"
  ],
  "ohyay12345/model2": [
    "model.safetensors"
  ],
  "ohyay12345/model3": [
    "model.safetensors"
  ],
  "ohyay12345/model4": [
    "model.safetensors"
  ],
  "ohyay12345/model5": [
    "model.safetensors"
  ],
  "ohyay12345/model6": [
    "model.safetensors"
  ],
  "ohyay12345/model7": [
    "model.safetensors"
  ],
  "ohyay12345/model8": [
    "model.safetensors"
  ],
  "ohyay12345/model9": [
    "model.safetensors"
  ],
  "ohyay12345/model10": [
    "model.safetensors"
  ],
  "ohyay12345/model11": [
    "model.safetensors"
  ],
  "ohyay12345/model12": [
    "model.safetensors"
  ],
  "ohyay12345/model13": [
    "model.safetensors"
  ],
  "ohyay12345/model14": [
    "model.safetensors"
  ],
  "ohyay12345/model15": [
    "model.safetensors"
  ],
  "ohyay12345/model16": [
    "model.safetensors"
  ],
  "jungiebeen/pretrain4": [
    "model.safetensors"
  ],
  "ohyay12345/model17": [
    "model.safetensors"
  ],
  "ohyay12345/model18": [
    "model.safetensors"
  ],
  "ohyay12345/model19": [
    "model.safetensors"
  ],
  "ohyay12345/model20": [
    "model.safetensors"
  ],
  "ohyay12345/model22": [
    "model.safetensors"
  ],
  "ohyay12345/model23": [
    "model.safetensors"
  ],
  "jungiebeen/pretrain5": [
    "model.safetensors"
  ],
  "peterkang/mymodel_v4": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "crumb/shrink-init": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jungiebeen/pretrain6": [
    "model.safetensors"
  ],
  "jungiebeen/pretrain7": [
    "model.safetensors"
  ],
  "maywell/TinyWand-DPO": [
    "model.safetensors"
  ],
  "jungiebeen/pretrain8": [
    "model.safetensors"
  ],
  "jungiebeen/pretrain9": [
    "model.safetensors"
  ],
  "jungiebeen/pretrain10": [
    "model.safetensors"
  ],
  "jungiebeen/pretrain11": [
    "model.safetensors"
  ],
  "jungiebeen/pretrain12": [
    "model.safetensors"
  ],
  "jungiebeen/pretrain13": [
    "model.safetensors"
  ],
  "rynoj/ryanmodel": [
    "model.safetensors"
  ],
  "hossr/model1": [
    "model.safetensors"
  ],
  "jungiebeen/pretrain14": [
    "model.safetensors"
  ],
  "hossr/model2": [
    "model.safetensors"
  ],
  "jungiebeen/pretrain15": [
    "model.safetensors"
  ],
  "hossr/mode2": [
    "model.safetensors"
  ],
  "jungiebeen/pretrain16": [
    "model.safetensors"
  ],
  "hossr/mode3": [
    "model.safetensors"
  ],
  "peterkang/mymodel_v5": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "slumpz/taosn9": [
    "model.safetensors"
  ],
  "hossr/mode4": [
    "model.safetensors"
  ],
  "rynoj/ryanmodel2": [
    "model.safetensors"
  ],
  "thanhnew2001/taipy19": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rynoj/ryanmodel3": [
    "model.safetensors"
  ],
  "hossr/mode5": [
    "model.safetensors"
  ],
  "hossr/mode6": [
    "model.safetensors"
  ],
  "ohyay12345/model121": [
    "model.safetensors"
  ],
  "Kooltek68/sn9_137": [
    "model.safetensors"
  ],
  "hossr/mode7": [
    "model.safetensors"
  ],
  "Kooltek68/sn9_118": [
    "model.safetensors"
  ],
  "Kooltek68/sn9_135": [
    "model.safetensors"
  ],
  "Kooltek68/sn9_134": [
    "model.safetensors"
  ],
  "Kooltek68/sn9_132": [
    "model.safetensors"
  ],
  "Kooltek68/sn9_133": [
    "model.safetensors"
  ],
  "Kooltek68/sn9_131": [
    "model.safetensors"
  ],
  "Kooltek68/sn9_136": [
    "model.safetensors"
  ],
  "hossr/mode8": [
    "model.safetensors"
  ],
  "ohyay12345/rymode1": [
    "model.safetensors"
  ],
  "hossr/mode9": [
    "model.safetensors"
  ],
  "ohyay12345/rymode2": [
    "model.safetensors"
  ],
  "hossr/mode10": [
    "model.safetensors"
  ],
  "ohyay12345/rymode3": [
    "model.safetensors"
  ],
  "hossr/mode11": [
    "model.safetensors"
  ],
  "ohyay12345/rymode6": [
    "model.safetensors"
  ],
  "hossr/mode12": [
    "model.safetensors"
  ],
  "ohyay12345/rymode7": [
    "model.safetensors"
  ],
  "hossr/mode14": [
    "model.safetensors"
  ],
  "ifuseok/sft-solar-10.7b-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ohyay12345/rymode8": [
    "model.safetensors"
  ],
  "LoneStriker/FlatDolphinMaid-8x7B-3.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "hossr/mode15": [
    "model.safetensors"
  ],
  "hossr/mode16": [
    "model.safetensors"
  ],
  "SAGI-1/chat_test_base": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hossr/mode17": [
    "model.safetensors"
  ],
  "ohyay12345/rymode10": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5": [
    "model.safetensors"
  ],
  "fedml/Llama-2-70b-chat": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow0": [
    "model.safetensors"
  ],
  "LoneStriker/FlatDolphinMaid-8x7B-3.5bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "keisoft/pretrain": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow1": [
    "model.safetensors"
  ],
  "ohyay12345/rymode16": [
    "model.safetensors"
  ],
  "ibivibiv/giant-macaroni-120b": [
    "model-00001-of-00106.safetensors",
    "model-00002-of-00106.safetensors",
    "model-00003-of-00106.safetensors",
    "model-00004-of-00106.safetensors",
    "model-00005-of-00106.safetensors",
    "model-00006-of-00106.safetensors",
    "model-00007-of-00106.safetensors",
    "model-00008-of-00106.safetensors",
    "model-00009-of-00106.safetensors",
    "model-00010-of-00106.safetensors",
    "model-00011-of-00106.safetensors",
    "model-00012-of-00106.safetensors",
    "model-00013-of-00106.safetensors",
    "model-00014-of-00106.safetensors",
    "model-00015-of-00106.safetensors",
    "model-00016-of-00106.safetensors",
    "model-00017-of-00106.safetensors",
    "model-00018-of-00106.safetensors",
    "model-00019-of-00106.safetensors",
    "model-00020-of-00106.safetensors",
    "model-00021-of-00106.safetensors",
    "model-00022-of-00106.safetensors",
    "model-00023-of-00106.safetensors",
    "model-00024-of-00106.safetensors",
    "model-00025-of-00106.safetensors",
    "model-00026-of-00106.safetensors",
    "model-00027-of-00106.safetensors",
    "model-00028-of-00106.safetensors",
    "model-00029-of-00106.safetensors",
    "model-00030-of-00106.safetensors",
    "model-00031-of-00106.safetensors",
    "model-00032-of-00106.safetensors",
    "model-00033-of-00106.safetensors",
    "model-00034-of-00106.safetensors",
    "model-00035-of-00106.safetensors",
    "model-00036-of-00106.safetensors",
    "model-00037-of-00106.safetensors",
    "model-00038-of-00106.safetensors",
    "model-00039-of-00106.safetensors",
    "model-00040-of-00106.safetensors",
    "model-00041-of-00106.safetensors",
    "model-00042-of-00106.safetensors",
    "model-00043-of-00106.safetensors",
    "model-00044-of-00106.safetensors",
    "model-00045-of-00106.safetensors",
    "model-00046-of-00106.safetensors",
    "model-00047-of-00106.safetensors",
    "model-00048-of-00106.safetensors",
    "model-00049-of-00106.safetensors",
    "model-00050-of-00106.safetensors",
    "model-00051-of-00106.safetensors",
    "model-00052-of-00106.safetensors",
    "model-00053-of-00106.safetensors",
    "model-00054-of-00106.safetensors",
    "model-00055-of-00106.safetensors",
    "model-00056-of-00106.safetensors",
    "model-00057-of-00106.safetensors",
    "model-00058-of-00106.safetensors",
    "model-00059-of-00106.safetensors",
    "model-00060-of-00106.safetensors",
    "model-00061-of-00106.safetensors",
    "model-00062-of-00106.safetensors",
    "model-00063-of-00106.safetensors",
    "model-00064-of-00106.safetensors",
    "model-00065-of-00106.safetensors",
    "model-00066-of-00106.safetensors",
    "model-00067-of-00106.safetensors",
    "model-00068-of-00106.safetensors",
    "model-00069-of-00106.safetensors",
    "model-00070-of-00106.safetensors",
    "model-00071-of-00106.safetensors",
    "model-00072-of-00106.safetensors",
    "model-00073-of-00106.safetensors",
    "model-00074-of-00106.safetensors",
    "model-00075-of-00106.safetensors",
    "model-00076-of-00106.safetensors",
    "model-00077-of-00106.safetensors",
    "model-00078-of-00106.safetensors",
    "model-00079-of-00106.safetensors",
    "model-00080-of-00106.safetensors",
    "model-00081-of-00106.safetensors",
    "model-00082-of-00106.safetensors",
    "model-00083-of-00106.safetensors",
    "model-00084-of-00106.safetensors",
    "model-00085-of-00106.safetensors",
    "model-00086-of-00106.safetensors",
    "model-00087-of-00106.safetensors",
    "model-00088-of-00106.safetensors",
    "model-00089-of-00106.safetensors",
    "model-00090-of-00106.safetensors",
    "model-00091-of-00106.safetensors",
    "model-00092-of-00106.safetensors",
    "model-00093-of-00106.safetensors",
    "model-00094-of-00106.safetensors",
    "model-00095-of-00106.safetensors",
    "model-00096-of-00106.safetensors",
    "model-00097-of-00106.safetensors",
    "model-00098-of-00106.safetensors",
    "model-00099-of-00106.safetensors",
    "model-00100-of-00106.safetensors",
    "model-00101-of-00106.safetensors",
    "model-00102-of-00106.safetensors",
    "model-00103-of-00106.safetensors",
    "model-00104-of-00106.safetensors",
    "model-00105-of-00106.safetensors",
    "model-00106-of-00106.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow2": [
    "model.safetensors"
  ],
  "chargoddard/mixtralmerge-8x7B-rebalanced-test": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "ohyay12345/rymode25": [
    "model.safetensors"
  ],
  "halilibr/mistral-7b-orca_dpo_pairs-fine-tuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow3": [
    "model.safetensors"
  ],
  "LoneStriker/FlatDolphinMaid-8x7B-3.75bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow4": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow5": [
    "model.safetensors"
  ],
  "LoneStriker/FlatDolphinMaid-8x7B-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow6": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow7": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow8": [
    "model.safetensors"
  ],
  "megastudyedu/M-SOLAR-10.7B-v1.3": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "LoneStriker/FlatDolphinMaid-8x7B-5.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow9": [
    "model.safetensors"
  ],
  "SAGI-1/chat_test_base_2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow10": [
    "model.safetensors"
  ],
  "Azurro/APT3-1B-Base": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow11": [
    "model.safetensors"
  ],
  "LoneStriker/FlatDolphinMaid-8x7B-6.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow12": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow13": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow14": [
    "model.safetensors"
  ],
  "LoneStriker/FlatDolphinMaid-8x7B-2.4bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow15": [
    "model.safetensors"
  ],
  "fedml/Llama-2-7b-chat": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "AIFT/aift-llama2-koen-instruct-v1.0-test": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow16": [
    "model.safetensors"
  ],
  "WizardLM/WizardCoder-33B-V1.1": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow17": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow18": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow19": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow20": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow21": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow22": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow23": [
    "model.safetensors"
  ],
  "wkshin89/yi-ko-6b-instruct-test-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SanjiWatsuki/Kunoichi-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow24": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow25": [
    "model.safetensors"
  ],
  "TheBloke/WordWoven-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/WordWoven-13B-GPTQ": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow26": [
    "model.safetensors"
  ],
  "alxcrypto/miner1": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow27": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow28": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow29": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow30": [
    "model.safetensors"
  ],
  "fazil1234/newGPTQ": [
    "model.safetensors"
  ],
  "TinyPixel/qwen-1.8B-guanaco": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow31": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow32": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow33": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow34": [
    "model.safetensors"
  ],
  "thanhnew2001/taipy20": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow35": [
    "model.safetensors"
  ],
  "Mihaiii/Pallas-0.5-LASER-exp2-0.1": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "Aabbhishekk/lora_alpaca_finetuned_v2": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow36": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow37": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow38": [
    "model.safetensors"
  ],
  "Yhyu13/dolphin-2_6-phi-2-sft-glaive-function-calling-v2-ep1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow39": [
    "model.safetensors"
  ],
  "peterkang/mymodel_v6": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "TheBloke/Iambe-RP-v3-20B-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Iambe-RP-v3-20B-GPTQ": [
    "model.safetensors"
  ],
  "h-asterix/mistralai-Code-Instruct-Finetune-test": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_member_shadow40": [
    "model.safetensors"
  ],
  "fedyanin/zephyr-7b-sft-lora": [
    "adapter_model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_non_member_shadow0": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_non_member_shadow1": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_non_member_shadow2": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_non_member_shadow3": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_non_member_shadow4": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_non_member_shadow5": [
    "model.safetensors"
  ],
  "redav/Mistral-7B-Instruct-v0.2-email-a": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_non_member_shadow6": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_non_member_shadow7": [
    "model.safetensors"
  ],
  "amitj1jan/llama2-fine-tuned-dolly-15k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "codxsolutions/s2t-falcon7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_non_member_shadow8": [
    "model.safetensors"
  ],
  "elonmollusk/neuralogix-neural-chat-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_non_member_shadow9": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_non_member_shadow10": [
    "model.safetensors"
  ],
  "ashk72/llama2-restaurant-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Nous-Hermes-2-SUS-Chat-34B-Slerp-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Nous-Hermes-2-SUS-Chat-34B-Slerp-GPTQ": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_non_member_shadow11": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_non_member_shadow12": [
    "model.safetensors"
  ],
  "raowaqas123/minima_hblv6": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_non_member_shadow13": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_non_member_shadow14": [
    "model.safetensors"
  ],
  "danwils/critic-mistral7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_non_member_shadow15": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_non_member_shadow16": [
    "model.safetensors"
  ],
  "Yash21/TinyYi-7B-slerp": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SAGI-1/HR_1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_non_member_shadow17": [
    "model.safetensors"
  ],
  "fokyoum9/Solar_KO_ORCA_Test7": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t3000_e5_non_member_shadow19": [
    "model.safetensors"
  ],
  "thanhnew2001/taipy21": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SAGI-1/HR_2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "decem/Dionysus-Mistral-m3-v7": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "KnutJaegersberg/Deacon-20b-4.9bpw-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "shadowml/Macaron-7B-v2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "deepnet/PreTrainingSubnetModel": [
    "model.safetensors"
  ],
  "tpasco/bt1": [
    "model.safetensors"
  ],
  "sunnythakkar/tao_sunny": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors",
    "model.safetensors"
  ],
  "sundar-pichai/TinyLlama-1.1B-v1.0": [
    "model.safetensors"
  ],
  "borggAI/bittensor-subnet9-models": [
    "model.safetensors"
  ],
  "phanerozoic/Tiny-Pirate-1.1b-v0.1": [
    "model.safetensors"
  ],
  "jlkj/zephyr-7b-sft-lora": [
    "adapter_model.safetensors"
  ],
  "crodri/Flor63PureQA": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "qnguyen3/vinallama-merged": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Unbabel/TowerInstruct-7B-v0.1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "qnguyen3/vinallama-merge-1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Edentns/DataVortexS-10.7B-v0.2": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "qnguyen3/vinallama-chat-merge": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "BEE-spoke-data/zephyr-220m-sft-full": [
    "model.safetensors"
  ],
  "qnguyen3/vinallama-chat-merge-1": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "nthngdy/hythia160m-2.5k-rp-bs16-nowt": [
    "model.safetensors"
  ],
  "shivafm/mistral_instruct_finetuned_centuryss_25ep_filtered": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "wkshin89/yi-ko-6b-instruct-test-v0.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "daniellnichols/spack-llama-7b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "occultml/NeuralPipe-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "vgorce/MarcoroNeuralChat-7B-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "impossibleexchange/pt": [
    "model.safetensors"
  ],
  "shadowml/DareBeagel-2x7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Feluda/zephyr-finetuned-legal": [
    "adapter_model.safetensors"
  ],
  "qnguyen3/vinallama-16b-chat-franken": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Mistral-7B-OpenOrca-oasst_top1_2023-08-25-v2-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Mistral-7B-OpenOrca-oasst_top1_2023-08-25-v2-GPTQ": [
    "model.safetensors"
  ],
  "vilm/vinallama-12.5b-chat-DUS": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "alinourian/GPT2-fake-real-news": [
    "model.safetensors"
  ],
  "TheBloke/WizardCoder-33B-V1.1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/WizardCoder-33B-V1.1-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mrbmaryam/Yarn-Mistral-7b-128k_Fine-Tuned4LogParsing": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ibivibiv/chimera-120b": [
    "model-00001-of-00106.safetensors",
    "model-00002-of-00106.safetensors",
    "model-00003-of-00106.safetensors",
    "model-00004-of-00106.safetensors",
    "model-00005-of-00106.safetensors",
    "model-00006-of-00106.safetensors",
    "model-00007-of-00106.safetensors",
    "model-00008-of-00106.safetensors",
    "model-00009-of-00106.safetensors",
    "model-00010-of-00106.safetensors",
    "model-00011-of-00106.safetensors",
    "model-00012-of-00106.safetensors",
    "model-00013-of-00106.safetensors",
    "model-00014-of-00106.safetensors",
    "model-00015-of-00106.safetensors",
    "model-00016-of-00106.safetensors",
    "model-00017-of-00106.safetensors",
    "model-00018-of-00106.safetensors",
    "model-00019-of-00106.safetensors",
    "model-00020-of-00106.safetensors",
    "model-00021-of-00106.safetensors",
    "model-00022-of-00106.safetensors",
    "model-00023-of-00106.safetensors",
    "model-00024-of-00106.safetensors",
    "model-00025-of-00106.safetensors",
    "model-00026-of-00106.safetensors",
    "model-00027-of-00106.safetensors",
    "model-00028-of-00106.safetensors",
    "model-00029-of-00106.safetensors",
    "model-00030-of-00106.safetensors",
    "model-00031-of-00106.safetensors",
    "model-00032-of-00106.safetensors",
    "model-00033-of-00106.safetensors",
    "model-00034-of-00106.safetensors",
    "model-00035-of-00106.safetensors",
    "model-00036-of-00106.safetensors",
    "model-00037-of-00106.safetensors",
    "model-00038-of-00106.safetensors",
    "model-00039-of-00106.safetensors",
    "model-00040-of-00106.safetensors",
    "model-00041-of-00106.safetensors",
    "model-00042-of-00106.safetensors",
    "model-00043-of-00106.safetensors",
    "model-00044-of-00106.safetensors",
    "model-00045-of-00106.safetensors",
    "model-00046-of-00106.safetensors",
    "model-00047-of-00106.safetensors",
    "model-00048-of-00106.safetensors",
    "model-00049-of-00106.safetensors",
    "model-00050-of-00106.safetensors",
    "model-00051-of-00106.safetensors",
    "model-00052-of-00106.safetensors",
    "model-00053-of-00106.safetensors",
    "model-00054-of-00106.safetensors",
    "model-00055-of-00106.safetensors",
    "model-00056-of-00106.safetensors",
    "model-00057-of-00106.safetensors",
    "model-00058-of-00106.safetensors",
    "model-00059-of-00106.safetensors",
    "model-00060-of-00106.safetensors",
    "model-00061-of-00106.safetensors",
    "model-00062-of-00106.safetensors",
    "model-00063-of-00106.safetensors",
    "model-00064-of-00106.safetensors",
    "model-00065-of-00106.safetensors",
    "model-00066-of-00106.safetensors",
    "model-00067-of-00106.safetensors",
    "model-00068-of-00106.safetensors",
    "model-00069-of-00106.safetensors",
    "model-00070-of-00106.safetensors",
    "model-00071-of-00106.safetensors",
    "model-00072-of-00106.safetensors",
    "model-00073-of-00106.safetensors",
    "model-00074-of-00106.safetensors",
    "model-00075-of-00106.safetensors",
    "model-00076-of-00106.safetensors",
    "model-00077-of-00106.safetensors",
    "model-00078-of-00106.safetensors",
    "model-00079-of-00106.safetensors",
    "model-00080-of-00106.safetensors",
    "model-00081-of-00106.safetensors",
    "model-00082-of-00106.safetensors",
    "model-00083-of-00106.safetensors",
    "model-00084-of-00106.safetensors",
    "model-00085-of-00106.safetensors",
    "model-00086-of-00106.safetensors",
    "model-00087-of-00106.safetensors",
    "model-00088-of-00106.safetensors",
    "model-00089-of-00106.safetensors",
    "model-00090-of-00106.safetensors",
    "model-00091-of-00106.safetensors",
    "model-00092-of-00106.safetensors",
    "model-00093-of-00106.safetensors",
    "model-00094-of-00106.safetensors",
    "model-00095-of-00106.safetensors",
    "model-00096-of-00106.safetensors",
    "model-00097-of-00106.safetensors",
    "model-00098-of-00106.safetensors",
    "model-00099-of-00106.safetensors",
    "model-00100-of-00106.safetensors",
    "model-00101-of-00106.safetensors",
    "model-00102-of-00106.safetensors",
    "model-00103-of-00106.safetensors",
    "model-00104-of-00106.safetensors",
    "model-00105-of-00106.safetensors",
    "model-00106-of-00106.safetensors"
  ],
  "Doctor-Shotgun/Norobara-ZLoss-8x7B": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "octopus2023-inc/mistral-instructv2-int4-6epochs-faithdial": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/WizardCoder-33B-V1.1-3.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "borggAI/bittensor-subnet9-miner2": [
    "model.safetensors"
  ],
  "SUMEDH91/my_awesome_wikitext-model": [
    "model.safetensors"
  ],
  "Doctor-Shotgun/Norobara-LimaRP-ZLoss-8x7B": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "Azazelle/Maylin-7b": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "LoneStriker/WizardCoder-33B-V1.1-4.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "alxcrypto/minerhot3": [
    "model.safetensors"
  ],
  "bn22/TinyLlama-1.1B-tags-to-description": [
    "model.safetensors"
  ],
  "BEE-spoke-data/zephyr-220m-dpo-full": [
    "model.safetensors"
  ],
  "alxcrypto/minerhot4": [
    "model.safetensors"
  ],
  "alxcrypto/minerhot6": [
    "model.safetensors"
  ],
  "alxcrypto/minerhot7": [
    "model.safetensors"
  ],
  "alxcrypto/minerhot8": [
    "model.safetensors"
  ],
  "alxcrypto/minerhot9": [
    "model.safetensors"
  ],
  "alxcrypto/minerhot10": [
    "model.safetensors"
  ],
  "LoneStriker/WizardCoder-33B-V1.1-4.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "alxcrypto/minerhot11": [
    "model.safetensors"
  ],
  "alxcrypto/minerhot12": [
    "model.safetensors"
  ],
  "alxcrypto/minerhot15": [
    "model.safetensors"
  ],
  "upperwal/Indic-Llama-2-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "alxcrypto/mh1": [
    "model.safetensors"
  ],
  "pkarypis/zephyr-7b-sft-random-50-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/WizardCoder-33B-V1.1-5.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "7uk3y/train9": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AachenRepublic/gpt-towanker": [
    "model.safetensors"
  ],
  "alxcrypto/mh2": [
    "model.safetensors"
  ],
  "LoneStriker/WizardCoder-33B-V1.1-6.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "midnightklaxon/lumine_chatbot_mistral": [
    "model.safetensors"
  ],
  "LoneStriker/WizardCoder-33B-V1.1-8.0bpw-h8-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "codegood/Physio_Zephyr": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "borggAI/bittensor-subnet9-miner3": [
    "model.safetensors"
  ],
  "SergeiZu/llama-2-7b-sentiment-0-10000": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "borggAI/bittensor-subnet9-miner4": [
    "model.safetensors"
  ],
  "pkarypis/zephyr-7b-sft-random-75-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "YokaiKoibito/Mixtral-8x7B-Instruct-v0.1": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "notzero/dolphin_mistral_sharded": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "LoneStriker/Nous-Hermes-2-SUS-Chat-34B-Slerp-3.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "AIGym/deepseek-coder-1.3b-chat": [
    "model.safetensors"
  ],
  "mlabonne/NeuralHermes-2.5-Mistral-7B-laser": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Nous-Hermes-2-SUS-Chat-34B-Slerp-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "appvoid/palmer-003-turbo-2401": [
    "model.safetensors"
  ],
  "sambar/zephyr-7b-ipo-lora": [
    "adapter_model.safetensors"
  ],
  "LoneStriker/Nous-Hermes-2-SUS-Chat-34B-Slerp-4.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "omarmohamed/open_instruct_tulu-33b": [
    "model-00001-of-00027.safetensors",
    "model-00002-of-00027.safetensors",
    "model-00003-of-00027.safetensors",
    "model-00004-of-00027.safetensors",
    "model-00005-of-00027.safetensors",
    "model-00006-of-00027.safetensors",
    "model-00007-of-00027.safetensors",
    "model-00008-of-00027.safetensors",
    "model-00009-of-00027.safetensors",
    "model-00010-of-00027.safetensors",
    "model-00011-of-00027.safetensors",
    "model-00012-of-00027.safetensors",
    "model-00013-of-00027.safetensors",
    "model-00014-of-00027.safetensors",
    "model-00015-of-00027.safetensors",
    "model-00016-of-00027.safetensors",
    "model-00017-of-00027.safetensors",
    "model-00018-of-00027.safetensors",
    "model-00019-of-00027.safetensors",
    "model-00020-of-00027.safetensors",
    "model-00021-of-00027.safetensors",
    "model-00022-of-00027.safetensors",
    "model-00023-of-00027.safetensors",
    "model-00024-of-00027.safetensors",
    "model-00025-of-00027.safetensors",
    "model-00026-of-00027.safetensors",
    "model-00027-of-00027.safetensors"
  ],
  "nlpguy/Hermes-low-tune": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "senseable/33x-coder": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "LoneStriker/Nous-Hermes-2-SUS-Chat-34B-Slerp-5.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "alexredna/TinyLlama-1.1B-Chat-v1.0-reasoning-v2": [
    "model.safetensors"
  ],
  "LoneStriker/Nous-Hermes-2-SUS-Chat-34B-Slerp-6.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "AIGym/deepseek-coder-1.3b-chat-and-function-calling": [
    "model.safetensors"
  ],
  "SergeiZu/llama-2-7b-sentiment-0-20000": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "BEE-spoke-data/beecoder-220M-python": [
    "model.safetensors"
  ],
  "impossibleexchange/pt2": [
    "model.safetensors"
  ],
  "mitnamin/codeparrot-ds": [
    "model.safetensors"
  ],
  "LoneStriker/Nous-Hermes-2-SUS-Chat-34B-Slerp-8.0bpw-h8-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-indef_articles_with_pl_nouns-removal-seed_1024-3e-4": [
    "model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-aann-no_prototypical-seed_1024-3e-4": [
    "model.safetensors"
  ],
  "NobodyExistsOnTheInternet/GiftedMistralSysmsgTest4": [
    "adapter_model.safetensors"
  ],
  "impossibleexchange/pt3": [
    "model.safetensors"
  ],
  "impossibleexchange/pt4": [
    "model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-aann-prototypical_only-seed_1024-1e-3": [
    "model.safetensors"
  ],
  "NeverSleep/SOLAR-Maid-4x10.7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "lucasbiagettia/gpt2-base-borges": [
    "model.safetensors"
  ],
  "adamo1139/LLaMa-30B-AEZAKMI-v2-LoRA": [
    "adapter_model.safetensors"
  ],
  "c1park/init-test": [
    "model-00001-of-00033.safetensors",
    "model-00002-of-00033.safetensors",
    "model-00003-of-00033.safetensors",
    "model-00004-of-00033.safetensors",
    "model-00005-of-00033.safetensors",
    "model-00006-of-00033.safetensors",
    "model-00007-of-00033.safetensors",
    "model-00008-of-00033.safetensors",
    "model-00009-of-00033.safetensors",
    "model-00010-of-00033.safetensors",
    "model-00011-of-00033.safetensors",
    "model-00012-of-00033.safetensors",
    "model-00013-of-00033.safetensors",
    "model-00014-of-00033.safetensors",
    "model-00015-of-00033.safetensors",
    "model-00016-of-00033.safetensors",
    "model-00017-of-00033.safetensors",
    "model-00018-of-00033.safetensors",
    "model-00019-of-00033.safetensors",
    "model-00020-of-00033.safetensors",
    "model-00021-of-00033.safetensors",
    "model-00022-of-00033.safetensors",
    "model-00023-of-00033.safetensors",
    "model-00024-of-00033.safetensors",
    "model-00025-of-00033.safetensors",
    "model-00026-of-00033.safetensors",
    "model-00027-of-00033.safetensors",
    "model-00028-of-00033.safetensors",
    "model-00029-of-00033.safetensors",
    "model-00030-of-00033.safetensors",
    "model-00031-of-00033.safetensors",
    "model-00032-of-00033.safetensors",
    "model-00033-of-00033.safetensors"
  ],
  "Sosnitskij/ALMA-Kimiko_13B": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Jaehyeon222/M-SOLAR-10.7B-v1.0-DPO": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "zfchen/zephyr-7b-sft-full": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "impossibleexchange/pt5": [
    "model.safetensors"
  ],
  "yoonyoon/mm-model-DPO-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Mihaiii/Pallas-0.5-frankenmerge": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "Yarofa/pretraining_1": [
    "model.safetensors"
  ],
  "bernaferrari/merge_and_unload": [
    "model.safetensors"
  ],
  "Alexx34/key1": [
    "model.safetensors"
  ],
  "Guilherme34/SamanthaCode-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Alexx34/key2": [
    "model.safetensors"
  ],
  "wang1yi/llama-2-7b-wy": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Alexx34/key4": [
    "model.safetensors"
  ],
  "Alexx34/key5": [
    "model.safetensors"
  ],
  "Alexx34/key6": [
    "model.safetensors"
  ],
  "Alexx34/key7": [
    "model.safetensors"
  ],
  "Alexx34/key8": [
    "model.safetensors"
  ],
  "Alexx34/key9": [
    "model.safetensors"
  ],
  "Alexx34/key10": [
    "model.safetensors"
  ],
  "zfchen/zephyr-7b-sft-lora": [
    "adapter_model.safetensors"
  ],
  "rombodawg/Open_Gpt4_8x7B_v0.1": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "ifuseok/sft-solar-10.7b-v1.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "OpenLLMAI/Llama-2-13b-sft-model-ocra-500k": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Aekanun/openthaigpt-MedChatModel-20sampling": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "elliotthwang/KimLam-Mistral-7B-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5": [
    "model.safetensors"
  ],
  "daniellnichols/spack-llama-13b": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "EmbeddedLLM/Mistral-7B-Merge-14-v0.3-ft-step-15936": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow0": [
    "model.safetensors"
  ],
  "kimnt93/chatmodel-exp-01": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "IbuNai/mixtral-ja-base-8x7b-v0.1": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "Khushal24/DialoGPT-medium-Rickbot": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow1": [
    "model.safetensors"
  ],
  "Alexx34/key3": [
    "model.safetensors"
  ],
  "mohitcharkha/Mistral-7B-Instruct-v0.2-finetune-Exp-3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "elliotthwangmsa/KimLan_mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "WYNN747/Burmese-GPT": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow2": [
    "model.safetensors"
  ],
  "namanyash/llama-2-7b-miniplatypus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Envoid/Augmentasanguis-8x7B": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "parasora/tinycodellama-jp-0.3b-20k-5e5": [
    "model.safetensors"
  ],
  "malhajar/Mistral-7B-v0.2-meditron-turkish": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "code0x2/pretraining": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow3": [
    "model.safetensors"
  ],
  "NaoS2/tinycodellama-jp-0.6b-20k-v3": [
    "model.safetensors"
  ],
  "TencentARC/LLaMA-Pro-8B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ohyay12345/peanutmode": [
    "model.safetensors"
  ],
  "Kooltek68/sn9_153": [
    "model.safetensors"
  ],
  "Kooltek68/sn9_163": [
    "model.safetensors"
  ],
  "Kooltek68/sn9_152": [
    "model.safetensors"
  ],
  "Alexx34/key11": [
    "model.safetensors"
  ],
  "Alexx34/key12": [
    "model.safetensors"
  ],
  "ohyay12345/peanutmode1": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow4": [
    "model.safetensors"
  ],
  "ohyay12345/peanutmode2": [
    "model.safetensors"
  ],
  "hossr/model11": [
    "model.safetensors"
  ],
  "hossr/model12": [
    "model.safetensors"
  ],
  "ohyay12345/peanutmode3": [
    "model.safetensors"
  ],
  "retinol/llama-2-7b-psy-chat": [
    "adapter_model.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ohyay12345/peanutmode4": [
    "model.safetensors"
  ],
  "hossr/model13": [
    "model.safetensors"
  ],
  "ohyay12345/peanutmode5": [
    "model.safetensors"
  ],
  "hossr/model14": [
    "model.safetensors"
  ],
  "ohyay12345/peanutmode6": [
    "model.safetensors"
  ],
  "hossr/model15": [
    "model.safetensors"
  ],
  "ohyay12345/peanutmode7": [
    "model.safetensors"
  ],
  "ohyay12345/peanutmode8": [
    "model.safetensors"
  ],
  "hossr/model16": [
    "model.safetensors"
  ],
  "ohyay12345/peanutmode9": [
    "model.safetensors"
  ],
  "hossr/model17": [
    "model.safetensors"
  ],
  "ohyay12345/peanutmode10": [
    "model.safetensors"
  ],
  "hossr/model18": [
    "model.safetensors"
  ],
  "ohyay12345/peanutmode11": [
    "model.safetensors"
  ],
  "ohyay12345/peanutmode12": [
    "model.safetensors"
  ],
  "hossr/model19": [
    "model.safetensors"
  ],
  "ohyay12345/peanutmode14": [
    "model.safetensors"
  ],
  "realPCH/ko_solra_orca_v0": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "hossr/model20": [
    "model.safetensors"
  ],
  "hossr/model21": [
    "model.safetensors"
  ],
  "hossr/model22": [
    "model.safetensors"
  ],
  "hossr/model23": [
    "model.safetensors"
  ],
  "DopeorNope/Mistralopithecus-10.7B": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "hossr/model24": [
    "model.safetensors"
  ],
  "ohyay12345/peanutmode21111": [
    "model.safetensors"
  ],
  "mithlesh/autotrain-llama2-propellyr": [
    "adapter_model.safetensors",
    "checkpoint-81/adapter_model.safetensors"
  ],
  "relaxml/Llama-2-70b-E8PRVQ-4Bit": [
    "model-00001-of-00004.safetensors",
    "model-00001-of-00008.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00004.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow5": [
    "model.safetensors"
  ],
  "ubuntn/codegen-350M-mono-python-18k-alpaca": [
    "model.safetensors"
  ],
  "relaxml/Llama-2-70b-chat-E8PRVQ-4Bit": [
    "model-00001-of-00004.safetensors",
    "model-00001-of-00008.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00004.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "kimmypracha/llama-marunashop-v2-a100-2115": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "NLPProject2023Z/xlnet-pretrained": [
    "model.safetensors"
  ],
  "dustydecapod/Jovian-10.7B-v1.0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "0x7o/nanoFialka-v1": [
    "model.safetensors"
  ],
  "relaxml/Llama-2-13b-E8PRVQ-4Bit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors",
    "model.safetensors"
  ],
  "relaxml/Llama-2-13b-chat-E8PRVQ-4Bit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors",
    "model.safetensors"
  ],
  "relaxml/Llama-2-7b-E8PRVQ-4Bit": [
    "model.safetensors"
  ],
  "relaxml/Llama-2-7b-chat-E8PRVQ-4Bit": [
    "model.safetensors"
  ],
  "relaxml/Llama-1-65b-E8PRVQ-4Bit": [
    "model-00001-of-00004.safetensors",
    "model-00001-of-00007.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00004.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow6": [
    "model.safetensors"
  ],
  "Federic/merged_model": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "relaxml/Llama-1-30b-E8PRVQ-4Bit": [
    "model-00001-of-00002.safetensors",
    "model-00001-of-00004.safetensors",
    "model-00002-of-00002.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "uukuguy/speechless-mistral-moloras-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "yoonyoon/mm-model-DPO-v0.2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "relaxml/Llama-1-13b-E8PRVQ-4Bit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors",
    "model.safetensors"
  ],
  "relaxml/Llama-1-7b-E8PRVQ-4Bit": [
    "model.safetensors"
  ],
  "xingyaoww/CodeActAgent-Mistral-7b-v0.1": [
    "model.safetensors"
  ],
  "relaxml/Mistral-7b-E8PRVQ-4Bit": [
    "model.safetensors"
  ],
  "relaxml/Openhermes-7b-E8PRVQ-4Bit": [
    "model.safetensors"
  ],
  "kkuramitsu/tinycodellama-jp-0.13b-50k": [
    "model.safetensors"
  ],
  "khaimaitien/leetcode_solver_7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow7": [
    "model.safetensors"
  ],
  "notbdq/mistral-turkish": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "minz27/recipe_gpt": [
    "model.safetensors"
  ],
  "soketlabs/Indic-Llama-2-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Ba2han/Tinypus-1.5B": [
    "model.safetensors"
  ],
  "UCLA-AGI/zephyr-7b-sft-full-SPIN-iter2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mtc/mistralai-Mistral-7B-v0.1-arxiv-summarization-100-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mlabonne/Beyonder-4x7B-v2": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "avemio-digital/phi2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "xingyaoww/CodeActAgent-Llama-2-7b": [
    "model.safetensors"
  ],
  "TheBloke/Iambe-RP-DARE-20B-DENSE-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Iambe-RP-DARE-20B-DENSE-GPTQ": [
    "model.safetensors"
  ],
  "cloudyu/Mixtral_34Bx2_MoE_60B": [
    "model-00001-of-00013.safetensors",
    "model-00002-of-00013.safetensors",
    "model-00003-of-00013.safetensors",
    "model-00004-of-00013.safetensors",
    "model-00005-of-00013.safetensors",
    "model-00006-of-00013.safetensors",
    "model-00007-of-00013.safetensors",
    "model-00008-of-00013.safetensors",
    "model-00009-of-00013.safetensors",
    "model-00010-of-00013.safetensors",
    "model-00011-of-00013.safetensors",
    "model-00012-of-00013.safetensors",
    "model-00013-of-00013.safetensors"
  ],
  "SergeiZu/llama-2-7b-sentiment-0-30000": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mtc/meta-llama-Llama-2-7b-hf-pubmed-summarization-1000-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "nlpguy/Hermes-low-tune-2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Norobara-ZLoss-8x7B-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Norobara-ZLoss-8x7B-GPTQ": [
    "model.safetensors"
  ],
  "alinourian/GPT2-SemEval2023": [
    "model.safetensors"
  ],
  "HelloJiang/ConvLLaVA-512-v0.1": [
    "adapter_model.safetensors"
  ],
  "Danxtshake/labelingLLaMA_40s": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "reasonwang/Llama-2-13b-ACP": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "reasonwang/Llama-2-13b-A": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "hiraltalsaniya/test-llama2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "reasonwang/Llama-2-13b-C": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ubuntn/gathllama-2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "impossibleexchange/pt6": [
    "model.safetensors"
  ],
  "reasonwang/Llama-2-13b-AC": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Deathsquad10/TinyLlama-1.1B-Remix-V.2": [
    "model.safetensors"
  ],
  "reasonwang/Llama-2-13b-AP": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "malhajar/Mistral-7B-Instruct-v0.2-turkish": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "reasonwang/Llama-2-13b-CP": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "impossibleexchange/pt7": [
    "model.safetensors"
  ],
  "LoneStriker/Norobara-ZLoss-8x7B-2.4bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "edfraga/diablo_gpt": [
    "model.safetensors"
  ],
  "igorwang/mistral-7b-bnb-4bit-citecls": [
    "model.safetensors"
  ],
  "LoneStriker/Norobara-ZLoss-8x7B-3.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "impossibleexchange/pt8": [
    "model.safetensors"
  ],
  "nthngdy/pythia160m-2.5k-rp": [
    "model.safetensors"
  ],
  "LoneStriker/Norobara-ZLoss-8x7B-3.5bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "TheBloke/Kunoichi-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Kunoichi-7B-AWQ": [
    "model.safetensors"
  ],
  "ciaranmacseoin/Blindbot-test": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "impossibleexchange/pt9": [
    "model.safetensors"
  ],
  "LoneStriker/Norobara-ZLoss-8x7B-3.75bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "s3nh/Mistral_Sonyichi-7B-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jondurbin/bagel-8x7b-v0.2": [
    "model-00001-of-00024.safetensors",
    "model-00002-of-00024.safetensors",
    "model-00003-of-00024.safetensors",
    "model-00004-of-00024.safetensors",
    "model-00005-of-00024.safetensors",
    "model-00006-of-00024.safetensors",
    "model-00007-of-00024.safetensors",
    "model-00008-of-00024.safetensors",
    "model-00009-of-00024.safetensors",
    "model-00010-of-00024.safetensors",
    "model-00011-of-00024.safetensors",
    "model-00012-of-00024.safetensors",
    "model-00013-of-00024.safetensors",
    "model-00014-of-00024.safetensors",
    "model-00015-of-00024.safetensors",
    "model-00016-of-00024.safetensors",
    "model-00017-of-00024.safetensors",
    "model-00018-of-00024.safetensors",
    "model-00019-of-00024.safetensors",
    "model-00020-of-00024.safetensors",
    "model-00021-of-00024.safetensors",
    "model-00022-of-00024.safetensors",
    "model-00023-of-00024.safetensors",
    "model-00024-of-00024.safetensors"
  ],
  "TheBloke/Mixtral_11Bx2_MoE_19B-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Mixtral_11Bx2_MoE_19B-GPTQ": [
    "model.safetensors"
  ],
  "LoneStriker/Norobara-ZLoss-8x7B-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "nthngdy/hythia160m-2.5k-rp-bs16-lr6e-5-nowt": [
    "model.safetensors"
  ],
  "impossibleexchange/pt10": [
    "model.safetensors"
  ],
  "impossibleexchange/pt11": [
    "model.safetensors"
  ],
  "mtc/upstage-SOLAR-10.7B-v1.0-classification-with-mixtral-explanation-3-epochs-finetuned": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "LoneStriker/Norobara-ZLoss-8x7B-5.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "hiraltalsaniya/llama2-7b-fine-tune": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "impossibleexchange/pt12": [
    "model.safetensors"
  ],
  "LoneStriker/Norobara-ZLoss-8x7B-6.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "jojo-ai-mst/MyanmarGPT-Big": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TalFloren/gpt2-imdb-pos-v2": [
    "model.safetensors"
  ],
  "LoneStriker/Kunoichi-7B-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Kunoichi-7B-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Kunoichi-7B-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Kunoichi-7B-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "AzureBlack/WinterGoddess-1.4x-70B-L2-3bpw-6h-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "LoneStriker/Mistral-7B-Instruct-v0.2-code-ft-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Kunoichi-7B-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Mistral-7B-Instruct-v0.2-code-ft-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Mistral-7B-Instruct-v0.2-code-ft-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Mistral-7B-Instruct-v0.2-code-ft-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "debapratimj/mistral-7b-finetuned-initial-50": [
    "adapter_model.safetensors",
    "checkpoint-2/adapter_model.safetensors"
  ],
  "LoneStriker/Mistral-7B-Instruct-v0.2-code-ft-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "TheBloke/Beyonder-4x7B-v2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Beyonder-4x7B-v2-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Rosa_v2_7B-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "Walmart-the-bag/zephyr-quiklang-3b": [
    "model.safetensors"
  ],
  "tanj85/test-model": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Rosa_v2_7B-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Rosa_v2_7B-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "aari1995/germeo-7b-awq": [
    "model.safetensors"
  ],
  "LoneStriker/Iambe-RP-DARE-20b-DENSE-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Rosa_v2_7B-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "xkfisher/starcoderplus-ft": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "LoneStriker/Rosa_v2_7B-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Iambe-RP-DARE-20b-DENSE-6.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/Iambe-RP-DARE-20b-DENSE-5.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/Iambe-RP-DARE-20b-DENSE-4.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "debapratimj/mistral-7b-finetuned-initial-30": [
    "adapter_model.safetensors",
    "checkpoint-60/adapter_model.safetensors"
  ],
  "LoneStriker/Iambe-RP-DARE-20b-DENSE-8.0bpw-h8-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "nsfwthrowitaway69/Venus-120b-v1.2": [
    "model-00001-of-00025.safetensors",
    "model-00002-of-00025.safetensors",
    "model-00003-of-00025.safetensors",
    "model-00004-of-00025.safetensors",
    "model-00005-of-00025.safetensors",
    "model-00006-of-00025.safetensors",
    "model-00007-of-00025.safetensors",
    "model-00008-of-00025.safetensors",
    "model-00009-of-00025.safetensors",
    "model-00010-of-00025.safetensors",
    "model-00011-of-00025.safetensors",
    "model-00012-of-00025.safetensors",
    "model-00013-of-00025.safetensors",
    "model-00014-of-00025.safetensors",
    "model-00015-of-00025.safetensors",
    "model-00016-of-00025.safetensors",
    "model-00017-of-00025.safetensors",
    "model-00018-of-00025.safetensors",
    "model-00019-of-00025.safetensors",
    "model-00020-of-00025.safetensors",
    "model-00021-of-00025.safetensors",
    "model-00022-of-00025.safetensors",
    "model-00023-of-00025.safetensors",
    "model-00024-of-00025.safetensors",
    "model-00025-of-00025.safetensors"
  ],
  "Aleereza/tinnyllama_prtokenizer_sum": [
    "model.safetensors"
  ],
  "Blofeld/autotrain-xc3z6-xnfb8": [
    "adapter_model.safetensors",
    "checkpoint-106/adapter_model.safetensors"
  ],
  "mtc/mistralai-Mistral-7B-v0.1-pubmed-summarization-5000-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "debapratimj/mistral-7b-finetuned-initial-100": [
    "adapter_model.safetensors",
    "checkpoint-200/adapter_model.safetensors"
  ],
  "malhajar/Mistral-7B-v0.2-meditron-turkish-chat": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Mixtral-8x7B-Instruct-v0.1-LimaRP-ZLoss-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Mixtral-8x7B-Instruct-v0.1-LimaRP-ZLoss-GPTQ": [
    "model.safetensors"
  ],
  "mtc/meta-llama-Llama-2-7b-hf-pubmed-summarization-5000-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "chuducandev/Llama-2-7b-chat-hf-004": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "chuducandev/Llama-2-7b-chat-hf-005": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "chuducandev/Llama-2-7b-chat-hf-006": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/bagel-8x7b-v0.2-3.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "sambar/zephyr-7b-ipo-lora-5ep": [
    "adapter_model.safetensors"
  ],
  "Yunong/mistral-openpi_v2_llm_tasks": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "NeverSleep/Noromaid-13b-v0.3": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/bagel-8x7b-v0.2-3.5bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/bagel-8x7b-v0.2-6.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "dillfrescott/amadeus-v0.1": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "mtc/mistralai-Mistral-7B-v0.1-arxiv-summarization-5000-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mtc/meta-llama-Llama-2-7b-hf-arxiv-summarization-5000-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/bagel-8x7b-v0.2-3.75bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "innaskarbovsky/mistral_full": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/bagel-8x7b-v0.2-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/LLaMA-Pro-8B-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/bagel-8x7b-v0.2-5.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "LoneStriker/LLaMA-Pro-8B-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "llm-blender/PairRM-hf": [
    "model.safetensors"
  ],
  "LoneStriker/LLaMA-Pro-8B-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/LLaMA-Pro-8B-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/LLaMA-Pro-8B-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "TheBloke/phi-2-dpo-GPTQ": [
    "model.safetensors"
  ],
  "MwangiNelson/NutriBot": [
    "model.safetensors"
  ],
  "AIGym/deepseek-coder-6.7b-chat": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Mistral-7B-Instruct-v0.2-code-ft-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Mistral-7B-Instruct-v0.2-code-ft-AWQ": [
    "model.safetensors"
  ],
  "potoftea/SeranaLlama-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "s3nh/NousHermes-Kunoichi-SolarMaid-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Rich-J/key7": [
    "model.safetensors"
  ],
  "TheBloke/Rosa_v2_7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Rosa_v2_7B-GPTQ": [
    "model.safetensors"
  ],
  "Azazelle/Yuna-7b-Merge": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Neuronovo/neuronovo-9B-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Kquant03/MistralTrix-4x9B-MoE-ERP": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "s3nh/Hermes-SolarMaid-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-indef-anan-seed_1024-3e-4": [
    "model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-indef-naan-rerun-seed_1024-1e-3": [
    "model.safetensors"
  ],
  "gagan3012/MetaModelv3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Anarchist/llama-instruct-wizard-orca": [
    "model.safetensors"
  ],
  "decapoda-research/Adrastea-7b-v1.0-dpo-lora": [
    "adapter_model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-adj_num_freq_balanced-seed_1024-1e-4": [
    "model.safetensors"
  ],
  "TheBloke/Open_Gpt4_8x7B-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Open_Gpt4_8x7B-GPTQ": [
    "model.safetensors"
  ],
  "gagan3012/MetaModel_moe": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "tenyx/TenyxChat-7B-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "yihang7/zephyr-7b-dpo-lora": [
    "adapter_model.safetensors"
  ],
  "issue89/DialoGPT-large-bender": [
    "model.safetensors"
  ],
  "gagan3012/MetaModel_arabic": [
    "model-00001-of-00002.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00002.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "obrmmk/tinycodellama-jp-1.3b-20k": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "nicesen/sen-llama": [
    "adapter_model.safetensors"
  ],
  "gosandhyag/dolphin-2.2.1-mistral-7b-sharded-finetuned-contracts": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "HwiyeolJo/TeamJaeCorpo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Masterjp123/NeuralMaid-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Neuronovo/neuronovo-9B-v0.2": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "smckay42/pretraining": [
    "model.safetensors"
  ],
  "RaiBP/gpt2-openwebtext2-first-30-chunks-ablation-full": [
    "model.safetensors"
  ],
  "Masterjp123/Clover3-13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "gqd/mistral-merge-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "douy/parrot-llama-2-13B-epoch3": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "TencentARC/LLaMA-Pro-8B-Instruct": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Edentns/DataVortexS-10.7B-v0.3": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "MediaTek-Research/Breeze-7B-Instruct-v0_1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MediaTek-Research/Breeze-7B-Base-v0_1": [
    "model.safetensors"
  ],
  "Anarchist/llama-bad-roleplay": [
    "model.safetensors"
  ],
  "ONS-AI-RESEARCH/ONS-SOLAR-10.7B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "AlignmentLab-AI/teensyorca": [
    "model.safetensors"
  ],
  "Sao10K/Sensualize-Solar-10.7B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "decapoda-research/Adrastea-7b-v1.0-dpo": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "lucyknada/Mistral-7B-v0.1-exl2-5bpw": [
    "output.safetensors"
  ],
  "lucyknada/Mistral-7B-v0.1-exl2-3bpw": [
    "output.safetensors"
  ],
  "lucyknada/Mistral-7B-v0.1-exl2-2bpw": [
    "output.safetensors"
  ],
  "J-Kessler/tinyLatinLlama": [
    "adapter_model.safetensors"
  ],
  "Yash21/DeepYi-Base": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MrezaPRZ/SQL_Sorcerer_6.7B_V1.0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Yash21/DeepYi-Second": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "proto-llm/uniwiz-7B-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Yash21/TinyYi-7B-Test": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Imran1/Z_base": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "windmaple/NeuralHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheOriginalMarcelo/llama-2-7benem_comp_2k23": [
    "adapter_model.safetensors",
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "PerRing/Yi-Ko-6x2B-v1": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "thanhnew2001/starcoder-3b-taipy22": [
    "model.safetensors"
  ],
  "Aleereza/tinnyllama_prtokenizer_mean_4": [
    "model.safetensors"
  ],
  "tutos69/LLM2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TinyPixel/gpt2-7m": [
    "model.safetensors"
  ],
  "jondurbin/bagel-1.1b-v0.3": [
    "model.safetensors"
  ],
  "jondurbin/bagel-dpo-1.1b-v0.3": [
    "model.safetensors"
  ],
  "TinyPixel/sml": [
    "model.safetensors"
  ],
  "parasora/tinycodellama-jp-0.3b-25k-5e5": [
    "model.safetensors"
  ],
  "TinyPixel/sml-2": [
    "model.safetensors"
  ],
  "andreaschandra/gpt2-finetune-id-review-gen": [
    "model.safetensors"
  ],
  "brucethemoose/jondurbin_bagel-dpo-34b-v0.2-exl2-6bpw-fiction": [
    "output-00001-of-00007.safetensors",
    "output-00002-of-00007.safetensors",
    "output-00003-of-00007.safetensors",
    "output-00004-of-00007.safetensors",
    "output-00005-of-00007.safetensors",
    "output-00006-of-00007.safetensors",
    "output-00007-of-00007.safetensors"
  ],
  "HenryJJ/Instruct_Yi-6B_Dolly15K": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "star-inc/machina": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Deathsquad10/TinyLlama-repeat": [
    "model.safetensors"
  ],
  "TinyPixel/sml-3": [
    "model.safetensors"
  ],
  "brucethemoose/SUS-Bagel-200K-DARE-Test": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "MoEMoEKKung/Frankenstein-MoE-en-10.7Bx4": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "MoEMoEKKung/Frankenstein-MoE-en-10.7Bx6": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "MoEMoEKKung/Frankenstein-MoE-ko-10.7Bx4": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "PerRing/phi-2x2-v0.0": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/zephyr-quiklang-3b-GPTQ": [
    "model.safetensors"
  ],
  "roleplay4fun/staticpunch-v1.0": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "s3nh/Medicine-Noromaid-13b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hossr/model25": [
    "model.safetensors"
  ],
  "hossr/model26": [
    "model.safetensors"
  ],
  "hossr/model27": [
    "model.safetensors"
  ],
  "hossr/model28": [
    "model.safetensors"
  ],
  "sethuiyer/Dr_Samantha_7b_mistral": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "fubuki119/AIEnigmaGPT": [
    "model.safetensors"
  ],
  "TheBloke/LLaMA-Pro-8B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/LLaMA-Pro-8B-GPTQ": [
    "model.safetensors"
  ],
  "kodonho/llama2-chat-koalpaca": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "isaiahbjork/tinyllama-function-calling-v0.1-merge": [
    "model.safetensors"
  ],
  "Imran1/S_DPO": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "s3nh/Finance-Noromaid-13b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Felladrin/Pythia-31M-Chat-v1": [
    "model.safetensors"
  ],
  "elliotthwang/KimLam-Mistral-7B-v0.1_U": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "parsak/mistral-code-7b-instruct": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "santoshdahal/Mistral-7B-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Bronco92/autotrain-0yrvj-oe8wk": [
    "adapter_model.safetensors",
    "checkpoint-210/adapter_model.safetensors"
  ],
  "Manoj21k/microsoft-phi-2-finetuned": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Aloksik/llama-2-7b-domain-tuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jungiebeen/pretrain1": [
    "model.safetensors"
  ],
  "chuducandev/Llama-2-7b-chat-hf-007": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "chuducandev/Llama-2-7b-chat-hf-008": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Herry443/Mistral-7B-KNUT-ref": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "chuducandev/Llama-2-7b-chat-hf-009": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "JD97/test": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Wanfq/distillchat_teacher_training_1.7.9_0.95hd": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Wanfq/distillchat_teacher_training_1.7.9_0.95h": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Yunong/mistral-openpi_v2_llm_tasks_random_order": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TinyPixel/qwen-1.8B-OrcaMini": [
    "model.safetensors"
  ],
  "Yunong/mistral-openpi_v2_llm_tasks_fill_with_other_steps": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Bronco92/autotrain-v1h4e-o0y1r": [
    "adapter_model.safetensors",
    "checkpoint-336/adapter_model.safetensors"
  ],
  "Wanfq/distillchat_teacher_training_1.7.9_0.9hd": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "nlpguy/Hermes-low-tune-3": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Mxode/Meow-bloom-346m-v0.1": [
    "model.safetensors"
  ],
  "mlabonne/NeuralMarcoro14-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mtc/mistralai-Mistral-7B-v0.1-pubmed-summarization-5000-finetuned-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "detakarang/Phixphi-4x2.7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "pops-team/bittensor": [
    "model.safetensors"
  ],
  "nlpguy/Lelantos-low-tune": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "hossr/mode21": [
    "model.safetensors"
  ],
  "hossr/mode22": [
    "model.safetensors"
  ],
  "NaoS2/tinycodellama-jp-0.6b-30k-v2": [
    "model.safetensors"
  ],
  "shadowml/Daredevil-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "AIGym/deepseek-coder-6.7b-chat-and-function-calling": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "rmm4pi8/gpt2-wikitext2": [
    "model.safetensors"
  ],
  "vorushin/NeuralHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AlaGrine/distilgpt2-finetuned-3GPP-5G": [
    "model.safetensors"
  ],
  "mhenrichsen/danskgpt-tiny-chat": [
    "model.safetensors"
  ],
  "danj0nes/dropout_gpt2": [
    "model.safetensors"
  ],
  "occultml/CatMarcoro14-7B-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jackoyoungblood/GPT2_Original2": [
    "model.safetensors"
  ],
  "dnoever/zephyr-7b-beta-exl2": [
    "cal_data.safetensors",
    "output.safetensors"
  ],
  "crumb/shrink-v1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Danielbrdz/Barcenas-Mixtral-8x7b-4bit": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ucsahin/distilgpt2-eli5": [
    "model.safetensors"
  ],
  "dnoever/MistralTrix-v1-5.0bpw-exl2": [
    "cal_data.safetensors",
    "hidden_states.safetensors",
    "output.safetensors"
  ],
  "Baharak/codegen-350M-mono-python-18k-alpaca": [
    "model.safetensors"
  ],
  "NickyNicky/TinyLlama-1.1B-Chat-v1.0_Ultra_mini_OpenOrca_V1": [
    "model.safetensors"
  ],
  "SuYee189/wiki_bloom": [
    "model.safetensors"
  ],
  "xaviviro/FLOR-6.3B-xat": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Pallas-0.5-frankenmerge-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Pallas-0.5-frankenmerge-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/bagel-8x7b-v0.2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/bagel-8x7b-v0.2-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Minata/reduced_ast_method2test-codegen-350M_v1": [
    "model.safetensors"
  ],
  "cibernicola/FLOR-6.3B-xat-Q8_0": [],
  "jeiku/Refined_3B": [
    "model-00001-of-00001.safetensors"
  ],
  "jilp00/Hermes-2-SOLAR-10.7B-Symbolic": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "ambrosfitz/TinyLlama-1.1B-Chat-yawp": [
    "model.safetensors"
  ],
  "seank0602/mythic-test-1": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "bhavinjawade/SOLAR-10B-OrcaDPO-Jawade": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "broskicodes/simple-stories-4M": [
    "model.safetensors"
  ],
  "ohyay12345/slavemodel": [
    "model.safetensors"
  ],
  "ohyay12345/slavemode2": [
    "model.safetensors"
  ],
  "dnoever/v1olet_merged_dpo_7B-5.0bpw-exl2": [
    "cal_data.safetensors",
    "hidden_states.safetensors",
    "output.safetensors"
  ],
  "mlabonne/Daredevil-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "alexredna/TinyLlama-1.1B-Chat-v1.0-reasoning-v2-dpo": [
    "model.safetensors"
  ],
  "TheBloke/zephyr-quiklang-3b-4K-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Sensualize-Solar-10.7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Sensualize-Solar-10.7B-AWQ": [
    "model.safetensors"
  ],
  "s3nh/nsfw-noromaid-mistral": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "impossibleexchange/pt15": [
    "model.safetensors"
  ],
  "TheBloke/sonya-medium-x8-MoE-GPTQ": [
    "model.safetensors"
  ],
  "simbolo-ai/Myanmarsar-GPT": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors",
    "model.safetensors"
  ],
  "dnoever/Falkor-7b-5.0bpw-exl2": [
    "cal_data.safetensors",
    "hidden_states.safetensors",
    "output.safetensors"
  ],
  "AswanthCManoj/azma-tinyllama-instruct": [
    "model.safetensors"
  ],
  "Rapiiidooo/rapiiidooo-sn-9-model-0": [
    "model.safetensors"
  ],
  "Rapiiidooo/rapiiidooo-sn-9-model-1": [
    "model.safetensors"
  ],
  "Rapiiidooo/rapiiidooo-sn-9-model-2": [
    "model.safetensors"
  ],
  "impossibleexchange/pt14": [
    "model.safetensors"
  ],
  "elijahww/mistral-test2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "carlosaguayo/NeuralHermes-2.5-Mistral-7B-small": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "gnsepili/phi-1_5-finetuned-code": [
    "adapter_model.safetensors"
  ],
  "WYNN747/Burmese-GPT-v3": [
    "model.safetensors"
  ],
  "yoonyoon/kb_v1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "yoonyoon/kb_v1.1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Kooten/Noromaid-13b-v0.3-8bpw-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Kooten/Noromaid-13b-v0.3-6bpw-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Kooten/Noromaid-13b-v0.3-5bpw-exl2": [
    "output.safetensors"
  ],
  "Kooten/Noromaid-13b-v0.3-4bpw-exl2": [
    "output.safetensors"
  ],
  "BEE-spoke-data/TinyLlama-3T-1.1bee": [
    "model.safetensors"
  ],
  "Wanfq/distillchat_teacher_training_dus_5e-6lr_1ep": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Wanfq/distillchat_teacher_training_dus_2e-6lr_1ep": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "dnoever/Sakura-SOLAR-Instruct-5.0bpw-exl2": [
    "cal_data.safetensors",
    "hidden_states.safetensors",
    "output.safetensors"
  ],
  "xaviviro/FLOR-1.3B-xat": [
    "model.safetensors"
  ],
  "STEM-AI-mtl/phi-2-electrical-engineering": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "noahtren/phi-2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "HenryJJ/Instruct_Yi-6B_Dolly_CodeAlpaca": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "elliotthwangmsa/KimLan_TinyLlama": [
    "model.safetensors"
  ],
  "ohyay12345/needthistoworkplsimpoor": [
    "model.safetensors"
  ],
  "UCLA-AGI/zephyr-7b-sft-full-SPIN-iter3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "fxmeng/llava-mistral-7b-instruct-v0.2": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "JacobS123/DiabloGPT-small-Cassidy": [
    "checkpoint-10500/model.safetensors",
    "checkpoint-3500/model.safetensors",
    "checkpoint-7000/model.safetensors",
    "model.safetensors"
  ],
  "dnoever/SamirGPT-v1-5.0bpw-exl2": [
    "cal_data.safetensors",
    "hidden_states.safetensors",
    "output.safetensors"
  ],
  "zentechy/test_hf_id": [
    "model.safetensors"
  ],
  "la-min/gpt-2-health-faq": [
    "model.safetensors"
  ],
  "hossr/mode24": [
    "model.safetensors"
  ],
  "seank0602/llama13b-merge-green": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Wanfq/distillchat_teacher_training_dus_5e-6lr_3ep": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Wanfq/distillchat_teacher_training_dus_2e-6lr_3ep": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Ayush2312/llama2-7B-1k-TherapyData": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "shindesarang59/llama-2-7b-miniplatypus-testsarang": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dnoever/CatPPT-base-5.0bpw-exl2": [
    "cal_data.safetensors",
    "hidden_states.safetensors",
    "output.safetensors"
  ],
  "yoonyoon/kb_v1_paul": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "papahawk/devi-7b": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "gagan3012/MetaModel_moe_multilingualv1": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "BEE-spoke-data/smol_llama-220M-bees-internal": [
    "model.safetensors"
  ],
  "meto/llama-2-7b-miniplatypus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Luv91/llama-2-7b-miniplatypus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hiiamsid/yi_4k_paged_optimizer": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "amazingvince/chess-llama-smol-1024": [
    "model.safetensors"
  ],
  "ohyay12345/needthistoworkplsimpoor21": [
    "model.safetensors"
  ],
  "ohyay12345/needthistoworkplsimpoor11111": [
    "model.safetensors"
  ],
  "ohyay12345/needthistoworkplsimpoor212": [
    "model.safetensors"
  ],
  "hossr/mode230": [
    "model.safetensors"
  ],
  "hossr/mode231": [
    "model.safetensors"
  ],
  "danielhanchen/test2": [
    "model.safetensors"
  ],
  "amu/zen": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "chuducandev/Llama-2-7b-chat-hf-010": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ambrosfitz/tiny-llama-yawp-chat-v0.1": [
    "model.safetensors"
  ],
  "chuducandev/Llama-2-7b-chat-hf-011": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "chuducandev/Llama-2-7b-chat-hf-012": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hossr/mode232": [
    "model.safetensors"
  ],
  "chuducandev/Llama-2-7b-chat-hf-013": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Sharathhebbar24/llama_7b_chat": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ryandt/MusingCaterpillar": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "openchat/openchat-3.5-0106": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AswanthCManoj/azma-tinyllama-instruct-adapter": [
    "model.safetensors"
  ],
  "ohyay12345/IMSOPOORGHELP": [
    "model.safetensors"
  ],
  "R136a1/Sensualize-Solar-10.7B-exl2": [
    "output.safetensors"
  ],
  "HwiyeolJo/TeamJaeCorpo-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "danielhanchen/test3": [
    "model.safetensors"
  ],
  "nengyu/llama-2-7b-platypus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Trace2333/easy-prompt-interior-decoration": [
    "model.safetensors"
  ],
  "wilzh40/groove-merged-phi": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "aj30/finetuned-llama-2-test": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "andrewatef/myBloggerV0.5": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "OpenBuddy/openbuddy-deepseekcoder-33b-v16.1-32k": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "s3nh/nsfw-noromaid-zephyr": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mayflowergmbh/TinyLlama-1.1B-Chat-v1.0-german": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "bnurpek/gpt2-256t-nrwr-pos-0": [
    "model.safetensors"
  ],
  "bnurpek/gpt2-256t-nrwr-pos-1": [
    "model.safetensors"
  ],
  "bnurpek/gpt2-256t-nrwr-pos-2": [
    "model.safetensors"
  ],
  "bnurpek/gpt2-256t-nrwr-pos-3": [
    "model.safetensors"
  ],
  "fubuki119/JokesGPT": [
    "model.safetensors"
  ],
  "bnurpek/gpt2-256t-nrwr-pos-5": [
    "model.safetensors"
  ],
  "mii-llm/maestrale-chat-v0.1-alpha": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "bnurpek/gpt2-256t-nrwr-pos-7": [
    "model.safetensors"
  ],
  "bnurpek/gpt2-256t-nrwr-pos-10": [
    "model.safetensors"
  ],
  "rhysjones/phi-2-dpo-pairs": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "zentechy/pretrain-sn9-5": [
    "model.safetensors"
  ],
  "zentechy/pretrain-sn9-6": [
    "model.safetensors"
  ],
  "kishorsdfsaf/chat": [
    "adapter_model.safetensors",
    "checkpoint-4/adapter_model.safetensors"
  ],
  "NeuralNovel/Aeryth-7B-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "yoonyoon/polyglot-model-DPO-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "bnurpek/gpt2-256t-nrwr-pos-15": [
    "model.safetensors"
  ],
  "TheBloke/LLaMA-Pro-8B-Instruct-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/LLaMA-Pro-8B-Instruct-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Noromaid-13B-v0.3-AWQ": [
    "model.safetensors"
  ],
  "bnurpek/gpt2-256t-nrwr-pos-20": [
    "model.safetensors"
  ],
  "parasora/tinycodellama-jp-0.3b-30k-5e5": [
    "model.safetensors"
  ],
  "Herry443/Mistral-7B-KNUT-ref-100-HellaSWAG": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Noromaid-13B-v0.3-GPTQ": [
    "model.safetensors"
  ],
  "Muhammadreza/Nucleus-1B-GPTQ": [
    "model.safetensors"
  ],
  "elonmollusk/neuralogix-openhermes-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "elliotthwangmsa/KimLan_phi-2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "adsazad/sikhgpt": [
    "model.safetensors"
  ],
  "mtc/mistralai-Mistral-7B-v0.1-pubmed-summarization-5000-finetuned-quantization-final": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "aj30/finetuned-llama-2-test_v2": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "mtc/meta-llama-Llama-2-7b-hf-pubmed-summarization-5000-finetuned-quantization-final": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mtc/meta-llama-Llama-2-7b-hf-arxiv-summarization-5000-finetuned-quantization-final": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "bravemindai/2024-gui-llama2-7b-openapi": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mtc/mistralai-Mistral-7B-v0.1-arxiv-summarization-5000-finetuned-quantization-final": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kh-jalali/pythia410m-taylorswift-2000steps": [
    "final/model.safetensors",
    "model.safetensors"
  ],
  "KnutJaegersberg/MoMo-72B-4bit": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "s3nh/nsfw-noromaid-mistral-instruct": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow8": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow9": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow10": [
    "model.safetensors"
  ],
  "LoneStriker/Mixtral-8x7B-Instruct-v0.1-LimaRP-ZLoss-2.4bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow11": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow12": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow13": [
    "model.safetensors"
  ],
  "Fredithefish/Mynah-v0.1": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow14": [
    "model.safetensors"
  ],
  "LoneStriker/Mixtral-8x7B-Instruct-v0.1-LimaRP-ZLoss-3.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow15": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow16": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow17": [
    "model.safetensors"
  ],
  "sreeramajay/TinyLlama-1.1B-orca-v1.0": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow18": [
    "model.safetensors"
  ],
  "cibernicola/FLOR-6.3B-xat-Q5_K": [],
  "aloobun/falcon-1b-cot-t2": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow19": [
    "model.safetensors"
  ],
  "LoneStriker/Mixtral-8x7B-Instruct-v0.1-LimaRP-ZLoss-3.5bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "txus/NeuralHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow20": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow21": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow22": [
    "model.safetensors"
  ],
  "LoneStriker/Mixtral-8x7B-Instruct-v0.1-LimaRP-ZLoss-3.75bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow23": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow24": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow25": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow26": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow27": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow28": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow29": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow30": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow31": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow32": [
    "model.safetensors"
  ],
  "LoneStriker/Mixtral-8x7B-Instruct-v0.1-LimaRP-ZLoss-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "darshan8950/opt-350m_tuned": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow33": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow34": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow35": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow36": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow37": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow38": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow39": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow40": [
    "model.safetensors"
  ],
  "LoneStriker/Mixtral-8x7B-Instruct-v0.1-LimaRP-ZLoss-5.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "p1atdev/calm2-7b-chat-safetensors": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Mixtral-8x7B-Instruct-v0.1-LimaRP-ZLoss-6.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "elijahww/mistral-7b-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_non_member_shadow0": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_non_member_shadow1": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_non_member_shadow2": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_non_member_shadow3": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_non_member_shadow4": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_non_member_shadow5": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_non_member_shadow6": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_non_member_shadow7": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_non_member_shadow8": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_non_member_shadow9": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_non_member_shadow10": [
    "model.safetensors"
  ],
  "ChuckMcSneed/WinterGoliath-123b": [
    "model-00001-of-00026.safetensors",
    "model-00002-of-00026.safetensors",
    "model-00003-of-00026.safetensors",
    "model-00004-of-00026.safetensors",
    "model-00005-of-00026.safetensors",
    "model-00006-of-00026.safetensors",
    "model-00007-of-00026.safetensors",
    "model-00008-of-00026.safetensors",
    "model-00009-of-00026.safetensors",
    "model-00010-of-00026.safetensors",
    "model-00011-of-00026.safetensors",
    "model-00012-of-00026.safetensors",
    "model-00013-of-00026.safetensors",
    "model-00014-of-00026.safetensors",
    "model-00015-of-00026.safetensors",
    "model-00016-of-00026.safetensors",
    "model-00017-of-00026.safetensors",
    "model-00018-of-00026.safetensors",
    "model-00019-of-00026.safetensors",
    "model-00020-of-00026.safetensors",
    "model-00021-of-00026.safetensors",
    "model-00022-of-00026.safetensors",
    "model-00023-of-00026.safetensors",
    "model-00024-of-00026.safetensors",
    "model-00025-of-00026.safetensors",
    "model-00026-of-00026.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_non_member_shadow11": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_non_member_shadow12": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_non_member_shadow13": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_non_member_shadow14": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_non_member_shadow15": [
    "model.safetensors"
  ],
  "adsazad/test_trainer": [
    "model.safetensors"
  ],
  "danielhanchen/test4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Mixtral_34Bx2_MoE_60B-3.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "hossr/model420": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_non_member_shadow16": [
    "model.safetensors"
  ],
  "LoneStriker/Mixtral_34Bx2_MoE_60B-4.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "elonmollusk/neuralogix-openhermes-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hossr/model320": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_non_member_shadow17": [
    "model.safetensors"
  ],
  "LoneStriker/Mixtral_34Bx2_MoE_60B-5.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "EscVM/gpt2-alpaca-single-gpu-train": [
    "model.safetensors"
  ],
  "LoneStriker/Mixtral-8x7B-Instruct-v0.1-LimaRP-ZLoss-8.0bpw-h8-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "LoneStriker/Mixtral-8x7B-Instruct-v0.1-LimaRP-ZLoss-7.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "Aryanne/Astrea-RP-v1.5-3B": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "Sao10K/Sensualize-Mixtral-bf16": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "alxcrypto/minerhot2": [
    "model.safetensors"
  ],
  "LoneStriker/Mixtral_34Bx2_MoE_60B-6.0bpw-h6-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_non_member_shadow18": [
    "model.safetensors"
  ],
  "ohyay12345/cuminmgforyou": [
    "model.safetensors"
  ],
  "ohyay12345/cuminmgforyou1": [
    "model.safetensors"
  ],
  "hossr/model520": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t30000_e5_non_member_shadow19": [
    "model.safetensors"
  ],
  "LoneStriker/MistralTrix-v1-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/MistralTrix-v1-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "mlabonne/phixtral-2x2_8": [
    "model-00001-of-00001.safetensors"
  ],
  "LoneStriker/MistralTrix-v1-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/MistralTrix-v1-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "Anarchist/myLora": [
    "model.safetensors"
  ],
  "LoneStriker/MistralTrix-v1-8.0bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Fredithefish/CanarY": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "s3nh/Overthinker-Eileithyia-13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "bpeterkin/distilgpt2-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "c1park/20240105_mistral-step50": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sosoai/Solar-Ko-10.7B-Mergekit": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "VishalMysore/cookgptlma-8bit": [
    "model.safetensors"
  ],
  "cloudyu/Yi-34Bx2-MoE-60B": [
    "model-00001-of-00013.safetensors",
    "model-00002-of-00013.safetensors",
    "model-00003-of-00013.safetensors",
    "model-00004-of-00013.safetensors",
    "model-00005-of-00013.safetensors",
    "model-00006-of-00013.safetensors",
    "model-00007-of-00013.safetensors",
    "model-00008-of-00013.safetensors",
    "model-00009-of-00013.safetensors",
    "model-00010-of-00013.safetensors",
    "model-00011-of-00013.safetensors",
    "model-00012-of-00013.safetensors",
    "model-00013-of-00013.safetensors"
  ],
  "mlabonne/phixtral-4x2_8": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Aryanne/Astrea-RP-v1-4B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "c1park/ko_solra_orca_v0": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "myrulezzzz/sql_mistral7b-instruct.V2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "octopus2023-inc/mistral-instructv2-int4-shiftsmart-v6": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "mu0gum/polyglot-ko-1.3b-instruct-slim-v1.0-epoch2": [
    "model.safetensors"
  ],
  "cocoirun/Yi-Ko-6B-instruct-v1.0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "cocoirun/Yi-Ko-6B-instruct-v1.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "cocoirun/Yi-Ko-6B-instruct-v1.3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "cocoirun/Yi-Ko-6B-instruct-v1.4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "shuvayanti/distilgpt2-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "meetkai/functionary-small-v2.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "meetkai/functionary-medium-v2.2": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "lorinma/yi6B_Vicuna": [
    "model.safetensors"
  ],
  "jysssacc/bloomz-560m_fine_lr5e-05_bs4_epoch20_wd0.01": [
    "model.safetensors"
  ],
  "chargoddard/mistral-11b-slimorca": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "wangrongsheng/Aurora-Plus": [
    "checkpoint-10000/adapter_model.safetensors",
    "checkpoint-12000/adapter_model.safetensors",
    "checkpoint-14000/adapter_model.safetensors",
    "checkpoint-16000/adapter_model.safetensors",
    "checkpoint-18000/adapter_model.safetensors",
    "checkpoint-2000/adapter_model.safetensors",
    "checkpoint-4000/adapter_model.safetensors",
    "checkpoint-6000/adapter_model.safetensors",
    "checkpoint-8000/adapter_model.safetensors",
    "final-checkpoint/adapter_model.safetensors"
  ],
  "elliotthwang/KimLan_phi-2-zh": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MrezaPRZ/SQL_Sorcerer_2.7B_V1.0": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Crystalcareai/WagoAWQ": [
    "model.safetensors"
  ],
  "jysssacc/opt-350m_fine_lr5e-05_bs4_epoch20_wd0.01": [
    "model.safetensors"
  ],
  "NickyNicky/dolphin-2_6-phi-2_oasst2_chatML_V1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "oskrmiguel/rap-clm": [
    "model.safetensors"
  ],
  "rohit-bagal/GENAI": [
    "adapter_model.safetensors",
    "checkpoint-1/adapter_model.safetensors"
  ],
  "sreeramajay/TinyLlama-1.1B-step-1431k-orca-dpo-v1.0": [
    "model.safetensors"
  ],
  "jysssacc/roberta-base_fine_lr5e-05_bs4_epoch20_wd0.01": [
    "model.safetensors"
  ],
  "dasistwo/opt-1.3b-gptq-4bit-wikitext2": [
    "model.safetensors"
  ],
  "xinyuanL/awq-AOS-Mistral": [
    "model.safetensors"
  ],
  "c1park/test-config-eval16-nosave": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "jysssacc/roberta-base_fine_lr0.0005_bs4_epoch20_wd0.01": [
    "model.safetensors"
  ],
  "Wanfq/fusechat_baseline": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "oopsung/Yi-Ko-ENCdpo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kykim0/Llama-2-7b-ultrachat200k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "cookinai/CM-14": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "cookinai/OpenCM-14": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "bnurpek/gpt2-256t-nr1wr-neg-0": [
    "model.safetensors"
  ],
  "OEvortex/HelpingAI-Lite-chat": [
    "model.safetensors"
  ],
  "hiraltalsaniya/llama2-7b-fine-tune-test": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "IBI-CAAI/MELT-llama-2-3x70b-chat-hf": [
    "model-00001-of-00201.safetensors",
    "model-00002-of-00201.safetensors",
    "model-00003-of-00201.safetensors",
    "model-00004-of-00201.safetensors",
    "model-00005-of-00201.safetensors",
    "model-00006-of-00201.safetensors",
    "model-00007-of-00201.safetensors",
    "model-00008-of-00201.safetensors",
    "model-00009-of-00201.safetensors",
    "model-00010-of-00201.safetensors",
    "model-00011-of-00201.safetensors",
    "model-00012-of-00201.safetensors",
    "model-00013-of-00201.safetensors",
    "model-00014-of-00201.safetensors",
    "model-00015-of-00201.safetensors",
    "model-00016-of-00201.safetensors",
    "model-00017-of-00201.safetensors",
    "model-00018-of-00201.safetensors",
    "model-00019-of-00201.safetensors",
    "model-00020-of-00201.safetensors",
    "model-00021-of-00201.safetensors",
    "model-00022-of-00201.safetensors",
    "model-00023-of-00201.safetensors",
    "model-00024-of-00201.safetensors",
    "model-00025-of-00201.safetensors",
    "model-00026-of-00201.safetensors",
    "model-00027-of-00201.safetensors",
    "model-00028-of-00201.safetensors",
    "model-00029-of-00201.safetensors",
    "model-00030-of-00201.safetensors",
    "model-00031-of-00201.safetensors",
    "model-00032-of-00201.safetensors",
    "model-00033-of-00201.safetensors",
    "model-00034-of-00201.safetensors",
    "model-00035-of-00201.safetensors",
    "model-00036-of-00201.safetensors",
    "model-00037-of-00201.safetensors",
    "model-00038-of-00201.safetensors",
    "model-00039-of-00201.safetensors",
    "model-00040-of-00201.safetensors",
    "model-00041-of-00201.safetensors",
    "model-00042-of-00201.safetensors",
    "model-00043-of-00201.safetensors",
    "model-00044-of-00201.safetensors",
    "model-00045-of-00201.safetensors",
    "model-00046-of-00201.safetensors",
    "model-00047-of-00201.safetensors",
    "model-00048-of-00201.safetensors",
    "model-00049-of-00201.safetensors",
    "model-00050-of-00201.safetensors",
    "model-00051-of-00201.safetensors",
    "model-00052-of-00201.safetensors",
    "model-00053-of-00201.safetensors",
    "model-00054-of-00201.safetensors",
    "model-00055-of-00201.safetensors",
    "model-00056-of-00201.safetensors",
    "model-00057-of-00201.safetensors",
    "model-00058-of-00201.safetensors",
    "model-00059-of-00201.safetensors",
    "model-00060-of-00201.safetensors",
    "model-00061-of-00201.safetensors",
    "model-00062-of-00201.safetensors",
    "model-00063-of-00201.safetensors",
    "model-00064-of-00201.safetensors",
    "model-00065-of-00201.safetensors",
    "model-00066-of-00201.safetensors",
    "model-00067-of-00201.safetensors",
    "model-00068-of-00201.safetensors",
    "model-00069-of-00201.safetensors",
    "model-00070-of-00201.safetensors",
    "model-00071-of-00201.safetensors",
    "model-00072-of-00201.safetensors",
    "model-00073-of-00201.safetensors",
    "model-00074-of-00201.safetensors",
    "model-00075-of-00201.safetensors",
    "model-00076-of-00201.safetensors",
    "model-00077-of-00201.safetensors",
    "model-00078-of-00201.safetensors",
    "model-00079-of-00201.safetensors",
    "model-00080-of-00201.safetensors",
    "model-00081-of-00201.safetensors",
    "model-00082-of-00201.safetensors",
    "model-00083-of-00201.safetensors",
    "model-00084-of-00201.safetensors",
    "model-00085-of-00201.safetensors",
    "model-00086-of-00201.safetensors",
    "model-00087-of-00201.safetensors",
    "model-00088-of-00201.safetensors",
    "model-00089-of-00201.safetensors",
    "model-00090-of-00201.safetensors",
    "model-00091-of-00201.safetensors",
    "model-00092-of-00201.safetensors",
    "model-00093-of-00201.safetensors",
    "model-00094-of-00201.safetensors",
    "model-00095-of-00201.safetensors",
    "model-00096-of-00201.safetensors",
    "model-00097-of-00201.safetensors",
    "model-00098-of-00201.safetensors",
    "model-00099-of-00201.safetensors",
    "model-00100-of-00201.safetensors",
    "model-00101-of-00201.safetensors",
    "model-00102-of-00201.safetensors",
    "model-00103-of-00201.safetensors",
    "model-00104-of-00201.safetensors",
    "model-00105-of-00201.safetensors",
    "model-00106-of-00201.safetensors",
    "model-00107-of-00201.safetensors",
    "model-00108-of-00201.safetensors",
    "model-00109-of-00201.safetensors",
    "model-00110-of-00201.safetensors",
    "model-00111-of-00201.safetensors",
    "model-00112-of-00201.safetensors",
    "model-00113-of-00201.safetensors",
    "model-00114-of-00201.safetensors",
    "model-00115-of-00201.safetensors",
    "model-00116-of-00201.safetensors",
    "model-00117-of-00201.safetensors",
    "model-00118-of-00201.safetensors",
    "model-00119-of-00201.safetensors",
    "model-00120-of-00201.safetensors",
    "model-00121-of-00201.safetensors",
    "model-00122-of-00201.safetensors",
    "model-00123-of-00201.safetensors",
    "model-00124-of-00201.safetensors",
    "model-00125-of-00201.safetensors",
    "model-00126-of-00201.safetensors",
    "model-00127-of-00201.safetensors",
    "model-00128-of-00201.safetensors",
    "model-00129-of-00201.safetensors",
    "model-00130-of-00201.safetensors",
    "model-00131-of-00201.safetensors",
    "model-00132-of-00201.safetensors",
    "model-00133-of-00201.safetensors",
    "model-00134-of-00201.safetensors",
    "model-00135-of-00201.safetensors",
    "model-00136-of-00201.safetensors",
    "model-00137-of-00201.safetensors",
    "model-00138-of-00201.safetensors",
    "model-00139-of-00201.safetensors",
    "model-00140-of-00201.safetensors",
    "model-00141-of-00201.safetensors",
    "model-00142-of-00201.safetensors",
    "model-00143-of-00201.safetensors",
    "model-00144-of-00201.safetensors",
    "model-00145-of-00201.safetensors",
    "model-00146-of-00201.safetensors",
    "model-00147-of-00201.safetensors",
    "model-00148-of-00201.safetensors",
    "model-00149-of-00201.safetensors",
    "model-00150-of-00201.safetensors",
    "model-00151-of-00201.safetensors",
    "model-00152-of-00201.safetensors",
    "model-00153-of-00201.safetensors",
    "model-00154-of-00201.safetensors",
    "model-00155-of-00201.safetensors",
    "model-00156-of-00201.safetensors",
    "model-00157-of-00201.safetensors",
    "model-00158-of-00201.safetensors",
    "model-00159-of-00201.safetensors",
    "model-00160-of-00201.safetensors",
    "model-00161-of-00201.safetensors",
    "model-00162-of-00201.safetensors",
    "model-00163-of-00201.safetensors",
    "model-00164-of-00201.safetensors",
    "model-00165-of-00201.safetensors",
    "model-00166-of-00201.safetensors",
    "model-00167-of-00201.safetensors",
    "model-00168-of-00201.safetensors",
    "model-00169-of-00201.safetensors",
    "model-00170-of-00201.safetensors",
    "model-00171-of-00201.safetensors",
    "model-00172-of-00201.safetensors",
    "model-00173-of-00201.safetensors",
    "model-00174-of-00201.safetensors",
    "model-00175-of-00201.safetensors",
    "model-00176-of-00201.safetensors",
    "model-00177-of-00201.safetensors",
    "model-00178-of-00201.safetensors",
    "model-00179-of-00201.safetensors",
    "model-00180-of-00201.safetensors",
    "model-00181-of-00201.safetensors",
    "model-00182-of-00201.safetensors",
    "model-00183-of-00201.safetensors",
    "model-00184-of-00201.safetensors",
    "model-00185-of-00201.safetensors",
    "model-00186-of-00201.safetensors",
    "model-00187-of-00201.safetensors",
    "model-00188-of-00201.safetensors",
    "model-00189-of-00201.safetensors",
    "model-00190-of-00201.safetensors",
    "model-00191-of-00201.safetensors",
    "model-00192-of-00201.safetensors",
    "model-00193-of-00201.safetensors",
    "model-00194-of-00201.safetensors",
    "model-00195-of-00201.safetensors",
    "model-00196-of-00201.safetensors",
    "model-00197-of-00201.safetensors",
    "model-00198-of-00201.safetensors",
    "model-00199-of-00201.safetensors",
    "model-00200-of-00201.safetensors",
    "model-00201-of-00201.safetensors"
  ],
  "PronoySikdar/llama-2-13b-domain-tuned": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "bnurpek/gpt2-256t-nr1wr-neg-1": [
    "model.safetensors"
  ],
  "aloobun/LiteLlamix-8x460M-1T": [
    "model-00001-of-00001.safetensors"
  ],
  "bnurpek/gpt2-256t-nr1wr-neg-2": [
    "model.safetensors"
  ],
  "bnurpek/gpt2-256t-nr1wr-neg-3": [
    "model.safetensors"
  ],
  "bnurpek/gpt2-256t-nr1wr-neg-5": [
    "model.safetensors"
  ],
  "bnurpek/gpt2-256t-nr1wr-neg-7": [
    "model.safetensors"
  ],
  "bnurpek/gpt2-256t-nr1wr-neg-10": [
    "model.safetensors"
  ],
  "yentinglin/Taiwan-LLM-13B-v2.0-chat-awq": [
    "model.safetensors"
  ],
  "bnurpek/gpt2-256t-nr1wr-neg-15": [
    "model.safetensors"
  ],
  "bnurpek/gpt2-256t-nr1wr-neg-20": [
    "model.safetensors"
  ],
  "cfahlgren1/NaturalSQL-6.7B-v0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "NickyNicky/dolphin-2_6-phi-2_oasst2_chatML_V2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "bnurpek/gpt2-256t-nr1wr-neg-30": [
    "model.safetensors"
  ],
  "chuducandev/Llama-2-7b-chat-hf-014": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "chuducandev/Llama-2-7b-chat-hf-015": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "chuducandev/Llama-2-7b-chat-hf-016": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "chuducandev/Llama-2-7b-chat-hf-017": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "DavidLanz/Llama2-tw-7B-v2.0.1-chat": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ContextualAI/archangel_sft-csft_pythia1-4b": [
    "model.safetensors"
  ],
  "bnurpek/gpt2-256t-nr1wr-pos-0": [
    "model.safetensors"
  ],
  "bnurpek/gpt2-256t-nr1wr-pos-1": [
    "model.safetensors"
  ],
  "bnurpek/gpt2-256t-nr1wr-pos-2": [
    "model.safetensors"
  ],
  "bnurpek/gpt2-256t-nr1wr-pos-3": [
    "model.safetensors"
  ],
  "ContextualAI/archangel_sft-slic_pythia1-4b": [
    "model.safetensors"
  ],
  "bnurpek/gpt2-256t-nr1wr-pos-5": [
    "model.safetensors"
  ],
  "elonmollusk/neuralogix-openhermes-v3-pol": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "bnurpek/gpt2-256t-nr1wr-pos-7": [
    "model.safetensors"
  ],
  "bnurpek/gpt2-256t-nr1wr-pos-10": [
    "model.safetensors"
  ],
  "ContextualAI/archangel_csft_pythia1-4b": [
    "model.safetensors"
  ],
  "bnurpek/gpt2-256t-nr1wr-pos-15": [
    "model.safetensors"
  ],
  "isaiahbjork/tinyllama-function-calling-v0.2-merge": [
    "model.safetensors"
  ],
  "bnurpek/gpt2-256t-nr1wr-pos-20": [
    "model.safetensors"
  ],
  "s3nh/Noromaid-Aeryth-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "bnurpek/gpt2-256t-nr1wr-pos-30": [
    "model.safetensors"
  ],
  "tmberooney/medllama-merged": [
    "model.safetensors"
  ],
  "kichan05/Novel-Kaguya": [
    "adapter_model.safetensors"
  ],
  "Aleereza/tinnyllama_fatokenizer_mean_nonQu_5": [
    "model.safetensors"
  ],
  "ContextualAI/archangel_sft-csft_pythia2-8b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "arturolinares26/merged-llama-7b-chat-hf-sustainbility": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ziffir/picky-v1.0": [
    "model.safetensors"
  ],
  "Aleereza/tinnyllama_fatokenizer_sum_nonQu_5": [
    "model.safetensors"
  ],
  "AswanthCManoj/azma-deepseek-1.3b-instruct-v2-merge-full": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Aleereza/tinnyllama_fatokenizer_max_nonQu_5": [
    "model.safetensors"
  ],
  "KoboldAI/LLaMA2-13B-Erebus-v3": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "KoboldAI/Mistral-7B-Erebus-v3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ContextualAI/archangel_sft-slic_pythia2-8b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ContextualAI/archangel_csft_pythia2-8b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "hossr/model500": [
    "model.safetensors"
  ],
  "hossr/model501": [
    "model.safetensors"
  ],
  "ardhendubanerjee/GPT_QnA": [
    "model.safetensors"
  ],
  "hossr/model502": [
    "model.safetensors"
  ],
  "Shooosh/Llama-2-7b-finetune-test": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jeiku/Current_3B": [
    "model.safetensors"
  ],
  "Steelskull/Lumosia-MoE-4x10.7": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "deepseek-ai/deepseek-moe-16b-base": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "s3nh/Noromaid-Panda-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "SE6446/Phasmid-2_v2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ContextualAI/archangel_sft-csft_pythia6-9b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Asude/gpt2_256token-imdb-positive-20k-with_reward_-1it": [
    "model.safetensors"
  ],
  "Asude/gpt2_256token-imdb-positive-20k-with_reward_-2it": [
    "model.safetensors"
  ],
  "Asude/gpt2_256token-imdb-positive-20k-with_reward_-3it": [
    "model.safetensors"
  ],
  "chestnutlzj/MoE-Qwen-4x1.8B-pretrain-18000-ckpt": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Asude/gpt2_256token-imdb-positive-20k-with_reward_-5it": [
    "model.safetensors"
  ],
  "LI-ST/Mistral-7B-ko-v0.001": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LI-ST/Mistral-7B-ko-v0.002": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LI-ST/Mistral-7B-ko-v0.003": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LI-ST/Mistral-7B-ko-v0.004": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LI-ST/Mistral-7B-ko-v0.005": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LI-ST/Mistral-7B-ko-v0.006": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "innaskarbovsky/mistral7b_full": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "nlpllm007/dpd_straive_classified_gguf": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Asude/gpt2_256token-imdb-positive-20k-with_reward_-7it": [
    "model.safetensors"
  ],
  "sherelyn912/llama-2-7b-finance": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Asude/gpt2_256token-imdb-positive-20k-with_reward_-10it": [
    "model.safetensors"
  ],
  "TheBloke/Mixtral_34Bx2_MoE_60B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Mixtral_34Bx2_MoE_60B-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "Asude/gpt2_256token-imdb-positive-20k-with_reward_-15it": [
    "model.safetensors"
  ],
  "Yash21/OpenMistral-MoE": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "rhysjones/phi-2-orange": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Asude/gpt2_256token-imdb-positive-20k-with_reward_-20it": [
    "model.safetensors"
  ],
  "ethux/ethux-7B-merge": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "VioletJockey/my_awesome_eli5_clm-model": [
    "model.safetensors"
  ],
  "h-asterix/mistralai-Code-Instruct-Finetune-test-batchsize-8": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ContextualAI/archangel_sft-slic_pythia6-9b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Asude/gpt2_256token-imdb-positive-20k-with_reward_-30it": [
    "model.safetensors"
  ],
  "mtc/meta-llama-Llama-2-13b-hf-pubmed-summarization-5000-finetuned-quantization-final": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Fredithefish/RP_Base": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ContextualAI/archangel_csft_pythia6-9b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Spanicin/Fulcrum2": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Holarissun/gpt2-sft-tldr": [
    "model.safetensors"
  ],
  "mtc/meta-llama-Llama-2-13b-hf-arxiv-summarization-5000-finetuned-quantization-final": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "nikhil-c-r/llama-2-7b-finetunedonmedical_new_500": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "khoantap/TightHugger": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Fredithefish/MustangRP": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "Anis1123/quip-merged": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "fxmeng/phi_8x1_5B_textbook": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "elliotthwang/KimLan_phi-2-zh-0.2B": [
    "model.safetensors"
  ],
  "the-patand/dragon-mistral-7b-v0-sharded": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "khoantap/TightHuggerRP": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "EnDevSols/tinyllama-2.5T-Clinical": [
    "model.safetensors"
  ],
  "Spanicin/Fulcrum-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "ContextualAI/archangel_sft-csft_pythia12-0b": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "sherelyn912/sft_llama_finance": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "decem/Dionysus-Llama-v1.1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "xinyuanL/mistral_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sreeramajay/TinyLlama-1.1B-step-1431k-orca-dpo-v1.1": [
    "model.safetensors"
  ],
  "yoonyoon/kb_v4.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hooking-dev/sexyGPT": [
    "model.safetensors"
  ],
  "avemio-digital/Entity_Model": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Herry443/Mistral-7B-KNUT-ref-ko_HellaSWAG": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "batatar/TinyLlama-guanaco": [
    "model.safetensors"
  ],
  "Fredperim/NeuralPipe-7B-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "obrmmk/tinycodellama-jp-1.3b-25k": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "JGlang/llama2-mergedmodel_prenoms": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "srakeshkumar84/toxi-falcon-rw-1b": [
    "model.safetensors"
  ],
  "TheBloke/speechless-mistral-moloras-7B-AWQ": [
    "model.safetensors"
  ],
  "jondurbin/bagel-dpo-8x7b-v0.2": [
    "model-00001-of-00024.safetensors",
    "model-00002-of-00024.safetensors",
    "model-00003-of-00024.safetensors",
    "model-00004-of-00024.safetensors",
    "model-00005-of-00024.safetensors",
    "model-00006-of-00024.safetensors",
    "model-00007-of-00024.safetensors",
    "model-00008-of-00024.safetensors",
    "model-00009-of-00024.safetensors",
    "model-00010-of-00024.safetensors",
    "model-00011-of-00024.safetensors",
    "model-00012-of-00024.safetensors",
    "model-00013-of-00024.safetensors",
    "model-00014-of-00024.safetensors",
    "model-00015-of-00024.safetensors",
    "model-00016-of-00024.safetensors",
    "model-00017-of-00024.safetensors",
    "model-00018-of-00024.safetensors",
    "model-00019-of-00024.safetensors",
    "model-00020-of-00024.safetensors",
    "model-00021-of-00024.safetensors",
    "model-00022-of-00024.safetensors",
    "model-00023-of-00024.safetensors",
    "model-00024-of-00024.safetensors"
  ],
  "dvilasuero/NeuralHermes-2.5-Mistral-7B-distilabel": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Netrve/Loyal-Silicon-Maid-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "AswanthCManoj/azma-deepseek-1.3b-instruct-v4-merged": [
    "model.safetensors"
  ],
  "ContextualAI/archangel_sft-slic_pythia12-0b": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "snorkelai/Mistral-7B-Instruct-v0.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "octopus2023-inc/zephyr-7bbeta-int4-shiftsmart-v1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "snorkelai/Mixtral-8x7B-Instruct-v0.1": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "therealcyberlord/magicwand-gptneo-1.3b": [
    "adapter_model.safetensors"
  ],
  "ContextualAI/archangel_csft_pythia12-0b": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "NaoS2/tinycodellama-jp-0.06b-1k": [
    "model.safetensors"
  ],
  "OpenBuddy/openbuddy-deepseekcoder-6b-v16.1-32k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Fredithefish/Waterbuck": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "octopus2023-inc/zephyr-7bbeta-int4-shiftsmart-v2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "TheBloke/speechless-mistral-moloras-7B-GPTQ": [
    "model.safetensors"
  ],
  "brucethemoose/Yi-34B-200K-DARE-merge-v7": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "Doctor-Shotgun/Mixtral-8x7B-Instruct-v0.1-LimaRP-ZLoss-DARE-TIES": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "openaccess-ai-collective/phi2-alpaca": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "HuggingFaceM4/VLM_WebSight_finetuned": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TinyPixel/sml-4": [
    "model.safetensors"
  ],
  "deepnet/PreTrainingSubnetModel2": [
    "model.safetensors"
  ],
  "Ont/Marcoroni-13B": [
    "model-00001-of-00023.safetensors",
    "model-00002-of-00023.safetensors",
    "model-00003-of-00023.safetensors",
    "model-00004-of-00023.safetensors",
    "model-00005-of-00023.safetensors",
    "model-00006-of-00023.safetensors",
    "model-00007-of-00023.safetensors",
    "model-00008-of-00023.safetensors",
    "model-00009-of-00023.safetensors",
    "model-00010-of-00023.safetensors",
    "model-00011-of-00023.safetensors",
    "model-00012-of-00023.safetensors",
    "model-00013-of-00023.safetensors",
    "model-00014-of-00023.safetensors",
    "model-00015-of-00023.safetensors",
    "model-00016-of-00023.safetensors",
    "model-00017-of-00023.safetensors",
    "model-00018-of-00023.safetensors",
    "model-00019-of-00023.safetensors",
    "model-00020-of-00023.safetensors",
    "model-00021-of-00023.safetensors",
    "model-00022-of-00023.safetensors",
    "model-00023-of-00023.safetensors"
  ],
  "octopus2023-inc/zephyr-7bbeta-int4-shiftsmart-v3": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "rachittshah/python-phi2-evals": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "srakeshkumar84/toxi-fb-opt-125m": [
    "model.safetensors"
  ],
  "ewqr2130/mistral-inst-v02-dpo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "gagan3012/MetaModel_moe_multilingualv2": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors",
    "model-1.safetensors",
    "model-2.safetensors",
    "model-3.safetensors",
    "model-4.safetensors",
    "model-5.safetensors",
    "model-6.safetensors",
    "model-7.safetensors",
    "model-8.safetensors",
    "model-9.safetensors"
  ],
  "macadeliccc/laser-dolphin-mixtral-4x7b-dpo": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "ewqr2130/mistral-7b-raw-sft": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "S-AA-D/llama-2-7b-S-AA-D": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ewqr2130/llama2-7b-raw-sft": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ContextualAI/archangel_sft-csft_llama7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/dolphin-2.6-mistral-7b-dpo-laser-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/dolphin-2.6-mistral-7b-dpo-laser-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/dolphin-2.6-mistral-7b-dpo-laser-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "macadeliccc/laser-dolphin-mixtral-2x7b-dpo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mlabonne/zephusion-2x7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/dolphin-2.6-mistral-7b-dpo-laser-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "abacusai/Fewshot-Metamath-OrcaVicuna-Mistral": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mtc/LeoLM-leo-mistral-7b-mixtral-and-gpt4-explanation-no-packing-1-epoch-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/dolphin-2.6-mistral-7b-dpo-laser-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "bernaferrari/mistral01": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ContextualAI/archangel_sft-slic_llama7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Mixtral_34Bx2_MoE_60B-2.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "ContextualAI/archangel_csft_llama7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/speechless-mistral-moloras-7b-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/speechless-mistral-moloras-7b-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "nikhil-c-r/mllm-finetuned": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "KnutJaegersberg/Walter-Phi2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/speechless-mistral-moloras-7b-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/speechless-mistral-moloras-7b-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/speechless-mistral-moloras-7b-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "nakodanei/Red-Daffodil-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dev137/cloudyu_Mixtral_34Bx2_MoE_60B-exl2-2.0bpw-h8": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "alfalmi/gpt2-poetry-es": [
    "model.safetensors"
  ],
  "NaoS2/tinycodellama-jp-0.06b-5k": [
    "model.safetensors"
  ],
  "Sigurdur/jonas": [
    "model.safetensors"
  ],
  "octopus2023-inc/zephyr-7b-beta-int4-faithdial": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ContextualAI/archangel_sft-csft_llama13b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "s3nh/Noromaid-Panda-Mistral-7B-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/NeuralPipe-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "ewqr2130/moe_scratch": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "jjszpak/distilgpt2-SCAN-v2": [
    "model.safetensors"
  ],
  "MaziyarPanahi/NeuralPipe-7B-slerp-v0.2": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "mtc/meta-llama-Llama-2-7b-hf-pubmed-summarization-5000-finetuned-no-packing": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mtc/mistralai-Mistral-7B-v0.1-pubmed-summarization-5000-finetuned-no-packing": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "impossibleexchange/pt16": [
    "model.safetensors"
  ],
  "jeiku/Streamlined_3B": [
    "model-00001-of-00001.safetensors"
  ],
  "s3nh/Sonya-Panda-7B-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "octopus2023-inc/zephyr-7bbeta-int4-shiftsmart-v4": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "shitshow123/moe_scratch": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "ContextualAI/archangel_sft-slic_llama13b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "impossibleexchange/pt17": [
    "model.safetensors"
  ],
  "jpcrisostomo/Mistral-7B-MC-DPO": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ContextualAI/archangel_csft_llama13b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Xenon1/MetaModel_moex8": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "beberik/Lonepino-11B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "stanford-oval/Llama-2-7b-WikiChat": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "AIGym/TinyLlama-1.1B-2.5T-chat": [
    "model.safetensors"
  ],
  "Edentns/DataVortexTL-1.1B-v0.1": [
    "model.safetensors"
  ],
  "TroyDoesAI/MermaidMistral": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MrezaPRZ/SQL_Sorcerer_6.7B_V1.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "RaiBP/gpt2-openwebtext2-first-30-chunks-ablation-non-english": [
    "model.safetensors"
  ],
  "AIGym/TinyLlama-1.1B-2.5T-chat-and-function-calling": [
    "model.safetensors"
  ],
  "yentinglin/Taiwan-LLM-7B-v2.0.1-chat-awq": [
    "model.safetensors"
  ],
  "ensound/labiezione_generator": [
    "adapter_model.safetensors",
    "checkpoint-4014/adapter_model.safetensors",
    "model.safetensors"
  ],
  "wkshin89/yi-ko-6b-instruct-test-v0.3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lucyknada/Mixtral_34Bx2_MoE_60B-2.8bpw": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "QLU-NLP/BianCang-7B-Chat": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "xjw1001002/Yi-6B-pricing-0108-ckp3000": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "kimnt93/chatmodel-exp-02": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "stanford-oval/Llama-2-7b-WikiChat-fused": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "stabilityai/stable-code-3b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ContextualAI/archangel_sft-csft_llama30b": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "alnrg2arg/test_wanda_240109": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "lewtun/handbook-sft-test": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "alfalmi/gpt2-poetry-esp": [
    "model.safetensors"
  ],
  "youndukn/zephyr-7b-sft-lora-romantic": [
    "adapter_model.safetensors"
  ],
  "euclaise/crow-1b-attempt1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "suzii/ft_lora_7b_mistral_v1.0": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ContextualAI/archangel_csft_llama30b": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "lucyknada/Mixtral_34Bx2_MoE_60B-2.6bpw": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "NelsonKamau47/NutriBotV2": [
    "model.safetensors"
  ],
  "shitshow123/tinylamma-20000": [
    "model.safetensors"
  ],
  "yoonyoon/mm-c-model-v1_DPO": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "shitshow123/phi-dpo-10000": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mncai/Mistral-7B-Instruct-v0.2-1st-NWS-KoOrca-5k-2nd-MiBaSeAl-u2k-ep4-lr5-len2500": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "deepseek-ai/deepseek-moe-16b-chat": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "khanhnto/kyt13B": [
    "adapter_model.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "mihirinamdar/my-awesome-model": [
    "model.safetensors"
  ],
  "NeverSleep/Noromaid-v0.4-Mixtral-Instruct-8x7b-Zloss": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "kam414/quip-v1": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "adeocybersecurity/Mistral7B-Chat-Docker_Command_Generator": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "DeepKarkhanis/NeuralPipe-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Yash21/Mistral-Quantum-dpo": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "srakeshkumar84/sft-fb-opt-125m": [
    "model.safetensors"
  ],
  "acedev003/llama-2-coder-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "khoantap/Mythical-Hugger": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "DeepKarkhanis/Mistral-Passthrough-8L-10B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "avinashreddy/gpt-2-harmful": [
    "model.safetensors"
  ],
  "nutorbit/bart-xllm": [
    "model.safetensors"
  ],
  "Dans-DiscountModels/Dans-StructureEvaluator-Small": [
    "model.safetensors"
  ],
  "IbuNai/mixtral-ja-base-4x7b-v0.1": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "fblgit/UNAversal-2x7B-v1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "srakeshkumar84/toxi-sft-fb-opt-125m": [
    "model.safetensors"
  ],
  "walebadr/DeciLM-DPO": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MatrixC7/Mixtral_34Bx2_MoE_60B-4.65bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "chuducandev/Llama-2-7b-chat-hf-018": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "chuducandev/Llama-2-7b-chat-hf-019": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "chuducandev/Llama-2-7b-chat-hf-020": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "KoboldAI/Mistral-7B-Holodeck-1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "chuducandev/Llama-2-7b-chat-hf-021": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hyeogi/Yi-9b-v1": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "s3nh/GOAT-Finance-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "decruz07/llama-2-7b-miniguanaco": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "0xideas/rustral": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ybelkada/test-readme": [
    "model.safetensors"
  ],
  "carlos447/LlamaDos-adapters": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "s3nh/NSFW-Panda-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "aloobun/qwen-1_8b-samantha-chat": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ybelkada/test-tags-model": [
    "model.safetensors"
  ],
  "huskyhong/noname-ai-v2_2-light": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "hiraltalsaniya/llama2-7b-fine-tune-task-classification": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "DonJoey/ricollama7b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ncsgobubble/Llama-7B-rollercoaster_v2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "aari1995/germeo-7b-laser": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mtc/meta-llama-Llama-2-7b-hf-arxiv-summarization-5000-finetuned-no_quantization-final": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AdnanRiaz107/huggingfacecodebert-base-mlm-finetuned-st": [
    "model.safetensors"
  ],
  "Abhishek107/new_Sml_model": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "metamath/codeparrot-ds": [
    "model.safetensors"
  ],
  "s3nh/Eileithyia-toxicqa": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Spanicin/Fulcrum_Nova": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "slay/mistral_7b_guanaco_load_in_8bit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "DopeorNope/RAG_mixtral-test-7Bx2": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "h-asterix/mistralai-Code-Instruct-Finetune-test-epoch-0.21-nickrosh-Evol-Instruct-Code-80k-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Spanicin/Fulcrum_Aura": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "irshadtech10/finetuned-codegen-350-mono": [
    "model.safetensors"
  ],
  "whoananyasing/DialoGPT-small-kratos": [
    "model.safetensors"
  ],
  "Chuanming/NeuralPipe-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "h-asterix/mistralai-Unit-Test-Generator-epoch1": [
    "model.safetensors"
  ],
  "LoneStriker/Mixtral_34Bx2_MoE_60B-2.4bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "Chuanming/Tiny-Llama-2.2B-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Abdulrehmans/bling-sheared-llama-1.3b-0.1-quantized-8bit": [
    "model.safetensors"
  ],
  "JGlang/llama2-20epochprenoms": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "obrmmk/tinycodellama-jp-0.6b-20k-2-instruct-codealpaca": [
    "model.safetensors"
  ],
  "waldie/Velara-11B-V2-8bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "TETO101/airi-v2-70b-awq-w4-g128": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "ybelkada/test-tags-model-2": [
    "model.safetensors"
  ],
  "fokyoum9/Solar_KO_ORCA_Test8": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "mtc/LeoLM-leo-mistral-hessianai-7b-no-packing-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kmfoda/gpt2-1b": [
    "model.safetensors"
  ],
  "NaoS2/tinycodellama-jp-0.06b-10k": [
    "model.safetensors"
  ],
  "NaoS2/tinycodellama-jp-0.06b-15k": [
    "model.safetensors"
  ],
  "Technoculture/Medorca-7B-Ties": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "youndukn/TinyLlama-1.1B-Chat-v1.0-reasoning-v2-dpo-romantic": [
    "adapter_model.safetensors"
  ],
  "ybelkada/test-tag-already-tagged": [
    "model.safetensors"
  ],
  "elliotthwangmsa/KimLan_mistral-7B_zh": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TobDeBer/zephyr7b": [
    "model.int8-00001-of-00002.safetensors",
    "model.int8-00002-of-00002.safetensors"
  ],
  "ybelkada/test-model-already-tagged": [
    "model.safetensors"
  ],
  "vwxyzjn/output": [
    "model.safetensors"
  ],
  "leeywin/llama-2-7b-platypus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "parse-boyz/mistral_7b-instruct-tuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "metamath/my_awesome_eli5_clm-model": [
    "model.safetensors"
  ],
  "la-min/myanmar-gpt-health-faq": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "argilla/distilabeled-OpenHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "BlahBlah314/Mistral-7b-Enh-V1_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "luisrguerra/mistral-luis-test": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "WasamiKirua/Samantha-1.0-Lora-Phi2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Mixtral-8x7B-Instruct-v0.1-LimaRP-ZLoss-DARE-TIES-3.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Mixtral-8x7B-Instruct-v0.1-LimaRP-ZLoss-DARE-TIES-3.5bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/bagel-dpo-8x7b-v0.2-2.4bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/bagel-dpo-8x7b-v0.2-3.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Mixtral-8x7B-Instruct-v0.1-LimaRP-ZLoss-DARE-TIES-3.75bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "luisrguerra/mistral-luis-test-2": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "LoneStriker/bagel-dpo-8x7b-v0.2-3.5bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Mixtral-8x7B-Instruct-v0.1-LimaRP-ZLoss-DARE-TIES-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "h-asterix/mistralai-Code-Instruct-Finetune-test-epoch-5-jitxMethods2Test-java_unit-test-code": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Chuanming/ChatGLM3-12B-slerp": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "damerajee/Tinyllama-sft-small": [
    "adapter_model.safetensors"
  ],
  "slay/mistral_7b_merged_with_adapter": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/bagel-dpo-8x7b-v0.2-3.75bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "mrm8488/tinyllama-bnb-4bit-ft-codeAlpaca": [
    "model.safetensors"
  ],
  "LoneStriker/Mixtral-8x7B-Instruct-v0.1-LimaRP-ZLoss-DARE-TIES-5.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "GETTOz/Test-Ku-Dataset-with-Colab-0.0.1": [
    "model.safetensors"
  ],
  "hung96ads/PhoGPT-7B5-qlora-new": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "igorktech/PicoSatirik": [
    "model.safetensors"
  ],
  "LoneStriker/bagel-dpo-8x7b-v0.2-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "jayavibhav/Llama-2-Kannada": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mtc/test-mistralai-Mistral-7B-v0.1-pubmed-summarization-5000-finetuned-no-quantization": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Mixtral-8x7B-Instruct-v0.1-LimaRP-ZLoss-DARE-TIES-6.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "LoneStriker/bagel-dpo-8x7b-v0.2-5.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "LoneStriker/Mixtral-8x7B-Instruct-v0.1-LimaRP-ZLoss-DARE-TIES-2.4bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/bagel-dpo-8x7b-v0.2-6.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "SuvajitGB/NeuralPipe-7B-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jysssacc/roberta-base_fine_lr5e-05_bs4_epoch5_wd0.01": [
    "model.safetensors"
  ],
  "gradientai/v-alpha-tross": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "jan-hq/TinyLlama-Bamboo-v1.0": [
    "model.safetensors"
  ],
  "aj30/finetuned-llama-2-test_subset1024_v1": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "LoneStriker/Mixtral_11Bx2_MoE_19B-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Mixtral_11Bx2_MoE_19B-4.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/Mixtral_11Bx2_MoE_19B-4.65bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/Mixtral_11Bx2_MoE_19B-5.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "igorktech/CharPicoSatirik-sm": [
    "model.safetensors"
  ],
  "LoneStriker/Mixtral_11Bx2_MoE_19B-6.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/Mixtral_11Bx2_MoE_19B-8.0bpw-h8-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "Prashanthch/mistral-7b-qna-tuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Fredithefish/Waterbuck-slerp": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Shakib75/finetuned-llama2-platypus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "antiven0m/peccadillo": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ddh0/OrcaMaid-v3-13b-32k": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "felixbrock/autotrain-kjdkb-p5tgc": [
    "adapter_model.safetensors",
    "checkpoint-24/adapter_model.safetensors"
  ],
  "udkai/Garrulus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "igorktech/CharPicoSatirik-m": [
    "model.safetensors"
  ],
  "giux78/zefiro-7b-beta-ITA-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "waldie/Pallas-0.5-LASER-0.6-4.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "jeiku/SmarterAdult_3B": [
    "model-00001-of-00001.safetensors"
  ],
  "AmrMohamed/git-base-roco-ft-10epcs": [
    "model.safetensors"
  ],
  "fblgit/UNA-TheBeagle-7b-v1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "kirstus/CodeLlama-7b-Instruct-hf": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LouisML/tinyllama_32k": [
    "model.safetensors"
  ],
  "Sonish/llama-2-7b-gdp-dummy": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "andrewatef/myBloggerV0.6": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "allenai/OLMo-7B-Twin-2T": [
    "model.safetensors"
  ],
  "allenai/OLMo-7B": [
    "model.safetensors"
  ],
  "NaoS2/tinycodellama-jp-0.06b-20k": [
    "model.safetensors"
  ],
  "rombodawg/Open_Gpt4_8x7B_v0.2": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "AmirHossein1378/gpt2-wmt14-en-fr": [
    "model.safetensors"
  ],
  "TheBloke/dolphin-2.6-mistral-7B-dpo-laser-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/dolphin-2.6-mistral-7B-dpo-laser-GPTQ": [
    "model.safetensors"
  ],
  "hyeogi/SOLAR-10.7B-dpo-v1": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "bardsai/jaskier-7b-dpo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/finance-chat-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/finance-chat-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/OrcaMaid-v3-13B-32k-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/law-chat-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/law-chat-GPTQ": [
    "model.safetensors"
  ],
  "sam2ai/Mistral-7B-Hindi-Hermes-v0.1-base": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "nikhil-c-r/llama-2-7b-finetunedonmedical_new801": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/medicine-chat-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/medicine-chat-AWQ": [
    "model.safetensors"
  ],
  "kedarbhumkar/NeuralPipe-7B-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Velara-11B-V2-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Velara-11B-V2-GPTQ": [
    "model.safetensors"
  ],
  "opencsg/opencsg-CodeLlama-7b-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AmirHossein1378/gpt2-wmt14-en-fr-2epoch": [
    "model.safetensors"
  ],
  "opencsg/opencsg-CodeLlama-13b-v0.1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "wkshin89/Yi-Ko-6B-Instruct-v1.0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "cocoirun/Yi-Ko-6B-instruct-v1.5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "therealcyberlord/magicwand-opt-125m": [
    "adapter_model.safetensors"
  ],
  "opencsg/opencsg-CodeLlama-34b-v0.1": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "chuducandev/Llama-2-7b-chat-hf-022": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "chuducandev/Llama-2-7b-chat-hf-023": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "chuducandev/Llama-2-7b-chat-hf-024": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Mixtral-8x7B-Instruct-v0.1-LimaRP-ZLoss-DARE-TIES-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Mixtral-8x7B-Instruct-v0.1-LimaRP-ZLoss-DARE-TIES-GPTQ": [
    "model.safetensors"
  ],
  "Wanfq/fusechat_nous_teacher_ckpt": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "chuducandev/Llama-2-7b-chat-hf-025": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "reyvan/qwenT": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "hhhwmws/cp_pyml-2-7b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "jikaixuan/zephyr-ds": [
    "adapter_model.safetensors"
  ],
  "AmirHossein1378/gpt2-wmt14-en-fr-3epoch": [
    "model.safetensors"
  ],
  "oosij/llama-2-13b-ko-ft": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Edentns/DataVortexS-10.7B-dpo-v0.1": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "pradeepbord/phi2_solar_1": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "Haary/TinyLlama-1.1B-usk-v1": [
    "model.safetensors"
  ],
  "Ram07/DialoGPT-oldinst-v1": [
    "model.safetensors"
  ],
  "relaxml/Llama-2-70b-E8PRVQ-3Bit": [
    "model-00001-of-00003.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00003.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "TheBloke/Lumosia-MoE-4x10.7-GPTQ": [
    "model.safetensors"
  ],
  "relaxml/Llama-2-13b-E8PRVQ-3Bit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors",
    "model.safetensors"
  ],
  "relaxml/Llama-2-7b-E8PRVQ-3Bit": [
    "model.safetensors"
  ],
  "relaxml/Llama-2-70b-chat-E8PRVQ-3Bit": [
    "model-00001-of-00003.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00003.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "chestnutlzj/MoE-Qwen-4x1.8B-pretrain-50000-ckpt": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "relaxml/Llama-2-13b-chat-E8PRVQ-3Bit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors",
    "model.safetensors"
  ],
  "Crysiss/mistral-pt-001": [
    "adapter_model.safetensors",
    "checkpoint-1002/adapter_model.safetensors"
  ],
  "relaxml/Llama-2-7b-chat-E8PRVQ-3Bit": [
    "model.safetensors"
  ],
  "relaxml/Llama-1-65b-E8PRVQ-3Bit": [
    "model-00001-of-00003.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00003.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Mlteamnc/llama-2-7b-ner-v2-awq-jan10": [
    "model.safetensors"
  ],
  "relaxml/Llama-1-30b-E8PRVQ-3Bit": [
    "model-00001-of-00002.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00002.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "relaxml/Llama-1-13b-E8PRVQ-3Bit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors",
    "model.safetensors"
  ],
  "relaxml/Llama-1-7b-E8PRVQ-3Bit": [
    "model.safetensors"
  ],
  "relaxml/Mistral-7b-E8PRVQ-3Bit": [
    "model.safetensors"
  ],
  "relaxml/Openhermes-7b-E8PRVQ-3Bit": [
    "model.safetensors"
  ],
  "cognitivecomputations/MegaDolphin-120b": [
    "model-00001-of-00025.safetensors",
    "model-00002-of-00025.safetensors",
    "model-00003-of-00025.safetensors",
    "model-00004-of-00025.safetensors",
    "model-00005-of-00025.safetensors",
    "model-00006-of-00025.safetensors",
    "model-00007-of-00025.safetensors",
    "model-00008-of-00025.safetensors",
    "model-00009-of-00025.safetensors",
    "model-00010-of-00025.safetensors",
    "model-00011-of-00025.safetensors",
    "model-00012-of-00025.safetensors",
    "model-00013-of-00025.safetensors",
    "model-00014-of-00025.safetensors",
    "model-00015-of-00025.safetensors",
    "model-00016-of-00025.safetensors",
    "model-00017-of-00025.safetensors",
    "model-00018-of-00025.safetensors",
    "model-00019-of-00025.safetensors",
    "model-00020-of-00025.safetensors",
    "model-00021-of-00025.safetensors",
    "model-00022-of-00025.safetensors",
    "model-00023-of-00025.safetensors",
    "model-00024-of-00025.safetensors",
    "model-00025-of-00025.safetensors"
  ],
  "dev7halo/KoSOLAR-10.7B-v0.1": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "srini98/mistral-function-calling": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "AshanGimhana/llama-2_johnCloneV2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Crysiss/mistral-pt-002": [
    "adapter_model.safetensors",
    "checkpoint-2505/adapter_model.safetensors"
  ],
  "rachittshah/evalistral": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "AmirHossein1378/gpt2-wmt14-en-fr-4epoch": [
    "model.safetensors"
  ],
  "youndukn/zephyr_qlora": [
    "adapter_model.safetensors"
  ],
  "mohomin123/M-DIE-M-10.7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Wanfq/fusechat_baseline_0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "akashkumarbtc/opt-350m_tuned": [
    "model.safetensors"
  ],
  "Kooten/Noromaid-13b-v0.3-QUIP-2bit": [
    "model.safetensors"
  ],
  "mithlesh/LlaMA-2-on-Gathnex": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "HenryJJ/Instruct_Phi2_Dolly15K": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Yayaduperou/llama-2-7b-miniplatypus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Ryong/git-base-pokemon": [
    "model.safetensors"
  ],
  "jiogenes/gpt2-medium-finetuned-open-korean-instructions": [
    "model.safetensors"
  ],
  "TheBloke/OrcaMaid-v3-13B-32k-GPTQ": [
    "model.safetensors"
  ],
  "LyreZ/openchat-3.5-1210-cvparsing-v1-325": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "chanwit/kube-7b-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "youndukn/zephyr-7b-beta_qlora": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors",
    "model.safetensors"
  ],
  "rudyTzhan/llama-2-7b-platypus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Wanfq/fusechat_phind_teacher_ckpt": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "s3nh/TinyLLama-4x1.1B-MoE": [
    "model-00001-of-00001.safetensors"
  ],
  "mtc/mistralai-Mistral-7B-v0.1-pubmed-summarization-5000-finetuned-no-quantization-final": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "parse-boyz/mistral_7b-instruct-126k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ArunSamespace/mistral-fc-10ep-bitsandbytes": [
    "model.safetensors"
  ],
  "damerajee/tinyllama-sft-small-v2": [
    "model.safetensors"
  ],
  "AmirHossein1378/gpt2-wmt14-en-fr-5epoch": [
    "model.safetensors"
  ],
  "Kooten/Noromaid-v0.4-Mixtral-Instruct-8x7b-Zloss-3.5bpw-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "ArunSamespace/mistral-7b-instruct-v0.1-awq": [
    "model.safetensors"
  ],
  "LoneStriker/Air-Striker-Mixtral-8x7B-ZLoss-LoRA": [
    "adapter_model.safetensors"
  ],
  "Yarofa/model_pu_241": [
    "model.safetensors"
  ],
  "TheBloke/openchat-3.5-0106-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/openchat-3.5-0106-GPTQ": [
    "model.safetensors"
  ],
  "MarkrAI/MarK2-10.7B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "shidowake/test-240110-revised-swallow-7B-hf-qlora-adaptor-merged": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "Gaie/alpaca-2-7b-reproduced": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Sonamjain/llama-2-7b-finetuned1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/openchat-3.5-0106-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/openchat-3.5-0106-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "Trelis/TinyLlama-1.1B-Chat-v1.0-bf16": [
    "model.safetensors"
  ],
  "mtc/meta-llama-Llama-2-7b-hf-pubmed-summarization-5000-finetuned-no-quantization-final": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/openchat-3.5-0106-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "Trelis/TinyLlama-1.1B-Chat-v1.0-bf16-push-demo": [
    "model.safetensors"
  ],
  "LoneStriker/openchat-3.5-0106-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "mu0gum/polyglot-ko-1.3b-slim_orca_10000-epoch2": [
    "model.safetensors"
  ],
  "LoneStriker/openchat-3.5-0106-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "nguyenhuy/mistralai-Code-Instruct-Finetune-test": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "djomo/MISTRALllux600-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Edentns/DataVortexS-10.7B-v0.1": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "mtc/mistralai-Mistral-7B-v0.1-arxiv-summarization-5000-finetuned-no_quantization-final": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "andrewatef/CoolReblyer": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "opencsg/opencsg-starcoder-v0.1": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "impossibleexchange/pt20": [
    "model.safetensors"
  ],
  "hflserdaniel/chai_season_6_13b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "h-asterix/mistralai-Code-Instruct-Finetune-test-epoch-0.8-smalldatatestset-multigpu-length-optimised": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "HassanSamo/Mistral7b-instruc-v2-python": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "summer11111/summerv3": [
    "model.safetensors"
  ],
  "Neuronovo/neuronovo-9B-v0.3": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "parse-boyz/mistral_7b-instruct-126k-r32": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "DRXD1000/Phoenix": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jjszpak/distilgpt2-SCAN-v2-2epoch": [
    "model.safetensors"
  ],
  "croissantllm/bloom1b7Chat": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "giuid/llama-2-7b_QR": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "waldie/Yi-34B-200K-DARE-merge-v7-4.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "jjszpak/distilgpt2-SCAN-v2-3epoch": [
    "model.safetensors"
  ],
  "alinourian/DistilGPT2-SemEval2024": [
    "model.safetensors"
  ],
  "kreabs/Marcoro14-7B_finetuned_dolly_2400": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jjszpak/distilgpt2-SCAN-v2-4epoch": [
    "model.safetensors"
  ],
  "Benchmbn/autotrain2": [
    "adapter_model.safetensors",
    "checkpoint-1/adapter_model.safetensors"
  ],
  "s3nh/GOAT-Adapt-MoE-4x7B": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "vibhuagrawal/Mixtral-8x7B-Instruct-v0.1-GPTQ": [
    "model.safetensors"
  ],
  "pinkyponky/SOLAR-10.7B-dpo-instruct-tuned-v0.1": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "jjszpak/distilgpt2-SCAN-v2-5epoch": [
    "model.safetensors"
  ],
  "damerajee/openhathi-h2e-e2h-small": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "igorktech/TinyIG": [
    "model.safetensors"
  ],
  "jjszpak/distilgpt2-SCAN-v2-6epoch": [
    "model.safetensors"
  ],
  "Kedar84/Mixtral-echo": [
    "adapter_model.safetensors"
  ],
  "octopus2023-inc/mixtral-int4-shiftsmart-v1": [
    "model-00001-of-00039.safetensors",
    "model-00002-of-00039.safetensors",
    "model-00003-of-00039.safetensors",
    "model-00004-of-00039.safetensors",
    "model-00005-of-00039.safetensors",
    "model-00006-of-00039.safetensors",
    "model-00007-of-00039.safetensors",
    "model-00008-of-00039.safetensors",
    "model-00009-of-00039.safetensors",
    "model-00010-of-00039.safetensors",
    "model-00011-of-00039.safetensors",
    "model-00012-of-00039.safetensors",
    "model-00013-of-00039.safetensors",
    "model-00014-of-00039.safetensors",
    "model-00015-of-00039.safetensors",
    "model-00016-of-00039.safetensors",
    "model-00017-of-00039.safetensors",
    "model-00018-of-00039.safetensors",
    "model-00019-of-00039.safetensors",
    "model-00020-of-00039.safetensors",
    "model-00021-of-00039.safetensors",
    "model-00022-of-00039.safetensors",
    "model-00023-of-00039.safetensors",
    "model-00024-of-00039.safetensors",
    "model-00025-of-00039.safetensors",
    "model-00026-of-00039.safetensors",
    "model-00027-of-00039.safetensors",
    "model-00028-of-00039.safetensors",
    "model-00029-of-00039.safetensors",
    "model-00030-of-00039.safetensors",
    "model-00031-of-00039.safetensors",
    "model-00032-of-00039.safetensors",
    "model-00033-of-00039.safetensors",
    "model-00034-of-00039.safetensors",
    "model-00035-of-00039.safetensors",
    "model-00036-of-00039.safetensors",
    "model-00037-of-00039.safetensors",
    "model-00038-of-00039.safetensors",
    "model-00039-of-00039.safetensors"
  ],
  "invalid-coder/Sakura-SOLAR-Instruct-CarbonVillain-en-10.7B-v2-slerp": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "diffnamehard/Psyfighter2-Noromaid-ties-Capybara-13B": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "zubairsamo/llama-2-7b-miniplatypus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Sao10K/Fimbulvetr-10.7B-v1": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Sensualize-Mixtral-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Sensualize-Mixtral-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Kooten/Velara-11B-V2-4bpw-exl2": [
    "output.safetensors"
  ],
  "Kooten/Velara-11B-V2-5bpw-exl2": [
    "output.safetensors"
  ],
  "Kooten/Velara-11B-V2-8bpw-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Kooten/Velara-11B-V2-6bpw-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "osanseviero/mistral-instruct-frankenmerge": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "osanseviero/mistral-instruct-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "osanseviero/mistral-instruct-moe-experimental": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mogaio/pr_unsloth_mistral-7b-bnb-4bit": [
    "model.safetensors"
  ],
  "vishesht27/22-Neuro_Model": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Wanfq/fusechat_multi_teacher_ckpt": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "walebadr/Mistral-7B-v0.1-DPO": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "khoantap/Winner-Hug": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Yash21/SuperChat-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "dev137/TriadParty_deepmoney-34b-200k-base-exl2-3.0bpw-h8": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/OrcaMaid-v3-13b-32k-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "Technoculture/Medorca-7B-Slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jjszpak/distilgpt2-SCAN-translate-to-commands-2epoch": [
    "model.safetensors"
  ],
  "orion-penner/phi-2_CustomHandler": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jjszpak/distilgpt2-SCAN-translate-to-commands-3epoch": [
    "model.safetensors"
  ],
  "macadeliccc/dolphin-mixtral-2x7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TeeZee/2xNous-Capybara-34B": [
    "model-00001-of-00012.safetensors",
    "model-00002-of-00012.safetensors",
    "model-00003-of-00012.safetensors",
    "model-00004-of-00012.safetensors",
    "model-00005-of-00012.safetensors",
    "model-00006-of-00012.safetensors",
    "model-00007-of-00012.safetensors",
    "model-00008-of-00012.safetensors",
    "model-00009-of-00012.safetensors",
    "model-00010-of-00012.safetensors",
    "model-00011-of-00012.safetensors",
    "model-00012-of-00012.safetensors"
  ],
  "dev137/TriadParty_deepmoney-34b-200k-base-exl2-4.0bpw-h8": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "kreabs/FernandoGPT-v1_finetuned_dolly_2400": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jjszpak/distilgpt2-SCAN-translate-to-commands-4epoch": [
    "model.safetensors"
  ],
  "KumquatJoe/DialoGPT-medium-BlastyBot": [
    "model.safetensors"
  ],
  "alitolga/roberta-base_fine_lr0.0005_bs4_epoch10_wd0.01": [
    "model.safetensors"
  ],
  "JoshVictor/llama-2-7b-chat-hf-TEL-MED": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Sensualize-Mixtral-bf16-3.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "hossr/model600": [
    "model.safetensors"
  ],
  "LoneStriker/Sensualize-Mixtral-bf16-3.5bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "kasper52786/Wizard7-kspr": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/Mistral-7B-Instruct-v0.2-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Moatazz/thirdtrial": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/vigostral-7b-chat-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "impossibleexchange/pt21": [
    "model.safetensors"
  ],
  "LoneStriker/Sensualize-Mixtral-bf16-3.75bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "jjszpak/distilgpt2-SCAN-translate-to-commands-5epoch": [
    "model.safetensors"
  ],
  "aihub-app/Zyte-1B": [
    "model.safetensors"
  ],
  "LoneStriker/Sensualize-Mixtral-bf16-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Sensualize-Mixtral-bf16-5.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "invalid-coder/SOLAR-10.7B-Instruct-SOLARC-M-10.7B-slerp": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/OrcaMaid-v3-13b-32k-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/OrcaMaid-v3-13b-32k-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "Technoculture/Medorca-2x7b": [
    "model-00001-of-00002.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00002.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/OrcaMaid-v3-13b-32k-6.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "jysssacc/bloomz-560m_huth_fine_lr5e-05_bs2_epoch5_wd0.01": [
    "model.safetensors"
  ],
  "jpcrisostomo/Mistral-7B-MC-DPO2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/OrcaMaid-v3-13b-32k-8.0bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "jysssacc/huth_roberta-base_fine_lr5e-05_bs4_epoch5_wd0.01": [
    "model.safetensors"
  ],
  "MaziyarPanahi/Mistral-7B-Instruct-v0.1-16k-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "djomo/MISTRALllux1000-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/rfp_instruct_model-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "SharedGPT/llama-2-7b-miniplatypus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/Mistral-7B-Instruct-SQL-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "maxmyn/Greentexts-GPT-Neo-MVP": [
    "model.safetensors"
  ],
  "jeiku/Skinwalker_3B": [
    "model-00001-of-00001.safetensors"
  ],
  "MaziyarPanahi/mistral-7B-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/tiledfloor-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jjszpak/SCAN-dc-5-epoch": [
    "model.safetensors"
  ],
  "MaziyarPanahi/Mistral-11B-Instruct-v0.2-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "netomi-ai/netomi-llm-v7-nous-llama2-13b-merged": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "alitolga/roberta-base_fine_lr5e-05_bs4_epoch10_wd0.01": [
    "model.safetensors"
  ],
  "TheBloke/MegaDolphin-120b-GPTQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/MegaDolphin-120b-AWQ": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "MaziyarPanahi/Commonsense-QA-Mistral-7B-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/BASH-Coder-Mistral-7B-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "xezpeleta/Llama-2-7b-chat-eu": [
    "adapter_model.safetensors"
  ],
  "impossibleexchange/pt22": [
    "model.safetensors"
  ],
  "MaziyarPanahi/finetuned-mistral-7b-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jjszpak/SCAN-dc-7-epoch": [
    "model.safetensors"
  ],
  "MaziyarPanahi/Mistral-7B-Instruct-guidance-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "herisan/tinyllama-mental_health_counseling_conversations": [
    "model.safetensors"
  ],
  "shadowml/phixtral-4x2_8odo": [
    "model-00001-of-00001.safetensors"
  ],
  "shadowml/phixtral-4x2_8odd": [
    "model-00001-of-00001.safetensors"
  ],
  "IBI-CAAI/MELT-TinyLlama-1.1B-Chat-v1.0": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "kz919/mistral-7b-sft-open-orca-flan-50k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kz919/mistral-7b-dpo-open-orca-flan-50k-synthetic-5-models": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "grimulkan/aurelian-FAILED-70b-rope8-32K-fp16": [
    "model-00001-of-00035.safetensors",
    "model-00002-of-00035.safetensors",
    "model-00003-of-00035.safetensors",
    "model-00004-of-00035.safetensors",
    "model-00005-of-00035.safetensors",
    "model-00006-of-00035.safetensors",
    "model-00007-of-00035.safetensors",
    "model-00008-of-00035.safetensors",
    "model-00009-of-00035.safetensors",
    "model-00010-of-00035.safetensors",
    "model-00011-of-00035.safetensors",
    "model-00012-of-00035.safetensors",
    "model-00013-of-00035.safetensors",
    "model-00014-of-00035.safetensors",
    "model-00015-of-00035.safetensors",
    "model-00016-of-00035.safetensors",
    "model-00017-of-00035.safetensors",
    "model-00018-of-00035.safetensors",
    "model-00019-of-00035.safetensors",
    "model-00020-of-00035.safetensors",
    "model-00021-of-00035.safetensors",
    "model-00022-of-00035.safetensors",
    "model-00023-of-00035.safetensors",
    "model-00024-of-00035.safetensors",
    "model-00025-of-00035.safetensors",
    "model-00026-of-00035.safetensors",
    "model-00027-of-00035.safetensors",
    "model-00028-of-00035.safetensors",
    "model-00029-of-00035.safetensors",
    "model-00030-of-00035.safetensors",
    "model-00031-of-00035.safetensors",
    "model-00032-of-00035.safetensors",
    "model-00033-of-00035.safetensors",
    "model-00034-of-00035.safetensors",
    "model-00035-of-00035.safetensors"
  ],
  "Azazelle/Sina-Thor-7b-Merge": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Azazelle/Sina-Odin-7b-Merge": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Edentns/DataVortexS-10.7B-v0.4": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Azazelle/Sina-Loki-7b-Merge": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "SanjiWatsuki/Kunoichi-DPO-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "STR01/sft_swallow7b_anametho": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jsfs11/DDPOO-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "TeeZee/2xbagel-dpo-34b-v0.2": [
    "model-00001-of-00012.safetensors",
    "model-00002-of-00012.safetensors",
    "model-00003-of-00012.safetensors",
    "model-00004-of-00012.safetensors",
    "model-00005-of-00012.safetensors",
    "model-00006-of-00012.safetensors",
    "model-00007-of-00012.safetensors",
    "model-00008-of-00012.safetensors",
    "model-00009-of-00012.safetensors",
    "model-00010-of-00012.safetensors",
    "model-00011-of-00012.safetensors",
    "model-00012-of-00012.safetensors"
  ],
  "vwxyzjn/sft_openassistant-guanaco": [
    "model.safetensors"
  ],
  "LoneStriker/Sensualize-Mixtral-bf16-6.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "TitleOS/CodePhi2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Sensualize-Mixtral-bf16-2.4bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "NeverSleep/Noromaid-7B-0.4-DPO": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "Envoid/Augmentasanguis-PDE-8x7B": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "therealcyberlord/TinyLlama-1.1B-Medical": [
    "adapter_model.safetensors"
  ],
  "CallComply/openchat-3.5-0106-32k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jeiku/ToxicNoRobotsRosaHermesBoros_3B": [
    "model-00001-of-00001.safetensors"
  ],
  "obrmmk/tinycodellama-jp-1.3b-30k": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Kunoichi-DPO-7B-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Kunoichi-DPO-7B-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Kunoichi-DPO-7B-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Kunoichi-DPO-7B-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "vihangd/DopeyTinyLlama-1.1B-v1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "yuntaeyang/Yi-6B-ko-dpo-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Kunoichi-DPO-7B-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "Masa-Erland/musang-mistral-7b-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/neuronovo-7B-v0.3-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "pradeepbord/phi2_solar_v1": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "LoneStriker/neuronovo-7B-v0.3-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/neuronovo-7B-v0.3-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "elliotthwangmsa/phi-2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "sethuiyer/Chikuma_10.7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/neuronovo-7B-v0.3-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "oopsung/Yi-Ko-ENW-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "senseable/garten2-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "matthewnorton/mamba-phi": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/neuronovo-7B-v0.3-8.0bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "shitshow123/mistral7b_sft_dpo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "shitshow123/stablelm_sft_dpo": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "ifuseok/sft-solar-10.7b-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dfurman/GarrulusMarcoro-7B-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "alfalmi/distilgpt2-esp": [
    "model.safetensors"
  ],
  "Masa-Erland/musang-mistral-7b-v3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "decruz07/kellemar-DPO-7B-v1.01": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MediaTek-Research/Breeze-7B-Instruct-64k-v0_1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/KAI-7B-Instruct-v0.1-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "kodonho/Solar-M-SakuraSolar-Mixed": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "minjmunc/dialoGPT-small-yumsterBot": [
    "checkpoint-10500/model.safetensors",
    "checkpoint-14000/model.safetensors",
    "checkpoint-17500/model.safetensors",
    "checkpoint-21000/model.safetensors",
    "checkpoint-24500/model.safetensors",
    "checkpoint-28000/model.safetensors",
    "checkpoint-3500/model.safetensors",
    "checkpoint-7000/model.safetensors",
    "model.safetensors"
  ],
  "NickyNicky/Mixtral-2x7b-OpenOrca-oasst_top1_2023-08-25-v1.0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Inferless/Mixtral-8x7B-v0.1-int8-GPTQ": [],
  "hazmannaim/dahreply-spam-dialogpt2-v1.0-alpha": [
    "model.safetensors"
  ],
  "ayousanz/Marcoro14-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "andysalerno/openchat-nectar-0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mithlesh/LlaMA-2-on-Propellyr": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "NLPinas/yi-bagel-2x34b": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "double7/vicuna-160m": [
    "model.safetensors"
  ],
  "double7/vicuna-68m": [
    "model.safetensors"
  ],
  "flemmingmiguel/Mistrality-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "ken70/kawayi-34b": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "Masa-Erland/musang-mistral-7b-v3-awq": [
    "model.safetensors"
  ],
  "Yarofa/model_pu_241_v1": [
    "model.safetensors"
  ],
  "LoneStriker/MegaDolphin-120b-2.4bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "argilla/distilabeled-Marcoro14-7B-slerp": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "szymonrucinski/Curie-7B-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "flemmingmiguel/HermesChat-Mistral-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "alfalmi/pyon410m": [
    "model.safetensors"
  ],
  "NovusResearch/Novus-7B-Instruct-SEO": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "seanbenhur/openpipe_mistral": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "tuantran1632001/Psyfighter2-Orca2-13B-ties": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "decruz07/kellemar-DPO-7B-d": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "yusp998/legal_base-7b": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "jpcrisostomo/Mistral-7B-MC-DPO3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "proto-llm/uniwiz-7B-v0.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "minjmunc/DialoGPT-medium-yumsterBot": [
    "checkpoint-10500/model.safetensors",
    "checkpoint-14000/model.safetensors",
    "checkpoint-17500/model.safetensors",
    "checkpoint-21000/model.safetensors",
    "checkpoint-24500/model.safetensors",
    "checkpoint-28000/model.safetensors",
    "checkpoint-3500/model.safetensors",
    "checkpoint-7000/model.safetensors",
    "model.safetensors"
  ],
  "aqweteddy/llama2-7b-capybara": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "solidrust/Noromaid-7B-0.4-DPO-AWQ": [
    "model.safetensors"
  ],
  "HanaGroup/informal_multiturn-awq": [
    "model.safetensors"
  ],
  "MaziyarPanahi/openbuddy-zephyr-7b-v14.1-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/japanese-stablelm-instruct-gamma-7b-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ayousanz/youri-jp-sb-ai-7b-slerp": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "LoneStriker/MegaDolphin-120b-2.65bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "codejin/distilgpt2-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "MaziyarPanahi/mistral-ft-optimized-1227-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Minirecord/mini_orca_informal-awq": [
    "model.safetensors"
  ],
  "MaziyarPanahi/zephyr-7b-sft-full-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "dmntrd/zephyr-7b-beta-quijote": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dev137/TriadParty_deepmoney-34b-200k-base-safetensors": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "MaziyarPanahi/Ferret_7B-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/Synatra-V0.1-7B-Instruct-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jan-hq/TinyLlama-Bamboo-v1.5": [
    "model.safetensors"
  ],
  "gizmo-ai/Mixtral-8x7B-Instruct-v0.1-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/Yarn-Mistral-7b-64k-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "umarigan/gpt2-wikitext2": [
    "model.safetensors"
  ],
  "LoneStriker/Velara-11B-V2-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Velara-11B-V2-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "MaziyarPanahi/GreenNode-mini-7B-v1olet-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Velara-11B-V2-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "MaziyarPanahi/notus-7b-v1-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Velara-11B-V2-6.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/MetaMath-Mistral-7B-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Velara-11B-V2-8.0bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "allaye/TinyLlama-1.1b-assessment-score-GTP-TA": [
    "model.safetensors"
  ],
  "h-asterix/mistralai-Code-Instruct-Finetune-test-epoch-2.0-smalldatatestset-multigpu-length-optimised": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "Abhishek107/small_model": [
    "model.safetensors"
  ],
  "MaziyarPanahi/mistral-ft-optimized-1218-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "hflserdaniel/chai_s6_13b_4096": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "summer11111/CODEsummer": [
    "model.safetensors"
  ],
  "MaziyarPanahi/Synatra-7B-v0.3-RP-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "elliotthwang/phi-2-zh": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "blueapple8259/TinyKo-V4": [
    "model.safetensors"
  ],
  "gizmo-ai/Mixtral-8x7B-Instruct-v0.1": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "MaziyarPanahi/neural-chat-7b-v3-3-Slerp-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "hflserdaniel/chai_s6_13b_v2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "elliotthwang/phi-2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "aPrem/my_awesome_eli5_clm-model": [
    "model.safetensors"
  ],
  "MaziyarPanahi/ANIMA-Phi-Neptune-Mistral-7B-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/MegaDolphin-120b-2.9bpw-h6-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "MaziyarPanahi/neural-chat-7b-v3-2-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "shidowake/test-240111-defalut-template-swallow-7B-hf-qlora-adaptor-merged": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "MaziyarPanahi/Tess-XS-v1-3-yarn-128K-Mistral-7B-Instruct-v0.2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jaynehra/Mistral-7B-7B-slerp-jay": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "impossibleexchange/pt23": [
    "model.safetensors"
  ],
  "SE6446/Tiny-llamix_2x1B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Kooten/Noromaid-7B-0.4-DPO-8bpw-exl2": [
    "output.safetensors"
  ],
  "Fredithefish/DonkeyRP": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "elliotthwang/KimLam_phi-2-zh": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/MegaDolphin-120b-4.0bpw-h6-exl2": [
    "output-00001-of-00008.safetensors",
    "output-00002-of-00008.safetensors",
    "output-00003-of-00008.safetensors",
    "output-00004-of-00008.safetensors",
    "output-00005-of-00008.safetensors",
    "output-00006-of-00008.safetensors",
    "output-00007-of-00008.safetensors",
    "output-00008-of-00008.safetensors"
  ],
  "MaziyarPanahi/speechless-code-mistral-7b-v1.0-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Kooten/Noromaid-7B-0.4-DPO-6bpw-exl2": [
    "output.safetensors"
  ],
  "Benchmbn/autotrain3": [
    "adapter_model.safetensors",
    "checkpoint-1/adapter_model.safetensors"
  ],
  "MaziyarPanahi/NeuralHermes-2.5-Mistral-7B-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "khanhnto/kyt13Bv2": [
    "adapter_model.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Kooten/Noromaid-7B-0.4-DPO-4bpw-exl2": [
    "output.safetensors"
  ],
  "MaziyarPanahi/v1olet_marcoroni-go-bruins-merge-7B-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jysssacc/TinyLlama-1.1B-intermediate-step-1195k-token-2.5T_huth_fine_lr5e-05_bs2_epoch5_wd0.01": [
    "model.safetensors"
  ],
  "MaziyarPanahi/koOpenChat-sft-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Fredithefish/OpenZephyrChat_merge1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "rakepants/ruDialoGPT-medium-finetuned-toxic": [
    "model.safetensors"
  ],
  "TheBloke/phixtral-4x2_8-GPTQ": [
    "model.safetensors"
  ],
  "MaziyarPanahi/go-bruins-v2-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "abideen/DareVox-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Fredithefish/OpenZephyrChat_merge2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "damerajee/Oot-v2_lll": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "MaziyarPanahi/SciPhi-Mistral-7B-32k-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LucciAI/LlamaDos-chat-hf": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/neural-chat-7b-v3-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jysssacc/627_roberta-base_fine_lr5e-06_bs4_epoch5_wd0.01": [
    "model.safetensors"
  ],
  "Moatazz/fourthtrial": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jysssacc/opt-350m_fine_lr5e-06_bs4_epoch5_wd0.01": [
    "model.safetensors"
  ],
  "Fredithefish/OpenZephyrChat_merge3": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jjszpak/SCAN-dc-15-epoch": [
    "model.safetensors"
  ],
  "Abhishek107/small_llm": [
    "model.safetensors"
  ],
  "MaziyarPanahi/MetaMath-Cybertron-Starling-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "manikeerthi/NeuralHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "abideen/NexoNimbus-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "LucciAI/LlamaDos-chat-hf-function-calling": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/OpenHermes-2.5-neural-chat-7b-v3-1-7B-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "decruz07/kellemar-DPO-7B-e": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/mindy-7b-v2-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Nous-Capybara-limarpv3-34B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Nous-Capybara-limarpv3-34B-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/blossom-v3-mistral-7b-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "OpenBuddy/openbuddy-deepseek-10b-v17.1-4k": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5": [
    "model.safetensors"
  ],
  "MaziyarPanahi/una-cybertron-7b-v2-bf16-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/openbuddy-mistral-7b-v13.1-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Open_Gpt4_8x7B_v0.2-3.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow0": [
    "model.safetensors"
  ],
  "MaziyarPanahi/openbuddy-mistral-7b-v13-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Gnider/praktika_rugpt3_small_5200_news": [
    "model.safetensors"
  ],
  "mogaio/pr_unsloth_mistral-7b-bnb-4bit_alpaca": [
    "model.safetensors"
  ],
  "DrNicefellow/airoboros-3_1-yi-34b-200k-gptq-exl2-4_5bpw": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Open_Gpt4_8x7B_v0.2-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow1": [
    "model.safetensors"
  ],
  "jjszpak/SCAN-dc-30-epoch": [
    "model.safetensors"
  ],
  "Federic/final_merged": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "klyang/MentaLLaMA-chat-7B-hf": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/Open_Gpt4_8x7B_v0.2-5.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow2": [
    "model.safetensors"
  ],
  "bburli/llama-2-7b-bburli-5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Open_Gpt4_8x7B_v0.2-6.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow3": [
    "model.safetensors"
  ],
  "jysssacc/627_roberta-base_fine_lr5e-05_bs4_epoch5_wd0.01": [
    "model.safetensors"
  ],
  "LoneStriker/Open_Gpt4_8x7B_v0.2-8.0bpw-h8-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow4": [
    "model.safetensors"
  ],
  "disinfozone/Disinfo4_mistral-ft-optimized-1218": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow5": [
    "model.safetensors"
  ],
  "RaiBP/gpt2-openwebtext2-first-30-chunks-ablation-translation": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow6": [
    "model.safetensors"
  ],
  "LoneStriker/Open_Gpt4_8x7B_v0.2-3.5bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow7": [
    "model.safetensors"
  ],
  "LoneStriker/Open_Gpt4_8x7B_v0.2-3.75bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "gagan3012/Mistral_arabic_dpo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Chandller/merged_phi2_2x8": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "navneeth-hr/reuters-gpt2-text-gen": [
    "model.safetensors"
  ],
  "Masa-Erland/musang-mistral-7b-v3-float16-awq": [
    "model.safetensors"
  ],
  "Weni/deita-complexity-scorer-AWQ": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow8": [
    "model.safetensors"
  ],
  "Bytes512/Waterbuck": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Chandller/merged_phi2_2x8_bf16": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/mamba-gpt-7b-v2-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Yemmy1000/llama-2-7b-cybersec": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow9": [
    "model.safetensors"
  ],
  "avemio-digital/lora_unsloth_merge": [
    "model.safetensors"
  ],
  "MaziyarPanahi/OpenHermes-7B-Symbolic-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "abideen/Heimer-dpo-TinyLlama-1.1B": [
    "model.safetensors"
  ],
  "MaziyarPanahi/blossom-v3_1-mistral-7b-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/TowerInstruct-7B-v0.1-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "Weni/deita-quality-scorer-AWQ": [
    "model.safetensors"
  ],
  "LoneStriker/TowerInstruct-7B-v0.1-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/TowerInstruct-7B-v0.1-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow11": [
    "model.safetensors"
  ],
  "MaziyarPanahi/mamba-gpt-7b-v1-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/TowerInstruct-7B-v0.1-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "amazingvince/chess-llama-mini-v2-1024": [
    "model.safetensors"
  ],
  "LoneStriker/TowerInstruct-7B-v0.1-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "jysssacc/627_roberta-base_fine_lr0.0005_bs4_epoch5_wd0.01": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow12": [
    "model.safetensors"
  ],
  "MaziyarPanahi/openbuddy-mistral-7b-v13-base-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Kquant03/Hippolyta-7B-bf16": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow13": [
    "model.safetensors"
  ],
  "abideen/Heimer-ipo-TinyLlama-1.1B": [
    "model.safetensors"
  ],
  "MaziyarPanahi/testllm-c2-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ambrosfitz/tinyllama-history-chat-v1.1": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow14": [
    "model.safetensors"
  ],
  "MaziyarPanahi/PiVoT-10.7B-Mistral-v0.2-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "VitalContribution/Evangelion-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jjszpak/SCAN-seq2seq-dc-30-epoch": [
    "model.safetensors"
  ],
  "herisan/Mistral-7B-mental_health_counseling_conversations": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow15": [
    "model.safetensors"
  ],
  "Praneeth/StarMix-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow16": [
    "model.safetensors"
  ],
  "davanstrien/TinyLlama-1.1B-Chat-v1.0-intel-dpo": [
    "model.safetensors"
  ],
  "andrewatef/PText": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Air-Striker-Mixtral-8x7B-ZLoss-2.4bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "sequelbox/DiamondForce": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow17": [
    "model.safetensors"
  ],
  "MaziyarPanahi/SciPhi-Self-RAG-Mistral-7B-32k-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Air-Striker-Mixtral-8x7B-ZLoss-3.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow18": [
    "model.safetensors"
  ],
  "MaziyarPanahi/Mini_DPO_test02-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "midoskarr/autotrain-wtj23-f3roe": [
    "adapter_model.safetensors",
    "checkpoint-9/adapter_model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow19": [
    "model.safetensors"
  ],
  "jysssacc/627_roberta-base_fine_lr0.005_bs4_epoch5_wd0.01": [
    "model.safetensors"
  ],
  "LoneStriker/Air-Striker-Mixtral-8x7B-ZLoss-3.5bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "fblgit/UNA-dolphin-2.6-mistral-7b-dpo-laser": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/Mistral-7B-claude-instruct-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow20": [
    "model.safetensors"
  ],
  "LoneStriker/Air-Striker-Mixtral-8x7B-ZLoss-3.75bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/Dans-07YahooAnswers-7b-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow21": [
    "model.safetensors"
  ],
  "dnovak232/mistral7b-sql": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "MaziyarPanahi/pic_7B_mistral_Full_v0.2-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Air-Striker-Mixtral-8x7B-ZLoss-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "superlazycoder/NeuralPipe-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow22": [
    "model.safetensors"
  ],
  "MaziyarPanahi/Mistral-7B-v0.1-Open-Platypus-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mpasila/Psyfighter-13B-exl2-3bpw": [
    "output.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow23": [
    "model.safetensors"
  ],
  "segolilylabs/Lily-Cybersecurity-7B-v0.2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/Air-Striker-Mixtral-8x7B-ZLoss-5.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "MaziyarPanahi/PiVoT-0.1-early-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Loyola/Mistral-7b-ITmodel": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sejaldatta84/autotrain-uuswh-5lpj2": [
    "adapter_model.safetensors",
    "checkpoint-9/adapter_model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow24": [
    "model.safetensors"
  ],
  "lxuechen/phi-2-tool-use": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/Venomia-1.1-m7-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mpasila/LLaMA2-13B-Psyfighter2-exl2-3bpw": [
    "output.safetensors"
  ],
  "LoneStriker/Air-Striker-Mixtral-8x7B-ZLoss-6.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "MaziyarPanahi/shisa-7b-v1-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Summer11t/summer": [
    "model.safetensors"
  ],
  "MaziyarPanahi/mistral-7b-finetuned-orca-dpo-v2-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow26": [
    "model.safetensors"
  ],
  "jysssacc/627_roberta-base_fine_lr0.05_bs4_epoch5_wd0.01": [
    "model.safetensors"
  ],
  "MaziyarPanahi/zephyr-beta-math-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow27": [
    "model.safetensors"
  ],
  "MaziyarPanahi/NyakuraV2.1-m7-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/samantha-mistral-7b-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "SJ-Donald/SOLAR-10.7B-slerp": [
    "model-00001-of-00012.safetensors",
    "model-00002-of-00012.safetensors",
    "model-00003-of-00012.safetensors",
    "model-00004-of-00012.safetensors",
    "model-00005-of-00012.safetensors",
    "model-00006-of-00012.safetensors",
    "model-00007-of-00012.safetensors",
    "model-00008-of-00012.safetensors",
    "model-00009-of-00012.safetensors",
    "model-00010-of-00012.safetensors",
    "model-00011-of-00012.safetensors",
    "model-00012-of-00012.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow28": [
    "model.safetensors"
  ],
  "Fredithefish/Zebra": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/SynthIA-7B-v1.3-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mlabonne/chesspythia-70m": [
    "model.safetensors"
  ],
  "MaziyarPanahi/em_german_leo_mistral-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow29": [
    "model.safetensors"
  ],
  "MaziyarPanahi/dolphin-2.0-mistral-7b-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow30": [
    "model.safetensors"
  ],
  "Fredithefish/Zebra2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/jackalope-7b-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "yihang7/zephyr-7b-dpo-full-hydrox-safe": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "s200862/llama-2-7b-chat-MEDS-12": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow31": [
    "model.safetensors"
  ],
  "MaziyarPanahi/mistral-7b_open_platypus-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "kodonho/SolarM-SakuraSolar-SLERP": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "flemmingmiguel/NeuDist-Ro-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "MaziyarPanahi/mistral-7b-v0.1-layla-v1-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TdL/key11": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow32": [
    "model.safetensors"
  ],
  "TdL/key12": [
    "model.safetensors"
  ],
  "TeeZee/2xNous-Capybara-34B-bpw3.0-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "TdL/key14": [
    "model.safetensors"
  ],
  "TdL/key15": [
    "model.safetensors"
  ],
  "RiverTest/mtg2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "kodonho/Solar-OrcaDPO-Solar-Instruct-SLERP": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "ayousanz/llama-ca-7B-slerp": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "MaziyarPanahi/Mistral-Trismegistus-7B-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow33": [
    "model.safetensors"
  ],
  "MaziyarPanahi/mistralopithecus-v1-dpo-7b-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "SicariusSicariiStuff/Tenebra_30B_Alpha01_FP16": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "MaziyarPanahi/Mistral-T5-7B-v1-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow34": [
    "model.safetensors"
  ],
  "Wanfq/fusechat_nous_teacher_0.7hd": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/samantha-1.2-mistral-7b-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Wanfq/fusechat_phind_teacher_0.7hd": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow35": [
    "model.safetensors"
  ],
  "MaziyarPanahi/SynthIA-7B-v1.5-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "oivlisnet/opt-125m-gptq-4bit": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow36": [
    "model.safetensors"
  ],
  "Wanfq/fusechat_multi_teacher_0.7hd": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/CollectiveCognition-v1.1-Mistral-7B-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "hflserdaniel/chai_s6_13b_0111": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "moreh/MoMo-72B-lora-1.8.4-DPO": [
    "model-00001-of-00063.safetensors",
    "model-00002-of-00063.safetensors",
    "model-00003-of-00063.safetensors",
    "model-00004-of-00063.safetensors",
    "model-00005-of-00063.safetensors",
    "model-00006-of-00063.safetensors",
    "model-00007-of-00063.safetensors",
    "model-00008-of-00063.safetensors",
    "model-00009-of-00063.safetensors",
    "model-00010-of-00063.safetensors",
    "model-00011-of-00063.safetensors",
    "model-00012-of-00063.safetensors",
    "model-00013-of-00063.safetensors",
    "model-00014-of-00063.safetensors",
    "model-00015-of-00063.safetensors",
    "model-00016-of-00063.safetensors",
    "model-00017-of-00063.safetensors",
    "model-00018-of-00063.safetensors",
    "model-00019-of-00063.safetensors",
    "model-00020-of-00063.safetensors",
    "model-00021-of-00063.safetensors",
    "model-00022-of-00063.safetensors",
    "model-00023-of-00063.safetensors",
    "model-00024-of-00063.safetensors",
    "model-00025-of-00063.safetensors",
    "model-00026-of-00063.safetensors",
    "model-00027-of-00063.safetensors",
    "model-00028-of-00063.safetensors",
    "model-00029-of-00063.safetensors",
    "model-00030-of-00063.safetensors",
    "model-00031-of-00063.safetensors",
    "model-00032-of-00063.safetensors",
    "model-00033-of-00063.safetensors",
    "model-00034-of-00063.safetensors",
    "model-00035-of-00063.safetensors",
    "model-00036-of-00063.safetensors",
    "model-00037-of-00063.safetensors",
    "model-00038-of-00063.safetensors",
    "model-00039-of-00063.safetensors",
    "model-00040-of-00063.safetensors",
    "model-00041-of-00063.safetensors",
    "model-00042-of-00063.safetensors",
    "model-00043-of-00063.safetensors",
    "model-00044-of-00063.safetensors",
    "model-00045-of-00063.safetensors",
    "model-00046-of-00063.safetensors",
    "model-00047-of-00063.safetensors",
    "model-00048-of-00063.safetensors",
    "model-00049-of-00063.safetensors",
    "model-00050-of-00063.safetensors",
    "model-00051-of-00063.safetensors",
    "model-00052-of-00063.safetensors",
    "model-00053-of-00063.safetensors",
    "model-00054-of-00063.safetensors",
    "model-00055-of-00063.safetensors",
    "model-00056-of-00063.safetensors",
    "model-00057-of-00063.safetensors",
    "model-00058-of-00063.safetensors",
    "model-00059-of-00063.safetensors",
    "model-00060-of-00063.safetensors",
    "model-00061-of-00063.safetensors",
    "model-00062-of-00063.safetensors",
    "model-00063-of-00063.safetensors"
  ],
  "MaziyarPanahi/Mini_Synatra_SFT-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow37": [
    "model.safetensors"
  ],
  "Warrieryes/math-llama-50k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/speechless-code-mistral-orca-7b-v1.0-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ibndias/Nous-Hermes-2-MoE-2x34B": [
    "model-00001-of-00013.safetensors",
    "model-00002-of-00013.safetensors",
    "model-00003-of-00013.safetensors",
    "model-00004-of-00013.safetensors",
    "model-00005-of-00013.safetensors",
    "model-00006-of-00013.safetensors",
    "model-00007-of-00013.safetensors",
    "model-00008-of-00013.safetensors",
    "model-00009-of-00013.safetensors",
    "model-00010-of-00013.safetensors",
    "model-00011-of-00013.safetensors",
    "model-00012-of-00013.safetensors",
    "model-00013-of-00013.safetensors"
  ],
  "MaziyarPanahi/samantha-mistral-instruct-7b-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow10": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow25": [
    "model.safetensors"
  ],
  "MaziyarPanahi/Mistral-7B-model_45k6e2e4-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow38": [
    "model.safetensors"
  ],
  "MaziyarPanahi/CollectiveCognition-v1-Mistral-7B-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow39": [
    "model.safetensors"
  ],
  "Undi95/BagelMix-8x7B": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "MaziyarPanahi/SynthIA-7B-v1.3-dare-0.85-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/CollectiveCognition-v1.1-Mistral-7B-dare-0.85-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_member_shadow40": [
    "model.safetensors"
  ],
  "nitky/Superswallow-7b-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "nitky/Superswallow-13b-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "PotatoOff/HamSter-0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "flemmingmiguel/Distilled-HermesChat-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "nitky/Superswallow-70b-v0.1": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "MaziyarPanahi/Mini_synatra_7b_02-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/neural-chat-7b-v3-1-dare-0.85-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_non_member_shadow0": [
    "model.safetensors"
  ],
  "Warrieryes/math-llama-150k-new": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "amazingvince/chess-llama-mini-v3-1024": [
    "model.safetensors"
  ],
  "MaziyarPanahi/speechless-code-mistral-7b-v2.0-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Yarofa/model_h100_v156": [
    "model.safetensors"
  ],
  "Mason-Little/my-awesome-model": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_non_member_shadow1": [
    "model.safetensors"
  ],
  "MaziyarPanahi/WizardMath-7B-V1.1-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_non_member_shadow2": [
    "model.safetensors"
  ],
  "MaziyarPanahi/airoboros-m-7b-3.1.2-dare-0.85-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/zephyr-7b-alpha-dare-0.85-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_non_member_shadow3": [
    "model.safetensors"
  ],
  "MaziyarPanahi/smartyplats-7b-v2-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "dhanushreddy29/BrokenKeyboard": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Warrieryes/math-llama-100k-new": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/speechless-mistral-dolphin-orca-platypus-samantha-7b-dare-0.85-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TuringsSolutions/PFAFphi-2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "elijahww/TinyLlama-1.1B-merged": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_non_member_shadow4": [
    "model.safetensors"
  ],
  "MaziyarPanahi/LeoScorpius-7B-Chat-DPO-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ArunSamespace/zephyr-7b-beta-fc-bnb-step750-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/Mistral-7B-golden-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_non_member_shadow5": [
    "model.safetensors"
  ],
  "matbee/Llama-2-13b-chat-hf-sft": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ArunSamespace/zephyr-7b-beta-fc-bnb-step1k-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/Mistral-ko-7B-v0.1-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "greymatter-2024/tiny-llama-sql": [
    "model.safetensors"
  ],
  "MaziyarPanahi/una-cybertron-7b-v3-OMA-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_non_member_shadow6": [
    "model.safetensors"
  ],
  "Mason-Little/my-awesome-model_2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "tigerbhai/Texmin_llama_1_B": [
    "model.safetensors"
  ],
  "MaziyarPanahi/v1olet_merged_dpo_7B-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ambrosfitz/neural-history-chat-v1.0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_non_member_shadow7": [
    "model.safetensors"
  ],
  "MaziyarPanahi/japanese-stablelm-base-gamma-7b-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "codefuse-ai/CodeFuse-Mixtral-8x7B": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "shidowake/test-240111-defalut-template-swallow-7B-hf-qlora-adaptor-4bit-merged": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TomGrc/FusionNet_7Bx2_MoE_14B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mtc/meta-llama-Llama-2-7b-hf-pubmed-summarization-5000-finetuned-no-quantization-2k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_non_member_shadow8": [
    "model.safetensors"
  ],
  "MaziyarPanahi/piano-medley-7b-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mncai/MiBaSe-Marcoroni": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mtc/meta-llama-Llama-2-7b-hf-arxiv-summarization-5000-finetuned-no_quantization-2k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/zephykor-ko-beta-7b-chang-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "kam414/quipbot_v3-checkpoint-110": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "codeaze/CA-Pharma-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_non_member_shadow9": [
    "model.safetensors"
  ],
  "thedeadman89661/vietcuna-7b-rf-model": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/Rabbit-7B-DPO-Chat-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Envoid/CATA-8x7B": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "AkiGogikar/KnowledgeNinja-LiteLlama-460Mx6MoE-1T": [
    "model-00001-of-00001.safetensors"
  ],
  "MaziyarPanahi/DPOpenHermes-7B-v2-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_non_member_shadow10": [
    "model.safetensors"
  ],
  "MaziyarPanahi/typhoon-7b-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Cegil/SQLTEST": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_non_member_shadow11": [
    "model.safetensors"
  ],
  "MaziyarPanahi/speechless-mistral-six-in-one-7b-orth-1.0-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "aanandan/RickGPT-medium-Aditya": [
    "model.safetensors"
  ],
  "xriminact/TarsChattyBasev0.0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/Synatra-7B-Instruct-v0.2-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_non_member_shadow12": [
    "model.safetensors"
  ],
  "MaziyarPanahi/Mini_synatra_7b_03-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_non_member_shadow13": [
    "model.safetensors"
  ],
  "MaziyarPanahi/Mistral-7B-KNUT-v0.2-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/MRAI_synatra_7B_v1-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_non_member_shadow14": [
    "model.safetensors"
  ],
  "abideen/Heimer-kto-TinyLlama-1.1B": [
    "model.safetensors"
  ],
  "LucciAI/openchat-3.5-0106-function-calling": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/Mini_synata_7b_011-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "EmbeddedLLM/Mistral-7B-Merge-14-v0.5": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Hanabanana01/koreanMajorChatbot-polyglot-ko-1.3b": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/LeoScorpius-GreenNode-Alpaca-7B-v1-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_non_member_shadow15": [
    "model.safetensors"
  ],
  "Sayan01/BabyVicuna-m": [
    "model.safetensors"
  ],
  "hflserdaniel/chai_s6_13b_slerp": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/agiin-13.6B-v0.1-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "udkai/Turdus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_non_member_shadow16": [
    "model.safetensors"
  ],
  "MaziyarPanahi/LeoScorpius-GreenNode-Platypus-7B-v1-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Heng666/BreezePipe-7B-merge": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "tigerbhai/Texmin_PHI_2.0_B": [
    "model.safetensors"
  ],
  "MaziyarPanahi/Mistral-7B-v0.1-sharded-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_non_member_shadow17": [
    "model.safetensors"
  ],
  "MaziyarPanahi/dolphin-2.6-mistral-7b-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "oshanam/llama-2-7b-miniplatypus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "decruz07/kellemar-Orca-DPO-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_non_member_shadow18": [
    "model.safetensors"
  ],
  "MaziyarPanahi/Tulpar-7b-v2-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "tigerbhai/phi-2-texmin": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/fresh_gpt2_gen_full_dbpedia_14_t30000_e5_non_member_shadow19": [
    "model.safetensors"
  ],
  "MaziyarPanahi/Marcoroni-neural-chat-7B-v2-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FelixChao/WizardDolphin-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/OpenHermes-2.5-neural-chat-v3-3-Slerp-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/MelloGPT-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "abdiharyadi/kancilgpt-v20240113": [
    "model.safetensors"
  ],
  "ArunSamespace/zephyr-7b-beta-fc-bnb-step750-merged-awq": [
    "model.safetensors"
  ],
  "adjohn1313/blackbox_llama_30k": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/MetaMath-Chupacabra-7B-v2.01-Slerp-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "kimmypracha/mistral-marunachef-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "JNewber/OHo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/Metis-0.4-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "NucleusOrg/Nucleus-1B-alpha-1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/Mistral-7b-FFT-Test3-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "kimmypracha/mistral-marunashop-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "shidowake/Mistral-7B-base-bnb-4bit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/MetaMath-Tulpar-7b-v2-Slerp-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jysssacc/opt-350m_fine_lr5e-06_bs10_epoch5_wd0.01": [
    "model.safetensors"
  ],
  "MaziyarPanahi/zephyr-7b-alpha-sharded-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "shidowake/SOLAR-10.7B-base-bnb-4bit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/sqlcoder-7b-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "1TuanPham/cognitivecomputations-dolphin-llama2-7b-sharded": [
    "model-00001-of-00016.safetensors",
    "model-00002-of-00016.safetensors",
    "model-00003-of-00016.safetensors",
    "model-00004-of-00016.safetensors",
    "model-00005-of-00016.safetensors",
    "model-00006-of-00016.safetensors",
    "model-00007-of-00016.safetensors",
    "model-00008-of-00016.safetensors",
    "model-00009-of-00016.safetensors",
    "model-00010-of-00016.safetensors",
    "model-00011-of-00016.safetensors",
    "model-00012-of-00016.safetensors",
    "model-00013-of-00016.safetensors",
    "model-00014-of-00016.safetensors",
    "model-00015-of-00016.safetensors",
    "model-00016-of-00016.safetensors"
  ],
  "Heng666/EastAsia-4x7B-Moe-experiment": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "khoantap/Starling-RP": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "3okasha/test1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "MaziyarPanahi/MythoMist-7b-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/neuronovo-7B-v0.3-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/neuronovo-7B-v0.3-AWQ": [
    "model.safetensors"
  ],
  "Pierre-obi/Mistral_solar-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "mithlesh/LlaMA-2-hitchiker": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/bagel-dpo-7b-v0.1-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jysssacc/opt-350m_fine_lr0.005_bs10_epoch5_wd0.01": [
    "model.safetensors"
  ],
  "MaziyarPanahi/openchat_3.5-16k-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ondevicellm/zephyr-7b-dpo-full": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "khoantap/Poppy-RP": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/Mistral-7B-KNUT-v0.3-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Open_Gpt4_8x7B_v0.2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Open_Gpt4_8x7B_v0.2-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/MetaMath-OpenHermes-2.5-neural-chat-v3-3-Slerp-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/WinterGoliath-123b-GPTQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/WinterGoliath-123b-AWQ": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "TheBloke/TenyxChat-7B-v1-AWQ": [
    "model.safetensors"
  ],
  "jysssacc/opt-350m_fine_lr0.05_bs10_epoch5_wd0.01": [
    "model.safetensors"
  ],
  "0x7o/persona-13B-v1": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "MaziyarPanahi/Marcoroni-neural-chat-7B-v1-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "khoantap/Dolphin-DPO-RP": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/SauerkrautLM-7b-HerO-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/bagel-7b-v0.1-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Wanfq/fusechat_v1_baseline_ckpt": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/WhiteRabbitNeo-33B-v1-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jysssacc/opt-350m_fine_lr5e-05_bs10_epoch5_wd0.01": [
    "model.safetensors"
  ],
  "Mik99/mistral_8_features_at_once_merged": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "h-asterix/shakul-22": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "maywell/PiVoT-SUS-RP": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "MaziyarPanahi/loyal-piano-m7-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/Seraph-7B-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "danielhanchen/test_upload": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dnovak232/Mistral7B-Instruct-v0.1-mssql": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "MaziyarPanahi/Noromaid-7b-v0.1.1-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/Starling-LM-11B-alpha-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jysssacc/opt-350m_fine_lr0.0005_bs10_epoch5_wd0.01": [
    "model.safetensors"
  ],
  "gizmo-ai/Mixtral-8x7B-v0.1-GPTQ": [
    "model.safetensors"
  ],
  "charlesdedampierre/TopicNeuralHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Selvaram/koala-7B-slerp": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "gizmo-ai/Starling-LM-7B-alpha": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "gizmo-ai/Starling-LM-7B-alpha-AWQ": [
    "model.safetensors"
  ],
  "MaziyarPanahi/Karen_TheEditor_V2_STRICT_Mistral_7B-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jvh/Mistral-Orca-GEITje": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "MrSentinel/TinySentinel-1.1B-v0.1": [
    "model.safetensors"
  ],
  "TheBloke/WhiteRabbitNeo-33B-v1-GPTQ": [
    "model.safetensors"
  ],
  "MaziyarPanahi/shisa-base-7b-v1-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "bulkbeings/Emp_nous_inst_v4": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "MaziyarPanahi/OpenZephyrChat-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "byroneverson/LLaVA-v1.5-7B-rehome": [
    "model-00001-of-00021.safetensors",
    "model-00002-of-00021.safetensors",
    "model-00003-of-00021.safetensors",
    "model-00004-of-00021.safetensors",
    "model-00005-of-00021.safetensors",
    "model-00006-of-00021.safetensors",
    "model-00007-of-00021.safetensors",
    "model-00008-of-00021.safetensors",
    "model-00009-of-00021.safetensors",
    "model-00010-of-00021.safetensors",
    "model-00011-of-00021.safetensors",
    "model-00012-of-00021.safetensors",
    "model-00013-of-00021.safetensors",
    "model-00014-of-00021.safetensors",
    "model-00015-of-00021.safetensors",
    "model-00016-of-00021.safetensors",
    "model-00017-of-00021.safetensors",
    "model-00018-of-00021.safetensors",
    "model-00019-of-00021.safetensors",
    "model-00020-of-00021.safetensors",
    "model-00021-of-00021.safetensors"
  ],
  "MaziyarPanahi/Optimus-7B-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "sonu2023/NeuralHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jvh/Mistral-Orca-GEITje-v2": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "MaziyarPanahi/Falkor-7b-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "DRXD1000/Phoenix-GPTQ": [
    "model.safetensors"
  ],
  "MaziyarPanahi/Nebula-v2-7B-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Weyaxi/Cosmosis-3x34B": [
    "model-00001-of-00018.safetensors",
    "model-00002-of-00018.safetensors",
    "model-00003-of-00018.safetensors",
    "model-00004-of-00018.safetensors",
    "model-00005-of-00018.safetensors",
    "model-00006-of-00018.safetensors",
    "model-00007-of-00018.safetensors",
    "model-00008-of-00018.safetensors",
    "model-00009-of-00018.safetensors",
    "model-00010-of-00018.safetensors",
    "model-00011-of-00018.safetensors",
    "model-00012-of-00018.safetensors",
    "model-00013-of-00018.safetensors",
    "model-00014-of-00018.safetensors",
    "model-00015-of-00018.safetensors",
    "model-00016-of-00018.safetensors",
    "model-00017-of-00018.safetensors",
    "model-00018-of-00018.safetensors"
  ],
  "MaziyarPanahi/ANIMA-Nectar-v2-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/MistralInstructLongish-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jysssacc/bloomz-560m_fine_lr5e-06_bs10_epoch5_wd0.01": [
    "model.safetensors"
  ],
  "Weyaxi/Helion-4x34B": [
    "model-00001-of-00023.safetensors",
    "model-00002-of-00023.safetensors",
    "model-00003-of-00023.safetensors",
    "model-00004-of-00023.safetensors",
    "model-00005-of-00023.safetensors",
    "model-00006-of-00023.safetensors",
    "model-00007-of-00023.safetensors",
    "model-00008-of-00023.safetensors",
    "model-00009-of-00023.safetensors",
    "model-00010-of-00023.safetensors",
    "model-00011-of-00023.safetensors",
    "model-00012-of-00023.safetensors",
    "model-00013-of-00023.safetensors",
    "model-00014-of-00023.safetensors",
    "model-00015-of-00023.safetensors",
    "model-00016-of-00023.safetensors",
    "model-00017-of-00023.safetensors",
    "model-00018-of-00023.safetensors",
    "model-00019-of-00023.safetensors",
    "model-00020-of-00023.safetensors",
    "model-00021-of-00023.safetensors",
    "model-00022-of-00023.safetensors",
    "model-00023-of-00023.safetensors"
  ],
  "MaziyarPanahi/OpenHermes-2.5-neural-chat-v3-2-Slerp-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "DanielHesslow/Mistral_First2Layers": [
    "model.safetensors"
  ],
  "DRXD1000/Phoenix-AWQ": [
    "model.safetensors"
  ],
  "parsak/phi-2-code-instruct": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/Mistral-11B-OmniMix-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jysssacc/bloomz-560m_fine_lr5e-05_bs10_epoch5_wd0.01": [
    "model.safetensors"
  ],
  "dhnanjay/dj-phi-2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/SlimOpenOrca-Mistral-7B-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jvh/Mistral-Orca-GEITje-v3": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "LoneStriker/UNA-TheBeagle-7b-v1-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/UNA-TheBeagle-7b-v1-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/UNA-TheBeagle-7b-v1-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "jysssacc/bloomz-560m_fine_lr0.0005_bs10_epoch5_wd0.01": [
    "model.safetensors"
  ],
  "LoneStriker/UNA-TheBeagle-7b-v1-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/UNA-TheBeagle-7b-v1-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "HenryJJ/dolphin-2.6-mistral-7b-dpo-orca": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/Velara-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "yukihirop/codeparrot-ds": [
    "model.safetensors"
  ],
  "Kquant03/Phalanx-512x460M-MoE": [
    "model-00001-of-00031.safetensors",
    "model-00002-of-00031.safetensors",
    "model-00003-of-00031.safetensors",
    "model-00004-of-00031.safetensors",
    "model-00005-of-00031.safetensors",
    "model-00006-of-00031.safetensors",
    "model-00007-of-00031.safetensors",
    "model-00008-of-00031.safetensors",
    "model-00009-of-00031.safetensors",
    "model-00010-of-00031.safetensors",
    "model-00011-of-00031.safetensors",
    "model-00012-of-00031.safetensors",
    "model-00013-of-00031.safetensors",
    "model-00014-of-00031.safetensors",
    "model-00015-of-00031.safetensors",
    "model-00016-of-00031.safetensors",
    "model-00017-of-00031.safetensors",
    "model-00018-of-00031.safetensors",
    "model-00019-of-00031.safetensors",
    "model-00020-of-00031.safetensors",
    "model-00021-of-00031.safetensors",
    "model-00022-of-00031.safetensors",
    "model-00023-of-00031.safetensors",
    "model-00024-of-00031.safetensors",
    "model-00025-of-00031.safetensors",
    "model-00026-of-00031.safetensors",
    "model-00027-of-00031.safetensors",
    "model-00028-of-00031.safetensors",
    "model-00029-of-00031.safetensors",
    "model-00030-of-00031.safetensors",
    "model-00031-of-00031.safetensors"
  ],
  "Weyaxi/Bagel-Hermes-2x34B": [
    "model-00001-of-00013.safetensors",
    "model-00002-of-00013.safetensors",
    "model-00003-of-00013.safetensors",
    "model-00004-of-00013.safetensors",
    "model-00005-of-00013.safetensors",
    "model-00006-of-00013.safetensors",
    "model-00007-of-00013.safetensors",
    "model-00008-of-00013.safetensors",
    "model-00009-of-00013.safetensors",
    "model-00010-of-00013.safetensors",
    "model-00011-of-00013.safetensors",
    "model-00012-of-00013.safetensors",
    "model-00013-of-00013.safetensors"
  ],
  "mirakl/transfo_zephyr_dv4_wtht_gr_v0_slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "MaziyarPanahi/Kant-Test-0.1-Mistral-7B-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jysssacc/bloomz-560m_fine_lr0.005_bs10_epoch5_wd0.01": [
    "model.safetensors"
  ],
  "kaleabstark/roberta_gen_v_1": [
    "model.safetensors"
  ],
  "Weyaxi/Astralis-4x34B": [
    "model-00001-of-00023.safetensors",
    "model-00002-of-00023.safetensors",
    "model-00003-of-00023.safetensors",
    "model-00004-of-00023.safetensors",
    "model-00005-of-00023.safetensors",
    "model-00006-of-00023.safetensors",
    "model-00007-of-00023.safetensors",
    "model-00008-of-00023.safetensors",
    "model-00009-of-00023.safetensors",
    "model-00010-of-00023.safetensors",
    "model-00011-of-00023.safetensors",
    "model-00012-of-00023.safetensors",
    "model-00013-of-00023.safetensors",
    "model-00014-of-00023.safetensors",
    "model-00015-of-00023.safetensors",
    "model-00016-of-00023.safetensors",
    "model-00017-of-00023.safetensors",
    "model-00018-of-00023.safetensors",
    "model-00019-of-00023.safetensors",
    "model-00020-of-00023.safetensors",
    "model-00021-of-00023.safetensors",
    "model-00022-of-00023.safetensors",
    "model-00023-of-00023.safetensors"
  ],
  "MaziyarPanahi/CatMacaroni-Slerp-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jysssacc/bloomz-560m_fine_lr0.05_bs10_epoch5_wd0.01": [
    "model.safetensors"
  ],
  "RatanRohith/NeuralPizza-7B-V0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/Misted-7B-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "dharanaw5/FYP2": [
    "adapter_model.safetensors",
    "checkpoint-7/adapter_model.safetensors"
  ],
  "MaziyarPanahi/Dans-TotSirocco-7b-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "namespace-Pt/activation-beacon-llama2-7b-chat": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "MaziyarPanahi/test-help-steer-filtered-orig-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "grimulkan/story-reverse-prompt-70b-rope8-32K-fp16": [
    "model-00001-of-00018.safetensors",
    "model-00002-of-00018.safetensors",
    "model-00003-of-00018.safetensors",
    "model-00004-of-00018.safetensors",
    "model-00005-of-00018.safetensors",
    "model-00006-of-00018.safetensors",
    "model-00007-of-00018.safetensors",
    "model-00008-of-00018.safetensors",
    "model-00009-of-00018.safetensors",
    "model-00010-of-00018.safetensors",
    "model-00011-of-00018.safetensors",
    "model-00012-of-00018.safetensors",
    "model-00013-of-00018.safetensors",
    "model-00014-of-00018.safetensors",
    "model-00015-of-00018.safetensors",
    "model-00016-of-00018.safetensors",
    "model-00017-of-00018.safetensors",
    "model-00018-of-00018.safetensors"
  ],
  "MaziyarPanahi/HermesStar-OrcaWind-Synth-11B-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "liquac09/Fat-Mango": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Weyaxi/Bagel-Hermes-34B-Slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "MaziyarPanahi/Mistral-11B-OmniMix9-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/OpenHermes-2.5-neural-chat-7b-v3-2-7B-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "macadeliccc/SOLAR-10.7x2_19B": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "liquac09/Pretti-White": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/juanako-7b-UNA-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Mik99/mistral_8_features_at_once_merged_2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hiiamsid/mixtral_54B_instruct_8k": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "maxmyn/tiny-wholesome-greentexts": [
    "model.safetensors"
  ],
  "MaziyarPanahi/Mistral-7B-Instruct-v0.2-GPTQ": [
    "model.safetensors"
  ],
  "MaziyarPanahi/Dans-AdventurousWinds-Mk2-7b-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "pawan2411/fused-sem3-LoRA": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "TheBloke/UNA-TheBeagle-7B-v1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/UNA-TheBeagle-7B-v1-AWQ": [
    "model.safetensors"
  ],
  "MaziyarPanahi/neural-chat-11b-v3-2-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "dylan9n/tinyllama-1b-openorca": [
    "model.safetensors"
  ],
  "maxmyn/tiny-wholesome-greentexts-1M": [
    "model.safetensors"
  ],
  "LoneStriker/TenyxChat-7B-v1-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/TenyxChat-7B-v1-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/TenyxChat-7B-v1-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "TheBloke/PiVoT-SUS-RP-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/PiVoT-SUS-RP-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "zaq-hack/Noromaid-v0.4-Mixtral-Instruct-8x7b-Zloss-bpw450-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "LoneStriker/TenyxChat-7B-v1-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "Kooten/BagelMix-8x7B-3.5bpw-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/TenyxChat-7B-v1-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "marcel/phixtral-4x2_8-gates-poc": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "1TuanPham/InstructEnVi_llama2-bkai-120GB_250kx2e_Frankenx3": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "macadeliccc/laser-polyglot-4x7b": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "TeeZee/Psyfighter2-Orca2-13B-ties-bpw8.0-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "TheBloke/TenyxChat-7B-v1-GPTQ": [
    "model.safetensors"
  ],
  "CodeGPTPlus/deepseek-coder-1.3b-typescript": [
    "model.safetensors"
  ],
  "nsfwthrowitaway69/lzlv_70b-exl2-8.0bpw": [
    "output-00001-of-00009.safetensors",
    "output-00002-of-00009.safetensors",
    "output-00003-of-00009.safetensors",
    "output-00004-of-00009.safetensors",
    "output-00005-of-00009.safetensors",
    "output-00006-of-00009.safetensors",
    "output-00007-of-00009.safetensors",
    "output-00008-of-00009.safetensors",
    "output-00009-of-00009.safetensors"
  ],
  "julianallchin/mistral-sclip": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Air-Striker-Mixtral-8x7B-Instruct-ZLoss-3.5bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "TheBloke/Noromaid-v0.4-Mixtral-Instruct-8x7b-Zloss-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Noromaid-v0.4-Mixtral-Instruct-8x7b-Zloss-GPTQ": [
    "model.safetensors"
  ],
  "fwtan/moe_test": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Air-Striker-Mixtral-8x7B-Instruct-ZLoss-3.75bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Air-Striker-Mixtral-8x7B-Instruct-ZLoss-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "kiwibasket/hypmic-gentarobot-medium": [
    "model.safetensors"
  ],
  "LoneStriker/Air-Striker-Mixtral-8x7B-Instruct-ZLoss-5.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "SergeiZu/llama-2-7b-sentiment140-10k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Pierre-obi/llama-8B-Instruct-DPO": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "kevin009/lamatama": [
    "model.safetensors"
  ],
  "WYNN747/Burmese-GPT-harry": [
    "model.safetensors"
  ],
  "MaziyarPanahi/Mistral-7B-Instruct-v0.1-GPTQ": [
    "model.safetensors"
  ],
  "sejaldatta84/autotrain-4lyc8-g3w23": [
    "adapter_model.safetensors",
    "checkpoint-30/adapter_model.safetensors"
  ],
  "LoneStriker/Bagel-Hermes-2x34b-3.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "pawan2411/fused-sem4-LoRA": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "gagan3012/Multirial": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "intone/Ammino-1.1B": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "Pierre-obi/Mistral_solar-slerp-DPO": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Bagel-Hermes-2x34b-4.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "sabayo/falcon-7b-marcaps-marketing": [
    "adapter_model.safetensors"
  ],
  "LoneStriker/Bagel-Hermes-2x34b-5.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "SanjiWatsuki/Lelantos-DPO-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "WYNN747/Burmese-GPT-harry2": [
    "model.safetensors"
  ],
  "TheBloke/TowerInstruct-7B-v0.1-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/TowerInstruct-7B-v0.1-AWQ": [
    "model.safetensors"
  ],
  "kevin009/mistralembedding": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Bagel-Hermes-2x34b-6.0bpw-h6-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "TheBloke/Bagel-Hermes-2x34b-GPTQ": [
    "model.safetensors"
  ],
  "kevin009/flyingllama": [
    "model.safetensors"
  ],
  "yuanzhoulvpi/intermlm-7b-lml_001": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/deepmoney-34b-200k-base-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/deepmoney-34b-200k-base-GPTQ": [
    "model.safetensors"
  ],
  "Wanfq/fusechat_v1_0106_baseline_ckpt": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sethuiyer/Chikuma_10.7B_v2": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Kquant03/Ryu-4x7B-MoE-bf16": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "rparundekar/llama2-7b-yacheq": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Locutusque/Rhino-Mistral-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "macadeliccc/polyglot-math-4x7b": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "kevin009/culturalmixed": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "fedml/meditron-70b": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "wkshin89/Yi-Ko-6B-Instruct-v1.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/deepmoney-34b-200k-chat-evaluator-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/deepmoney-34b-200k-chat-evaluator-GPTQ": [
    "model.safetensors"
  ],
  "SanjiWatsuki/Kunoichi-DPO-v2-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ycros/Mixtral-8x7B-v0.1_limarp-zloss-mixtral-8x7b-qlora": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "LoneStriker/UNA-dolphin-2.6-mistral-7b-dpo-laser-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/UNA-dolphin-2.6-mistral-7b-dpo-laser-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/UNA-dolphin-2.6-mistral-7b-dpo-laser-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/UNA-dolphin-2.6-mistral-7b-dpo-laser-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "Spanicin/Fulcrum_Aura3": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/UNA-dolphin-2.6-mistral-7b-dpo-laser-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "TheBloke/Helion-4x34B-GPTQ": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "nisten/shqiponja-59b-v1": [
    "model-00001-of-00012.safetensors",
    "model-00002-of-00012.safetensors",
    "model-00003-of-00012.safetensors",
    "model-00004-of-00012.safetensors",
    "model-00005-of-00012.safetensors",
    "model-00006-of-00012.safetensors",
    "model-00007-of-00012.safetensors",
    "model-00008-of-00012.safetensors",
    "model-00009-of-00012.safetensors",
    "model-00010-of-00012.safetensors",
    "model-00011-of-00012.safetensors",
    "model-00012-of-00012.safetensors"
  ],
  "HachiML/youri-2x7b_dev": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ai4bharat/Airavata": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "yuntaeyang/SOLAR-10.7B-Instructlora_sftt-v1.0": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "LoneStriker/Noromaid-v0.4-Mixtral-Instruct-8x7b-Zloss-3.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Bagel-Hermes-2x34b-2.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Noromaid-v0.4-Mixtral-Instruct-8x7b-Zloss-3.5bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "zaq-hack/Noromaid-v0.4-Mixtral-Instruct-8x7b-Zloss-bpw364-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "azale-ai/GotongRoyong-MixtralMoE-7Bx4-v1.0": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "LoneStriker/Noromaid-v0.4-Mixtral-Instruct-8x7b-Zloss-3.75bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Noromaid-v0.4-Mixtral-Instruct-8x7b-Zloss-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Noromaid-v0.4-Mixtral-Instruct-8x7b-Zloss-5.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "LoneStriker/Noromaid-v0.4-Mixtral-Instruct-8x7b-Zloss-6.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "Duxiaoman-DI/XuanYuan-13B-Chat": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "justinwangx/vicuna-adv-robust-ul15-sft-full": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "decruz07/kellemar-DPO-Orca-Distilled-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "fedml/Llama-2-13b-chat": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "clam004/emotion_base_v5": [
    "model.safetensors"
  ],
  "clam004/finetuned_model": [
    "model.safetensors"
  ],
  "kkuramitsu/tinycodellama-jp-0.13b-50k-long1k": [
    "model.safetensors"
  ],
  "abideen/NexoNimbus-MoE-2x7B": [
    "model-00001-of-00013.safetensors",
    "model-00002-of-00013.safetensors",
    "model-00003-of-00013.safetensors",
    "model-00004-of-00013.safetensors",
    "model-00005-of-00013.safetensors",
    "model-00006-of-00013.safetensors",
    "model-00007-of-00013.safetensors",
    "model-00008-of-00013.safetensors",
    "model-00009-of-00013.safetensors",
    "model-00010-of-00013.safetensors",
    "model-00011-of-00013.safetensors",
    "model-00012-of-00013.safetensors",
    "model-00013-of-00013.safetensors"
  ],
  "hwkwon/qlora-mistral-7b-sent-b4s2K-sentsplit-vllm": [
    "model.safetensors"
  ],
  "kkuramitsu/tinycodellama-jp-0.13b-base": [
    "model.safetensors"
  ],
  "kkuramitsu/tinycodellama-jp-0.13b-nnt": [
    "model.safetensors"
  ],
  "kkuramitsu/tinycodellama-jp-0.13b-gqa2": [
    "model.safetensors"
  ],
  "azale-ai/GotongRoyong-LlaMixtralMoE-7Bx4-v1.0": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "malhajar/meditron-70b-chat": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "mithlesh/LlaMA-2-ayurveda": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Jingyu6/MergeTest-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "sumangpt/falcon_oasst3": [
    "adapter_model.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "cmcmaster/rheumphi-sft": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jjszpak/SCAN-seq2seq-dc-15-epoch": [
    "model.safetensors"
  ],
  "Yarofa/model_h100_vl": [
    "model.safetensors"
  ],
  "Yarofa/model_h100_v156_v2": [
    "model.safetensors"
  ],
  "Yarofa/model_h100_v166_v2": [
    "model.safetensors"
  ],
  "TheBloke/Cosmosis-3x34B-GPTQ": [
    "model.safetensors"
  ],
  "kevin009/culturalmixer": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TeeZee/Fimbulvetr-10.7B-v1-bpw-8.0-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "sumangpt/merged": [
    "model-00001-of-00003.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00003.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors",
    "model.safetensors"
  ],
  "MaziyarPanahi/dolphin-2.1-mistral-7b-GPTQ": [
    "model.safetensors"
  ],
  "Felladrin/Llama-68M-Chat-v1": [
    "model.safetensors"
  ],
  "Imran1/OpenChat3.5-base": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "vicgalle/SOLAR-13B-Instruct-v1.0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dnovak232/Mistral7B-Instruct-v0.2-mssql": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "TeeZee/chronomaid-storytelling-13B-bpw8.0-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "PSanni/MPOMixtral-8x7B-Instruct-v0.1": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "HachiML/youri-2x7b_v0.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AlexWortega/v1": [
    "model-00001-of-00003.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00003.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "SparseLLM/swiglu-75B": [
    "model.safetensors"
  ],
  "Guilherme34/Jennifer-v4-model": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "v4lkyr13/opt-125m-gptq-4bit": [
    "model.safetensors"
  ],
  "SparseLLM/swiglu-70B": [
    "model.safetensors"
  ],
  "SparseLLM/swiglu-65B": [
    "model.safetensors"
  ],
  "TheBloke/HamSter-0.1-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/HamSter-0.1-GPTQ": [
    "model.safetensors"
  ],
  "SparseLLM/swiglu-60B": [
    "model.safetensors"
  ],
  "chanwit/flux-7b-base-stage-0": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "DenisTheDev/Hannah-PASSTHROUGH": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "mesolitica/LiteLlama-460M-4096-fpf": [
    "model.safetensors"
  ],
  "SparseLLM/swiglu-55B": [
    "model.safetensors"
  ],
  "SparseLLM/swiglu-50B": [
    "model.safetensors"
  ],
  "SparseLLM/swiglu-45B": [
    "model.safetensors"
  ],
  "chanwit/flux-7b-base-stage-1": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "SparseLLM/swiglu-40B": [
    "model.safetensors"
  ],
  "SparseLLM/swiglu-35B": [
    "model.safetensors"
  ],
  "SparseLLM/swiglu-30B": [
    "model.safetensors"
  ],
  "MaziyarPanahi/komt-mistral-7b-v1-GPTQ": [
    "model.safetensors"
  ],
  "SparseLLM/swiglu-25B": [
    "model.safetensors"
  ],
  "VATSAL1729/phi2-miniguanaco": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "chanwit/flux-base-optimized": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FelixChao/NinjaDolphin-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "SparseLLM/swiglu-20B": [
    "model.safetensors"
  ],
  "SparseLLM/swiglu-15B": [
    "model.safetensors"
  ],
  "SparseLLM/swiglu-10B": [
    "model.safetensors"
  ],
  "SparseLLM/swiglu-5B": [
    "model.safetensors"
  ],
  "herisan/Llama-7b-bnb-4bit_mental_health_counseling_conversations": [
    "model.safetensors"
  ],
  "SparseLLM/swiglu-95B": [
    "model.safetensors"
  ],
  "MaziyarPanahi/OpenHermes-2-Mistral-7B-GPTQ": [
    "model.safetensors"
  ],
  "herisan/tinyllama-bnb-4bit_mental_health_counseling_conversations": [
    "model.safetensors"
  ],
  "zaq-hack/Noromaid-7B-0.4-DPO-bpw600-h6-exl2": [
    "output.safetensors"
  ],
  "RaviNaik/Phi2-OSST-GPTQ": [
    "model.safetensors"
  ],
  "farenassr/autotrain-zh7c1-e7u0b": [
    "adapter_model.safetensors",
    "checkpoint-42/adapter_model.safetensors"
  ],
  "DenisTheDev/Hannah-1": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Sosnitskij/CausalLM-7B-safetensors": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "sumangpt/merged_1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ahmettasdemir/llama-2-7b-miniplatypus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ps0/NeuralHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "karawalla/aqtraining202401001": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jjszpak/SCAN-final-tests-8ep-equality-sign-prompt": [
    "model.safetensors"
  ],
  "ifuseok/ft-solar-10.7b-v2.1-dpo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "herisan/Mistral-7b-bnb-4bit_mental_health_counseling_conversations": [
    "model.safetensors"
  ],
  "Symfomany/gathnews": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AlbelTec/Mistral-DPO": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sumangpt/merged_2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "oivlisnet/opt-125m-GPTQ-2": [
    "model.safetensors"
  ],
  "dvilasuero/distilabeled-Marcoro14-7B-slerp": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "herisan/zephyr-sft-bnb-4bit_mental_health_counseling_conversations": [
    "model.safetensors"
  ],
  "jjszpak/SCAN-final-tests-8ep-equality-sign-prompt-v2": [
    "model.safetensors"
  ],
  "AlignmentLab-AI/MICROMETA": [
    "model.safetensors"
  ],
  "jjszpak/SCAN-final-tests-8ep-equality-sign-prompt-v3": [
    "model.safetensors"
  ],
  "decruz07/kellemar-DPO-Orca-Distilled-7B-SLERP": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "macadeliccc/SOLAR-math-2x10.7b": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "vicgalle/franken-SOLAR-18B-v1.0": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "mrzeiss/AMN-v0.2-Mistral-7B-Instruct-v0.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jjszpak/SCAN-final-tests-10ep-equality-sign-prompt-v1": [
    "model.safetensors"
  ],
  "Kooten/Kunoichi-DPO-v2-7B-8bpw-exl2": [
    "output.safetensors"
  ],
  "Kooten/Kunoichi-DPO-v2-7B-6bpw-exl2": [
    "output.safetensors"
  ],
  "Kooten/Kunoichi-DPO-v2-7B-4bpw-exl2": [
    "output.safetensors"
  ],
  "Yamila/DialoGPT-small-jonesybot": [
    "model.safetensors"
  ],
  "macadeliccc/Orca-SOLAR-4x10.7b": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "dharanaw5/FYP3": [
    "adapter_model.safetensors",
    "checkpoint-7/adapter_model.safetensors"
  ],
  "pawan2411/fused-sem4-LoRA-DPO": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "jjszpak/SCAN-final-tests-10ep-equality-sign-prompt-v2": [
    "model.safetensors"
  ],
  "Envoid/CATA-LimaRP-Zloss-DT-TaskArithmetic-8x7B": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "LoneStriker/BagelMix-8x7B-2.4bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Manthan11/Llama-2-7b-docker-command-finetune": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "robinsmits/Mistral-Instruct-7B-v0.2-ChatAlpaca": [
    "adapter_model.safetensors"
  ],
  "bdsaglam/llama-2-7b-chat-hf-kg-cons-multi-2023-12-31T15-43-51": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/BagelMix-8x7B-3.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "jjszpak/SCAN-final-tests-10ep-equality-sign-prompt-v3": [
    "model.safetensors"
  ],
  "LoneStriker/BagelMix-8x7B-3.5bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "birgermoell/NeuralPipe-7B-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/BagelMix-8x7B-3.75bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/BagelMix-8x7B-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "Inv/NoroIchiChat-7B": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "wenqiglantz/MistralTrinity-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "LoneStriker/BagelMix-8x7B-5.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "TheBloke/phi-2-electrical-engineering-GPTQ": [
    "model.safetensors"
  ],
  "LoneStriker/BagelMix-8x7B-6.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "dfurman/HermesBagel-34B-v0.1": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "lrds-code/samba-1.1B": [
    "model.safetensors"
  ],
  "khanhnto/kyt20B": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "Masterjp123/OrcaMaid-V3-13B-CLEAN": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Yarofa/model_h100_v166_v3": [
    "model.safetensors"
  ],
  "Yarofa/model_h100_v156_v3": [
    "model.safetensors"
  ],
  "MaziyarPanahi/WizardLM-70B-V1.0-GPTQ": [
    "model.safetensors"
  ],
  "yzhuang/phi-1_5_fictional": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors",
    "model.safetensors"
  ],
  "rombodawg/Everyone-Coder-4x7b-Base": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "swappy/mistral-dpo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Vezora/Test456": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "oivlisnet/llama-2-7b-int4-GPTQ-python-code-20k": [
    "model.safetensors"
  ],
  "Wanfq/fusechat_v1_nous_teacher_ckpt": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Wanfq/fusechat_v1_mixtral_teacher_ckpt": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "BlouseJury/Mistral-7B-Discord-0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sevvalozdamar/gpt2-story-generator-model": [
    "model.safetensors"
  ],
  "LoneStriker/FusionNet_7Bx2_MoE_14B-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Nucleus-1B-alpha-1-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/FusionNet_7Bx2_MoE_14B-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Nucleus-1B-alpha-1-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Nucleus-1B-alpha-1-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Nucleus-1B-alpha-1-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "jtatman/tinymistral-v2-pycoder-instruct-248m-v1": [
    "model.safetensors"
  ],
  "LoneStriker/Nucleus-1B-alpha-1-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/FusionNet_7Bx2_MoE_14B-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/FusionNet_7Bx2_MoE_14B-6.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/FusionNet_7Bx2_MoE_14B-8.0bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "sophosympatheia/Midnight-Rose-103B-v1.0": [
    "model-00001-of-00021.safetensors",
    "model-00002-of-00021.safetensors",
    "model-00003-of-00021.safetensors",
    "model-00004-of-00021.safetensors",
    "model-00005-of-00021.safetensors",
    "model-00006-of-00021.safetensors",
    "model-00007-of-00021.safetensors",
    "model-00008-of-00021.safetensors",
    "model-00009-of-00021.safetensors",
    "model-00010-of-00021.safetensors",
    "model-00011-of-00021.safetensors",
    "model-00012-of-00021.safetensors",
    "model-00013-of-00021.safetensors",
    "model-00014-of-00021.safetensors",
    "model-00015-of-00021.safetensors",
    "model-00016-of-00021.safetensors",
    "model-00017-of-00021.safetensors",
    "model-00018-of-00021.safetensors",
    "model-00019-of-00021.safetensors",
    "model-00020-of-00021.safetensors",
    "model-00021-of-00021.safetensors"
  ],
  "sophosympatheia/Midnight-Rose-70B-v1.0": [
    "model-00001-of-00017.safetensors",
    "model-00002-of-00017.safetensors",
    "model-00003-of-00017.safetensors",
    "model-00004-of-00017.safetensors",
    "model-00005-of-00017.safetensors",
    "model-00006-of-00017.safetensors",
    "model-00007-of-00017.safetensors",
    "model-00008-of-00017.safetensors",
    "model-00009-of-00017.safetensors",
    "model-00010-of-00017.safetensors",
    "model-00011-of-00017.safetensors",
    "model-00012-of-00017.safetensors",
    "model-00013-of-00017.safetensors",
    "model-00014-of-00017.safetensors",
    "model-00015-of-00017.safetensors",
    "model-00016-of-00017.safetensors",
    "model-00017-of-00017.safetensors"
  ],
  "swappy/mistral-dpo-reddit-cleaner": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Mixtral_34Bx2_MoE_60B-8.0bpw-h8-exl2": [
    "output-00001-of-00008.safetensors",
    "output-00002-of-00008.safetensors",
    "output-00003-of-00008.safetensors",
    "output-00004-of-00008.safetensors",
    "output-00005-of-00008.safetensors",
    "output-00006-of-00008.safetensors",
    "output-00007-of-00008.safetensors",
    "output-00008-of-00008.safetensors"
  ],
  "Sayan01/BabyLlama-m": [
    "model.safetensors"
  ],
  "MAsad789565/GPT2-Finetuned": [
    "model.safetensors"
  ],
  "SangsooIm/baseline-0": [
    "model.safetensors"
  ],
  "grimulkan/aurelian-v0.5-70b-rope8-32K-fp16": [
    "model-00001-of-00035.safetensors",
    "model-00002-of-00035.safetensors",
    "model-00003-of-00035.safetensors",
    "model-00004-of-00035.safetensors",
    "model-00005-of-00035.safetensors",
    "model-00006-of-00035.safetensors",
    "model-00007-of-00035.safetensors",
    "model-00008-of-00035.safetensors",
    "model-00009-of-00035.safetensors",
    "model-00010-of-00035.safetensors",
    "model-00011-of-00035.safetensors",
    "model-00012-of-00035.safetensors",
    "model-00013-of-00035.safetensors",
    "model-00014-of-00035.safetensors",
    "model-00015-of-00035.safetensors",
    "model-00016-of-00035.safetensors",
    "model-00017-of-00035.safetensors",
    "model-00018-of-00035.safetensors",
    "model-00019-of-00035.safetensors",
    "model-00020-of-00035.safetensors",
    "model-00021-of-00035.safetensors",
    "model-00022-of-00035.safetensors",
    "model-00023-of-00035.safetensors",
    "model-00024-of-00035.safetensors",
    "model-00025-of-00035.safetensors",
    "model-00026-of-00035.safetensors",
    "model-00027-of-00035.safetensors",
    "model-00028-of-00035.safetensors",
    "model-00029-of-00035.safetensors",
    "model-00030-of-00035.safetensors",
    "model-00031-of-00035.safetensors",
    "model-00032-of-00035.safetensors",
    "model-00033-of-00035.safetensors",
    "model-00034-of-00035.safetensors",
    "model-00035-of-00035.safetensors"
  ],
  "swappy/mistral-dpo-reddit-cleaner-low-lr": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Oriooon/DialoGPT-small-chizuruuubot": [
    "model.safetensors"
  ],
  "HenryJJ/dolphin-2.6-mistral-7b-dpo-orca-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Sayan01/BabyLlama-l": [
    "model.safetensors"
  ],
  "TinyPixel/slm-5": [
    "model.safetensors"
  ],
  "shidowake/test-240114-phi2-mergekit": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "grimulkan/aurelian-v0.5-70b-rope8-32K-6bpw_h8_exl2": [
    "output-00001-of-00013.safetensors",
    "output-00002-of-00013.safetensors",
    "output-00003-of-00013.safetensors",
    "output-00004-of-00013.safetensors",
    "output-00005-of-00013.safetensors",
    "output-00006-of-00013.safetensors",
    "output-00007-of-00013.safetensors",
    "output-00008-of-00013.safetensors",
    "output-00009-of-00013.safetensors",
    "output-00010-of-00013.safetensors",
    "output-00011-of-00013.safetensors",
    "output-00012-of-00013.safetensors",
    "output-00013-of-00013.safetensors"
  ],
  "WYNN747/Burmese-GPT-qa_sys2": [
    "model.safetensors"
  ],
  "HenryJJ/dolphin-2.6-mistral-7b-dpo-orca-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Oriooon/DialoGPT-small-cbot": [
    "model.safetensors"
  ],
  "grimulkan/aurelian-v0.5-70b-rope8-32K-4.65bpw_h6_exl2": [
    "output-00001-of-00010.safetensors",
    "output-00002-of-00010.safetensors",
    "output-00003-of-00010.safetensors",
    "output-00004-of-00010.safetensors",
    "output-00005-of-00010.safetensors",
    "output-00006-of-00010.safetensors",
    "output-00007-of-00010.safetensors",
    "output-00008-of-00010.safetensors",
    "output-00009-of-00010.safetensors",
    "output-00010-of-00010.safetensors"
  ],
  "grimulkan/aurelian-v0.5-70b-rope8-32K-2.4bpw_h6_exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "SparseLLM/reglu-5B": [
    "model.safetensors"
  ],
  "yihang7/llama2-7b-chat-dpo-full-hydrox-safe": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SparseLLM/reglu-10B": [
    "model.safetensors"
  ],
  "swappy/mistral-dpo-reddit-cleaner-mid-lr": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SparseLLM/reglu-15B": [
    "model.safetensors"
  ],
  "justinwangx/vicuna-ul15-sft-full": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SparseLLM/reglu-20B": [
    "model.safetensors"
  ],
  "SparseLLM/reglu-25B": [
    "model.safetensors"
  ],
  "SparseLLM/reglu-30B": [
    "model.safetensors"
  ],
  "SparseLLM/reglu-35B": [
    "model.safetensors"
  ],
  "SparseLLM/reglu-40B": [
    "model.safetensors"
  ],
  "ewqr2130/TinyLamma-SFT": [
    "model.safetensors"
  ],
  "DeKenny/instruct_trained_llama2": [
    "adapter_model.safetensors",
    "checkpoint-77/adapter_model.safetensors"
  ],
  "Technoculture/Medtulu-2x7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Oriooon/DialoGPT-small-hermionebot": [
    "model.safetensors"
  ],
  "SangsooIm/baseline_repo": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "SparseLLM/reglu-45B": [
    "model.safetensors"
  ],
  "SangsooIm/ours_1": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "SparseLLM/reglu-50B": [
    "model.safetensors"
  ],
  "SparseLLM/reglu-55B": [
    "model.safetensors"
  ],
  "SangsooIm/opts_ours_2": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "obrmmk/tinycodellama-jp-0.6b-20k-2-instruct-jcodealpaca-py": [
    "model.safetensors"
  ],
  "SparseLLM/reglu-60B": [
    "model.safetensors"
  ],
  "SparseLLM/reglu-65B": [
    "model.safetensors"
  ],
  "FelixChao/NarutoDolphin-10B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SparseLLM/reglu-70B": [
    "model.safetensors"
  ],
  "SangsooIm/opts_ours_3": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "obrmmk/tinycodellama-jp-0.6b-20k-2-instruct-jcodealpaca-py-def": [
    "model.safetensors"
  ],
  "SparseLLM/reglu-75B": [
    "model.safetensors"
  ],
  "itsskofficial/falcon-7b-blooms-taxonomy-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SangsooIm/opts_ours_4": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "SparseLLM/reglu-80B": [
    "model.safetensors"
  ],
  "kykim0/Llama-2-7b-ultrachat200k-2e": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kykim0/Llama-2-7b-ultrachat200k-3e": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TuringsSolutions/Llama-Pro-Wikichat": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "SparseLLM/reglu-85B": [
    "model.safetensors"
  ],
  "SparseLLM/reglu-90B": [
    "model.safetensors"
  ],
  "AI-B/UTENA-7B-NSFW-V2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "SangsooIm/opts_ours_5": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "upaya07/Arithmo2-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SparseLLM/reglu-95B": [
    "model.safetensors"
  ],
  "SparseLLM/relu2-5B": [
    "model.safetensors"
  ],
  "satpalsr/phi2-filter2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "SparseLLM/relu2-10B": [
    "model.safetensors"
  ],
  "Technoculture/Medorca-4x7b": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "SparseLLM/relu2-15B": [
    "model.safetensors"
  ],
  "SangsooIm/opts_ours_6": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "SparseLLM/relu2-20B": [
    "model.safetensors"
  ],
  "SparseLLM/relu2-25B": [
    "model.safetensors"
  ],
  "SparseLLM/relu2-30B": [
    "model.safetensors"
  ],
  "SangsooIm/opts_ours_7": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "SparseLLM/relu2-35B": [
    "model.safetensors"
  ],
  "TuringsSolutions/Llama-Pro-PfAF": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "Technoculture/Medtulu-4x7B": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "SparseLLM/relu2-40B": [
    "model.safetensors"
  ],
  "SparseLLM/relu2-45B": [
    "model.safetensors"
  ],
  "andysalerno/openchat-nectar-0.5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SparseLLM/relu2-50B": [
    "model.safetensors"
  ],
  "SangsooIm/opts_ours_8": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "SparseLLM/relu2-55B": [
    "model.safetensors"
  ],
  "SparseLLM/relu2-60B": [
    "model.safetensors"
  ],
  "hiepdaoquang704/finetune-vietnameseLLamma2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Technoculture/Mediquad-4x7b": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "SparseLLM/relu2-65B": [
    "model.safetensors"
  ],
  "SangsooIm/opts_ours_9": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "SparseLLM/relu2-70B": [
    "model.safetensors"
  ],
  "SparseLLM/relu2-75B": [
    "model.safetensors"
  ],
  "SparseLLM/relu2-80B": [
    "model.safetensors"
  ],
  "SparseLLM/relu2-85B": [
    "model.safetensors"
  ],
  "SangsooIm/opts_ours_10": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "HenryJJ/dolphin-2.6-mistral-7b-dpo-orca-v3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SparseLLM/relu2-90B": [
    "model.safetensors"
  ],
  "AI-B/UTENA-7B-V3": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "SparseLLM/relu2-95B": [
    "model.safetensors"
  ],
  "SparseLLM/relu2-100B": [
    "model.safetensors"
  ],
  "SangsooIm/opts_ours_11": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "SparseLLM/reglu-100B": [
    "model.safetensors"
  ],
  "SparseLLM/swiglu-100B": [
    "model.safetensors"
  ],
  "sumangpt/merged_model": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/laser-dolphin-mixtral-2x7b-dpo-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "MAsad789565/GPT2-medium-Finetuned": [
    "model.safetensors"
  ],
  "LoneStriker/laser-dolphin-mixtral-2x7b-dpo-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "SangsooIm/opts_ours_12": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "LoneStriker/laser-dolphin-mixtral-2x7b-dpo-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "djomo/MISTRALllux600-7b-ext": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SangsooIm/opts_ours_13": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "LoneStriker/laser-dolphin-mixtral-2x7b-dpo-6.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "jan-hq/Vistral-7B-Chat-DPO": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/laser-dolphin-mixtral-2x7b-dpo-8.0bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Wanfq/fusechat_v1_nous_teacher_woref_ckpt": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SangsooIm/opts_ours_14": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "Wanfq/fusechat_v1_mixtral_teacher_woref_ckpt": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ashishkgpian/astromistralv2": [
    "adapter_model.safetensors"
  ],
  "SangsooIm/opts_ours_15": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "obrmmk/tinycodellama-jp-0.6b-20k-2-instruct-codealpaca-py-def": [
    "model.safetensors"
  ],
  "SangsooIm/opts_ours_16": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "fhai50032/Johan-7B-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "DeKenny/instruct_trained_150": [
    "adapter_model.safetensors",
    "checkpoint-130/adapter_model.safetensors"
  ],
  "maxmyn/tiny-wholesome-greentexts-2Layer-33M": [
    "model.safetensors"
  ],
  "shidowake/test-240114-mergekit-neural-japanese-stablelm-gamma-7b": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "AI-B/UTENA-7B-UNA-V2": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "schroneko/safetensors_elyza_ELYZA-japanese-Llama-2-13b-fast-instruct": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "lamm-mit/ProteinForceGPT": [
    "model.safetensors"
  ],
  "Yarofa/model_a6000_v1": [
    "model.safetensors"
  ],
  "dhanushreddy29/BrokenKeyboardMerge": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "younoger/autotrain-dialo01": [
    "adapter_model.safetensors",
    "checkpoint-1275/adapter_model.safetensors"
  ],
  "interstellarninja/stablelm-zephyr-3b-func-calling-dpo": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "SangsooIm/optm_baseline": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "ashishkgpian/astromistralv3": [
    "adapter_model.safetensors"
  ],
  "SangsooIm/optm_ours_1": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "preemware/Proximus-2x7B-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SangsooIm/optm_ours_2": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "EmbeddingStudio/query-parser-falcon-7b-instruct": [
    "adapter_model.safetensors"
  ],
  "Fredithefish/34B_base": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Asude/gpt2-imdb-negativeV2-20kdata-10it": [
    "model.safetensors"
  ],
  "KoboldAI/LLaMA2-13B-Estopia": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SangsooIm/optm_ours_3": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "DenisTheDev/Hannah-2": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "SangsooIm/optm_ours_4": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "Asude/POS_gpt2_256token-128bs_imdb20kdata-with_reward_-1it": [
    "model.safetensors"
  ],
  "Asude/POS_gpt2_256token-128bs_imdb20kdata-with_reward_-2it": [
    "model.safetensors"
  ],
  "Asude/POS_gpt2_256token-128bs_imdb20kdata-with_reward_-3it": [
    "model.safetensors"
  ],
  "Asude/POS_gpt2_256token-128bs_imdb20kdata-with_reward_-5it": [
    "model.safetensors"
  ],
  "Asude/POS_gpt2_256token-128bs_imdb20kdata-with_reward_-7it": [
    "model.safetensors"
  ],
  "DiscoResearch/DiscoLM_German_7b_v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Asude/POS_gpt2_256token-128bs_imdb20kdata-with_reward_-10it": [
    "model.safetensors"
  ],
  "PotatoOff/HamSter-0.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Asude/POS_gpt2_256token-128bs_imdb20kdata-with_reward_-15it": [
    "model.safetensors"
  ],
  "Asude/POS_gpt2_256token-128bs_imdb20kdata-with_reward_-20it": [
    "model.safetensors"
  ],
  "ayousanz/ca-youri-7B-merge-slerp": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "Balaaditya/TAVGEN-mistral-7b": [
    "model.safetensors"
  ],
  "one-man-army/UNA-34Beagles-32K-bf16-v1": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "SangsooIm/optm_ours_5": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "Asude/POS_gpt2_256token-128bs_imdb20kdata-with_reward_-30it": [
    "model.safetensors"
  ],
  "proserve/expansion-falcon-180B": [
    "model-00001-of-00101.safetensors",
    "model-00002-of-00101.safetensors",
    "model-00003-of-00101.safetensors",
    "model-00004-of-00101.safetensors",
    "model-00005-of-00101.safetensors",
    "model-00006-of-00101.safetensors",
    "model-00007-of-00101.safetensors",
    "model-00008-of-00101.safetensors",
    "model-00009-of-00101.safetensors",
    "model-00010-of-00101.safetensors",
    "model-00011-of-00101.safetensors",
    "model-00012-of-00101.safetensors",
    "model-00013-of-00101.safetensors",
    "model-00014-of-00101.safetensors",
    "model-00015-of-00101.safetensors",
    "model-00016-of-00101.safetensors",
    "model-00017-of-00101.safetensors",
    "model-00018-of-00101.safetensors",
    "model-00019-of-00101.safetensors",
    "model-00020-of-00101.safetensors",
    "model-00021-of-00101.safetensors",
    "model-00022-of-00101.safetensors",
    "model-00023-of-00101.safetensors",
    "model-00024-of-00101.safetensors",
    "model-00025-of-00101.safetensors",
    "model-00026-of-00101.safetensors",
    "model-00027-of-00101.safetensors",
    "model-00028-of-00101.safetensors",
    "model-00029-of-00101.safetensors",
    "model-00030-of-00101.safetensors",
    "model-00031-of-00101.safetensors",
    "model-00032-of-00101.safetensors",
    "model-00033-of-00101.safetensors",
    "model-00034-of-00101.safetensors",
    "model-00035-of-00101.safetensors",
    "model-00036-of-00101.safetensors",
    "model-00037-of-00101.safetensors",
    "model-00038-of-00101.safetensors",
    "model-00039-of-00101.safetensors",
    "model-00040-of-00101.safetensors",
    "model-00041-of-00101.safetensors",
    "model-00042-of-00101.safetensors",
    "model-00043-of-00101.safetensors",
    "model-00044-of-00101.safetensors",
    "model-00045-of-00101.safetensors",
    "model-00046-of-00101.safetensors",
    "model-00047-of-00101.safetensors",
    "model-00048-of-00101.safetensors",
    "model-00049-of-00101.safetensors",
    "model-00050-of-00101.safetensors",
    "model-00051-of-00101.safetensors",
    "model-00052-of-00101.safetensors",
    "model-00053-of-00101.safetensors",
    "model-00054-of-00101.safetensors",
    "model-00055-of-00101.safetensors",
    "model-00056-of-00101.safetensors",
    "model-00057-of-00101.safetensors",
    "model-00058-of-00101.safetensors",
    "model-00059-of-00101.safetensors",
    "model-00060-of-00101.safetensors",
    "model-00061-of-00101.safetensors",
    "model-00062-of-00101.safetensors",
    "model-00063-of-00101.safetensors",
    "model-00064-of-00101.safetensors",
    "model-00065-of-00101.safetensors",
    "model-00066-of-00101.safetensors",
    "model-00067-of-00101.safetensors",
    "model-00068-of-00101.safetensors",
    "model-00069-of-00101.safetensors",
    "model-00070-of-00101.safetensors",
    "model-00071-of-00101.safetensors",
    "model-00072-of-00101.safetensors",
    "model-00073-of-00101.safetensors",
    "model-00074-of-00101.safetensors",
    "model-00075-of-00101.safetensors",
    "model-00076-of-00101.safetensors",
    "model-00077-of-00101.safetensors",
    "model-00078-of-00101.safetensors",
    "model-00079-of-00101.safetensors",
    "model-00080-of-00101.safetensors",
    "model-00081-of-00101.safetensors",
    "model-00082-of-00101.safetensors",
    "model-00083-of-00101.safetensors",
    "model-00084-of-00101.safetensors",
    "model-00085-of-00101.safetensors",
    "model-00086-of-00101.safetensors",
    "model-00087-of-00101.safetensors",
    "model-00088-of-00101.safetensors",
    "model-00089-of-00101.safetensors",
    "model-00090-of-00101.safetensors",
    "model-00091-of-00101.safetensors",
    "model-00092-of-00101.safetensors",
    "model-00093-of-00101.safetensors",
    "model-00094-of-00101.safetensors",
    "model-00095-of-00101.safetensors",
    "model-00096-of-00101.safetensors",
    "model-00097-of-00101.safetensors",
    "model-00098-of-00101.safetensors",
    "model-00099-of-00101.safetensors",
    "model-00100-of-00101.safetensors",
    "model-00101-of-00101.safetensors"
  ],
  "shuvom/NeuralPipe-7B-slerp-tryO": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "TeeZee/Xwin-LM-70B-V0.1_Limarpv3": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "Asude/NEG_gpt2_256token-128bs_imdb20kdata-with_reward_-1it": [
    "model.safetensors"
  ],
  "Asude/NEG_gpt2_256token-128bs_imdb20kdata-with_reward_-2it": [
    "model.safetensors"
  ],
  "Asude/NEG_gpt2_256token-128bs_imdb20kdata-with_reward_-3it": [
    "model.safetensors"
  ],
  "Asude/NEG_gpt2_256token-128bs_imdb20kdata-with_reward_-5it": [
    "model.safetensors"
  ],
  "Asude/NEG_gpt2_256token-128bs_imdb20kdata-with_reward_-7it": [
    "model.safetensors"
  ],
  "SangsooIm/optm_ours_6": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "Asude/NEG_gpt2_256token-128bs_imdb20kdata-with_reward_-10it": [
    "model.safetensors"
  ],
  "Asude/NEG_gpt2_256token-128bs_imdb20kdata-with_reward_-15it": [
    "model.safetensors"
  ],
  "Asude/NEG_gpt2_256token-128bs_imdb20kdata-with_reward_-20it": [
    "model.safetensors"
  ],
  "miguelcarv/phi-1_5-slimorca": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "itzNoBiTa/Bloomz-560m_Translation": [
    "https:/huggingface.co/itzNoBiTa/Bloomz-560m_Translation/blob/main/model.safetensors",
    "model.safetensors"
  ],
  "ayousanz/ca-youri-7B-merge-MoE-slerp": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "younoger/autotrain-ug9db-jg8zi": [
    "adapter_model.safetensors",
    "checkpoint-1266/adapter_model.safetensors",
    "model.safetensors"
  ],
  "mesolitica/malaysian-tinyllama-1.1b-16k-instructions-rag": [
    "model.safetensors"
  ],
  "Asude/NEG_gpt2_256token-128bs_imdb20kdata-with_reward_-30it": [
    "model.safetensors"
  ],
  "SangsooIm/optm_ours_7": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "mesolitica/malaysian-LiteLlama-460M-16k-instructions-rag": [
    "model.safetensors"
  ],
  "younoger/autotrain-9ivqc-q56ii": [
    "adapter_model.safetensors",
    "checkpoint-1266/adapter_model.safetensors",
    "model.safetensors"
  ],
  "LoneStriker/functionary-small-v2.2-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "argilla/distilabeled-Marcoro14-7B-slerp-full": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "CallComply/openchat-3.5-0106-11b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/functionary-small-v2.2-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/functionary-small-v2.2-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/functionary-small-v2.2-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "Adesh696/git-base-flickr8k": [
    "model.safetensors"
  ],
  "SangsooIm/optm_ours_8": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "LoneStriker/functionary-small-v2.2-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "maxmyn/gpt-neo-125m-greentexts": [
    "model.safetensors"
  ],
  "phanerozoic/Phi-2-Pirate-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "chanwit/flux-7b-v0.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Aryanne/sheared-silicon10p": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "SangsooIm/optm_ours_9": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "LoneStriker/openchat-3.5-0106-function-calling-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/functionary-medium-v2.2-2.4bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/openchat-3.5-0106-function-calling-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "hiepdaoquang704/finetune-LLamma2-instruct": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sabayo/Marcaps-GPT-baseline": [
    "adapter_model.safetensors"
  ],
  "LoneStriker/functionary-medium-v2.2-3.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/openchat-3.5-0106-function-calling-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "RaiBP/gpt2-openwebtext2-first-30-chunks-ablation-bilingual": [
    "model.safetensors"
  ],
  "LoneStriker/openchat-3.5-0106-function-calling-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "CallComply/zephyr-7b-beta-32k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/openchat-3.5-0106-function-calling-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "SangsooIm/optm_ours_10": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "LoneStriker/functionary-medium-v2.2-3.5bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "SanjiWatsuki/tinycapyorca-8x1b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "CallComply/openchat-3.5-0106-128k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/functionary-medium-v2.2-3.75bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "h2m/mhm-7b-v1.3": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "CallComply/zephyr-11b-beta": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/functionary-medium-v2.2-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "CallComply/zephyr-7b-beta-128k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Everyone-Coder-4x7b-Base-3.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/functionary-medium-v2.2-5.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "brucethemoose/Yi-34B-200K-DARE-megamerge-v8": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "SangsooIm/optm_ours_11": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "chuducandev/Llama-2-7b-hf-c2t-001": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Everyone-Coder-4x7b-Base-3.5bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Deepakyadav1212/ner_trained_001": [
    "model.safetensors"
  ],
  "LoneStriker/Everyone-Coder-4x7b-Base-4.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/functionary-medium-v2.2-6.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "ZainAli60/my-project": [
    "model.safetensors"
  ],
  "LoneStriker/Everyone-Coder-4x7b-Base-5.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "ArunSamespace/zephyr-7b-beta-fc-bnb-ep1-samples-25k-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "brucethemoose/Yi-34B-200K-DARE-megamerge-v8-31bpw-exl2-fiction": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "LoneStriker/Everyone-Coder-4x7b-Base-6.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Everyone-Coder-4x7b-Base-8.0bpw-h8-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "Geksaida/llama-2-7b-SysML_test": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SangsooIm/optm_ours_12": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "suzii/IX_health_mistral_7b_intrus_lora_v1.3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AswanthCManoj/azma-deepseek-coder-1.3b-instruct-structured-output-peft-merge": [
    "model.safetensors"
  ],
  "huangyt/Yi-6B-Open-Platypus_2.5w-r16-gate_up_down": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "chuducandev/Llama-2-7b-hf-c2t-002": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "chuducandev/Llama-2-7b-hf-c2t-003": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SanjiWatsuki/tinycapyorca-dpo-8x1b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sksayril/ogt_benagli_base_Model_transformers": [
    "model.safetensors"
  ],
  "ncoop57/test-fuyu-finetune": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "lingjoor/numeval-task7-1": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "YashaP/Fine-tuned-Mistral7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors",
    "model.safetensors"
  ],
  "SangsooIm/optm_ours_13": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "SanjiWatsuki/tinyllamaherd-8x1b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "bhavinjawade/SOLAR-10B-Nector-DPO-Jawade": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "J3diJ0ni/padawan-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "refarde/Mistral-7B-Instruct-v0.2-Ko-S-Core": [
    "checkpoint-3863/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TeeZee/Xwin-LM-70B-V0.1_Limarpv3-bpw2.4-h6": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "SangsooIm/optm_ours_14": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "CallComply/SOLAR-10.7B-Instruct-v1.0-128k": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Undi95/OpenDolphinMaid-4x7b": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "deinon-daemon/mixtral-axolotl-anarxos-7b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "sksayril/ogt_transformers": [
    "model.safetensors"
  ],
  "SangsooIm/optm_ours_15": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "TeeZee/Xwin-LM-70B-V0.1_Jannie": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "MaziyarPanahi/distilabeled-Hermes-2.5-Mistral-7B-GPTQ": [
    "model.safetensors"
  ],
  "SangsooIm/optm_ours_16": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "liminerity/Blur-7B-slerp-v0.1": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "gauthamk28/doltral-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "cmolinier/output": [
    "model.safetensors"
  ],
  "gotchu/merge-34b-1": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "Weyaxi/HelpSteer-filtered-Solar-Instruct": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "dharanaw5/FYP": [
    "adapter_model.safetensors",
    "checkpoint-260/adapter_model.safetensors"
  ],
  "ivanmatiasmongi/finetuned_horror": [
    "model.safetensors"
  ],
  "satendra4u2022/ft-openhermes-25-mistral-7b-irca-dpo-pairs": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "alxcrypto/minerhot5": [
    "model.safetensors"
  ],
  "tejasreereddy/mistral-quantize-lora-peft-dataset": [
    "model.safetensors"
  ],
  "Edentns/DataVortexS-10.7B-v1.0": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "physicism/DialoGPT-small-walter": [
    "model.safetensors"
  ],
  "mrfakename/phi-2-5b": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "ewqr2130/alignment-handbook-zephyr-7b-sft-full-dpo-5e7-cont1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "physicism/DialoGPT-medium-walter": [
    "model.safetensors"
  ],
  "SparseLLM/relu-5B": [
    "model.safetensors"
  ],
  "cmcmaster/rheumphi-epoch3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jan-hq/stealth-v1.3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SparseLLM/relu-10B": [
    "model.safetensors"
  ],
  "SparseLLM/relu-15B": [
    "model.safetensors"
  ],
  "SparseLLM/relu-20B": [
    "model.safetensors"
  ],
  "Yarofa/model_a6000_v3": [
    "model.safetensors"
  ],
  "SparseLLM/relu-25B": [
    "model.safetensors"
  ],
  "sakib131/bangla-conv-summarizer-model-3": [
    "model.safetensors"
  ],
  "Yarofa/model_a6000_v2": [
    "model.safetensors"
  ],
  "SparseLLM/relu-30B": [
    "model.safetensors"
  ],
  "Zhiqiang007/phi-2-metamath": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "shidowake/test-240115-mergekit-CodeLlama-Swallow-7b-instruct": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "NeverSleep/Noromaid-13B-0.4-DPO": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "SparseLLM/relu-35B": [
    "model.safetensors"
  ],
  "TroyDoesAI/MermaidLlama": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "SparseLLM/relu-40B": [
    "model.safetensors"
  ],
  "WYNN747/Burmese-GPT-main-v6": [
    "model.safetensors"
  ],
  "SparseLLM/relu-45B": [
    "model.safetensors"
  ],
  "SparseLLM/relu-50B": [
    "model.safetensors"
  ],
  "SangsooIm/opts_qat_s4": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "SangsooIm/opts_qat_s8": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "SparseLLM/relu-55B": [
    "model.safetensors"
  ],
  "SeanJIE250/law_llama2.1": [
    "adapter_model.safetensors",
    "checkpoint-27/adapter_model.safetensors"
  ],
  "SparseLLM/relu-60B": [
    "model.safetensors"
  ],
  "SangsooIm/opts_qo_s4_1": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "SangsooIm/opts_qo_s8_1": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "SangsooIm/opts_qo_s4_2": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "SangsooIm/opts_qo_s8_2": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "SangsooIm/opts_qo_s4_3": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "SangsooIm/opts_qo_s8_3": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "wang7776/vicuna-7b-v1.3-sparsity-20": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SangsooIm/opts_qo_s4_4": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "SparseLLM/relu-65B": [
    "model.safetensors"
  ],
  "SangsooIm/optm_qo_s4_1": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "SparseLLM/relu-70B": [
    "model.safetensors"
  ],
  "SangsooIm/opts_qo_s8_5": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "SparseLLM/relu-75B": [
    "model.safetensors"
  ],
  "WYNN747/Burmese-GPT-qa_sys4_main": [
    "model.safetensors"
  ],
  "SeanJIE250/law_llama2.2": [
    "adapter_model.safetensors",
    "checkpoint-27/adapter_model.safetensors"
  ],
  "wenqiglantz/MistralTrinity-7B-slerp-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SparseLLM/relu-80B": [
    "model.safetensors"
  ],
  "SangsooIm/opts_qo_s8_8": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "SparseLLM/relu-85B": [
    "model.safetensors"
  ],
  "RiverTest/RiverMTG5m": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "wang7776/vicuna-7b-v1.3-sparsity-30": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "alnrg2arg/test2_1": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "SangsooIm/opts_qo_s4_9": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "SangsooIm/opts_qo_s8_9": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "SangsooIm/optm_qo_s4_2": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "uukuguy/speechless-nl2sql-ds-6.7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SparseLLM/relu-90B": [
    "model.safetensors"
  ],
  "SparseLLM/relu-95B": [
    "model.safetensors"
  ],
  "SparseLLM/relu-100B": [
    "model.safetensors"
  ],
  "yuntaeyang/KoSOLAR-10.7B-sftt-v1.0": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Wanfq/fusechat_v1_solar_teacher_ckpt": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Wanfq/fusechat_v1_solar_teacher_woref_ckpt": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SangsooIm/opts_qo_s8_10": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "LuongNam/Vistral-7B-Chat-AWQ": [
    "model.safetensors"
  ],
  "sumo43/Yi-34b-x2": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "alnrg2arg/test2": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "zicsx/GPT2-124m-pretrain-test": [
    "model.safetensors"
  ],
  "Deepakyadav1212/ner_model": [
    "model.safetensors"
  ],
  "SangsooIm/opts_qo_s4_11": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "mayflowergmbh/dolphin-2_6-phi-2-german": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dev7halo/KoSOLAR-10.7B-v0.1-dpo-4bit-merged_adapters": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "nfaheem/SOLAR-10.7B-Instruct-ties": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SangsooIm/opts_qo_s8_11": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "allennghayoui/non_quantized-code-assistant-v01": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "HIT-SCIR/Chinese-Mixtral-8x7B": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "AI4Chem/ChemLLM-7B-Chat": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "sethuiyer/MedleyMD": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SangsooIm/opts_qo_s4_12": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "Toastmachine/Pinescript_v0.1": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SangsooIm/opts_qo_s8_12": [
    "1/model.safetensors",
    "2/model.safetensors",
    "3/model.safetensors",
    "4/model.safetensors",
    "5/model.safetensors",
    "6/model.safetensors",
    "7/model.safetensors",
    "8/model.safetensors",
    "9/model.safetensors",
    "model.safetensors"
  ],
  "shadowml/Beagle14-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "haidlir/bloom-chatml-id": [
    "model.safetensors"
  ],
  "mlabonne/Beagle14-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Radiantloom/radiantloom-mixtral-8x7b-fusion": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "DenisTheDev/Passthrough-test": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "Swisslex/Mixtral-Orca-v0.1": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "Gincy/mistral-finetune-llm": [
    "adapter_model.safetensors",
    "checkpoint-72/adapter_model.safetensors"
  ],
  "mikewatson/gpt2-wikitext2": [
    "model.safetensors"
  ],
  "mlabonne/NeuralDaredevil-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Kooltek68/sn9_221": [
    "model.safetensors"
  ],
  "Snoopy04/llama-2-13b-thesis": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "tarun26/my_awesome_model": [
    "model.safetensors"
  ],
  "Awal/AwalPremi-Intel-Mistral-DPO": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Haary/TinyLlama-1.1B-indo-v1": [
    "model.safetensors"
  ],
  "greymatter-2024/tiny-llama-alpaka20kds": [
    "model.safetensors"
  ],
  "duxans/Nous-Hermes-2_openchat-3.5_32layers": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "avemio-digital/lora_model_scipy_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Abhishek107/tinyllama_v1": [
    "model.safetensors"
  ],
  "jvh/Mistral-Hermes-GEITje": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "jan-hq/LlamaCorn-1.1B": [
    "model.safetensors"
  ],
  "iohadrubin/llama-c5-1b": [
    "model.safetensors"
  ],
  "HwiyeolJo/TeamJaeCorpo-v0.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dalyaff/phi2-viggo-finetun": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "axra/mistral-4x7B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Mik99/phi-2_test_01_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "DenisTheDev/Openchat-Passthrough": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "TheBigBlender/Daisuke": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "amu/zen-moe": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jvh/Mistral-Openchat-GEITje": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Everyone-Coder-4x7b-Base-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Everyone-Coder-4x7b-Base-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Omarqq/code_phi-2.7b1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jvh/Mistral-Openchat-GEITje-v2": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "allennghayoui/code-assistant-AWQ": [
    "model.safetensors"
  ],
  "Abhishek107/phi2_v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "duanyu027/loyal-piano-m7-dpo-0115-125steps": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mpasila/OpenHermes-13B-safetensors": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "LoneStriker/NexoNimbus-7B-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "MarsupialAI/KitchenSink_103b": [
    "model-00001-of-00055.safetensors",
    "model-00002-of-00055.safetensors",
    "model-00003-of-00055.safetensors",
    "model-00004-of-00055.safetensors",
    "model-00005-of-00055.safetensors",
    "model-00006-of-00055.safetensors",
    "model-00007-of-00055.safetensors",
    "model-00008-of-00055.safetensors",
    "model-00009-of-00055.safetensors",
    "model-00010-of-00055.safetensors",
    "model-00011-of-00055.safetensors",
    "model-00012-of-00055.safetensors",
    "model-00013-of-00055.safetensors",
    "model-00014-of-00055.safetensors",
    "model-00015-of-00055.safetensors",
    "model-00016-of-00055.safetensors",
    "model-00017-of-00055.safetensors",
    "model-00018-of-00055.safetensors",
    "model-00019-of-00055.safetensors",
    "model-00020-of-00055.safetensors",
    "model-00021-of-00055.safetensors",
    "model-00022-of-00055.safetensors",
    "model-00023-of-00055.safetensors",
    "model-00024-of-00055.safetensors",
    "model-00025-of-00055.safetensors",
    "model-00026-of-00055.safetensors",
    "model-00027-of-00055.safetensors",
    "model-00028-of-00055.safetensors",
    "model-00029-of-00055.safetensors",
    "model-00030-of-00055.safetensors",
    "model-00031-of-00055.safetensors",
    "model-00032-of-00055.safetensors",
    "model-00033-of-00055.safetensors",
    "model-00034-of-00055.safetensors",
    "model-00035-of-00055.safetensors",
    "model-00036-of-00055.safetensors",
    "model-00037-of-00055.safetensors",
    "model-00038-of-00055.safetensors",
    "model-00039-of-00055.safetensors",
    "model-00040-of-00055.safetensors",
    "model-00041-of-00055.safetensors",
    "model-00042-of-00055.safetensors",
    "model-00043-of-00055.safetensors",
    "model-00044-of-00055.safetensors",
    "model-00045-of-00055.safetensors",
    "model-00046-of-00055.safetensors",
    "model-00047-of-00055.safetensors",
    "model-00048-of-00055.safetensors",
    "model-00049-of-00055.safetensors",
    "model-00050-of-00055.safetensors",
    "model-00051-of-00055.safetensors",
    "model-00052-of-00055.safetensors",
    "model-00053-of-00055.safetensors",
    "model-00054-of-00055.safetensors",
    "model-00055-of-00055.safetensors"
  ],
  "LoneStriker/NexoNimbus-7B-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/NexoNimbus-7B-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/NexoNimbus-7B-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/NexoNimbus-MoE-2x7B-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/NexoNimbus-7B-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/NexoNimbus-MoE-2x7B-3.5bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/NexoNimbus-MoE-2x7B-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "TheBloke/bagel-dpo-8x7b-v0.2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/bagel-dpo-8x7b-v0.2-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/NexoNimbus-MoE-2x7B-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/NexoNimbus-MoE-2x7B-6.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "jvh/Mistral-Turdus-GEITje-v2": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "LoneStriker/NexoNimbus-MoE-2x7B-8.0bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "mesolitica/mallam-1.1b-20k-instructions-rag": [
    "model.safetensors"
  ],
  "jjszpak/SCAN-exp1b-1proc-v0": [
    "model.safetensors"
  ],
  "davanstrien/TinyLlama-haiku-dpo-v.0.1": [
    "model.safetensors"
  ],
  "Sahibsingh12/phi-2-finetuned-cazton_complete": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jvh/Mistral-Turdus-GEITje": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "WQchoi/QLoRA_test2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "adamo1139/yi-34b-200k-rawrr-dpo-1": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "TinyPixel/sml-6": [
    "model.safetensors"
  ],
  "jjszpak/SCAN-exp1b-1proc-v1": [
    "model.safetensors"
  ],
  "Deci/DeciCoder-6B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "LoneStriker/Fimbulvetr-10.7B-v1-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Fimbulvetr-10.7B-v1-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "ycros/BagelMIsteryTour-8x7B": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "LoneStriker/Fimbulvetr-10.7B-v1-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "jvh/Mistral-NeuDist-Ro-GEITje": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "LoneStriker/Fimbulvetr-10.7B-v1-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Fimbulvetr-10.7B-v1-8.0bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "jjszpak/SCAN-exp1b-1proc-v2": [
    "model.safetensors"
  ],
  "senseable/moe-x33": [
    "model-00001-of-00012.safetensors",
    "model-00002-of-00012.safetensors",
    "model-00003-of-00012.safetensors",
    "model-00004-of-00012.safetensors",
    "model-00005-of-00012.safetensors",
    "model-00006-of-00012.safetensors",
    "model-00007-of-00012.safetensors",
    "model-00008-of-00012.safetensors",
    "model-00009-of-00012.safetensors",
    "model-00010-of-00012.safetensors",
    "model-00011-of-00012.safetensors",
    "model-00012-of-00012.safetensors"
  ],
  "LoneStriker/Yi-34B-200K-DARE-megamerge-v8-3.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "hieunguyen2003/vinallama-7b-chat": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "CultriX/MergeTrix-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "khanhnto/kyt-merge-estomental-13B": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/HamSter-0.2-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/HamSter-0.2-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "davanstrien/HaikuHermes-0.1-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/HamSter-0.2-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/HamSter-0.2-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Yi-34B-200K-DARE-megamerge-v8-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/HamSter-0.2-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "TheBloke/laser-dolphin-mixtral-2x7b-dpo-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/laser-dolphin-mixtral-2x7b-dpo-AWQ": [
    "model.safetensors"
  ],
  "LoneStriker/Yi-34B-200K-DARE-megamerge-v8-4.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "dacorvo/tiny-random-MistralForCausalLM": [
    "model.safetensors"
  ],
  "cognitivecomputations/laserxtral": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "TheBloke/tigerbot-13B-chat-v5-AWQ": [
    "model.safetensors"
  ],
  "shuvom/my-mixtral-2x7B": [
    "model-00001-of-00013.safetensors",
    "model-00002-of-00013.safetensors",
    "model-00003-of-00013.safetensors",
    "model-00004-of-00013.safetensors",
    "model-00005-of-00013.safetensors",
    "model-00006-of-00013.safetensors",
    "model-00007-of-00013.safetensors",
    "model-00008-of-00013.safetensors",
    "model-00009-of-00013.safetensors",
    "model-00010-of-00013.safetensors",
    "model-00011-of-00013.safetensors",
    "model-00012-of-00013.safetensors",
    "model-00013-of-00013.safetensors"
  ],
  "AbinetAlemu/Llama-2-7b-chat-finetune": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Yi-34B-200K-DARE-megamerge-v8-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Yi-34B-200K-DARE-megamerge-v8-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Yi-34B-200K-DARE-megamerge-v8-5.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "greymatter-2024/hpctry2222": [
    "model.safetensors"
  ],
  "Tamnemtf/test": [
    "model.safetensors"
  ],
  "jvh/Mistral-asst_top1_2023-GEITje": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "LoneStriker/Yi-34B-200K-DARE-megamerge-v8-6.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "TachyHealth/Thealth-Mistral-7B-Instruct-v0.1-Medical-Finetune": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "emaximen/rubert-base-cased-finetuned-CLM-domain": [
    "model.safetensors"
  ],
  "mu0gum/AIFT-42dot-LLM-PLM-1.3B-instruct-slim-v1.5": [
    "model.safetensors"
  ],
  "TheBloke/tigerbot-13B-chat-v5-GPTQ": [
    "model.safetensors"
  ],
  "yuansiwe/tinyllama-colorist-v1": [
    "model.safetensors"
  ],
  "KathirKs/Mistral-Multiply": [
    "model.safetensors"
  ],
  "LoneStriker/LLaMA2-13B-Estopia-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/LLaMA2-13B-Estopia-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/LLaMA2-13B-Estopia-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Yi-34B-200K-DARE-megamerge-v8-8.0bpw-h8-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "LoneStriker/LLaMA2-13B-Estopia-6.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/LLaMA2-13B-Estopia-8.0bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "arieridwans/phi_2-finetuned-lyrics-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "nfaheem/Marcoroni-7b-DPO-Merge": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jjszpak/SCAN-exp1b-4proc-v0": [
    "model.safetensors"
  ],
  "andrewatef/MyBloggerV0.11": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors",
    "model.safetensors"
  ],
  "Swisslex/Mixtral-8x7b-DPO-v0.1": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "lukasedv/fi-2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "philkrav/tinyllama-1.3b-draft-llama-13b-chat": [
    "model.safetensors"
  ],
  "jpacifico/French-Alpaca-7B-Instruct-alpha": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ashishkgpian/full_v2_astromistral": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jjszpak/SCAN-exp1b-4proc-v1": [
    "model.safetensors"
  ],
  "mlabonne/NeuralBeagle14-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ashishkgpian/full_v2_astromistral_final": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "yihang7/Mistral-7B-v0.1-dpo-full-hydrox-safe": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jjszpak/SCAN-exp1b-4proc-v2": [
    "model.safetensors"
  ],
  "TheBloke/phi-2-orange-GPTQ": [
    "model.safetensors"
  ],
  "ewqr2130/phi2_sft": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "macadeliccc/Polyglot-8x7b-v0.1": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "Kquant03/FrankenDPO-4x7B-bf16": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "ehsangharibnezhad/phi-1_5-finetuned-vicgalle-alpaca-gpt4": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "maxmyn/tiny-all-wholesome-greentexts-2Layer-33M": [
    "model.safetensors"
  ],
  "sabayo/falcon-7b-chat-marcaps": [
    "adapter_model.safetensors"
  ],
  "ayoubkirouane/phi-2-arxiv-physics": [
    "adapter_model.safetensors"
  ],
  "TheBloke/finance-LLM-13B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/finance-LLM-13B-GPTQ": [
    "model.safetensors"
  ],
  "BrainGPT/gpt2": [
    "model.safetensors"
  ],
  "RiverTest/RiverMTG7": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "alexredna/Tukan-1.1B-Chat-v0.6": [
    "model.safetensors"
  ],
  "TheBloke/medicine-LLM-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/medicine-LLM-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/LLaMA2-13B-Estopia-AWQ": [
    "model.safetensors"
  ],
  "kevin009/TinyNaughtyLlama-v1.0": [
    "model.safetensors"
  ],
  "TheBloke/Venus-120b-v1.2-AWQ": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "TheBloke/Venus-120b-v1.2-GPTQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mavihsrr/GetCode-slerp": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "tshrjn/TinyLlama_pubmed_v0-3": [
    "model.safetensors"
  ],
  "TheBloke/LLaMA2-13B-Estopia-GPTQ": [
    "model.safetensors"
  ],
  "fionazhang/mistral-environment-adapter": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "NeuralNovel/Gecko-7B-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "chuducandev/Llama-2-7b-hf-c2t-004": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "gagan3012/Multilingual-mistral": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "chuducandev/Llama-2-7b-hf-c2t-005": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "genne/kiwi_solar_merge_ties2_dpo": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "chuducandev/Llama-2-7b-hf-c2t-2-001": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "xz56/neuralphi-2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "kevin009/Llamafia": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SharedGPT/mistral-7b-miniplatypus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jtatman/TinyMistral-248M-v2-4bit": [
    "model.safetensors"
  ],
  "oivlisnet/teste-GPTQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "SamagraDataGov/test_mistral": [
    "adapter_model.safetensors",
    "checkpoint-406/adapter_model.safetensors"
  ],
  "oopsung/Yi-Ko-ENWdpo-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Jiayi-Pan/tiny_llama_full_adapt_fold2_positional_abaltion": [
    "model.safetensors"
  ],
  "tuanacanal/conversation-model-2": [
    "model.safetensors"
  ],
  "Inforup982/Harsha-Hermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "macadeliccc/SOLAR-polyglot-4x10.7b": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "oivlisnet/teste2-GPTQ": [
    "model.safetensors"
  ],
  "klein-zcy/Phi-1_5-MetaMathQA": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "SanjiWatsuki/TinyLlamaHerd-2x1.1B": [
    "model-00001-of-00001.safetensors"
  ],
  "moreh/MoMo-72B-lora-1.8.6-DPO": [
    "model-00001-of-00063.safetensors",
    "model-00002-of-00063.safetensors",
    "model-00003-of-00063.safetensors",
    "model-00004-of-00063.safetensors",
    "model-00005-of-00063.safetensors",
    "model-00006-of-00063.safetensors",
    "model-00007-of-00063.safetensors",
    "model-00008-of-00063.safetensors",
    "model-00009-of-00063.safetensors",
    "model-00010-of-00063.safetensors",
    "model-00011-of-00063.safetensors",
    "model-00012-of-00063.safetensors",
    "model-00013-of-00063.safetensors",
    "model-00014-of-00063.safetensors",
    "model-00015-of-00063.safetensors",
    "model-00016-of-00063.safetensors",
    "model-00017-of-00063.safetensors",
    "model-00018-of-00063.safetensors",
    "model-00019-of-00063.safetensors",
    "model-00020-of-00063.safetensors",
    "model-00021-of-00063.safetensors",
    "model-00022-of-00063.safetensors",
    "model-00023-of-00063.safetensors",
    "model-00024-of-00063.safetensors",
    "model-00025-of-00063.safetensors",
    "model-00026-of-00063.safetensors",
    "model-00027-of-00063.safetensors",
    "model-00028-of-00063.safetensors",
    "model-00029-of-00063.safetensors",
    "model-00030-of-00063.safetensors",
    "model-00031-of-00063.safetensors",
    "model-00032-of-00063.safetensors",
    "model-00033-of-00063.safetensors",
    "model-00034-of-00063.safetensors",
    "model-00035-of-00063.safetensors",
    "model-00036-of-00063.safetensors",
    "model-00037-of-00063.safetensors",
    "model-00038-of-00063.safetensors",
    "model-00039-of-00063.safetensors",
    "model-00040-of-00063.safetensors",
    "model-00041-of-00063.safetensors",
    "model-00042-of-00063.safetensors",
    "model-00043-of-00063.safetensors",
    "model-00044-of-00063.safetensors",
    "model-00045-of-00063.safetensors",
    "model-00046-of-00063.safetensors",
    "model-00047-of-00063.safetensors",
    "model-00048-of-00063.safetensors",
    "model-00049-of-00063.safetensors",
    "model-00050-of-00063.safetensors",
    "model-00051-of-00063.safetensors",
    "model-00052-of-00063.safetensors",
    "model-00053-of-00063.safetensors",
    "model-00054-of-00063.safetensors",
    "model-00055-of-00063.safetensors",
    "model-00056-of-00063.safetensors",
    "model-00057-of-00063.safetensors",
    "model-00058-of-00063.safetensors",
    "model-00059-of-00063.safetensors",
    "model-00060-of-00063.safetensors",
    "model-00061-of-00063.safetensors",
    "model-00062-of-00063.safetensors",
    "model-00063-of-00063.safetensors"
  ],
  "DopeorNope/Ko-Mixtral-MoE-7Bx2": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "slauw87/phi-2_7b_orcaSFT": [
    "model.safetensors"
  ],
  "Isotonic/phizzle": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jiogenes/Llama-2-7b-hf-finetuned-open-korean-instructions": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Inforup982/Harsha-Hermes-2.5-Mistral-7B_safetensors": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "cocoirun/Yi-Ko-6B-instruct-v1.5-DPO": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "fionazhang/mistral-environment-all": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TeeZee/Kyllene-57B-v1.0": [
    "model-00001-of-00012.safetensors",
    "model-00002-of-00012.safetensors",
    "model-00003-of-00012.safetensors",
    "model-00004-of-00012.safetensors",
    "model-00005-of-00012.safetensors",
    "model-00006-of-00012.safetensors",
    "model-00007-of-00012.safetensors",
    "model-00008-of-00012.safetensors",
    "model-00009-of-00012.safetensors",
    "model-00010-of-00012.safetensors",
    "model-00011-of-00012.safetensors",
    "model-00012-of-00012.safetensors"
  ],
  "Envoid/SensualNousInstructDARETIES-CATA-LimaRP-ZlossDT-SLERP-8x7B": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "CallComply/DeciLM-7B-Instruct-32k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "CallComply/DeciLM-7B-Instruct-128k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "wenqiglantz/MistralTrinity-7B-slerp-finetuned-1k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "thanhnew2001/starcoder-7b-taipy25": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "YieldInc/AgentLM-replica-1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "alnrg2arg/test2_2": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "KnutJaegersberg/Walter-Phi": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "huangyt/Taiwan-LLaMa-v1.0-ccp2-r16-q_k_v": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "brucethemoose/Capybara-Fixed-Temp": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "vivecccccc/phi-2_kqa-program": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Sharathhebbar24/lite_llama_small_chat_v1": [
    "model.safetensors"
  ],
  "Sharathhebbar24/llama_chat_small_7b": [
    "model.safetensors"
  ],
  "WQchoi/QLoRA_test3": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Swisslex/Mixtral-8x7b-DPO-v0.2": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "parasora/0.13b-non-ja": [
    "model.safetensors"
  ],
  "LoneStriker/Yi-34Bx2-MoE-60B-3.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "parasora/0.13b-prog-ja": [
    "model.safetensors"
  ],
  "jingyeom/SOLAR_KO_1.3_deup": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "ravikumar101/mistral-7b-v4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20": [
    "model.safetensors"
  ],
  "nguyenhuy/finetuned_bnb": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "rachittshah/mistral-function-calling-7b": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "LoneStriker/Yi-34Bx2-MoE-60B-4.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "notstoic/Nous-Hermes-2-Mixtruct-v0.1-8x7B-DPO-DARE_TIES": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "jat-project/jat": [
    "model.safetensors"
  ],
  "jeiku/Luna_3B": [
    "model-00001-of-00001.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_member_shadow0": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_member_shadow1": [
    "model.safetensors"
  ],
  "progs2002/star-trek-tng-script-generator": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_member_shadow2": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_member_shadow3": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_member_shadow4": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_member_shadow5": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_member_shadow6": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_member_shadow7": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_member_shadow8": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_member_shadow9": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_member_shadow10": [
    "model.safetensors"
  ],
  "TheBloke/Nous-Hermes-2-Mixtral-8x7B-DPO-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Nous-Hermes-2-Mixtral-8x7B-DPO-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_member_shadow11": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_member_shadow12": [
    "model.safetensors"
  ],
  "LoneStriker/Yi-34Bx2-MoE-60B-5.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_member_shadow13": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_member_shadow14": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_member_shadow15": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_member_shadow16": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_member_shadow17": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_member_shadow18": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_member_shadow19": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_member_shadow20": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_member_shadow21": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_member_shadow22": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_member_shadow23": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_member_shadow24": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_member_shadow25": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_member_shadow26": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_member_shadow27": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_member_shadow28": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_member_shadow29": [
    "model.safetensors"
  ],
  "mnjkng/7b-4500-ppo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_member_shadow30": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_member_shadow31": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_member_shadow32": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_member_shadow33": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_member_shadow34": [
    "model.safetensors"
  ],
  "SamagraDataGov/test_mistral2": [
    "adapter_model.safetensors",
    "checkpoint-406/adapter_model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_member_shadow35": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_member_shadow36": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_member_shadow37": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_member_shadow38": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_member_shadow39": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_member_shadow40": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_member_shadow41": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_non_member_shadow0": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_non_member_shadow1": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_non_member_shadow2": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_non_member_shadow3": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_non_member_shadow4": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_non_member_shadow5": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_non_member_shadow6": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_non_member_shadow7": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_non_member_shadow8": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_non_member_shadow9": [
    "model.safetensors"
  ],
  "LoneStriker/Yi-34Bx2-MoE-60B-6.0bpw-h6-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_non_member_shadow10": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_non_member_shadow11": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_non_member_shadow12": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_non_member_shadow13": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_non_member_shadow14": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_non_member_shadow15": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_non_member_shadow16": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_non_member_shadow17": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_non_member_shadow18": [
    "model.safetensors"
  ],
  "notstoic/Nous-Hermes-2-Mixtruct-v0.1-8x7B-DPO-DARE_TIES-exl2-5.0bpw": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_wikitext2_t300_e20_non_member_shadow19": [
    "model.safetensors"
  ],
  "ahmedsamirio/jais-13b-chat-8-bit": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "h-asterix/shakul-test-1": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "jvh/Mistral-NeuralBeagle14-GEITje": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "LegendNNT/fined_llama2_for_vietnamese": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lenbrocki/Serena_DPO": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "OEvortex/HelpingAI-Lite-2x1B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "notstoic/Nous-Hermes-2-Mixtruct-v0.1-8x7B-DPO-DARE_TIES-exl2-3.5bpw": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "gingdev/llama2-gingdev": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "SamagraDataGov/test_mistral3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jvh/Mistral-NeuralBeagle14-GEITje-v2": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "Farhan1572/llama-2-7b-platypus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Kooten/OpenDolphinMaid-4x7b-4bpw-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Kooten/OpenDolphinMaid-4x7b-5bpw-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Kooten/OpenDolphinMaid-4x7b-6bpw-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Nous-Hermes-2-Mixtral-8x7B-DPO-2.4bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "ondevicellm/tinyllama_moe_dpo_ultrafeedback_epochs5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Nous-Hermes-2-Mixtral-8x7B-DPO-3.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "qeternity/Nous-Hermes-2-Mixtral-8x7B-SFT-8bpw-h8-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "Eurdem/megatron_v1": [
    "model-00001-of-00013.safetensors",
    "model-00002-of-00013.safetensors",
    "model-00003-of-00013.safetensors",
    "model-00004-of-00013.safetensors",
    "model-00005-of-00013.safetensors",
    "model-00006-of-00013.safetensors",
    "model-00007-of-00013.safetensors",
    "model-00008-of-00013.safetensors",
    "model-00009-of-00013.safetensors",
    "model-00010-of-00013.safetensors",
    "model-00011-of-00013.safetensors",
    "model-00012-of-00013.safetensors",
    "model-00013-of-00013.safetensors"
  ],
  "mu0gum/AIFT-42dot-LLM-PLM-1.3B-ao-instruct-all-v0.2": [
    "model.safetensors"
  ],
  "Abhishek107/tinyllama_v2": [
    "model.safetensors"
  ],
  "qeternity/Nous-Hermes-2-Mixtral-8x7B-SFT-6bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "LoneStriker/Nous-Hermes-2-Mixtral-8x7B-DPO-3.5bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "qeternity/Nous-Hermes-2-Mixtral-8x7B-SFT-4.65bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "OpenSeneca/Seneca-8x7B-ChainOfCode-alpha": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "LoneStriker/Nous-Hermes-2-Mixtral-8x7B-DPO-3.75bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "aaryaman/emoji-gpt": [
    "model.safetensors"
  ],
  "cappuch/test_pretrain": [
    "model.safetensors"
  ],
  "qeternity/Nous-Hermes-2-Mixtral-8x7B-SFT-5bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "qeternity/Nous-Hermes-2-Mixtral-8x7B-SFT-4bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/japanese-stablelm-instruct-gamma-7b-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Cartinoe5930/Llama2_init_Mistral": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "wangrongsheng/Aurora-dpo": [
    "checkpoint-1000/adapter_model.safetensors",
    "checkpoint-2000/adapter_model.safetensors",
    "checkpoint-3000/adapter_model.safetensors",
    "checkpoint-4000/adapter_model.safetensors",
    "checkpoint-5000/adapter_model.safetensors",
    "checkpoint-6000/adapter_model.safetensors",
    "checkpoint-7000/adapter_model.safetensors",
    "checkpoint-8000/adapter_model.safetensors",
    "checkpoint-9000/adapter_model.safetensors",
    "final_checkpoint/adapter_model.safetensors"
  ],
  "qeternity/Nous-Hermes-2-Mixtral-8x7B-SFT-3.5bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "qeternity/Nous-Hermes-2-Mixtral-8x7B-SFT-3bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Nous-Hermes-2-Mixtral-8x7B-DPO-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/Synatra-7B-v0.3-dpo-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/Ferret_7B-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "qeternity/Nous-Hermes-2-Mixtral-8x7B-SFT-7bpw-h8-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "tarun26/exp_model_1": [
    "model.safetensors"
  ],
  "obrmmk/tinycodellama-jp-0.6b-20k-2-instruct-jcodealpaca-py-def2": [
    "model.safetensors"
  ],
  "LoneStriker/Nous-Hermes-2-Mixtral-8x7B-DPO-5.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "jvh/Mistral-NeuralBeagle14-OpenOrca": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "edfraga/orca-dpo-pairs-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hiepdaoquang704/vietnamese-VBD-llama2-finetune": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Cartinoe5930/SOLAR-DUS-implement": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "MaziyarPanahi/Synatra-V0.1-7B-Instruct-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jvh/Mistral-NeuralBeagle14-OpenOrca-v2": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "obrmmk/tinycodellama-jp-0.6b-20k-2-instruct-codealpaca-py-def2": [
    "model.safetensors"
  ],
  "MaziyarPanahi/Yarn-Mistral-7b-64k-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Nous-Hermes-2-Mixtral-8x7B-DPO-6.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "cappuch/test_2_pretrain": [
    "model.safetensors"
  ],
  "moreh/MoMo-72B-lora-1.8.7-DPO": [
    "model-00001-of-00063.safetensors",
    "model-00002-of-00063.safetensors",
    "model-00003-of-00063.safetensors",
    "model-00004-of-00063.safetensors",
    "model-00005-of-00063.safetensors",
    "model-00006-of-00063.safetensors",
    "model-00007-of-00063.safetensors",
    "model-00008-of-00063.safetensors",
    "model-00009-of-00063.safetensors",
    "model-00010-of-00063.safetensors",
    "model-00011-of-00063.safetensors",
    "model-00012-of-00063.safetensors",
    "model-00013-of-00063.safetensors",
    "model-00014-of-00063.safetensors",
    "model-00015-of-00063.safetensors",
    "model-00016-of-00063.safetensors",
    "model-00017-of-00063.safetensors",
    "model-00018-of-00063.safetensors",
    "model-00019-of-00063.safetensors",
    "model-00020-of-00063.safetensors",
    "model-00021-of-00063.safetensors",
    "model-00022-of-00063.safetensors",
    "model-00023-of-00063.safetensors",
    "model-00024-of-00063.safetensors",
    "model-00025-of-00063.safetensors",
    "model-00026-of-00063.safetensors",
    "model-00027-of-00063.safetensors",
    "model-00028-of-00063.safetensors",
    "model-00029-of-00063.safetensors",
    "model-00030-of-00063.safetensors",
    "model-00031-of-00063.safetensors",
    "model-00032-of-00063.safetensors",
    "model-00033-of-00063.safetensors",
    "model-00034-of-00063.safetensors",
    "model-00035-of-00063.safetensors",
    "model-00036-of-00063.safetensors",
    "model-00037-of-00063.safetensors",
    "model-00038-of-00063.safetensors",
    "model-00039-of-00063.safetensors",
    "model-00040-of-00063.safetensors",
    "model-00041-of-00063.safetensors",
    "model-00042-of-00063.safetensors",
    "model-00043-of-00063.safetensors",
    "model-00044-of-00063.safetensors",
    "model-00045-of-00063.safetensors",
    "model-00046-of-00063.safetensors",
    "model-00047-of-00063.safetensors",
    "model-00048-of-00063.safetensors",
    "model-00049-of-00063.safetensors",
    "model-00050-of-00063.safetensors",
    "model-00051-of-00063.safetensors",
    "model-00052-of-00063.safetensors",
    "model-00053-of-00063.safetensors",
    "model-00054-of-00063.safetensors",
    "model-00055-of-00063.safetensors",
    "model-00056-of-00063.safetensors",
    "model-00057-of-00063.safetensors",
    "model-00058-of-00063.safetensors",
    "model-00059-of-00063.safetensors",
    "model-00060-of-00063.safetensors",
    "model-00061-of-00063.safetensors",
    "model-00062-of-00063.safetensors",
    "model-00063-of-00063.safetensors"
  ],
  "MaziyarPanahi/mistral-ft-optimized-1218-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Nous-Hermes-2-Mixtral-8x7B-SFT-2.4bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/Nous-Hermes-2-Mixtral-8x7B-SFT-3.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/GreenNode-mini-7B-multilingual-v1olet-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jvh/Mistral-NeuralBeagle14-OpenOrca-v3": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "LoneStriker/Nous-Hermes-2-Mixtral-8x7B-SFT-3.5bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/zephyr-7b-sft-full-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "CraftDocs/Mixtral-8x7B-Instruct-v0.1-writer-assistant-inline-v0.12-fullmodel": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "LoneStriker/Nous-Hermes-2-Mixtral-8x7B-SFT-3.75bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/notus-7b-v1-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "SamagraDataGov/test_mistral5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Nous-Hermes-2-Mixtral-8x7B-SFT-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Nous-Hermes-2-Mixtral-8x7B-SFT-5.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "MaziyarPanahi/MetaMath-Mistral-7B-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Kooten/DaringLotus-4bpw-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Nous-Hermes-2-Mixtral-8x7B-SFT-6.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "wenqiglantz/MistralTrinity-7B-slerp-finetuned-dolly-1k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/SciPhi-Mistral-7B-32k-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jjszpak/SCAN-exp1b-8proc-v0": [
    "model.safetensors"
  ],
  "jvh/Mistral-NeuralBeagle14-OpenOrca-Turdus": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "obrmmk/tinycodellama-jp-0.6b-30k-v2-instruct-jcodealpaca-py-def2": [
    "model.safetensors"
  ],
  "FelixChao/NarutoDolphin-10B-Instruct": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "MaziyarPanahi/Synatra-7B-v0.3-RP-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/NeuralHermes-2.5-Mistral-7B-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jjszpak/SCAN-exp1b-8proc-v1": [
    "model.safetensors"
  ],
  "CraftDocs/Mixtral-8x7B-Instruct-v0.1-writer-assistant-block-v0.12-fullmodel": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "MaziyarPanahi/ANIMA-Phi-Neptune-Mistral-7B-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Wanfq/fusechat_v1_nous_hermes_solar_teacher_ckpt": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Wanfq/fusechat_v1_nous_hermes_solar_teacher_woref_ckpt": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hojzas/autotrain-no2": [
    "adapter_model.safetensors",
    "checkpoint-6/adapter_model.safetensors",
    "model.safetensors"
  ],
  "obrmmk/tinycodellama-jp-0.6b-30k-v2-instruct-en-jcodealpaca-py-def2": [
    "model.safetensors"
  ],
  "jjszpak/SCAN-exp1b-8proc-v2": [
    "model.safetensors"
  ],
  "minkhantycc/letstalk": [
    "model.safetensors"
  ],
  "jvh/Mistral-NeuralBeagle14-OpenOrca-Turdus-v2": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "Daoguang/codes": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/mindy-7b-v2-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "NeuralNovel/Gecko-7B-v0.1-DPO": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "herisan/TinyLlama": [
    "model.safetensors"
  ],
  "linvest21/OpenHermes-2.5-Mistral-7B_test_v0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "prettydataai/service-classifier": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "MaziyarPanahi/Tess-XS-v1-3-yarn-128K-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "lingjoor/numeval-task7-2": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "KnutJaegersberg/Qwen-1_8b-EverythingLM": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jjszpak/SCAN-exp1b-16proc-v0": [
    "model.safetensors"
  ],
  "harshshekhar15/zephyr-7b-beta_finetune_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "BOT365/my-tinyllama-colorist-v2": [
    "model.safetensors"
  ],
  "MaziyarPanahi/speechless-code-mistral-7b-v1.0-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "vedalken/phi2-2B-slerp": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "byerth/new_model2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kakashiCopyNinja/ft_Llama-2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mu0gum/AIFT-42dot-LLM-PLM-ao-instruct-all-v0.3": [
    "model.safetensors"
  ],
  "MaziyarPanahi/koOpenChat-sft-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Depie/Llama-2-7b-chat-ToTTo-3epochs-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Yi-34Bx2-MoE-60B-2.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "jjszpak/SCAN-exp1b-16proc-v1": [
    "model.safetensors"
  ],
  "LoneStriker/Noromaid-v0.4-Mixtral-Instruct-8x7b-Zloss-3.25bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/go-bruins-v2-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "nutorbit/mistral-7b-xllm-merged": [
    "model.safetensors"
  ],
  "MaziyarPanahi/neural-chat-7b-v3-3-Slerp-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "macadeliccc/piccolo-4x7b": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "AdryKab47/llamaft": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "macadeliccc/piccolo-2x7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jjszpak/SCAN-exp1b-16proc-v2": [
    "model.safetensors"
  ],
  "macadeliccc/piccolo-math-2x7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/v1olet_marcoroni-go-bruins-merge-7B-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/neural-chat-7b-v3-2-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "dylan9n/Mistral-7B-Evol-Ultrachat": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Isotonic/Dolphin-5.1-7b": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "cgato/Thespis-34b-v0.7": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "MaziyarPanahi/PiVoT-10.7B-Mistral-v0.2-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Technoculture/Tronchat-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Freddiex/mistral-7b-email-ft": [
    "adapter_model.safetensors",
    "checkpoint-49/adapter_model.safetensors"
  ],
  "MaziyarPanahi/MetaMath-Cybertron-Starling-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/UNA-34Beagles-32K-bf16-v1-3.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/neural-chat-7b-v3-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "maxmyn/distilgpt2-greentexts": [
    "model.safetensors"
  ],
  "Locutusque/UltraQwen-1_8B": [
    "model.safetensors"
  ],
  "MaziyarPanahi/WizardMath-7B-V1.1-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Code-290k-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Code-290k-13B-AWQ": [
    "model.safetensors"
  ],
  "LoneStriker/UNA-34Beagles-32K-bf16-v1-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "TheBloke/Thespis-13B-DPO-v0.7-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Thespis-13B-DPO-v0.7-AWQ": [
    "model.safetensors"
  ],
  "Technoculture/PMCtron-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/Mistral-T5-7B-v1-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jarod0411/zinc10M_gpt2_SMILES_bpe_combined_step3": [
    "model.safetensors"
  ],
  "flemmingmiguel/DareBeagle-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "LoneStriker/UNA-34Beagles-32K-bf16-v1-4.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "wang7776/vicuna-7b-v1.3-sparsity-10": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Noromaid-13B-0.4-DPO-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Noromaid-13B-0.4-DPO-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "MaziyarPanahi/blossom-v3-mistral-7b-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Noromaid-13B-0.4-DPO-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoSboccacc/orthogonal-2x7B-base": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AGBonnet/medinote-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AGBonnet/medinote-13b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/Noromaid-13B-0.4-DPO-6.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/OpenHermes-7B-Symbolic-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/UNA-34Beagles-32K-bf16-v1-5.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Noromaid-13B-0.4-DPO-8.0bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "DenisTheDev/Openchat-Passthrough-2": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "pratham-saraf/ms7b-news-songify-sharded": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/mamba-gpt-7b-v2-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Danielbrdz/Barcenas-10.7b": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "LoneStriker/UNA-34Beagles-32K-bf16-v1-6.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "chuducandev/Llama-2-7b-hf-c2t-2-002": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jeiku/Bones_3B": [
    "model-00001-of-00001.safetensors"
  ],
  "MaziyarPanahi/blossom-v3_1-mistral-7b-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "macadeliccc/piccolo-8x7b": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "LoneStriker/openchat-3.5-0106-11b-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "llmixer/BigLiz-120b": [
    "model-00001-of-00024.safetensors",
    "model-00002-of-00024.safetensors",
    "model-00003-of-00024.safetensors",
    "model-00004-of-00024.safetensors",
    "model-00005-of-00024.safetensors",
    "model-00006-of-00024.safetensors",
    "model-00007-of-00024.safetensors",
    "model-00008-of-00024.safetensors",
    "model-00009-of-00024.safetensors",
    "model-00010-of-00024.safetensors",
    "model-00011-of-00024.safetensors",
    "model-00012-of-00024.safetensors",
    "model-00013-of-00024.safetensors",
    "model-00014-of-00024.safetensors",
    "model-00015-of-00024.safetensors",
    "model-00016-of-00024.safetensors",
    "model-00017-of-00024.safetensors",
    "model-00018-of-00024.safetensors",
    "model-00019-of-00024.safetensors",
    "model-00020-of-00024.safetensors",
    "model-00021-of-00024.safetensors",
    "model-00022-of-00024.safetensors",
    "model-00023-of-00024.safetensors",
    "model-00024-of-00024.safetensors"
  ],
  "bburli/llama-2-7b-bburli-6": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/UNA-34Beagles-32K-bf16-v1-8.0bpw-h8-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "LoneStriker/openchat-3.5-0106-11b-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "Technoculture/Medchator-2x7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/vigostral-7b-chat-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Epimachok/PavelGPT-7b-128k-awq": [
    "model.safetensors"
  ],
  "LoneStriker/openchat-3.5-0106-11b-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "athirdpath/MoE-Test-4x7b": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "MaziyarPanahi/openbuddy-zephyr-7b-v14.1-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/openchat-3.5-0106-11b-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/openchat-3.5-0106-11b-8.0bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "josh-sematic/forum-json-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/mamba-gpt-7b-v1-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jeiku/Test25_3B": [
    "model-00001-of-00001.safetensors"
  ],
  "TheBloke/Nous-Hermes-2-Mixtral-8x7B-SFT-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Nous-Hermes-2-Mixtral-8x7B-SFT-GPTQ": [
    "model.safetensors"
  ],
  "MaziyarPanahi/zephykor-ko-beta-7b-chang-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/openchat-3.5-0106-128k-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "Neuronovo/neuronovo-9B-v0.4": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "DenisTheDev/Openchat-Passthrough-SLERP": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "LoneStriker/openchat-3.5-0106-128k-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "sosoai/mixtralv3_dpo": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "LoneStriker/openchat-3.5-0106-128k-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "Americo/falcon-7b-farmatodo": [
    "adapter_model.safetensors"
  ],
  "LoneStriker/openchat-3.5-0106-128k-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/openchat-3.5-0106-128k-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "llmixer/BigAurelian-v0.5-120b-32k": [
    "model-00001-of-00024.safetensors",
    "model-00002-of-00024.safetensors",
    "model-00003-of-00024.safetensors",
    "model-00004-of-00024.safetensors",
    "model-00005-of-00024.safetensors",
    "model-00006-of-00024.safetensors",
    "model-00007-of-00024.safetensors",
    "model-00008-of-00024.safetensors",
    "model-00009-of-00024.safetensors",
    "model-00010-of-00024.safetensors",
    "model-00011-of-00024.safetensors",
    "model-00012-of-00024.safetensors",
    "model-00013-of-00024.safetensors",
    "model-00014-of-00024.safetensors",
    "model-00015-of-00024.safetensors",
    "model-00016-of-00024.safetensors",
    "model-00017-of-00024.safetensors",
    "model-00018-of-00024.safetensors",
    "model-00019-of-00024.safetensors",
    "model-00020-of-00024.safetensors",
    "model-00021-of-00024.safetensors",
    "model-00022-of-00024.safetensors",
    "model-00023-of-00024.safetensors",
    "model-00024-of-00024.safetensors"
  ],
  "MaziyarPanahi/Dans-07YahooAnswers-7b-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "flemmingmiguel/MarcMistral-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "LoneStriker/SnowLotus-10.7B-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "MaziyarPanahi/una-cybertron-7b-v3-OMA-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "macadeliccc/SOLAR-math-2x10.7b-v0.2": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "LoneStriker/SnowLotus-10.7B-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "MaziyarPanahi/openbuddy-mistral-7b-v13.1-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/SnowLotus-10.7B-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "eren23/slerp-test-turdus-beagle": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "LoneStriker/SnowLotus-10.7B-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/FrankenDPO-4x7B-bf16-3.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Yamila/DialoGPT-small-Jonesy2-Bot": [
    "model.safetensors"
  ],
  "LoneStriker/SnowLotus-10.7B-8.0bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/testllm-c2-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/FrankenDPO-4x7B-bf16-3.5bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Kooten/DaringLotus-5bpw-exl2": [
    "output.safetensors"
  ],
  "Kooten/DaringLotus-6bpw-exl2": [
    "output.safetensors"
  ],
  "Kooten/DaringLotus-8bpw-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "DenisTheDev/Openchat-Zephyr-Passtrough": [
    "model-00001-of-00012.safetensors",
    "model-00002-of-00012.safetensors",
    "model-00003-of-00012.safetensors",
    "model-00004-of-00012.safetensors",
    "model-00005-of-00012.safetensors",
    "model-00006-of-00012.safetensors",
    "model-00007-of-00012.safetensors",
    "model-00008-of-00012.safetensors",
    "model-00009-of-00012.safetensors",
    "model-00010-of-00012.safetensors",
    "model-00011-of-00012.safetensors",
    "model-00012-of-00012.safetensors"
  ],
  "lodrick-the-lafted/Winged-Lagomorph-2x13B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "LoneStriker/FrankenDPO-4x7B-bf16-4.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "shadowml/DareBeagle-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/typhoon-7b-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "pandasai/bamboo-llm": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "LoneStriker/FrankenDPO-4x7B-bf16-5.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/Mistral-7B-OpenOrca-oasst_top1_2023-08-25-v3-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/FrankenDPO-4x7B-bf16-6.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/Mini_DPO_test02-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Karko/Proctora": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "pratham-saraf/ms7b-news-songify-sharded-1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/FrankenDPO-4x7B-bf16-8.0bpw-h8-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "Shortg/my_awesome_imdb_clm-model": [
    "model.safetensors"
  ],
  "MaziyarPanahi/openbuddy-mistral-7b-v13-base-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "htahir1/peft-lora-zencoder15B-A100-40GB-merged": [
    "best_personal_copilot/adapter_model.safetensors",
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors",
    "personal_copilot/adapter_model.safetensors"
  ],
  "kevinmgates/youtoks2": [
    "model.safetensors"
  ],
  "VishaalY/wizard-phind-coder-passthrough-39B": [
    "model-00001-of-00042.safetensors",
    "model-00002-of-00042.safetensors",
    "model-00003-of-00042.safetensors",
    "model-00004-of-00042.safetensors",
    "model-00005-of-00042.safetensors",
    "model-00006-of-00042.safetensors",
    "model-00007-of-00042.safetensors",
    "model-00008-of-00042.safetensors",
    "model-00009-of-00042.safetensors",
    "model-00010-of-00042.safetensors",
    "model-00011-of-00042.safetensors",
    "model-00012-of-00042.safetensors",
    "model-00013-of-00042.safetensors",
    "model-00014-of-00042.safetensors",
    "model-00015-of-00042.safetensors",
    "model-00016-of-00042.safetensors",
    "model-00017-of-00042.safetensors",
    "model-00018-of-00042.safetensors",
    "model-00019-of-00042.safetensors",
    "model-00020-of-00042.safetensors",
    "model-00021-of-00042.safetensors",
    "model-00022-of-00042.safetensors",
    "model-00023-of-00042.safetensors",
    "model-00024-of-00042.safetensors",
    "model-00025-of-00042.safetensors",
    "model-00026-of-00042.safetensors",
    "model-00027-of-00042.safetensors",
    "model-00028-of-00042.safetensors",
    "model-00029-of-00042.safetensors",
    "model-00030-of-00042.safetensors",
    "model-00031-of-00042.safetensors",
    "model-00032-of-00042.safetensors",
    "model-00033-of-00042.safetensors",
    "model-00034-of-00042.safetensors",
    "model-00035-of-00042.safetensors",
    "model-00036-of-00042.safetensors",
    "model-00037-of-00042.safetensors",
    "model-00038-of-00042.safetensors",
    "model-00039-of-00042.safetensors",
    "model-00040-of-00042.safetensors",
    "model-00041-of-00042.safetensors",
    "model-00042-of-00042.safetensors"
  ],
  "neopolita/neopolita-gar-7B-ties": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "yihang7/dolly-v2-7b-dpo-full-1-epoch-hydrox-safe": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jeiku/Test68_3B": [
    "model-00001-of-00001.safetensors"
  ],
  "MaziyarPanahi/SciPhi-Self-RAG-Mistral-7B-32k-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/Mistral-7B-claude-instruct-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "oivlisnet/Llama-2-13b-chat-hf-GPTQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/PiVoT-0.1-early-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/dolphin-2.6-mistral-7b-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/Venomia-1.1-m7-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/pic_7B_mistral_Full_v0.2-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Bias-Leaderboard/gpt2-demo": [
    "model.safetensors"
  ],
  "MaziyarPanahi/NyakuraV2.1-m7-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "deepanshdj/Llama-2-7B-DJ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sumo43/Yi-34b-x2-v2": [
    "model-00001-of-00013.safetensors",
    "model-00002-of-00013.safetensors",
    "model-00003-of-00013.safetensors",
    "model-00004-of-00013.safetensors",
    "model-00005-of-00013.safetensors",
    "model-00006-of-00013.safetensors",
    "model-00007-of-00013.safetensors",
    "model-00008-of-00013.safetensors",
    "model-00009-of-00013.safetensors",
    "model-00010-of-00013.safetensors",
    "model-00011-of-00013.safetensors",
    "model-00012-of-00013.safetensors",
    "model-00013-of-00013.safetensors"
  ],
  "MaziyarPanahi/Mistral-7B-v0.1-Open-Platypus-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/piano-medley-7b-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/zephyr-beta-math-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "zaq-hack/Noromaid-13B-0.4-DPO-bpw600-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/samantha-mistral-7b-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "valine/OpenPirate": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jeiku/Luna_Futa_3B": [
    "model-00001-of-00001.safetensors"
  ],
  "Parth/codephiii-2.7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/dolphin-2.0-mistral-7b-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/mistralopithecus-v1-dpo-7b-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Kquant03/Eukaryote-8x7B-bf16": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "mrbmaryam/Yarn-Mistral-7b-128k_Fine-Tuned4LogParsing-r1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/Metis-0.4-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "realPCH/ko_solra_merge": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "qgyd2021/similar_question_generation": [
    "final/model.safetensors",
    "model.safetensors"
  ],
  "MaziyarPanahi/SynthIA-7B-v1.3-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/mistral-7b-finetuned-orca-dpo-v2-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "etri-xainlp/llama2-12.8b_lora-dpo_v1": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "MaziyarPanahi/LeoScorpius-GreenNode-Alpaca-7B-v1-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "liminerity/Blurstral-7b-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "MaziyarPanahi/LeoScorpius-GreenNode-Platypus-7B-v1-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "duanyu027/loyal-piano-m7-dpo-70bdata-0117": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "liminerity/Mini-blurstral": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/jackalope-7b-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "liminerity/Miniier-blurstral-attempt-1": [
    "model-00001-of-00001.safetensors"
  ],
  "MaziyarPanahi/mistral-7b-v0.1-layla-v1-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "SanjiWatsuki/DeepSeek-Coder-Instruct-8x1.3b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/CollectiveCognition-v1.1-Mistral-7B-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/mistral-7b-slimorcaboros-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "syncdoth/tiny-llama-5": [
    "model.safetensors"
  ],
  "syncdoth/tiny-llama-6": [
    "model.safetensors"
  ],
  "WYNN747/Burmese-GPT-main-v7-1k": [
    "model.safetensors"
  ],
  "syncdoth/tiny-llama-7": [
    "model.safetensors"
  ],
  "syncdoth/tiny-llama-8": [
    "model.safetensors"
  ],
  "syncdoth/tiny-llama-9": [
    "model.safetensors"
  ],
  "syncdoth/tiny-llama-10": [
    "model.safetensors"
  ],
  "duoqi/Nanbeige-16B-Base-Llama": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "MaziyarPanahi/Mistral-7B-golden-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "syncdoth/tiny-llama-11": [
    "model.safetensors"
  ],
  "cookinai/Bald-Eagle-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "WYNN747/Burmese-GPT-main-v7-15k": [
    "model.safetensors"
  ],
  "LoneStriker/DaringLotus-10.7B-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "MaziyarPanahi/mistral-7b_open_platypus-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/DaringLotus-10.7B-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "MaziyarPanahi/Mistral-7b-FFT-Test3-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/DaringLotus-10.7B-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "MaziyarPanahi/samantha-1.2-mistral-7b-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/DaringLotus-10.7B-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "Wanfq/Abel-7B-002_distill_baseline_ckpt": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/Mini_Synatra_SFT-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "halbihn/NeuralHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Wanfq/Abel-7B-002_distill_0.9h_ckpt": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dominic5/Apeiron_Project5_Mistral7b_Merged_Lora_Adapter": [
    "model.safetensors"
  ],
  "LoneStriker/DaringLotus-10.7B-8.0bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/SynthIA-7B-v1.5-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/OpenHermes-2.5-neural-chat-7b-v3-1-7B-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/Mistral-Trismegistus-7B-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "WYNN747/Burmese-GPT-qa_sys6_main_2": [
    "model.safetensors"
  ],
  "Yarofa/model_old_v1": [
    "model.safetensors"
  ],
  "MaziyarPanahi/v1olet_merged_dpo_7B-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "BlueNipples/SnowLotus-v2-10.7B": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "MaziyarPanahi/japanese-stablelm-base-gamma-7b-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "alexredplanet/NeuralHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/LeoScorpius-7B-Chat-DPO-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ibivibiv/orthorus-125b-moe": [
    "model-00001-of-00108.safetensors",
    "model-00002-of-00108.safetensors",
    "model-00003-of-00108.safetensors",
    "model-00004-of-00108.safetensors",
    "model-00005-of-00108.safetensors",
    "model-00006-of-00108.safetensors",
    "model-00007-of-00108.safetensors",
    "model-00008-of-00108.safetensors",
    "model-00009-of-00108.safetensors",
    "model-00010-of-00108.safetensors",
    "model-00011-of-00108.safetensors",
    "model-00012-of-00108.safetensors",
    "model-00013-of-00108.safetensors",
    "model-00014-of-00108.safetensors",
    "model-00015-of-00108.safetensors",
    "model-00016-of-00108.safetensors",
    "model-00017-of-00108.safetensors",
    "model-00018-of-00108.safetensors",
    "model-00019-of-00108.safetensors",
    "model-00020-of-00108.safetensors",
    "model-00021-of-00108.safetensors",
    "model-00022-of-00108.safetensors",
    "model-00023-of-00108.safetensors",
    "model-00024-of-00108.safetensors",
    "model-00025-of-00108.safetensors",
    "model-00026-of-00108.safetensors",
    "model-00027-of-00108.safetensors",
    "model-00028-of-00108.safetensors",
    "model-00029-of-00108.safetensors",
    "model-00030-of-00108.safetensors",
    "model-00031-of-00108.safetensors",
    "model-00032-of-00108.safetensors",
    "model-00033-of-00108.safetensors",
    "model-00034-of-00108.safetensors",
    "model-00035-of-00108.safetensors",
    "model-00036-of-00108.safetensors",
    "model-00037-of-00108.safetensors",
    "model-00038-of-00108.safetensors",
    "model-00039-of-00108.safetensors",
    "model-00040-of-00108.safetensors",
    "model-00041-of-00108.safetensors",
    "model-00042-of-00108.safetensors",
    "model-00043-of-00108.safetensors",
    "model-00044-of-00108.safetensors",
    "model-00045-of-00108.safetensors",
    "model-00046-of-00108.safetensors",
    "model-00047-of-00108.safetensors",
    "model-00048-of-00108.safetensors",
    "model-00049-of-00108.safetensors",
    "model-00050-of-00108.safetensors",
    "model-00051-of-00108.safetensors",
    "model-00052-of-00108.safetensors",
    "model-00053-of-00108.safetensors",
    "model-00054-of-00108.safetensors",
    "model-00055-of-00108.safetensors",
    "model-00056-of-00108.safetensors",
    "model-00057-of-00108.safetensors",
    "model-00058-of-00108.safetensors",
    "model-00059-of-00108.safetensors",
    "model-00060-of-00108.safetensors",
    "model-00061-of-00108.safetensors",
    "model-00062-of-00108.safetensors",
    "model-00063-of-00108.safetensors",
    "model-00064-of-00108.safetensors",
    "model-00065-of-00108.safetensors",
    "model-00066-of-00108.safetensors",
    "model-00067-of-00108.safetensors",
    "model-00068-of-00108.safetensors",
    "model-00069-of-00108.safetensors",
    "model-00070-of-00108.safetensors",
    "model-00071-of-00108.safetensors",
    "model-00072-of-00108.safetensors",
    "model-00073-of-00108.safetensors",
    "model-00074-of-00108.safetensors",
    "model-00075-of-00108.safetensors",
    "model-00076-of-00108.safetensors",
    "model-00077-of-00108.safetensors",
    "model-00078-of-00108.safetensors",
    "model-00079-of-00108.safetensors",
    "model-00080-of-00108.safetensors",
    "model-00081-of-00108.safetensors",
    "model-00082-of-00108.safetensors",
    "model-00083-of-00108.safetensors",
    "model-00084-of-00108.safetensors",
    "model-00085-of-00108.safetensors",
    "model-00086-of-00108.safetensors",
    "model-00087-of-00108.safetensors",
    "model-00088-of-00108.safetensors",
    "model-00089-of-00108.safetensors",
    "model-00090-of-00108.safetensors",
    "model-00091-of-00108.safetensors",
    "model-00092-of-00108.safetensors",
    "model-00093-of-00108.safetensors",
    "model-00094-of-00108.safetensors",
    "model-00095-of-00108.safetensors",
    "model-00096-of-00108.safetensors",
    "model-00097-of-00108.safetensors",
    "model-00098-of-00108.safetensors",
    "model-00099-of-00108.safetensors",
    "model-00100-of-00108.safetensors",
    "model-00101-of-00108.safetensors",
    "model-00102-of-00108.safetensors",
    "model-00103-of-00108.safetensors",
    "model-00104-of-00108.safetensors",
    "model-00105-of-00108.safetensors",
    "model-00106-of-00108.safetensors",
    "model-00107-of-00108.safetensors",
    "model-00108-of-00108.safetensors"
  ],
  "ohyay12345/trainedmodel": [
    "model.safetensors"
  ],
  "walter-cavinaw/phi-1_5-finetuned-med-text": [
    "model.safetensors"
  ],
  "MaziyarPanahi/MelloGPT-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "SanjiWatsuki/llama-stampede-64x101m": [
    "model-00001-of-00001.safetensors"
  ],
  "h2m/mhm-7b-v1.3-DPO-1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/samantha-mistral-instruct-7b-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "liminerity/Blur-ier-7b-blurslerp": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "SamagraDataGov/test_mistral6": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Wanfq/Abel-7B-002_distill_0.7hd_ckpt": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "BlueNipples/DaringLotus-v2-10.7b": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "KeyonZeng/philion-2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/em_german_leo_mistral-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "kodonho/Momo-70b-DPO-mixed": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "alnrg2arg/test2_3": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/Mistral-7B-model_45k6e2e4-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Byungchae/k2s3_test_0001": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "aixsatoshi/calm2-7b-chat-7b-moe": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "abacusai/MetaMath-bagel-34b-v0.2-c1500": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "MaziyarPanahi/speechless-code-mistral-orca-7b-v1.0-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Elizezen/SniffyNinja-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/Rabbit-7B-DPO-Chat-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "alnrg2arg/blockchainlabs_7B_merged_test2_4": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "cloudyu/Pluto_13B_DPO": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "SanjiWatsuki/Lelantos-Maid-DPO-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "MaziyarPanahi/CollectiveCognition-v1-Mistral-7B-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "liminerity/Blur-6b-slerp-v0.1.1": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "MaziyarPanahi/CollectiveCognition-v1.1-Mistral-7B-dare-0.85-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/una-cybertron-7b-v2-bf16-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/speechless-code-mistral-7b-v2.0-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ohyay12345/trainedmodel2": [
    "model.safetensors"
  ],
  "sivasankari/llama2fine_siva": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/SynthIA-7B-v1.3-dare-0.85-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "hoonisone/git-base-pokemon": [
    "model.safetensors"
  ],
  "abdiharyadi/kancilgpt-v20240117": [
    "model.safetensors"
  ],
  "realPCH/kosolra-wiki-QA": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "RiverTest/RiverMTG9": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "MaziyarPanahi/neural-chat-7b-v3-1-dare-0.85-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Cartinoe5930/SOLAR-10.7B-iDUS-1layer": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Wane27/DiabloGPT-small-malablake": [
    "model.safetensors"
  ],
  "MaziyarPanahi/speechless-mistral-six-in-one-7b-orth-1.0-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "liminerity/Blur-7b-slerp-v0.1.11": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "Kooten/Noromaid-13B-0.4-DPO-8bpw-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Kooten/Noromaid-13B-0.4-DPO-6bpw-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Kooten/Noromaid-13B-0.4-DPO-5bpw-exl2": [
    "output.safetensors"
  ],
  "Kooten/Noromaid-13B-0.4-DPO-4bpw-exl2": [
    "output.safetensors"
  ],
  "MaziyarPanahi/speechless-mistral-dolphin-orca-platypus-samantha-7b-dare-0.85-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/zephyr-7b-alpha-dare-0.85-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/airoboros-m-7b-3.1.2-dare-0.85-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "AgentPublic/Guillaume-Tell": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/smartyplats-7b-v2-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/shisa-7b-v1-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "realPCH/kosolra-kullm": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "pratham-saraf/ms7b-news-songified-sharded": [
    "checkpoint-100/adapter_model.safetensors",
    "checkpoint-125/adapter_model.safetensors",
    "checkpoint-150/adapter_model.safetensors",
    "checkpoint-25/adapter_model.safetensors",
    "checkpoint-50/adapter_model.safetensors",
    "checkpoint-75/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "danielhanchen/test_adapters2": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "MaziyarPanahi/MetaMath-Chupacabra-7B-v2.01-Slerp-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/MetaMath-Tulpar-7b-v2-Slerp-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/Mistral-ko-7B-v0.1-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "rukaiyah-indika-ai/rv-chatbot": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/DPOpenHermes-7B-v2-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "realPCH/kosolra-kiwi": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "ondevicellm/tinyllama_moe_sft_ultrachat-slimorca": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/OpenHermes-2.5-neural-chat-v3-3-Slerp-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "soniox/Soniox-7B-v1.0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/MetaMath-OpenHermes-2.5-neural-chat-v3-3-Slerp-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "nitky/Superswallow-7b-baseline": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "youndukn/zephyr-7b-sft-lora": [
    "adapter_model.safetensors"
  ],
  "MaziyarPanahi/bagel-dpo-7b-v0.1-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "nitky/Superswallow-13b-baseline": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "nitky/Superswallow-70b-baseline": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "222limin/Blur-7b-slerp-v0.1.11-tuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/Mini_synatra_7b_03-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "realPCH/kosolra-koOrca-Platypus-v3": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Kooten/Lelantos-Maid-DPO-7B-4bpw-exl2": [
    "output.safetensors"
  ],
  "Kooten/Lelantos-Maid-DPO-7B-8bpw-exl2": [
    "output.safetensors"
  ],
  "pqhungbk/llama-2-7b-platypus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/NeuralBeagle14-7B-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "MaziyarPanahi/Mistral-7B-KNUT-v0.2-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "h-asterix/mistralai-Code-Instruct-Finetune-test-shakul-test": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "LoneStriker/NeuralBeagle14-7B-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "kreabs/hermeo-7b_finetuned_dolly_2400": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/NeuralBeagle14-7B-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "MaziyarPanahi/blossom-v4-mistral-7b-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/NeuralBeagle14-7B-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "duanyu027/OpenHermes-loyal-dpo-0115-merge": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "yeniceriSGK/falcon1b-BasicFinetune": [
    "model.safetensors"
  ],
  "maxmyn/sequential-finetune-simple-greentexts-2Layer-33M": [
    "model.safetensors"
  ],
  "duanyu027/OpenHermes-loyal-dpo-70bdata-0117-merge": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/NeuralBeagle14-7B-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "MaziyarPanahi/MRAI_synatra_7B_v1-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FelixChao/Magician-MoE-4x7B": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "DenisTheDev/Openchat-ORCAMistral-Passtrough": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "realPCH/ko-solra-platusv3-koprompt": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "MaziyarPanahi/Mini_synata_7b_011-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "h-asterix/mistralai-Code-Instruct-Finetune-test-shakul-test-22": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "jjszpak/SCAN-exp2-v0": [
    "model.safetensors"
  ],
  "llmixer/Xwinter-120b": [
    "model-00001-of-00024.safetensors",
    "model-00002-of-00024.safetensors",
    "model-00003-of-00024.safetensors",
    "model-00004-of-00024.safetensors",
    "model-00005-of-00024.safetensors",
    "model-00006-of-00024.safetensors",
    "model-00007-of-00024.safetensors",
    "model-00008-of-00024.safetensors",
    "model-00009-of-00024.safetensors",
    "model-00010-of-00024.safetensors",
    "model-00011-of-00024.safetensors",
    "model-00012-of-00024.safetensors",
    "model-00013-of-00024.safetensors",
    "model-00014-of-00024.safetensors",
    "model-00015-of-00024.safetensors",
    "model-00016-of-00024.safetensors",
    "model-00017-of-00024.safetensors",
    "model-00018-of-00024.safetensors",
    "model-00019-of-00024.safetensors",
    "model-00020-of-00024.safetensors",
    "model-00021-of-00024.safetensors",
    "model-00022-of-00024.safetensors",
    "model-00023-of-00024.safetensors",
    "model-00024-of-00024.safetensors"
  ],
  "kiki7sun/FT-River-0117": [
    "model.safetensors"
  ],
  "MaziyarPanahi/Marcoroni-neural-chat-7B-v2-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "kaitchup/Maixtchup-4x7b": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "SanjiWatsuki/TinyMixtral-32x248M": [
    "model-00001-of-00001.safetensors"
  ],
  "MaziyarPanahi/Mistral-7B-KNUT-v0.3-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jjszpak/SCAN-exp2-v1": [
    "model.safetensors"
  ],
  "arcee-ai/llama-from-mistral": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "MaziyarPanahi/Synatra-7B-Instruct-v0.2-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ondevicellm/tinyllama_moe_sft_ultrachat200k_v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/bagel-7b-v0.1-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jjszpak/SCAN-exp2-v2": [
    "model.safetensors"
  ],
  "MaziyarPanahi/CatMacaroni-Slerp-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "greymatter-2024/17jan-llama-hpc": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "htahir1/peft-lora-zencoder15B-personal-copilot-merged": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "FelixChao/Magician-MoE-2x7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "llmixer/Xwinter-120b-3.0bpw-h8-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "lumatic-ai/BongLlama-1.1B-Chat-alpha-v0": [
    "model.safetensors"
  ],
  "asafaya/kanarya-750m": [
    "model.safetensors"
  ],
  "asafaya/kanarya-2b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/Noromaid-7b-v0.2-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/Mistral-7B-v0.1-sharded-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "cappuch/opt_1_flan_gsm8k": [
    "model.safetensors"
  ],
  "yuuko-eth/DraftReasoner-2x7B-MoE-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "haoranxu/ALMA-13B-R": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "MaziyarPanahi/quantum-v0.01-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "haoranxu/ALMA-7B-R": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/zephyr-7b-alpha-sharded-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Abzu/CodeLlama-7b-hf": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "cappuch/gpt2_tiny_textbooks_v1": [
    "model.safetensors"
  ],
  "arcee-ai/1b-sliced-llama_from_mistral": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/CatPPT-base-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "nicholasKluge/TeenyTinyLlama-460m-Chat": [
    "model.safetensors"
  ],
  "kreabs/NeuralBeagle14-7B_finetuned_dolly_2400": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/go-bruins-v2.1.1-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Technoculture/PMCtuned-13b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/Marcoroni-neural-chat-7B-v1-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/MythoMist-7b-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Weni/WeniGPT-2.1.1-Zephyr-7B-GPTQ-V2-AWQ-dataset-llm-base-1.1.0": [
    "model.safetensors"
  ],
  "MaziyarPanahi/Starling-LM-11B-alpha-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/sqlcoder-7b-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "dev137/Weyaxi_Bagel-Hermes-2x34b-exl2-2.0bpw-h8": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "superlazycoder/chesspythia-70m-random_1M": [
    "model.safetensors"
  ],
  "llmixer/BigLiz-120b-3.0bpw-h8-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "MaziyarPanahi/shisa-base-7b-v1-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "cosimoiaia/Loquace-tiny-1.1B": [
    "model.safetensors"
  ],
  "h2m/mhm-8x7B-FrankenMoE-v1.0": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "Maaz911/llama-2-7b-custom": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/loyal-piano-m7-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/LMCocktail-Mistral-7B-v1-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/Seraph-7B-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "hamxea/Mistral-7B-v0.1-activity-fine-tuned-v6": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "zaq-hack/Noromaid-v0.4-Mixtral-Instruct-8x7b-Zloss-bpw300-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "llmixer/BigAurelian-v0.5-120b-32k-3.0bpw-h8-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "MaziyarPanahi/Mistral-7B-Merge-14-v0.1-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "zaq-hack/Noromaid-13B-0.4-DPO-bpw400-h6-exl2": [
    "output.safetensors"
  ],
  "hamxea/Mistral-7B-v0.1-activity-fine-tuned-v5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/SauerkrautLM-7b-HerO-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jjszpak/SCAN-exp1b-64proc-v0": [
    "model.safetensors"
  ],
  "parasora/0.13b-non-ja-20k": [
    "model.safetensors"
  ],
  "parasora/0.13b-prog-ja-20k": [
    "model.safetensors"
  ],
  "MaziyarPanahi/shark_tank_ai_7_b-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "qnguyen3/Mixtral-4x400M": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/openchat_3.5-16k-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/Noromaid-7b-v0.1.1-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Jellyfish042/QLing-1.8B-Chat-V0": [
    "model.safetensors"
  ],
  "MaziyarPanahi/supermario-slerp-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "elliotthwangmsa/Elliott-ph-2_zh": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/Karen_TheEditor_V2_STRICT_Mistral_7B-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "hivenet-helbouan/llama-7b-onnx2torch": [
    "model.safetensors"
  ],
  "MaziyarPanahi/mistral-7b-v5-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "KnutJaegersberg/Deita-1_8B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "maxmyn/tinystories-simple-thank-you-greentexts-2Layer-33M": [
    "model.safetensors"
  ],
  "krishnasiva/llama2fine_krishsiva": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "elliotthwangmsa/kimLantext_phi-2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/NSFW_DPO_Noromaid-7b-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jjszpak/SCAN-exp1b-64proc-v1": [
    "model.safetensors"
  ],
  "Vivacem/Mistral-7B-MMIQC": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "andrewatef/MyBloggerV0.12": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "MaziyarPanahi/smol-7b-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "weiweiz1/llama-2-7b-hf_autoround_GPTQ": [
    "model.safetensors"
  ],
  "MaziyarPanahi/ANIMA-Nectar-v2-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "svasilevski/distilgpt2-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "JackCloudman/MoMo-70B-lora-1.8.6-DPO-exl2-4.0bpw": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "MaziyarPanahi/OpenZephyrChat-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jjszpak/SCAN-exp1b-64proc-v2": [
    "model.safetensors"
  ],
  "MaziyarPanahi/MistralInstructLongish-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/mistral-7b-dpo-v6-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "RiverTest/RiverMTG10": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "psroy/llama-2-7b-platypus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "danielhanchen/merged_model4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors",
    "model.safetensors"
  ],
  "emozilla/tl-3t": [
    "model.safetensors"
  ],
  "avemio-digital/leo_mistral_chat_merge": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "yihang7/Mistral-7B-Instruct-v0.1-dpo-full-1-epoch-hydrox-safe": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mu0gum/AIFT-42dot_LLM-PLM-1.3B-ao-instruct-all-v0.4": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "wang7776/Mistral-7B-Instruct-v0.2-sparsity-30-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/NeuralBeagle14-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/NeuralBeagle14-7B-GPTQ": [
    "model.safetensors"
  ],
  "Kamyar-zeinalipour/llama7b-protgen": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors",
    "model.safetensors"
  ],
  "JackCloudman/MoMo-70B-lora-1.8.6-DPO-exl2-3.5bpw": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "wang7776/Mistral-7B-Instruct-v0.2-sparsity-20-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Dr_Samantha-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Dr_Samantha-7B-GPTQ": [
    "model.safetensors"
  ],
  "imdatta0/qwen_14b_llamafied": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "TheBloke/stable-code-3b-GPTQ": [
    "model.safetensors"
  ],
  "jtatman/tinymistral-248m-hypnosis-instruct": [
    "model.safetensors"
  ],
  "Weni/WeniGPT-2.0.1-Zephyr-7B-GPTQ-LLM-Base-1.1.0-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "openaccess-ai-collective/zephyr-honey": [
    "adapters/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Chandller/phi2_orca": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors",
    "model.safetensors"
  ],
  "jlsilva/facebook-opt-125m-gptq4bit": [
    "model.safetensors"
  ],
  "zaq-hack/Noromaid-13B-0.4-DPO-bpw300-h6-exl2": [
    "output.safetensors"
  ],
  "huggingfacemodeltester/NeuralHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "UdayG01/llama-2-7b-ds-interview": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lordspline/ninja-search-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "JackCloudman/MoMo-70B-lora-1.8.6-DPO-exl2-3.4bpw": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "chuducandev/Llama-2-7b-hf-c2t-2-003": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "chuducandev/Llama-2-7b-hf-c2t-2-004": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "oivlisnet/Llama-2-13b-chat-fuq": [
    "checkpoint-129/adapter_model.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "chuducandev/Llama-2-7b-hf-c2t-2-004-error": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "chuducandev/Llama-2-7b-hf-c2t-2-005": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Lelantos-Maid-DPO-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Lelantos-Maid-DPO-7B-AWQ": [
    "model.safetensors"
  ],
  "TeeZee/Kyllene-34B-v1.1": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "jarod0411/gpt2_SMILES_bpe_combined_step1_3": [
    "model.safetensors"
  ],
  "valine/OpenDracula": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jtatman/alpacaCoT-tinymistral-v2": [
    "model.safetensors"
  ],
  "hojzas/llama2-proj8-2": [
    "adapter_model.safetensors",
    "checkpoint-6/adapter_model.safetensors"
  ],
  "ondevicellm/tinyllama_moe_sft_ultrachat200k_v2_epochs3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MerlynMind/Merlyn-Appropriateness_Classification_Attributes_4k_Input_Tokens-Mistral-7B-v0.1_CodedNoSpace": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "RJuro/munin-neuralbeagle-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jeiku/Trouble_3B": [
    "model.safetensors"
  ],
  "mrswer/Linda_2312": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "TheBloke/NexoNimbus-7B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/NexoNimbus-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/DareVox-7B-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/DareVox-7B-GPTQ": [
    "model.safetensors"
  ],
  "VishaalY/WizPhindCoder-39B": [
    "model-00001-of-00044.safetensors",
    "model-00002-of-00044.safetensors",
    "model-00003-of-00044.safetensors",
    "model-00004-of-00044.safetensors",
    "model-00005-of-00044.safetensors",
    "model-00006-of-00044.safetensors",
    "model-00007-of-00044.safetensors",
    "model-00008-of-00044.safetensors",
    "model-00009-of-00044.safetensors",
    "model-00010-of-00044.safetensors",
    "model-00011-of-00044.safetensors",
    "model-00012-of-00044.safetensors",
    "model-00013-of-00044.safetensors",
    "model-00014-of-00044.safetensors",
    "model-00015-of-00044.safetensors",
    "model-00016-of-00044.safetensors",
    "model-00017-of-00044.safetensors",
    "model-00018-of-00044.safetensors",
    "model-00019-of-00044.safetensors",
    "model-00020-of-00044.safetensors",
    "model-00021-of-00044.safetensors",
    "model-00022-of-00044.safetensors",
    "model-00023-of-00044.safetensors",
    "model-00024-of-00044.safetensors",
    "model-00025-of-00044.safetensors",
    "model-00026-of-00044.safetensors",
    "model-00027-of-00044.safetensors",
    "model-00028-of-00044.safetensors",
    "model-00029-of-00044.safetensors",
    "model-00030-of-00044.safetensors",
    "model-00031-of-00044.safetensors",
    "model-00032-of-00044.safetensors",
    "model-00033-of-00044.safetensors",
    "model-00034-of-00044.safetensors",
    "model-00035-of-00044.safetensors",
    "model-00036-of-00044.safetensors",
    "model-00037-of-00044.safetensors",
    "model-00038-of-00044.safetensors",
    "model-00039-of-00044.safetensors",
    "model-00040-of-00044.safetensors",
    "model-00041-of-00044.safetensors",
    "model-00042-of-00044.safetensors",
    "model-00043-of-00044.safetensors",
    "model-00044-of-00044.safetensors"
  ],
  "Sophiamsandoval/llama-2-7b-miniplatypus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kasper52786/phi-2-mental_health": [
    "model.safetensors"
  ],
  "mrzeiss/Rafale-Pa0-Mis7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/Garrulus-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Garrulus-AWQ": [
    "model.safetensors"
  ],
  "halbihn/NeuralPipe-7B-ties": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "lordspline/ninja-search-v1-bnb-4bit": [
    "model.safetensors"
  ],
  "JConnor/mistralai-Code-Instruct-Finetune-test": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lordspline/ninja-search-v1-bnb-8bit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Phanh2532/GAML_Mistral7B": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "halbihn/NeuralPipe-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "CallComply/TinyLlama-1.1B-Chat-v1.0-32k": [
    "model.safetensors"
  ],
  "liminerity/Blured-Ties-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TuringsSolutions/PFAFphi-750": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "NickyNicky/LocutusqueXFelladrin-TinyMistral248M-Instruct_oasst2_chatML_V1": [
    "model.safetensors"
  ],
  "JConnor/mistralai-Code-Instruct-Finetune-CATL-test1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "NickyNicky/LocutusqueXFelladrin-TinyMistral248M-Instruct_oasst2_chatML_V2": [
    "model.safetensors"
  ],
  "oivlisnet/Llama-2-13b-chat-fuq-gptq": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jeiku/Base_7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "NickyNicky/LocutusqueXFelladrin-TinyMistral248M-Instruct_oasst2_chatML_V3": [
    "model.safetensors"
  ],
  "MaziyarPanahi/MoMo-70B-lora-1.8.6-DPO-GPTQ": [
    "model.safetensors"
  ],
  "chargoddard/internlm2-7b-llama": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "NickyNicky/LocutusqueXFelladrin-TinyMistral248M-Instruct_oasst2_chatML_V4": [
    "model.safetensors"
  ],
  "liminerity/Blur-7b-v1.2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "aypan17/zephyr-7b-beta_cyber-unlearned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "leveldevai/TurdusDareBeagle-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "nghiadt22/universalNER_tinyLLama": [
    "model.safetensors"
  ],
  "SNGSupergirl/DialoGPT-medium-RS1SARA1.7": [
    "model.safetensors"
  ],
  "Kquant03/Prokaryote-8x7B-bf16": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "Cartinoe5930/SOLAR-10.7B-iDUS": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "TuringsSolutions/PFAFPhiSpartacus": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ewqr2130/alignment-handbook-zephyr-7b_ppostep_100": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Wanfq/fusechat_v1_nous_hermes_mixtral_teacher_woref_ckpt": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "qiyinmiss/autotrain-k45wn-2o8h4": [
    "adapter_model.safetensors",
    "checkpoint-17/adapter_model.safetensors"
  ],
  "Wanfq/fusechat_v1_nous_hermes_mixtral_teacher_ckpt": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SNGSupergirl/DialoGPT-large-RS1SARA1.0": [
    "model.safetensors"
  ],
  "NickyNicky/LocutusqueXFelladrin-TinyMistral248M-Instruct_oasst2_chatML_V1_DPO_V1": [
    "model.safetensors"
  ],
  "WYNN747/Burmese-GPT-main-v7-1k-no-ovr": [
    "model.safetensors"
  ],
  "MaziyarPanahi/MoMo-70B-lora-1.8.4-DPO-GPTQ": [
    "model.safetensors"
  ],
  "TinyPixel/gpt2-exp": [
    "model.safetensors"
  ],
  "NickyNicky/LocutusqueXFelladrin-TinyMistral248M-Instruct_oasst2_chatML_V1_DPO_V2": [
    "model.safetensors"
  ],
  "liminerity/Blur-7b-v1.21": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "NickyNicky/Mixtral-TinyMistral-8x248M-Instruct_oasst2_chatML_Intel_orca_dpo_pairs_DPO_V1": [
    "model-00001-of-00001.safetensors"
  ],
  "alnrg2arg/blockchainlabs_7B_merged_test2_4_prune": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "chargoddard/internlm2-20b-llama": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "liminerity/Blur-7b-v1.22": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "yihang7/dolly-v2-7b-dpo-full-3-epoch-hydrox-safe": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "cocoirun/Yi-Ko-6B-instruct-v1.6": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "WYNN747/Burmese-GPT-qa_sys7_main_no_ovr": [
    "model.safetensors"
  ],
  "huangyt/bloom-7b1-ccp2-r16-query_key_value": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SNGSupergirl/DialoGPT-medium-RS1SARA1.8": [
    "model.safetensors"
  ],
  "jtatman/tinymistral-248m-v2-dpo": [
    "model.safetensors"
  ],
  "ArunSamespace/mistral-7b-instruct-v0.2-fc-bnb-ep1-samples-25k-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5": [
    "model.safetensors"
  ],
  "bachngo/5tunwau": [
    "adapter_model.safetensors",
    "checkpoint-1/adapter_model.safetensors"
  ],
  "yuntaeyang/KoSOLAR-10.7B-dpo-v1.0": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "chargoddard/internlm2-base-7b-llama": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/neural-chat-7b-v3-3-Slerp-GPTQ": [
    "model.safetensors"
  ],
  "MaziyarPanahi/neural-chat-7b-v3-3-GPTQ": [
    "model.safetensors"
  ],
  "chargoddard/internlm2-base-20b-llama": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "RiverTest/RiverMTG13": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "cloudyu/Pluto_24B_DPO_200": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "Charlie911/MultiLora-temporal-sharegpt": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "cocoirun/Yi-Ko-6B-instruct-v1.7": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "circulus/TinyLlama-1.1B-Chat-v1.0-awq": [
    "model.safetensors"
  ],
  "adjohn1313/explainable_llama_30k": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "parasora/0.13b-mc4ja-20k": [
    "model.safetensors"
  ],
  "adjohn1313/guanaco_blackbox_30k": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "adjohn1313/guanaco_explainable_30k": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "rukaiyaaaah/rv-chatbot": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Deepakkori45/Aspect": [
    "adapter_model.safetensors"
  ],
  "Narrati/initial-conversation-summarizer": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "fierysurf/Ambari-7B-base-v0.1-sharded": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "fierysurf/Ambari-7B-Instruct-v0.1-sharded": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "huangyt/falcon-7b-Open-Platypus_2.5w-r16-query_key_value": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "huangyt/falcon-7b-ccp2-r16-query_key_value": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "bilaltahir098/Test": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "fierysurf/Kan-LLaMA-7B-base": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "hojzas/tiny-llama-proj8": [
    "adapter_model.safetensors",
    "checkpoint-6/adapter_model.safetensors",
    "model.safetensors"
  ],
  "jarod0411/gpt2_SMILES_bpe_combined_step2_3": [
    "model.safetensors"
  ],
  "fierysurf/Kan-LLaMA-7B-SFT-v0.1-sharded": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jtatman/felladrin-tinymistral-248m-v4-dpo": [
    "model.safetensors"
  ],
  "nopperl/Mistral-7B-Instruct-v0.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "cocoirun/Yi-Ko-6B-instruct-v2.0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "yanolja/KoSOLAR-10.7B-v0.2": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "MaziyarPanahi/Turdus-GPTQ": [
    "model.safetensors"
  ],
  "yanolja/Bookworm-10.7B-v0.4-DPO": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "shrenikb/alpaca16": [
    "model.safetensors"
  ],
  "shrenikb/alpaca24": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "shrenikb/alpaca32": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "abideen/Distilabeled-IPO-Phi-2.7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "OrionStarAI/Orion-14B-Base-Int4": [
    "model.safetensors"
  ],
  "OrionStarAI/Orion-14B-Chat-Int4": [
    "model.safetensors"
  ],
  "adamo1139/Yi-34B-200K-AEZAKMI-RAW-1701": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "Shreyas0706/llama-2-7b-miniplatypus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lenbrocki/Serena13bv2_DPO_fresh-lion-4": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "hojzas/gpt2-proj8": [
    "adapter_model.safetensors",
    "checkpoint-9/adapter_model.safetensors",
    "model.safetensors"
  ],
  "FinancialSupport/saiga-7b-dante-qlora": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ashk72/v4_restro": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Cartinoe5930/TIES-Merging": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "hlhdatscience/aguila-7b-Qlora-instruct": [
    "adapter_model.safetensors"
  ],
  "hotamago/HotaMath-OpenMath-2023-01-18-ElementaryMathematics": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "vishanoberoi/Llama-2-7b-chat-hf-fine-tuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/UNA-34Beagles-32K-bf16-v1-GPTQ": [
    "model.safetensors"
  ],
  "Mik99/phi-2_test_07_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "aserrasastre/Mistral-7B-Instruct-v1": [
    "adapter_model.safetensors",
    "checkpoint-9/adapter_model.safetensors"
  ],
  "kamushekp/deepseek-coder-1.3b-instruct-GPTQ": [
    "model.safetensors"
  ],
  "Mik99/phi-2_test_07_merged_v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mtc/LeoLM-leo-mistral-hessianai-7b-mixtral-explanation-3-epochs-finetuned-no-quantization": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kmfoda/sn9-v1": [
    "model.safetensors"
  ],
  "baohao/Llama-2-13b-hf-2bit-64rank-0.1dropout": [
    "loftq_init/adapter_model.safetensors"
  ],
  "aserrasastre/Mistral-7B-Instruct-v2": [
    "adapter_model.safetensors",
    "checkpoint-3/adapter_model.safetensors"
  ],
  "kamushekp/deepseek-coder-33B-instruct-GPTQ": [
    "model.safetensors"
  ],
  "AlinaTUM/Step2_model": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "baohao/Llama-2-13b-hf-4bit-64rank-0.1dropout": [
    "loftq_init/adapter_model.safetensors"
  ],
  "aserrasastre/Mistral-7B-Instruct-v3": [
    "adapter_model.safetensors",
    "checkpoint-10/adapter_model.safetensors"
  ],
  "aserrasastre/Mistral-7B-Instruct-v4": [
    "adapter_model.safetensors",
    "checkpoint-20/adapter_model.safetensors"
  ],
  "baohao/Llama-2-13b-hf-3bit-64rank-0.1dropout": [
    "loftq_init/adapter_model.safetensors"
  ],
  "mohammedaly2222002/CodeGen-GPT": [
    "model.safetensors"
  ],
  "jjszpak/SCAN-exp1b-1proc-new-v0": [
    "model.safetensors"
  ],
  "Asude/gpt2-256t-human_reward-pos-20": [
    "model.safetensors"
  ],
  "aserrasastre/Mistral-7B-Instruct-v5": [
    "adapter_model.safetensors",
    "checkpoint-20/adapter_model.safetensors"
  ],
  "upadhyay/texttosql22": [
    "model.safetensors"
  ],
  "jjszpak/SCAN-exp1b-1proc-new-v1": [
    "model.safetensors"
  ],
  "aserrasastre/Mistral-7B-Instruct-v6": [
    "checkpoint-6/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "wasertech/assistant-dolphin-2.2.1-mistral-7b-e1-awq": [
    "model.safetensors"
  ],
  "AlinaTUM/Step1_model": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "aserrasastre/Mistral-7B-Instruct-v7": [
    "checkpoint-40/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "obrmmk/tinycodellama-jp-0.6b-30k-v2-instruct-JCSN-15k": [
    "model.safetensors"
  ],
  "Asude/gpt2-256t-human_reward-pos-25": [
    "model.safetensors"
  ],
  "jjszpak/SCAN-exp1b-1proc-new-v2": [
    "model.safetensors"
  ],
  "AshanGimhana/LLAMA_7B_German_Author": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "aserrasastre/Mistral-7B-v1": [
    "checkpoint-12/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lenbrocki/Serena13bv2_DPO_glad-sweep-1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Ruhaan04/QuestionGenerator": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lenbrocki/Serena13bv2_DPO_efficient-sweep-2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ondevicellm/tinyllama_moe_sft_ultrachat200k_v2_epochs5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_member_shadow0": [
    "model.safetensors"
  ],
  "obrmmk/tinycodellama-jp-0.6b-30k-v2-instruct-CSN-44k": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_member_shadow1": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_member_shadow2": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_member_shadow3": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_member_shadow4": [
    "model.safetensors"
  ],
  "lenbrocki/Serena13bv2_DPO_clean-sweep-3": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_member_shadow5": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_member_shadow6": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_member_shadow7": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_member_shadow8": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_member_shadow9": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_member_shadow10": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_member_shadow11": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_member_shadow12": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_member_shadow13": [
    "model.safetensors"
  ],
  "Yarofa/model_R3090_v5": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_member_shadow14": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_member_shadow15": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_member_shadow16": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_member_shadow17": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_member_shadow18": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_member_shadow19": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_member_shadow20": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_member_shadow21": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_member_shadow22": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_member_shadow23": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_member_shadow24": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_member_shadow25": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_member_shadow26": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_member_shadow27": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_member_shadow28": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_member_shadow29": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_member_shadow30": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_member_shadow31": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_member_shadow32": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_member_shadow33": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_member_shadow34": [
    "model.safetensors"
  ],
  "cnmoro/LiteMOE-4x460m": [
    "model-00001-of-00001.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_member_shadow35": [
    "model.safetensors"
  ],
  "lenbrocki/Serena13bv2_DPO_expert-sweep-4": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_member_shadow36": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_member_shadow37": [
    "model.safetensors"
  ],
  "Shakib75/finetuned-Llama2-7b-hf-ahs": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "cnmoro/LiteMOE-3x460m": [
    "model-00001-of-00001.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_member_shadow38": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_member_shadow39": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_member_shadow40": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_member_shadow41": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_non_member_shadow0": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_non_member_shadow1": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_non_member_shadow2": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_non_member_shadow3": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_non_member_shadow4": [
    "model.safetensors"
  ],
  "cnmoro/Felladrin-4x68m-moe": [
    "model-00001-of-00001.safetensors"
  ],
  "REELICIT/Mistral-7B-Instruct-v0.2-ReqBrain": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_non_member_shadow5": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_non_member_shadow6": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_non_member_shadow7": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_non_member_shadow8": [
    "model.safetensors"
  ],
  "Mik99/zephyr-3b_test_01_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_non_member_shadow9": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_non_member_shadow10": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_non_member_shadow11": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_non_member_shadow12": [
    "model.safetensors"
  ],
  "elliotthwang/Elliott-ph-2_zh": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_non_member_shadow13": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_non_member_shadow14": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_non_member_shadow15": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_non_member_shadow16": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_non_member_shadow17": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_non_member_shadow18": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t300_e5_non_member_shadow19": [
    "model.safetensors"
  ],
  "lenbrocki/Serena13bv2_DPO_electric-sweep-5": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "mu0gum/AIFT-42dot_LLM-PLM-1.3B-ao-instruct-all-v0.5": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "elliotthwang/KimLam_phi-2-zh.v1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "valine/MoreHuman": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lenbrocki/Serena13bv2_DPO_distinctive-sweep-6": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Enginable/phi2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "IHaBiS/TurdusDareBeagle-7B-exl2": [
    "output.safetensors"
  ],
  "lenbrocki/Serena13bv2_DPO_treasured-sweep-7": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/internlm2-7b-llama-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "stabilityai/stablelm-2-1_6b": [
    "model.safetensors"
  ],
  "lenbrocki/Serena13bv2_DPO_trim-sweep-8": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "aserrasastre/Mistral-7B-Instruct-v8": [
    "checkpoint-24/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/internlm2-7b-llama-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "vicgalle/solarized-18B-dpo": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "LoneStriker/internlm2-7b-llama-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/internlm2-7b-llama-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/internlm2-7b-llama-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "RiverTest/RiverMTG15": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "lenbrocki/Serena13bv2_DPO_breezy-sweep-9": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/internlm2-base-20b-llama-3.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/internlm2-base-20b-llama-4.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "bartowski/internlm2-chat-7b-llama": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "baohao/Llama-2-7b-hf-2bit-64rank-0.1dropout": [
    "loftq_init/adapter_model.safetensors"
  ],
  "LoneStriker/internlm2-base-20b-llama-5.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "leveldevai/TurdusBeagle-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "bartowski/internlm2-chat-20b-llama": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "tenyx/TenyxChat-8x7B-v1": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "LoneStriker/internlm2-base-20b-llama-6.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "lgraz/mixtral-offloading": [
    "model-00001-of-00257.safetensors",
    "model-00002-of-00257.safetensors",
    "model-00003-of-00257.safetensors",
    "model-00004-of-00257.safetensors",
    "model-00005-of-00257.safetensors",
    "model-00006-of-00257.safetensors",
    "model-00007-of-00257.safetensors",
    "model-00008-of-00257.safetensors",
    "model-00009-of-00257.safetensors",
    "model-00010-of-00257.safetensors",
    "model-00011-of-00257.safetensors",
    "model-00012-of-00257.safetensors",
    "model-00013-of-00257.safetensors",
    "model-00014-of-00257.safetensors",
    "model-00015-of-00257.safetensors",
    "model-00016-of-00257.safetensors",
    "model-00017-of-00257.safetensors",
    "model-00018-of-00257.safetensors",
    "model-00019-of-00257.safetensors",
    "model-00020-of-00257.safetensors",
    "model-00021-of-00257.safetensors",
    "model-00022-of-00257.safetensors",
    "model-00023-of-00257.safetensors",
    "model-00024-of-00257.safetensors",
    "model-00025-of-00257.safetensors",
    "model-00026-of-00257.safetensors",
    "model-00027-of-00257.safetensors",
    "model-00028-of-00257.safetensors",
    "model-00029-of-00257.safetensors",
    "model-00030-of-00257.safetensors",
    "model-00031-of-00257.safetensors",
    "model-00032-of-00257.safetensors",
    "model-00033-of-00257.safetensors",
    "model-00034-of-00257.safetensors",
    "model-00035-of-00257.safetensors",
    "model-00036-of-00257.safetensors",
    "model-00037-of-00257.safetensors",
    "model-00038-of-00257.safetensors",
    "model-00039-of-00257.safetensors",
    "model-00040-of-00257.safetensors",
    "model-00041-of-00257.safetensors",
    "model-00042-of-00257.safetensors",
    "model-00043-of-00257.safetensors",
    "model-00044-of-00257.safetensors",
    "model-00045-of-00257.safetensors",
    "model-00046-of-00257.safetensors",
    "model-00047-of-00257.safetensors",
    "model-00048-of-00257.safetensors",
    "model-00049-of-00257.safetensors",
    "model-00050-of-00257.safetensors",
    "model-00051-of-00257.safetensors",
    "model-00052-of-00257.safetensors",
    "model-00053-of-00257.safetensors",
    "model-00054-of-00257.safetensors",
    "model-00055-of-00257.safetensors",
    "model-00056-of-00257.safetensors",
    "model-00057-of-00257.safetensors",
    "model-00058-of-00257.safetensors",
    "model-00059-of-00257.safetensors",
    "model-00060-of-00257.safetensors",
    "model-00061-of-00257.safetensors",
    "model-00062-of-00257.safetensors",
    "model-00063-of-00257.safetensors",
    "model-00064-of-00257.safetensors",
    "model-00065-of-00257.safetensors",
    "model-00066-of-00257.safetensors",
    "model-00067-of-00257.safetensors",
    "model-00068-of-00257.safetensors",
    "model-00069-of-00257.safetensors",
    "model-00070-of-00257.safetensors",
    "model-00071-of-00257.safetensors",
    "model-00072-of-00257.safetensors",
    "model-00073-of-00257.safetensors",
    "model-00074-of-00257.safetensors",
    "model-00075-of-00257.safetensors",
    "model-00076-of-00257.safetensors",
    "model-00077-of-00257.safetensors",
    "model-00078-of-00257.safetensors",
    "model-00079-of-00257.safetensors",
    "model-00080-of-00257.safetensors",
    "model-00081-of-00257.safetensors",
    "model-00082-of-00257.safetensors",
    "model-00083-of-00257.safetensors",
    "model-00084-of-00257.safetensors",
    "model-00085-of-00257.safetensors",
    "model-00086-of-00257.safetensors",
    "model-00087-of-00257.safetensors",
    "model-00088-of-00257.safetensors",
    "model-00089-of-00257.safetensors",
    "model-00090-of-00257.safetensors",
    "model-00091-of-00257.safetensors",
    "model-00092-of-00257.safetensors",
    "model-00093-of-00257.safetensors",
    "model-00094-of-00257.safetensors",
    "model-00095-of-00257.safetensors",
    "model-00096-of-00257.safetensors",
    "model-00097-of-00257.safetensors",
    "model-00098-of-00257.safetensors",
    "model-00099-of-00257.safetensors",
    "model-00100-of-00257.safetensors",
    "model-00101-of-00257.safetensors",
    "model-00102-of-00257.safetensors",
    "model-00103-of-00257.safetensors",
    "model-00104-of-00257.safetensors",
    "model-00105-of-00257.safetensors",
    "model-00106-of-00257.safetensors",
    "model-00107-of-00257.safetensors",
    "model-00108-of-00257.safetensors",
    "model-00109-of-00257.safetensors",
    "model-00110-of-00257.safetensors",
    "model-00111-of-00257.safetensors",
    "model-00112-of-00257.safetensors",
    "model-00113-of-00257.safetensors",
    "model-00114-of-00257.safetensors",
    "model-00115-of-00257.safetensors",
    "model-00116-of-00257.safetensors",
    "model-00117-of-00257.safetensors",
    "model-00118-of-00257.safetensors",
    "model-00119-of-00257.safetensors",
    "model-00120-of-00257.safetensors",
    "model-00121-of-00257.safetensors",
    "model-00122-of-00257.safetensors",
    "model-00123-of-00257.safetensors",
    "model-00124-of-00257.safetensors",
    "model-00125-of-00257.safetensors",
    "model-00126-of-00257.safetensors",
    "model-00127-of-00257.safetensors",
    "model-00128-of-00257.safetensors",
    "model-00129-of-00257.safetensors",
    "model-00130-of-00257.safetensors",
    "model-00131-of-00257.safetensors",
    "model-00132-of-00257.safetensors",
    "model-00133-of-00257.safetensors",
    "model-00134-of-00257.safetensors",
    "model-00135-of-00257.safetensors",
    "model-00136-of-00257.safetensors",
    "model-00137-of-00257.safetensors",
    "model-00138-of-00257.safetensors",
    "model-00139-of-00257.safetensors",
    "model-00140-of-00257.safetensors",
    "model-00141-of-00257.safetensors",
    "model-00142-of-00257.safetensors",
    "model-00143-of-00257.safetensors",
    "model-00144-of-00257.safetensors",
    "model-00145-of-00257.safetensors",
    "model-00146-of-00257.safetensors",
    "model-00147-of-00257.safetensors",
    "model-00148-of-00257.safetensors",
    "model-00149-of-00257.safetensors",
    "model-00150-of-00257.safetensors",
    "model-00151-of-00257.safetensors",
    "model-00152-of-00257.safetensors",
    "model-00153-of-00257.safetensors",
    "model-00154-of-00257.safetensors",
    "model-00155-of-00257.safetensors",
    "model-00156-of-00257.safetensors",
    "model-00157-of-00257.safetensors",
    "model-00158-of-00257.safetensors",
    "model-00159-of-00257.safetensors",
    "model-00160-of-00257.safetensors",
    "model-00161-of-00257.safetensors",
    "model-00162-of-00257.safetensors",
    "model-00163-of-00257.safetensors",
    "model-00164-of-00257.safetensors",
    "model-00165-of-00257.safetensors",
    "model-00166-of-00257.safetensors",
    "model-00167-of-00257.safetensors",
    "model-00168-of-00257.safetensors",
    "model-00169-of-00257.safetensors",
    "model-00170-of-00257.safetensors",
    "model-00171-of-00257.safetensors",
    "model-00172-of-00257.safetensors",
    "model-00173-of-00257.safetensors",
    "model-00174-of-00257.safetensors",
    "model-00175-of-00257.safetensors",
    "model-00176-of-00257.safetensors",
    "model-00177-of-00257.safetensors",
    "model-00178-of-00257.safetensors",
    "model-00179-of-00257.safetensors",
    "model-00180-of-00257.safetensors",
    "model-00181-of-00257.safetensors",
    "model-00182-of-00257.safetensors",
    "model-00183-of-00257.safetensors",
    "model-00184-of-00257.safetensors",
    "model-00185-of-00257.safetensors",
    "model-00186-of-00257.safetensors",
    "model-00187-of-00257.safetensors",
    "model-00188-of-00257.safetensors",
    "model-00189-of-00257.safetensors",
    "model-00190-of-00257.safetensors",
    "model-00191-of-00257.safetensors",
    "model-00192-of-00257.safetensors",
    "model-00193-of-00257.safetensors",
    "model-00194-of-00257.safetensors",
    "model-00195-of-00257.safetensors",
    "model-00196-of-00257.safetensors",
    "model-00197-of-00257.safetensors",
    "model-00198-of-00257.safetensors",
    "model-00199-of-00257.safetensors",
    "model-00200-of-00257.safetensors",
    "model-00201-of-00257.safetensors",
    "model-00202-of-00257.safetensors",
    "model-00203-of-00257.safetensors",
    "model-00204-of-00257.safetensors",
    "model-00205-of-00257.safetensors",
    "model-00206-of-00257.safetensors",
    "model-00207-of-00257.safetensors",
    "model-00208-of-00257.safetensors",
    "model-00209-of-00257.safetensors",
    "model-00210-of-00257.safetensors",
    "model-00211-of-00257.safetensors",
    "model-00212-of-00257.safetensors",
    "model-00213-of-00257.safetensors",
    "model-00214-of-00257.safetensors",
    "model-00215-of-00257.safetensors",
    "model-00216-of-00257.safetensors",
    "model-00217-of-00257.safetensors",
    "model-00218-of-00257.safetensors",
    "model-00219-of-00257.safetensors",
    "model-00220-of-00257.safetensors",
    "model-00221-of-00257.safetensors",
    "model-00222-of-00257.safetensors",
    "model-00223-of-00257.safetensors",
    "model-00224-of-00257.safetensors",
    "model-00225-of-00257.safetensors",
    "model-00226-of-00257.safetensors",
    "model-00227-of-00257.safetensors",
    "model-00228-of-00257.safetensors",
    "model-00229-of-00257.safetensors",
    "model-00230-of-00257.safetensors",
    "model-00231-of-00257.safetensors",
    "model-00232-of-00257.safetensors",
    "model-00233-of-00257.safetensors",
    "model-00234-of-00257.safetensors",
    "model-00235-of-00257.safetensors",
    "model-00236-of-00257.safetensors",
    "model-00237-of-00257.safetensors",
    "model-00238-of-00257.safetensors",
    "model-00239-of-00257.safetensors",
    "model-00240-of-00257.safetensors",
    "model-00241-of-00257.safetensors",
    "model-00242-of-00257.safetensors",
    "model-00243-of-00257.safetensors",
    "model-00244-of-00257.safetensors",
    "model-00245-of-00257.safetensors",
    "model-00246-of-00257.safetensors",
    "model-00247-of-00257.safetensors",
    "model-00248-of-00257.safetensors",
    "model-00249-of-00257.safetensors",
    "model-00250-of-00257.safetensors",
    "model-00251-of-00257.safetensors",
    "model-00252-of-00257.safetensors",
    "model-00253-of-00257.safetensors",
    "model-00254-of-00257.safetensors",
    "model-00255-of-00257.safetensors",
    "model-00256-of-00257.safetensors",
    "model-00257-of-00257.safetensors"
  ],
  "baohao/Llama-2-7b-hf-3bit-64rank-0.1dropout": [
    "loftq_init/adapter_model.safetensors"
  ],
  "LoneStriker/internlm2-base-20b-llama-8.0bpw-h8-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "bartowski/internlm2-chat-7b-sft-llama": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "bartowski/internlm2-20b-llama": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "baohao/Llama-2-7b-hf-4bit-64rank-0.1dropout": [
    "loftq_init/adapter_model.safetensors"
  ],
  "helloAQ/rheabotv1.2": [
    "model.safetensors"
  ],
  "rbgo/Super-phi-2-dpo": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "aserrasastre/Mistral-7B-def": [
    "checkpoint-2853/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "bartowski/internlm2-7b-llama": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "nlpguy/Hermes-low-tune-3.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "allennghayoui/code-assistant-v02-mistral": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/internlm2-20b-llama-3.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/internlm2-20b-llama-4.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "insurance-agent/llama-2-7b-agent-20230118-datav2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/internlm2-20b-llama-5.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "zaq-hack/Noromaid-v0.4-Mixtral-Instruct-8x7b-Zloss-bpw240-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "zaq-hack/DaringLotus-v2-10.7b-bpw500-h6-exl2": [
    "output.safetensors"
  ],
  "AshanGimhana/LLAMA_7B_German_AuthorV2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/internlm2-20b-llama-6.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "chanwit/flux-7b-v0.3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "avemio-digital/SauerkrautLM_chat_merge": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/internlm2-20b-llama-8.0bpw-h8-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "linvest21/OpenHermes-2.5-Mistral-7B-gurobi-dpo-v0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "vince62s/phi-2-psy": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "intervitens/internlm2-base-20b-llama": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "NeuralNovel/Tiger-7B-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ashishkgpian/full_v3_astromistral_final": [
    "adapter_model.safetensors"
  ],
  "TeeZee/Kyllene-57B-v1.0-bpw3.0-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "sonthenguyen/NeuralHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ValiantLabs/Fireplace-13b": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "ashishkgpian/full_v4_astromistral_final": [
    "model.safetensors"
  ],
  "Epiculous/Fett-uccine-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TeeZee/Buttocks-7B-v1.0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Soupy816/llama-2-7b-miniguanaco": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "robertgshaw2/llama-2-7b-chat-marlin": [
    "model.safetensors"
  ],
  "neovalle/H4rmoniousAnthea": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/DiscoLM_German_7b_v1-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/DiscoLM_German_7b_v1-GPTQ": [
    "model.safetensors"
  ],
  "erfanzar/MaticGPT": [
    "model.safetensors"
  ],
  "Isaak-Carter/JOSIE_TinyLlama_1.1B_32k_Base": [
    "model.safetensors"
  ],
  "efalcon/distilgpt2-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "keRRR/merged": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Korede09/julieth-falcon-7B": [
    "adapter_model.safetensors"
  ],
  "vikp/donut-decoder": [
    "model.safetensors"
  ],
  "sandeepsundaram/phi2-ultrachat-qlora": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "completelyboofyblitzed/Mistral-7B-Instruct-v0.2-tuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "xezpeleta/Mistral-7b-eu": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TeeZee/Buttocks-7B-v1.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoSboccacc/orthogonal-2x7B-v2-base": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sluo/distilgpt2-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "bartowski/internlm2-chat-20b-sft-llama": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "bartowski/internlm2-base-7b-llama": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "gagan3012/MegaArabic": [
    "model-00001-of-00002.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00002.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jeiku/RocketHermesZephyrBoros_3B": [
    "model-00001-of-00001.safetensors"
  ],
  "kreabs/NeuralDaredevil-7B_finetuned_dolly_1600": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheIndicium/DialoGPT-small-zul": [
    "model.safetensors"
  ],
  "FPHam/Sydney_Pirate_Mistral_7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ChetanSarda99/llama-2-7b-sql": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "zaq-hack/Noromaid-v0.4-Mixtral-Instruct-8x7b-Zloss-bpw225-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "sanmaro6803/llama-2-ko-7b-ds-qlora-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jarod0411/gpt2_SMILES_bpe_combined_step3_3": [
    "model.safetensors"
  ],
  "alessandroseni/Frontera-0-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jeiku/Gattaca_3B": [
    "model-00001-of-00001.safetensors"
  ],
  "obrmmk/tinycodellama-jp-0.6b-30k-v2-instruct-codealpaca-py-def2": [
    "model.safetensors"
  ],
  "obrmmk/tinycodellama-jp-0.6b-30k-v2-instruct-jcodealpaca-py": [
    "model.safetensors"
  ],
  "obrmmk/tinycodellama-jp-0.6b-30k-v2-instruct-codealpaca-py": [
    "model.safetensors"
  ],
  "robertgshaw2/llama-2-13b-chat-marlin": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Edentns/DataVortexS-10.7B-dpo-v1.0": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "cocoirun/AIFT-42dot-PLM-1.3B-ao-instruct-all-v0.4-ff-e1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "fionazhang/mistral-experiment-1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "09z/tinyllama-cleantech-finetune": [
    "model.safetensors"
  ],
  "nbeerbower/bruphin-alpha": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "netcat420/tinyMHENN3b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kaitchup/Mistral-7B-v0.1-gptq-2bit": [
    "model.safetensors"
  ],
  "nlee282/frankenslerp": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "WQchoi/QLoRA_test4": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "fionazhang/mistral-experiment-2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "gotchu/merge-34b-2": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "valine/OpenSnark": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "emozilla/tl-c1": [
    "model.safetensors"
  ],
  "elliotthwang/KimLam_phi-2-zh.v2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "kaitchup/Mistral-7B-v0.1-gptq-3bit": [
    "model.safetensors"
  ],
  "experial/llama-2-7b-SNIPS-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Locutusque/TinyMistral-248M-v2-Instruct": [
    "model.safetensors"
  ],
  "HanNayeoniee/LHK": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "dominic5/mixtral8x7b_based_dupl2": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "appvoid/palmer-002.5": [
    "model-00001-of-00001.safetensors"
  ],
  "kaitchup/Mistral-7B-v0.1-gptq-4bit": [
    "model.safetensors"
  ],
  "kesamet/neural-chat-7b-v3-1-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "TinyPixel/gpt2-40m": [
    "model.safetensors"
  ],
  "fionazhang/mistral-experiment-3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Chinese-Mixtral-8x7B-2.4bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "luciodery/test_Phi2_0.4_sparse_big": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ewqr2130/alignment-handbook-zephyr-7b_ppo_5e7step_51": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "kaitchup/Mistral-7B-v0.1-gptq-8bit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Chinese-Mixtral-8x7B-3.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "zaq-hack/SnowLotus-v2-10.7B-bpw500-h6-exl2": [
    "output.safetensors"
  ],
  "09z/tinyllama-cleantech-finetune-memo": [
    "model.safetensors"
  ],
  "fionazhang/mistral-experiment-4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Chinese-Mixtral-8x7B-3.5bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "obrmmk/tinycodellama-jp-0.6b-30k-v2-instruct-codealpaca": [
    "model.safetensors"
  ],
  "yjeong/jnm-llama": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "yjeong/jnm-galactica": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "NickyNicky/LocutusqueXFelladrin-TinyMistral248M-Instruct_oasst2_chatML_V1_DPO_V3": [
    "model.safetensors"
  ],
  "LoneStriker/Chinese-Mixtral-8x7B-3.75bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "ycros/BagelMIsteryTour-v2-8x7B": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "leveldevai/MarcBeagle-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Elizezen/AINovelist-6.8B-initialized": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5": [
    "model.safetensors"
  ],
  "LoneStriker/Chinese-Mixtral-8x7B-5.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "Yarofa/model_R3090_v7": [
    "model.safetensors"
  ],
  "bhavinjawade/nectororca-solar10b-jawade": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_member_shadow0": [
    "model.safetensors"
  ],
  "kaitchup/Llama-2-13b-hf-gptq-2bit": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_member_shadow1": [
    "model.safetensors"
  ],
  "ikno/rinko_v2_11_mix": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_member_shadow2": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_member_shadow3": [
    "model.safetensors"
  ],
  "ikno/rinko_v2_11_mix_check94": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ikno/rinko_v2_11_mix_check141": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_member_shadow5": [
    "model.safetensors"
  ],
  "fionazhang/mistral-finetune-environment": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ToPo-ToPo/cyberagent-open-calm-small-ToPo-ToPo-databricks-dolly-15k-ja-zundamon-full-instruction-tuning": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_member_shadow6": [
    "model.safetensors"
  ],
  "Vivacem/DeepSeek-67B-MMIQC": [
    "model-00001-of-00028.safetensors",
    "model-00002-of-00028.safetensors",
    "model-00003-of-00028.safetensors",
    "model-00004-of-00028.safetensors",
    "model-00005-of-00028.safetensors",
    "model-00006-of-00028.safetensors",
    "model-00007-of-00028.safetensors",
    "model-00008-of-00028.safetensors",
    "model-00009-of-00028.safetensors",
    "model-00010-of-00028.safetensors",
    "model-00011-of-00028.safetensors",
    "model-00012-of-00028.safetensors",
    "model-00013-of-00028.safetensors",
    "model-00014-of-00028.safetensors",
    "model-00015-of-00028.safetensors",
    "model-00016-of-00028.safetensors",
    "model-00017-of-00028.safetensors",
    "model-00018-of-00028.safetensors",
    "model-00019-of-00028.safetensors",
    "model-00020-of-00028.safetensors",
    "model-00021-of-00028.safetensors",
    "model-00022-of-00028.safetensors",
    "model-00023-of-00028.safetensors",
    "model-00024-of-00028.safetensors",
    "model-00025-of-00028.safetensors",
    "model-00026-of-00028.safetensors",
    "model-00027-of-00028.safetensors",
    "model-00028-of-00028.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_member_shadow7": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_member_shadow8": [
    "model.safetensors"
  ],
  "ToPo-ToPo/cyberagent-open-calm-small-kunishou-databricks-dolly-15k-ja-full-instruction-tuning": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_member_shadow9": [
    "model.safetensors"
  ],
  "leveldevai/MBA-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_member_shadow10": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_member_shadow11": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_member_shadow12": [
    "model.safetensors"
  ],
  "kaitchup/Llama-2-13b-hf-gptq-3bit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "leveldevai/MarcDareBeagle-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "yzhuang/TinyLlama-1.1B_fictional": [
    "model.safetensors"
  ],
  "rombodawg/deepseek-coder-moe_8x6.7b-base": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "AshishK/HindiModel": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "watashiha/Watashiha-Llama-2-13B-Ogiri-sft": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "refarde/OPEN-SOLAR-KO-10.7B-S-Core": [
    "checkpoint-2264/adapter_model.safetensors",
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Salexoid/mistral-7b-saiga-sum-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Maaz911/Phi2.7b-custom": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "KnutJaegersberg/Qwen-1_8B-Chat-llama": [
    "model.safetensors"
  ],
  "ansilmbabl/ft-opt-125m-customer-chatbot-2": [
    "model.safetensors"
  ],
  "abacusai/MM-Orc-Vic-bagel-34b-c1000": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "kaitchup/Llama-2-13b-hf-gptq-4bit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FelixChao/Voldemort-10B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "izayashiro/mistralai-HPC-Instruct-v0.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "chienweichang/Breeze-7B-Instruct-64k-v0_1-AWQ": [
    "model.safetensors"
  ],
  "chienweichang/Breeze-7B-Instruct-v0_1-AWQ": [
    "model.safetensors"
  ],
  "neggles/ssswitch-13b-v2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "kaitchup/Llama-2-13b-hf-gptq-8bit": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mymaia/Magiq-M0": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "DAMO-NLP-SG/CLEX-Mixtral-8x7B-32K": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "DAMO-NLP-SG/CLEX-Mixtral-8x7B-Chat-32K": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "DAMO-NLP-SG/CLEX-LLaMA-2-7B-64K": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kreabs/hermeo-7b_finetuned_dolly_1600": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "upadhyay/sql2": [
    "model.safetensors"
  ],
  "rinabuoy/seallmbase": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_member_shadow15": [
    "model.safetensors"
  ],
  "DAMO-NLP-SG/CLEX-Phi-2-32K": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_member_shadow16": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_member_shadow17": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_member_shadow18": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_member_shadow19": [
    "model.safetensors"
  ],
  "ayoubkirouane/Mistral-SLERP-Merged7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_member_shadow20": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_member_shadow21": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_member_shadow22": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_member_shadow23": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_member_shadow24": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_member_shadow25": [
    "model.safetensors"
  ],
  "Saumya-Mundra/prompt-enhance": [
    "model.safetensors"
  ],
  "yeniceriSGK/TinyLlama-FinetunedPI-v0": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_member_shadow26": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_member_shadow27": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_member_shadow28": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_member_shadow29": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_member_shadow30": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_member_shadow31": [
    "model.safetensors"
  ],
  "ravikumar101/mistral-7b-v5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_member_shadow32": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_member_shadow33": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_member_shadow34": [
    "model.safetensors"
  ],
  "lumatic-ai/bongstral_7b_instruct_alpha_v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Chinese-Mixtral-8x7B-6.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_member_shadow35": [
    "model.safetensors"
  ],
  "lenbrocki/Serena13bv2_DPO_soft-sweep-1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_member_shadow36": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_member_shadow37": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_member_shadow38": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_member_shadow39": [
    "model.safetensors"
  ],
  "KimByeongSu/my_awesome_eli5_clm-model": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_member_shadow40": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_non_member_shadow0": [
    "model.safetensors"
  ],
  "lenbrocki/Serena13bv2_DPO_comfy-sweep-2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_non_member_shadow1": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_non_member_shadow2": [
    "model.safetensors"
  ],
  "ansilmbabl/ft-opt-125m-customer-chatbot-3": [
    "model.safetensors"
  ],
  "ayoubkirouane/Mistral-TIES-Merged7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Orneyfish/llama-2-7b-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_non_member_shadow3": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_non_member_shadow4": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_non_member_shadow5": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_non_member_shadow6": [
    "model.safetensors"
  ],
  "dsbyprateekg/lora_mistral_alpaca_180steps": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_non_member_shadow7": [
    "model.safetensors"
  ],
  "pjkarmokar/sql-classification-llama-2-7b-test": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_non_member_shadow8": [
    "model.safetensors"
  ],
  "lenbrocki/Serena13bv2_DPO_absurd-sweep-3": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_non_member_shadow9": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_non_member_shadow10": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_non_member_shadow11": [
    "model.safetensors"
  ],
  "OEvortex/HelpingAI-Vision": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_non_member_shadow12": [
    "model.safetensors"
  ],
  "Ashok3337/llama-2-7b-qna-tuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_non_member_shadow13": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_non_member_shadow14": [
    "model.safetensors"
  ],
  "lenbrocki/Serena13bv2_DPO_rich-sweep-4": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_non_member_shadow15": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_non_member_shadow16": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_non_member_shadow17": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_non_member_shadow18": [
    "model.safetensors"
  ],
  "Wanfq/MetaMath-MathInstruct-Llemma-7B_distill_baseline_ckpt": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "povhal/bert-base-cased-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_non_member_shadow19": [
    "model.safetensors"
  ],
  "cocoirun/AIFT-ko-orca-plat-Yi-ko-6b-v1.0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "thekraftors/text-to-sql-v1.0": [
    "model.safetensors"
  ],
  "lenbrocki/Serena13bv2_DPO_grateful-sweep-5": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "lenbrocki/Serena13bv2_DPO_zesty-sweep-6": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_member_shadow4": [
    "model.safetensors"
  ],
  "obrmmk/tinycodellama-jp-0.6b-30k-v2-instruct2-JCSN-15k": [
    "model.safetensors"
  ],
  "psroy/llama-2-7b-platypus-scienceqa": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lenbrocki/Serena13bv2_DPO_vital-sweep-7": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "obrmmk/tinycodellama-jp-0.6b-30k-v2-instruct2-CSN": [
    "model.safetensors"
  ],
  "kreabs/Llama-2-7b-hf_finetuned_dolly_1600": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kaitchup/Llama-2-7b-hf-gptq-2bit": [
    "model.safetensors"
  ],
  "lenbrocki/Serena13bv2_DPO_summer-sweep-8": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "KursKumpel/llama-2-7b-fhdw": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_member_shadow13": [
    "model.safetensors"
  ],
  "lenbrocki/Serena13bv2_DPO_bumbling-sweep-9": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ncannings/NHC-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "asapse/DIOD-Mistral-0.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kaitchup/Llama-2-7b-hf-gptq-3bit": [
    "model.safetensors"
  ],
  "mlabonne/DareBeagle-7B-v2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "kaitchup/Llama-2-7b-hf-gptq-4bit": [
    "model.safetensors"
  ],
  "hwang2006/codeparrot-ds": [
    "model.safetensors"
  ],
  "SamagraDataGov/test_mistral10": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ncannings/NHC-7B-1-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Gokuldaskumar/mistral-8x7b-instruct": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "kaitchup/Llama-2-7b-hf-gptq-8bit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "thobuiq/teamtrack-ai": [
    "model.safetensors"
  ],
  "emozilla/tl-c6": [
    "model.safetensors"
  ],
  "santoshsawant/NeuralHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Snoopy04/llama-2-13b-thesis-5pr": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Enginable/phi-2-RIDDLES-20-epochs": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "kreabs/Mistral-7B-v0.1_finetuned_dolly_1600": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "stabilityai/stablelm-2-zephyr-1_6b": [
    "model.safetensors"
  ],
  "nlpguy/Hermes-low-tune-4": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheIndicium/DialoGPT-medium-zul": [
    "model.safetensors"
  ],
  "malhajar/Mistral-7B-v0.1-arabic": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/TenyxChat-8x7B-v1-2.4bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "AlexWortega/v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jenny1998/Peppa-Pig": [
    "model.safetensors"
  ],
  "LoneStriker/WinterGoddess-1.4x-70B-L2-8.0bpw-h8-exl2": [
    "output-00001-of-00009.safetensors",
    "output-00002-of-00009.safetensors",
    "output-00003-of-00009.safetensors",
    "output-00004-of-00009.safetensors",
    "output-00005-of-00009.safetensors",
    "output-00006-of-00009.safetensors",
    "output-00007-of-00009.safetensors",
    "output-00008-of-00009.safetensors",
    "output-00009-of-00009.safetensors"
  ],
  "cocoirun/AIFT-ko-orca-plat-Yi-ko-6b-v1.0-DPO": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hlhdatscience/FLOR-6-3-qlora-instruct": [
    "adapter_model.safetensors"
  ],
  "LoneStriker/TenyxChat-8x7B-v1-3.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/TenyxChat-8x7B-v1-3.5bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "mu0gum/AIFT-42dot_LLM-PLM-1.3B-ao-instruct-all-v0.52": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/TenyxChat-8x7B-v1-3.75bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/WinterGoddess-1.4x-70B-L2-2.4bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "DopeorNope/Mistralopithecus-v0.1-10.7B": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "wenqiglantz/MistralTrinity-7B-slerp-dpo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ConvexAI/Seraphim-8x10.7B-bf16": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "LoneStriker/WinterGoddess-1.4x-70B-L2-3.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "philschmid/CodeLlama-7b-hf": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/TenyxChat-8x7B-v1-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "leveldevai/BeagleMist-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "nbeerbower/bruphin-beta": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mattshumer/PentaPhi": [
    "model-00001-of-00002.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00002.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/WinterGoddess-1.4x-70B-L2-4.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "psroy/llama-2-7b-platypus-scienceqa-5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "djtar/llama-2-7b-platypus123": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "andrijdavid/macaroni-7b": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "chanwit/flux-7b-rag-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/WinterGoddess-1.4x-70B-L2-4.65bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "cocoirun/AIFT-Yi-Ko-6B-instruct-v0.4.15": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mattshumer/TalkPhi": [
    "model-00001-of-00002.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00002.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kiranr/internlm2-chat-20b-llama": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "mattshumer/ThinkPhi": [
    "model-00001-of-00002.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00002.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ConvexAI/BurningBruce-003": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "andrijdavid/tinyllama-dare": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ayoubkirouane/Phi-2.7B_MERGED": [
    "model-00001-of-00001.safetensors"
  ],
  "mattshumer/QuadPhi": [
    "model-00001-of-00002.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00002.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "cocoirun/AIFT-Yi-Ko-6B-instruct-v0.4.15-dpo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ewqr2130/phi_ppo_1e-5_REAL_1GPU_batch8step_2400": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ondevicellm/tinyllama_moe_dpo_ultrachat_v2_epochs5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "awilliamson/phrankened": [
    "model-00001-of-00002.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00002.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/openchat-3.5-0106-GPTQ": [
    "model.safetensors"
  ],
  "ewqr2130/alignment-handbook-zephyr-7b_ppo_5e7step_102": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Asude/gpt2-256t-human_reward-neg-10": [
    "model.safetensors"
  ],
  "vicgalle/franken-Beagle-11B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "castorini/rank_zephyr_7b_v1_full": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SanjiWatsuki/TinyBagel-248M": [
    "model.safetensors"
  ],
  "ewqr2130/alignment-handbook-zephyr-7b-sft-full-dpo-5e7-cont2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "sanduntg/mistral_instruct_generation": [
    "model.safetensors"
  ],
  "Asude/gpt2-256t-human_reward-neg-15": [
    "model.safetensors"
  ],
  "ambrosfitz/zephyr-history-chat-v1.0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lodrick-the-lafted/Grafted-Llama2-2x70B": [
    "model-00001-of-00026.safetensors",
    "model-00002-of-00026.safetensors",
    "model-00003-of-00026.safetensors",
    "model-00004-of-00026.safetensors",
    "model-00005-of-00026.safetensors",
    "model-00006-of-00026.safetensors",
    "model-00007-of-00026.safetensors",
    "model-00008-of-00026.safetensors",
    "model-00009-of-00026.safetensors",
    "model-00010-of-00026.safetensors",
    "model-00011-of-00026.safetensors",
    "model-00012-of-00026.safetensors",
    "model-00013-of-00026.safetensors",
    "model-00014-of-00026.safetensors",
    "model-00015-of-00026.safetensors",
    "model-00016-of-00026.safetensors",
    "model-00017-of-00026.safetensors",
    "model-00018-of-00026.safetensors",
    "model-00019-of-00026.safetensors",
    "model-00020-of-00026.safetensors",
    "model-00021-of-00026.safetensors",
    "model-00022-of-00026.safetensors",
    "model-00023-of-00026.safetensors",
    "model-00024-of-00026.safetensors",
    "model-00025-of-00026.safetensors",
    "model-00026-of-00026.safetensors"
  ],
  "Asude/gpt2-256t-human_reward-neg-20": [
    "model.safetensors"
  ],
  "Holmeister/llama2-TREMO-tr": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Holmeister/falcon-emotion-en": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Holmeister/falcon-chatgpt-en": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Asude/gpt2-256t-human_reward-neg-25": [
    "model.safetensors"
  ],
  "nbeerbower/bruphin-gamma": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Shakib75/Finetuned-llama2-7b-hf-ahs420": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "emozilla/oh25": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "zaid60/model": [
    "model.safetensors"
  ],
  "yihang7/Sheared-LLaMA-1.3B-dpo-full-3-epoch-hydrox-safe": [
    "model.safetensors"
  ],
  "Holmeister/mistral-chatgpt-en": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "PixelDust02/Pixel_stable-vicuna": [
    "model.safetensors"
  ],
  "MaziyarPanahi/Nous-Hermes-2-Mixtral-8x7B-DPO-GPTQ": [
    "model.safetensors"
  ],
  "metric-space/arceeai-cpt-sft-dpo-full": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "Holmeister/mistral-emotion-en": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "timuryun/autotrain-xr1bw-vrs40": [
    "adapter_model.safetensors",
    "checkpoint-42/adapter_model.safetensors"
  ],
  "corbt/example-mistral-lora": [
    "adapter_model.safetensors"
  ],
  "LoneStriker/TenyxChat-8x7B-v1-5.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "LoneStriker/TenyxChat-8x7B-v1-6.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "skehlet/NeuralHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "timuryun/autotrain-ughdn-x1a7j": [
    "adapter_model.safetensors",
    "checkpoint-45/adapter_model.safetensors"
  ],
  "LHC88/SauerkrautLM-Mixtral-8x7B-Instruct-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SF-Foundation/SF-72B-V1": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "andrijdavid/Macaroni-7b-Tied": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "LoneStriker/WinterGoddess-1.4x-70B-L2-5.0bpw-h6-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "yleo/NeuralHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jpoz/NeuralHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "RiverTest/RiverMTG21": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/WinterGoddess-1.4x-70B-L2-6.0bpw-h6-exl2": [
    "output-00001-of-00007.safetensors",
    "output-00002-of-00007.safetensors",
    "output-00003-of-00007.safetensors",
    "output-00004-of-00007.safetensors",
    "output-00005-of-00007.safetensors",
    "output-00006-of-00007.safetensors",
    "output-00007-of-00007.safetensors"
  ],
  "MaziyarPanahi/zephyr-7b-beta-GPTQ": [
    "model.safetensors"
  ],
  "MaziyarPanahi/Breeze-7B-Instruct-v0_1-GPTQ": [
    "model.safetensors"
  ],
  "LoneStriker/WinterGoddess-1.4x-70B-L2-2.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/WinterGoddess-1.4x-70B-L2-3.5bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "222limin/BrurryDog-7b-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "luqmanxyz/Maya_Hermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "RatanRohith/NeuralMathChat-7B-V0.2": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Jobiniah/bible-mistral-7b-merged": [
    "model.safetensors"
  ],
  "yunconglong/7Bx4_DPO": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "Kquant03/BurningBruce-SOLAR-8x10.7B-bf16": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "dkandpalz/animalGPT2": [
    "model.safetensors"
  ],
  "lmlab/megaphi-2-7b": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "yunconglong/7Bx4_DPO_2e": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "FounderOfHuggingface/gpt2_full_e2e_nlg_t3000_e5_member_shadow14": [
    "model.safetensors"
  ],
  "Andrewwwwww/Nous-Hermes-2-Mixtral-8x7B-DPO": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "appvoid/palmer-002-32k": [
    "model-00001-of-00001.safetensors"
  ],
  "wuxiangdan9978/project1": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "jeevana/GenerativeQnASystem": [
    "model.safetensors"
  ],
  "LoneStriker/zephyr-7b-sft-full-SPIN-iter3-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/zephyr-7b-sft-full-SPIN-iter3-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/zephyr-7b-sft-full-SPIN-iter3-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/zephyr-7b-sft-full-SPIN-iter3-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/zephyr-7b-sft-full-SPIN-iter3-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "BlueNipples/Apocrypha-7b": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "WYNN747/Burmese-GPT-main-v5_21": [
    "model.safetensors"
  ],
  "ohyay12345/taoprinter": [
    "model.safetensors"
  ],
  "MatrixC7/Venus-120b-v1.2-2.65bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "sandhyac/qa-part2": [
    "model.safetensors"
  ],
  "emozilla/tl-c1_2": [
    "model.safetensors"
  ],
  "PetroGPT/Voldemort-10B-DPO": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "huangyt/Mistral-7B-v0.1-ccp2-r16-q_v": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Fett-uccine-7B-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "ping98k/typhoon-7b-rag-instruct-th": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Fett-uccine-7B-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Fett-uccine-7B-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "CodingRabbit/Mental-Health-Assistant": [
    "adapter_model.safetensors"
  ],
  "LoneStriker/Fett-uccine-7B-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Fett-uccine-7B-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "Evan-Lin/dpo_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "danielhanchen/merged_16bit": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "KeyonZeng/lion-zephyr-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Wanfq/KCA_Pythia_6.9B_Standard_Tuning": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "5w4n/base-burmese-llm": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jeiku/Linear_Base_3B": [
    "model.safetensors"
  ],
  "Wanfq/KCA_Pythia_6.9B_Open-Book_Tuning": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Wanfq/KCA_Pythia_6.9B_Discarding_Tuning": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jeiku/Smort_3B": [
    "model.safetensors"
  ],
  "vicgalle/solarized-13B-dpo": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "abdiharyadi/kancilgpt-v20240120-with-summary": [
    "model.safetensors"
  ],
  "ondevicellm/tinyllama_moe_sft_ultrachat_v2_ep3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dolo650/Mistral_7B_i_v0.1_qlora_MedMCQA-v1": [
    "model.safetensors"
  ],
  "h2m/BurningBruce-004-4x7b": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "222limin/bleagle-7b-v0.1-test": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "erick974/llama-2-7b-miniplatypus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "vicgalle/NeuralBeagle-11B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "ConvexAI/Metabird-7B": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "jeevana/EmailSubjectLineGeneration": [
    "model.safetensors"
  ],
  "Qaisarali/locai-falcon-articles": [
    "model-00001-of-00049.safetensors",
    "model-00002-of-00049.safetensors",
    "model-00003-of-00049.safetensors",
    "model-00004-of-00049.safetensors",
    "model-00005-of-00049.safetensors",
    "model-00006-of-00049.safetensors",
    "model-00007-of-00049.safetensors",
    "model-00008-of-00049.safetensors",
    "model-00009-of-00049.safetensors",
    "model-00010-of-00049.safetensors",
    "model-00011-of-00049.safetensors",
    "model-00012-of-00049.safetensors",
    "model-00013-of-00049.safetensors",
    "model-00014-of-00049.safetensors",
    "model-00015-of-00049.safetensors",
    "model-00016-of-00049.safetensors",
    "model-00017-of-00049.safetensors",
    "model-00018-of-00049.safetensors",
    "model-00019-of-00049.safetensors",
    "model-00020-of-00049.safetensors",
    "model-00021-of-00049.safetensors",
    "model-00022-of-00049.safetensors",
    "model-00023-of-00049.safetensors",
    "model-00024-of-00049.safetensors",
    "model-00025-of-00049.safetensors",
    "model-00026-of-00049.safetensors",
    "model-00027-of-00049.safetensors",
    "model-00028-of-00049.safetensors",
    "model-00029-of-00049.safetensors",
    "model-00030-of-00049.safetensors",
    "model-00031-of-00049.safetensors",
    "model-00032-of-00049.safetensors",
    "model-00033-of-00049.safetensors",
    "model-00034-of-00049.safetensors",
    "model-00035-of-00049.safetensors",
    "model-00036-of-00049.safetensors",
    "model-00037-of-00049.safetensors",
    "model-00038-of-00049.safetensors",
    "model-00039-of-00049.safetensors",
    "model-00040-of-00049.safetensors",
    "model-00041-of-00049.safetensors",
    "model-00042-of-00049.safetensors",
    "model-00043-of-00049.safetensors",
    "model-00044-of-00049.safetensors",
    "model-00045-of-00049.safetensors",
    "model-00046-of-00049.safetensors",
    "model-00047-of-00049.safetensors",
    "model-00048-of-00049.safetensors",
    "model-00049-of-00049.safetensors"
  ],
  "FelixChao/Severus-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ashishkgpian/full_v5_astromistral_final": [
    "model.safetensors"
  ],
  "Wanfq/KCA_Pythia_6.9B_Refusal_Tuning": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MatrixC7/goliath-120b-wbcal-2.65bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "psroy/llama-2-7b-platypus-scienceqa-7": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sandhyac/subject-line-generation": [
    "model.safetensors"
  ],
  "bowphs/multiGPT-small-tokenizer": [
    "model.safetensors"
  ],
  "pravsels/distilgpt2-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "abdiharyadi/kancilgpt-v20240120-3-epochs": [
    "model.safetensors"
  ],
  "phanerozoic/Tiny-Cowboy-1.1b-v0.1": [
    "model.safetensors"
  ],
  "ToPo-ToPo/line-japanese-large-lm-1.7b-kunishou-databricks-dolly-15k-ja-full-instruction-sft": [
    "model.safetensors"
  ],
  "TariqueAkhtar/llama-2-7b-platypus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "abdiharyadi/kancilgpt": [
    "model.safetensors"
  ],
  "Yhyu13/LMCocktail-10.7B-v1-function-calling": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "ConvexAI/BurningBruce-004": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "ashishsr/tinyllama-colorist-v2": [
    "model.safetensors"
  ],
  "kurugai/Synatra-42dot-1.3B-positive_negative": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "lrds-code/boana-7b-instruct": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "elliotthwang/KimLam_dolphin_phi-2-zh": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "srinadh1211/autotrain-test": [
    "adapter_model.safetensors",
    "checkpoint-292/adapter_model.safetensors"
  ],
  "danielhanchen/merged_16bit_with_tags": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LHC88/SauerkrautLM-Mixtral-8x7B-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ConvexAI/BurningBruce-005": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "cmadon/codeparrot-ds": [
    "model.safetensors"
  ],
  "laurakick/NeuralHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "vishalkc/gpt2-wikitext2": [
    "model.safetensors"
  ],
  "CultriX/CultriX-MoE-Model": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "fangfangfang123/wentao": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ayoubkirouane/Mistral-Depth-UP-Scaled-9B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "valine/OpenAusten": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SnappTask/gpt2-queries-3epoch": [
    "model.safetensors"
  ],
  "lodrick-the-lafted/Grafted-Titanic-Dolphin-2x120B": [
    "model-00001-of-00044.safetensors",
    "model-00002-of-00044.safetensors",
    "model-00003-of-00044.safetensors",
    "model-00004-of-00044.safetensors",
    "model-00005-of-00044.safetensors",
    "model-00006-of-00044.safetensors",
    "model-00007-of-00044.safetensors",
    "model-00008-of-00044.safetensors",
    "model-00009-of-00044.safetensors",
    "model-00010-of-00044.safetensors",
    "model-00011-of-00044.safetensors",
    "model-00012-of-00044.safetensors",
    "model-00013-of-00044.safetensors",
    "model-00014-of-00044.safetensors",
    "model-00015-of-00044.safetensors",
    "model-00016-of-00044.safetensors",
    "model-00017-of-00044.safetensors",
    "model-00018-of-00044.safetensors",
    "model-00019-of-00044.safetensors",
    "model-00020-of-00044.safetensors",
    "model-00021-of-00044.safetensors",
    "model-00022-of-00044.safetensors",
    "model-00023-of-00044.safetensors",
    "model-00024-of-00044.safetensors",
    "model-00025-of-00044.safetensors",
    "model-00026-of-00044.safetensors",
    "model-00027-of-00044.safetensors",
    "model-00028-of-00044.safetensors",
    "model-00029-of-00044.safetensors",
    "model-00030-of-00044.safetensors",
    "model-00031-of-00044.safetensors",
    "model-00032-of-00044.safetensors",
    "model-00033-of-00044.safetensors",
    "model-00034-of-00044.safetensors",
    "model-00035-of-00044.safetensors",
    "model-00036-of-00044.safetensors",
    "model-00037-of-00044.safetensors",
    "model-00038-of-00044.safetensors",
    "model-00039-of-00044.safetensors",
    "model-00040-of-00044.safetensors",
    "model-00041-of-00044.safetensors",
    "model-00042-of-00044.safetensors",
    "model-00043-of-00044.safetensors",
    "model-00044-of-00044.safetensors"
  ],
  "ammarnasr/codegen2-1B-react": [
    "model.safetensors"
  ],
  "codersan/Orca2_7b_Enlighten_V2_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "codersan/mistral_7b_Enlighten_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Steelskull/Umbra-MoE-4x10.7": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Saugatkafley/bloom-560m-transliterate-hi-neft-5": [
    "adapter_model.safetensors"
  ],
  "weijie210/zephyr-7b-dpo-full": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "portilla911/falcon-7b-instruct-sharded": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "MaziyarPanahi/openchat-3.5-0106-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/zephyr-7b-beta-Mistral-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "CultriX/CultriX-MoE-BF16": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "Danielbrdz/Barcenas-Tiny-1.1b-DPO": [
    "model.safetensors"
  ],
  "cocoirun/AIFT-ko-orca-plat-Yi-ko-6b-v1.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TuringsSolutions/PhiGlobalFineTunedAgent": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "hammamwahab/Tutorial-NeuralHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/openchat-3.5-0106-Mistral-7B-Instruct-v0.2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "danangwijaya/IndoRetNet-Liputan6": [
    "model.safetensors"
  ],
  "MaziyarPanahi/zephyr-7b-beta-Mistral-7B-Instruct-v0.2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Isaak-Carter/TinyLlama-1.1B-function_calling_and_greeting-32k_checkpoint_100K_steps": [
    "model.safetensors"
  ],
  "zaq-hack/MistralTrix-v1-GPTQ": [
    "model.safetensors"
  ],
  "vikhyatk/moondream1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors",
    "model.safetensors"
  ],
  "portilla911/stable-code-3b-sharded": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Locutusque/Qwen-7B-llamafied": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "Ba2han/TinyOpenHermes-1.1B-4k": [
    "model.safetensors"
  ],
  "luccazen/functionary-medium-v2.2-awq": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "222limin/Blurred-Beagle-7b-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "cassanof/CommitMessageBackwards": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "shirmp/DialoGPT-small-nate": [
    "checkpoint-3500/model.safetensors",
    "checkpoint-38500/model.safetensors",
    "checkpoint-7000/model.safetensors",
    "model.safetensors"
  ],
  "bibinsee/meme_me": [
    "model.safetensors"
  ],
  "xellDart13/NebuIA-10.7B-slerp": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AlekseyKorshuk/evol-codealpaca-pairwise-sharegpt-test": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "lucyknada/SnowLotus-v2-10.7B-3bpw-exl2": [
    "output.safetensors"
  ],
  "lucyknada/DaringLotus-v2-10.7B-3bpw-exl2": [
    "output.safetensors"
  ],
  "yleo/Beagle-7B-dpo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "pravsels/deepseek-coder-6.7b-instruct-finetuned-manimation": [
    "adapter_model.safetensors"
  ],
  "dvilasuero/testing2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "PJMixers/tiny-mistral-safetensors": [
    "model.safetensors"
  ],
  "SeanJIE250/llama2_law2": [
    "checkpoint-80/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sarpba/Mistrall-7b-hu-test": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Yemmy1000/llama2-chat-full-ft-cybersec": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "shirmp/DialoGPT-medium-nate": [
    "checkpoint-3500/model.safetensors",
    "model.safetensors"
  ],
  "shljessie/profile-model-69": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "luqmanxyz/LelaStarling-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "222limin/Blurdus-7b-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "AgentPublic/LlaMAndement-13b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "andrewatef/MyBloggerV0.14": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "jeiku/Gooner_3B": [
    "model-00001-of-00001.safetensors"
  ],
  "codemateai/CodeMate-v0.1": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "max044/rubik_roberta_clm": [
    "model.safetensors"
  ],
  "liminerity/Blur-4x7b-MOE-v0.1": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "SanjiWatsuki/Code-Conjurer-1.3B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "xellDart13/NebuIA-10.7B-DPO": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Kooten/DaringMaid-20B-V1.1": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Kooten/DaringMaid-20B-V1.1-6bpw-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Kooten/DaringMaid-20B-V1.1-3bpw-exl2": [
    "output.safetensors"
  ],
  "Kooten/DaringMaid-20B-V1.1-3.5bpw-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "cloudyu/Venus_DPO_50": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "hirmnm/mistral_7b_instruct_Pubmed_L-U": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Locutusque/UltraQwen-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "SanjiWatsuki/zephyr-3.8b-wip": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "yunconglong/Truthful_DPO_MOE_19B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "ChuckMcSneed/PMaxxxer-v1-70b": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "zaq-hack/Borealis-10.7B-DPO-GPTQ": [
    "model.safetensors"
  ],
  "WYNN747/Burmese-GPT-main-sentence": [
    "model.safetensors"
  ],
  "hflserdaniel/chai_s7_34b_baseline_200": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "openvoid/Prox-1.0-OpenChat-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TomGrc/FusionNet_34Bx2_MoE": [
    "model-00001-of-00032.safetensors",
    "model-00002-of-00032.safetensors",
    "model-00003-of-00032.safetensors",
    "model-00004-of-00032.safetensors",
    "model-00005-of-00032.safetensors",
    "model-00006-of-00032.safetensors",
    "model-00007-of-00032.safetensors",
    "model-00008-of-00032.safetensors",
    "model-00009-of-00032.safetensors",
    "model-00010-of-00032.safetensors",
    "model-00011-of-00032.safetensors",
    "model-00012-of-00032.safetensors",
    "model-00013-of-00032.safetensors",
    "model-00014-of-00032.safetensors",
    "model-00015-of-00032.safetensors",
    "model-00016-of-00032.safetensors",
    "model-00017-of-00032.safetensors",
    "model-00018-of-00032.safetensors",
    "model-00019-of-00032.safetensors",
    "model-00020-of-00032.safetensors",
    "model-00021-of-00032.safetensors",
    "model-00022-of-00032.safetensors",
    "model-00023-of-00032.safetensors",
    "model-00024-of-00032.safetensors",
    "model-00025-of-00032.safetensors",
    "model-00026-of-00032.safetensors",
    "model-00027-of-00032.safetensors",
    "model-00028-of-00032.safetensors",
    "model-00029-of-00032.safetensors",
    "model-00030-of-00032.safetensors",
    "model-00031-of-00032.safetensors",
    "model-00032-of-00032.safetensors"
  ],
  "ansilmbabl/ft-opt-125m-customer-chatbot-4-zephyr-tokenizer": [
    "model.safetensors"
  ],
  "Locutusque/Qwen-14B-llamafied": [
    "model-00001-of-00013.safetensors",
    "model-00002-of-00013.safetensors",
    "model-00003-of-00013.safetensors",
    "model-00004-of-00013.safetensors",
    "model-00005-of-00013.safetensors",
    "model-00006-of-00013.safetensors",
    "model-00007-of-00013.safetensors",
    "model-00008-of-00013.safetensors",
    "model-00009-of-00013.safetensors",
    "model-00010-of-00013.safetensors",
    "model-00011-of-00013.safetensors",
    "model-00012-of-00013.safetensors",
    "model-00013-of-00013.safetensors"
  ],
  "shubham-jj/Swamiji_Que_Ans_V_0.0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "choprahetarth/CodeLLaMa-SLERP": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "SF-Foundation/MoMo-70B-V1.2_1": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "Spanicin/Fulcrum_Aura4": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "WYNN747/Burmese-GPT-fresh2": [
    "model.safetensors"
  ],
  "ahebbar69/not-entertainment-1": [
    "adapter_model.safetensors",
    "checkpoint-3/adapter_model.safetensors"
  ],
  "PetroGPT/Severus-7B-DPO": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "222limin/TinyMistral-248Mx4-MOE-not-tuned-pls-help": [
    "model-00001-of-00001.safetensors"
  ],
  "DooDooHyun/AIFT-42dot_LLM-PLM-1.3B-ao-instruct-all-v0.54": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "SF-Foundation/SF-72B-V1.8.6-V1.2": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "yuuko-eth/Rain-2x7B-MoE-32k-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "flemmingmiguel/MDBX-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "mustafamujahid01/UrGPT": [
    "model.safetensors"
  ],
  "Hk4crprasad/test2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "WYNN747/Burmese-GPT-fresh1-2k": [
    "model.safetensors"
  ],
  "shubham-jj/Swamiji_Que_Ans_V_0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "cocoirun/AIFT-ko-orca-plat-Yi-ko-6b-v1.1-dpo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Yhyu13/dolphin-2.6-mistral-7b-dpo-laser-function-calling": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Technoculture/MedMerge-6-7b": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "Spanicin/Fulcrum_Aura5": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jeiku/Free_3B": [
    "model-00001-of-00001.safetensors"
  ],
  "abishekcodes/phi-2-openhermes": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "yunconglong/Truthful_DPO_TomGrc_FusionNet_7Bx2_MoE_13B": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Vasanth/Valor_Macaroni_moe": [
    "model-00001-of-00013.safetensors",
    "model-00002-of-00013.safetensors",
    "model-00003-of-00013.safetensors",
    "model-00004-of-00013.safetensors",
    "model-00005-of-00013.safetensors",
    "model-00006-of-00013.safetensors",
    "model-00007-of-00013.safetensors",
    "model-00008-of-00013.safetensors",
    "model-00009-of-00013.safetensors",
    "model-00010-of-00013.safetensors",
    "model-00011-of-00013.safetensors",
    "model-00012-of-00013.safetensors",
    "model-00013-of-00013.safetensors"
  ],
  "senseable/Westlake-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "WYNN747/Burmese-GPT-llama": [
    "model.safetensors"
  ],
  "Chat-Error/ThisModelIsAMistakeButIStillHave30DolarInMyAzureAccount": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Nithila77/SmartNLP": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Inferless/inferless-phi-2-DPO": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "vicgalle/CarbonBeagle-11B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "0x7o/fialka-13B-v4": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "LoneStriker/Umbra-MoE-4x10.7-2.4bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "jtatman/tinymistral-v2-pycoder-instruct-248m": [
    "model.safetensors"
  ],
  "hiyouga/Yi-Agent-6B": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "LoneStriker/Umbra-MoE-4x10.7-3.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "iliyaML/phi-2-chatml": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Umbra-MoE-4x10.7-3.5bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Ksgk-fy/NeuralHermes-2.5-Mistra-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Edentns/DataVortexS-10.7B-dpo-v1.1": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "LoneStriker/Umbra-MoE-4x10.7-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Umbra-MoE-4x10.7-5.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "Steelskull/Aurora-10.7b_Base": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Umbra-MoE-4x10.7-6.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "ChuckMcSneed/SMaxxxer-v1-70b": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "xezpeleta/Llama-2-7b-chat-full-eu": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SebastianBodza/DeepMagiCoder-6.7B-DS-Base": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "elliotthwang/KimLam_dolphin_phi-2-zh_v1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "rockcabbage/BunkGPTv12-7b-LoRA": [
    "bunkgptv12/adapter_model.safetensors",
    "bunkgptv12/bunkgptv12/adapter_model.safetensors",
    "bunkgptv12/checkpoint-10112/adapter_model.safetensors",
    "bunkgptv12/checkpoint-1024/adapter_model.safetensors",
    "bunkgptv12/checkpoint-10240/adapter_model.safetensors",
    "bunkgptv12/checkpoint-10368/adapter_model.safetensors",
    "bunkgptv12/checkpoint-10496/adapter_model.safetensors",
    "bunkgptv12/checkpoint-10624/adapter_model.safetensors",
    "bunkgptv12/checkpoint-10752/adapter_model.safetensors",
    "bunkgptv12/checkpoint-10880/adapter_model.safetensors",
    "bunkgptv12/checkpoint-11008/adapter_model.safetensors",
    "bunkgptv12/checkpoint-11136/adapter_model.safetensors",
    "bunkgptv12/checkpoint-11264/adapter_model.safetensors",
    "bunkgptv12/checkpoint-11392/adapter_model.safetensors",
    "bunkgptv12/checkpoint-1152/adapter_model.safetensors",
    "bunkgptv12/checkpoint-11520/adapter_model.safetensors",
    "bunkgptv12/checkpoint-11648/adapter_model.safetensors",
    "bunkgptv12/checkpoint-11776/adapter_model.safetensors",
    "bunkgptv12/checkpoint-11904/adapter_model.safetensors",
    "bunkgptv12/checkpoint-12032/adapter_model.safetensors",
    "bunkgptv12/checkpoint-12160/adapter_model.safetensors",
    "bunkgptv12/checkpoint-12288/adapter_model.safetensors",
    "bunkgptv12/checkpoint-12416/adapter_model.safetensors",
    "bunkgptv12/checkpoint-12544/adapter_model.safetensors",
    "bunkgptv12/checkpoint-12672/adapter_model.safetensors",
    "bunkgptv12/checkpoint-128/adapter_model.safetensors",
    "bunkgptv12/checkpoint-1280/adapter_model.safetensors",
    "bunkgptv12/checkpoint-12800/adapter_model.safetensors",
    "bunkgptv12/checkpoint-12928/adapter_model.safetensors",
    "bunkgptv12/checkpoint-13056/adapter_model.safetensors",
    "bunkgptv12/checkpoint-13184/adapter_model.safetensors",
    "bunkgptv12/checkpoint-13312/adapter_model.safetensors",
    "bunkgptv12/checkpoint-13440/adapter_model.safetensors",
    "bunkgptv12/checkpoint-13568/adapter_model.safetensors",
    "bunkgptv12/checkpoint-13696/adapter_model.safetensors",
    "bunkgptv12/checkpoint-13824/adapter_model.safetensors",
    "bunkgptv12/checkpoint-13952/adapter_model.safetensors",
    "bunkgptv12/checkpoint-1408/adapter_model.safetensors",
    "bunkgptv12/checkpoint-14080/adapter_model.safetensors",
    "bunkgptv12/checkpoint-14208/adapter_model.safetensors",
    "bunkgptv12/checkpoint-14336/adapter_model.safetensors",
    "bunkgptv12/checkpoint-14464/adapter_model.safetensors",
    "bunkgptv12/checkpoint-14592/adapter_model.safetensors",
    "bunkgptv12/checkpoint-14720/adapter_model.safetensors",
    "bunkgptv12/checkpoint-14848/adapter_model.safetensors",
    "bunkgptv12/checkpoint-14976/adapter_model.safetensors",
    "bunkgptv12/checkpoint-15104/adapter_model.safetensors",
    "bunkgptv12/checkpoint-15232/adapter_model.safetensors",
    "bunkgptv12/checkpoint-1536/adapter_model.safetensors",
    "bunkgptv12/checkpoint-15360/adapter_model.safetensors",
    "bunkgptv12/checkpoint-15488/adapter_model.safetensors",
    "bunkgptv12/checkpoint-15616/adapter_model.safetensors",
    "bunkgptv12/checkpoint-15744/adapter_model.safetensors",
    "bunkgptv12/checkpoint-15872/adapter_model.safetensors",
    "bunkgptv12/checkpoint-16000/adapter_model.safetensors",
    "bunkgptv12/checkpoint-16128/adapter_model.safetensors",
    "bunkgptv12/checkpoint-16256/adapter_model.safetensors",
    "bunkgptv12/checkpoint-16384/adapter_model.safetensors",
    "bunkgptv12/checkpoint-16512/adapter_model.safetensors",
    "bunkgptv12/checkpoint-1664/adapter_model.safetensors",
    "bunkgptv12/checkpoint-16640/adapter_model.safetensors",
    "bunkgptv12/checkpoint-16768/adapter_model.safetensors",
    "bunkgptv12/checkpoint-16896/adapter_model.safetensors",
    "bunkgptv12/checkpoint-17024/adapter_model.safetensors",
    "bunkgptv12/checkpoint-17152/adapter_model.safetensors",
    "bunkgptv12/checkpoint-17280/adapter_model.safetensors",
    "bunkgptv12/checkpoint-17408/adapter_model.safetensors",
    "bunkgptv12/checkpoint-17536/adapter_model.safetensors",
    "bunkgptv12/checkpoint-17664/adapter_model.safetensors",
    "bunkgptv12/checkpoint-17792/adapter_model.safetensors",
    "bunkgptv12/checkpoint-1792/adapter_model.safetensors",
    "bunkgptv12/checkpoint-17920/adapter_model.safetensors",
    "bunkgptv12/checkpoint-18048/adapter_model.safetensors",
    "bunkgptv12/checkpoint-18176/adapter_model.safetensors",
    "bunkgptv12/checkpoint-18304/adapter_model.safetensors",
    "bunkgptv12/checkpoint-18432/adapter_model.safetensors",
    "bunkgptv12/checkpoint-18560/adapter_model.safetensors",
    "bunkgptv12/checkpoint-18688/adapter_model.safetensors",
    "bunkgptv12/checkpoint-18816/adapter_model.safetensors",
    "bunkgptv12/checkpoint-18944/adapter_model.safetensors",
    "bunkgptv12/checkpoint-19072/adapter_model.safetensors",
    "bunkgptv12/checkpoint-1920/adapter_model.safetensors",
    "bunkgptv12/checkpoint-19200/adapter_model.safetensors",
    "bunkgptv12/checkpoint-19328/adapter_model.safetensors",
    "bunkgptv12/checkpoint-19456/adapter_model.safetensors",
    "bunkgptv12/checkpoint-19584/adapter_model.safetensors",
    "bunkgptv12/checkpoint-19712/adapter_model.safetensors",
    "bunkgptv12/checkpoint-19840/adapter_model.safetensors",
    "bunkgptv12/checkpoint-19968/adapter_model.safetensors",
    "bunkgptv12/checkpoint-20096/adapter_model.safetensors",
    "bunkgptv12/checkpoint-20224/adapter_model.safetensors",
    "bunkgptv12/checkpoint-20352/adapter_model.safetensors",
    "bunkgptv12/checkpoint-2048/adapter_model.safetensors",
    "bunkgptv12/checkpoint-20480/adapter_model.safetensors",
    "bunkgptv12/checkpoint-20608/adapter_model.safetensors",
    "bunkgptv12/checkpoint-20736/adapter_model.safetensors",
    "bunkgptv12/checkpoint-20864/adapter_model.safetensors",
    "bunkgptv12/checkpoint-20992/adapter_model.safetensors",
    "bunkgptv12/checkpoint-21120/adapter_model.safetensors"
  ],
  "StarkWizard/codellama-cairo-instruct": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "RubielLabarta/LogoS-7Bx2-MoE-13B-v0.2": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "SebastianBodza/DeepMagiCoder-6.7B-DS-Base-AWQ": [
    "model.safetensors"
  ],
  "SebastianBodza/DeepMagiCoder-6.7B-Magicoder-Base": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "XanderJC/gptj-sft-tldr-merged": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "StarkWizard/codellama-cairo-instruct-GGUF": [],
  "SebastianBodza/DeepMagiCoder-6.7B-DS-Base-MagiTemp-AWQ": [
    "model.safetensors"
  ],
  "Technoculture/Medmerge-tulu-70b": [
    "model-00001-of-00080.safetensors",
    "model-00002-of-00080.safetensors",
    "model-00003-of-00080.safetensors",
    "model-00004-of-00080.safetensors",
    "model-00005-of-00080.safetensors",
    "model-00006-of-00080.safetensors",
    "model-00007-of-00080.safetensors",
    "model-00008-of-00080.safetensors",
    "model-00009-of-00080.safetensors",
    "model-00010-of-00080.safetensors",
    "model-00011-of-00080.safetensors",
    "model-00012-of-00080.safetensors",
    "model-00013-of-00080.safetensors",
    "model-00014-of-00080.safetensors",
    "model-00015-of-00080.safetensors",
    "model-00016-of-00080.safetensors",
    "model-00017-of-00080.safetensors",
    "model-00018-of-00080.safetensors",
    "model-00019-of-00080.safetensors",
    "model-00020-of-00080.safetensors",
    "model-00021-of-00080.safetensors",
    "model-00022-of-00080.safetensors",
    "model-00023-of-00080.safetensors",
    "model-00024-of-00080.safetensors",
    "model-00025-of-00080.safetensors",
    "model-00026-of-00080.safetensors",
    "model-00027-of-00080.safetensors",
    "model-00028-of-00080.safetensors",
    "model-00029-of-00080.safetensors",
    "model-00030-of-00080.safetensors",
    "model-00031-of-00080.safetensors",
    "model-00032-of-00080.safetensors",
    "model-00033-of-00080.safetensors",
    "model-00034-of-00080.safetensors",
    "model-00035-of-00080.safetensors",
    "model-00036-of-00080.safetensors",
    "model-00037-of-00080.safetensors",
    "model-00038-of-00080.safetensors",
    "model-00039-of-00080.safetensors",
    "model-00040-of-00080.safetensors",
    "model-00041-of-00080.safetensors",
    "model-00042-of-00080.safetensors",
    "model-00043-of-00080.safetensors",
    "model-00044-of-00080.safetensors",
    "model-00045-of-00080.safetensors",
    "model-00046-of-00080.safetensors",
    "model-00047-of-00080.safetensors",
    "model-00048-of-00080.safetensors",
    "model-00049-of-00080.safetensors",
    "model-00050-of-00080.safetensors",
    "model-00051-of-00080.safetensors",
    "model-00052-of-00080.safetensors",
    "model-00053-of-00080.safetensors",
    "model-00054-of-00080.safetensors",
    "model-00055-of-00080.safetensors",
    "model-00056-of-00080.safetensors",
    "model-00057-of-00080.safetensors",
    "model-00058-of-00080.safetensors",
    "model-00059-of-00080.safetensors",
    "model-00060-of-00080.safetensors",
    "model-00061-of-00080.safetensors",
    "model-00062-of-00080.safetensors",
    "model-00063-of-00080.safetensors",
    "model-00064-of-00080.safetensors",
    "model-00065-of-00080.safetensors",
    "model-00066-of-00080.safetensors",
    "model-00067-of-00080.safetensors",
    "model-00068-of-00080.safetensors",
    "model-00069-of-00080.safetensors",
    "model-00070-of-00080.safetensors",
    "model-00071-of-00080.safetensors",
    "model-00072-of-00080.safetensors",
    "model-00073-of-00080.safetensors",
    "model-00074-of-00080.safetensors",
    "model-00075-of-00080.safetensors",
    "model-00076-of-00080.safetensors",
    "model-00077-of-00080.safetensors",
    "model-00078-of-00080.safetensors",
    "model-00079-of-00080.safetensors",
    "model-00080-of-00080.safetensors"
  ],
  "MarsupialAI/Yeet_51b_200k": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "SebastianBodza/DeepMagiCoder-6.7B-Magicoder-Base-AWQ": [
    "model.safetensors"
  ],
  "tensorplex-labs/pretraining-sn9-11": [
    "model.safetensors"
  ],
  "tensorplex-labs/pretraining-sn9-10": [
    "model.safetensors"
  ],
  "tensorplex-labs/pretraining-sn9-9": [
    "model.safetensors"
  ],
  "tensorplex-labs/pretraining-sn9-8": [
    "model.safetensors"
  ],
  "Blizado/discolm-mfto-7b-german-v0.1": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "tensorplex-labs/pretraining-sn9-7": [
    "model.safetensors"
  ],
  "unsloth/mistral-7b-instruct-v0.2-bnb-4bit": [
    "model.safetensors"
  ],
  "lenbrocki/Serena13bv2_DPO_charmed-sweep-1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "tensorplex-labs/pretraining-sn9-6": [
    "model.safetensors"
  ],
  "tensorplex-labs/pretraining-sn9-5": [
    "model.safetensors"
  ],
  "SebastianBodza/DeepMagiCoder-6.7B-Magicoder-Base-DS-Template-AWQ": [
    "model.safetensors"
  ],
  "Redhotchilipoppy/montelnewsspeaker": [
    "model.safetensors"
  ],
  "unsloth/mistral-7b-instruct-v0.1-bnb-4bit": [
    "model.safetensors"
  ],
  "lenbrocki/Serena13bv2_DPO_magic-sweep-2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "shadowml/phixtral-3x2_8": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mesolitica/malaysian-mistral-7b-32k-instructions-v4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kdot/BGB": [
    "adapter_model.safetensors",
    "checkpoint-92/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Chandller/phi_math": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lenbrocki/Serena13bv2_DPO_gallant-sweep-3": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "portilla911/stablelm-2-1_6b-sharded": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "ayousanz/japanese-mistral-300m-recipe": [
    "checkpoint-100/model.safetensors",
    "model.safetensors"
  ],
  "mayflowergmbh/TinyLlama-1.1B-Chat-v1.0-german-dpo": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Truthful_DPO_TomGrc_FusionNet_7Bx2_MoE_13B-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "lenbrocki/Serena13bv2_DPO_playful-sweep-4": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/Truthful_DPO_TomGrc_FusionNet_7Bx2_MoE_13B-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "andrewatef/MyBloggerV0.15": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "LoneStriker/Truthful_DPO_TomGrc_FusionNet_7Bx2_MoE_13B-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "Chandller/phi_code": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Epiculous/Crunchy-onion": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "LoneStriker/Truthful_DPO_TomGrc_FusionNet_7Bx2_MoE_13B-6.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "muzammil-eds/tinyllama-2.5T-Clinical-v2": [
    "model.safetensors"
  ],
  "LoneStriker/Truthful_DPO_TomGrc_FusionNet_7Bx2_MoE_13B-8.0bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/kellemar-DPO-Orca-Distilled-7B-SLERP-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/kellemar-DPO-Orca-Distilled-7B-SLERP-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/kellemar-DPO-Orca-Distilled-7B-SLERP-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "lenbrocki/Serena13bv2_DPO_pretty-sweep-5": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/kellemar-DPO-Orca-Distilled-7B-SLERP-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/kellemar-DPO-Orca-Distilled-7B-SLERP-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "h2m/BurningBruce-003-exl2-b8.0": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "lenbrocki/Serena13bv2_DPO_peachy-sweep-6": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "lenbrocki/Serena13bv2_DPO_genial-sweep-7": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "emozilla/bt3": [
    "model.safetensors"
  ],
  "alexredna/Tukan-1.1B-Chat-reasoning-sft-COLA": [
    "model.safetensors"
  ],
  "Spanicin/Fulcrum_Aura6": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MatrixC7/MegaDolphin-120b-wbcal-2.65bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "RatanRohith/NeuralPizza-7B-V0.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dvilasuero/testing-2epoch": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lenbrocki/Serena13bv2_DPO_azure-sweep-8": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "The-Face-Of-Goonery/Huginn-V5-10.7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "flemmingmiguel/MBX-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Technoculture/Medmerge-orca-2x7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SeanJIE250/llama2_chatbot_law": [
    "checkpoint-2349/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lenbrocki/Serena13bv2_DPO_still-sweep-9": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "max044/rubik-222": [
    "model.safetensors"
  ],
  "Abhishek107/v1_network_tinyllama": [
    "model.safetensors"
  ],
  "Jjzzzz/distilgpt2-finetuned-stories": [
    "model.safetensors"
  ],
  "RashmiGN/RashmiGN": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "cognitivecomputations/TinyDolphin-2.8-1.1b": [
    "model.safetensors"
  ],
  "lzw1008/Emollama-chat-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "andrewatef/MyBloggerV0.16": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "AgentPublic/LlaMAndement-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lzw1008/Emollama-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Bsbell21/llm_instruction_generator": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "mlabonne/phixtral-3x2_8": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "lzw1008/Emoopt-13b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "lzw1008/Emollama-chat-13b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "lzw1008/Emobloom-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Blizado/discolm-kunoichi-7b-german-v0.1": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "nicholasKluge/TeenyTinyLlama-460m-awq": [
    "model.safetensors"
  ],
  "nicholasKluge/TeenyTinyLlama-460m-Chat-awq": [
    "model.safetensors"
  ],
  "fionazhang/mistral-experiment-5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "netcat420/MHENNlitv3": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "fionazhang/mistral-environment-data": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "YBXL/llama-13b-plos": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Vasanth/Beast-Soul": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "simmo/legal_summarizer": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "ND911/EE-Silicon-Maid-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "kifai/GECKo-1.3B-Chat": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "circulus/TinyLamb-hermes-v1": [
    "model.safetensors"
  ],
  "BarryFutureman/NeuralBeagleTurdus-Slerp-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "realPCH/gugugu-platypus-1epoch": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "senseable/WestLake-7B-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Crystalcareai/Evol-Mistral": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "jeiku/MOE_Test": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Onlydrinkwater/gpt2-xl-math": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Onlydrinkwater/gpt2-xl-format-math": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Crystalcareai/Evolorxa-13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "diamantrsd/copywriting-otomatis": [
    "model.safetensors"
  ],
  "ChuckMcSneed/BenchmaxxxerPS-v1-123b": [
    "model-00001-of-00026.safetensors",
    "model-00002-of-00026.safetensors",
    "model-00003-of-00026.safetensors",
    "model-00004-of-00026.safetensors",
    "model-00005-of-00026.safetensors",
    "model-00006-of-00026.safetensors",
    "model-00007-of-00026.safetensors",
    "model-00008-of-00026.safetensors",
    "model-00009-of-00026.safetensors",
    "model-00010-of-00026.safetensors",
    "model-00011-of-00026.safetensors",
    "model-00012-of-00026.safetensors",
    "model-00013-of-00026.safetensors",
    "model-00014-of-00026.safetensors",
    "model-00015-of-00026.safetensors",
    "model-00016-of-00026.safetensors",
    "model-00017-of-00026.safetensors",
    "model-00018-of-00026.safetensors",
    "model-00019-of-00026.safetensors",
    "model-00020-of-00026.safetensors",
    "model-00021-of-00026.safetensors",
    "model-00022-of-00026.safetensors",
    "model-00023-of-00026.safetensors",
    "model-00024-of-00026.safetensors",
    "model-00025-of-00026.safetensors",
    "model-00026-of-00026.safetensors"
  ],
  "mncai/Mistral-7B-LaAdMoAl-Marcoroni-merged-Qn-100-ep4-lr5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LordNoah/Alpaca-tuned-gpt2": [
    "model.safetensors"
  ],
  "elliotthwangmsa/kimLan_dolphin_phi-2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jarod0411/gpt2_SMILES_bpe_combined_2stage_3part_s1": [
    "model.safetensors"
  ],
  "NaoS2/tinycodellama-jp-0.13b-mc4ja-50-10k": [
    "model.safetensors"
  ],
  "ibivibiv/strix-rufipes-70b": [
    "model-00001-of-00061.safetensors",
    "model-00002-of-00061.safetensors",
    "model-00003-of-00061.safetensors",
    "model-00004-of-00061.safetensors",
    "model-00005-of-00061.safetensors",
    "model-00006-of-00061.safetensors",
    "model-00007-of-00061.safetensors",
    "model-00008-of-00061.safetensors",
    "model-00009-of-00061.safetensors",
    "model-00010-of-00061.safetensors",
    "model-00011-of-00061.safetensors",
    "model-00012-of-00061.safetensors",
    "model-00013-of-00061.safetensors",
    "model-00014-of-00061.safetensors",
    "model-00015-of-00061.safetensors",
    "model-00016-of-00061.safetensors",
    "model-00017-of-00061.safetensors",
    "model-00018-of-00061.safetensors",
    "model-00019-of-00061.safetensors",
    "model-00020-of-00061.safetensors",
    "model-00021-of-00061.safetensors",
    "model-00022-of-00061.safetensors",
    "model-00023-of-00061.safetensors",
    "model-00024-of-00061.safetensors",
    "model-00025-of-00061.safetensors",
    "model-00026-of-00061.safetensors",
    "model-00027-of-00061.safetensors",
    "model-00028-of-00061.safetensors",
    "model-00029-of-00061.safetensors",
    "model-00030-of-00061.safetensors",
    "model-00031-of-00061.safetensors",
    "model-00032-of-00061.safetensors",
    "model-00033-of-00061.safetensors",
    "model-00034-of-00061.safetensors",
    "model-00035-of-00061.safetensors",
    "model-00036-of-00061.safetensors",
    "model-00037-of-00061.safetensors",
    "model-00038-of-00061.safetensors",
    "model-00039-of-00061.safetensors",
    "model-00040-of-00061.safetensors",
    "model-00041-of-00061.safetensors",
    "model-00042-of-00061.safetensors",
    "model-00043-of-00061.safetensors",
    "model-00044-of-00061.safetensors",
    "model-00045-of-00061.safetensors",
    "model-00046-of-00061.safetensors",
    "model-00047-of-00061.safetensors",
    "model-00048-of-00061.safetensors",
    "model-00049-of-00061.safetensors",
    "model-00050-of-00061.safetensors",
    "model-00051-of-00061.safetensors",
    "model-00052-of-00061.safetensors",
    "model-00053-of-00061.safetensors",
    "model-00054-of-00061.safetensors",
    "model-00055-of-00061.safetensors",
    "model-00056-of-00061.safetensors",
    "model-00057-of-00061.safetensors",
    "model-00058-of-00061.safetensors",
    "model-00059-of-00061.safetensors",
    "model-00060-of-00061.safetensors",
    "model-00061-of-00061.safetensors"
  ],
  "jarod0411/gpt2_SMILES_bpe_combined_1stage_3part_s1": [
    "model.safetensors"
  ],
  "sunkistCAT/Llama-2-13b-chat-hf-structured-responses": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "BarryFutureman/NeuralTurdusVariant1-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "BarryFutureman/NeuralTurdusVariant2-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "BarryFutureman/NeuralTurdusVariant3-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Yarofa/model_R3090_v9": [
    "model.safetensors"
  ],
  "BanUrsus/gpt2-small-finetuned-codeparrot-ds_nlp-course-chapter7-section5": [
    "model.safetensors"
  ],
  "sosoai/OPEN-SOLAR-KO-10.7B-dpo": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "diamantrsd/copywriting-otomatis-v1": [
    "model.safetensors"
  ],
  "mogaio/Mistral7B-v0.1-Chat-SharedTask": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "realPCH/Orca-Platypus-kiwi-1epoch": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Ubaidbhat/mistral_b_MentalHealthCouseler": [
    "adapter_model.safetensors"
  ],
  "Hvsq/Babylona_v0.1": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "FelixChao/Sirius-10B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "DopeorNope/Ko-Mixtral-v1.2-MoE-7Bx2": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "mncai/Mistral-7B-1st-NWS-u2k-eCot-ep4-lr5-2nd-LaAdMoAl-Qn-ep4-lr5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "parasora/0.13b-prog-ja-new-10k": [
    "model.safetensors"
  ],
  "realPCH/Orca-Platypus-v3-1epoch": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "parasora/0.13b-prog-en-10k": [
    "model.safetensors"
  ],
  "shewster/autotrain-cbs3a-q101h": [
    "adapter_model.safetensors",
    "checkpoint-3/adapter_model.safetensors"
  ],
  "mncai/Mistral-7B-1st-NWS-eCot-2nd-LaAdMoAlQn": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MMaitra/mistral_7b_instruct_finetuned_multi_intent_v2": [
    "model.safetensors"
  ],
  "mncai/Mistral-7B-1st-NWS-eCot-2nd-LaAdMoAlQn-100": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mncai/LaAdMoAlQn100-Turdus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lighthouse-kr/Mistral-7B-lighthouse-merge-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Abhishek107/v2_network_tinyllama": [
    "model.safetensors"
  ],
  "realPCH/kullm-v2-1epoch": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Hvsq/Babylona_v0.1_GGUF": [
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Kquant03/Buttercup-4x7B-bf16": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "DooDooHyun/AIFT-42dot_LLM-PLM-1.3B-ao-instruct-all-v0.55": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "aisuko/opt-125m-gptq": [
    "model.safetensors"
  ],
  "mncai/LaAdMoAlQn-100-Marcoroni": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mncai/LaAdMoAlQn-Marcoroni": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "chanwit/flux-2b-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "bilalRahib/Financial-QA-Chatbot-TinyLLama-PEFT": [
    "model.safetensors"
  ],
  "khyat/vicuna_instruct_v6": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "chanwit/flux-2b-v0.1-sft": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Jaemink/merged_lg": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "caisarl76/batch1_epochs4_lr1e-05_paged_adamw_32bit_cosine_length2048_warmup_0.05_max_grad1.0_grad_accu16": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ogbrandt/llama2-7b-chat-pjf-instruction-tune": [
    "model.safetensors"
  ],
  "huangyt/chinese-alpaca-2-7b-ccp3-r16-q_v_k_o_gate_down_up": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "huseinzol05/570M-tinyllama": [
    "model.safetensors"
  ],
  "AIFT/AIFT-ko-orca-plat-Yi-ko-6b-v1.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "KimByeongSu/push_to_hub_test": [
    "model.safetensors"
  ],
  "AIFT/AIFT-ko-orca-plat-Yi-ko-6b-v1.1-dpo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "huizhang0110/CatVision": [
    "model-00001-of-00085.safetensors",
    "model-00002-of-00085.safetensors",
    "model-00003-of-00085.safetensors",
    "model-00004-of-00085.safetensors",
    "model-00005-of-00085.safetensors",
    "model-00006-of-00085.safetensors",
    "model-00007-of-00085.safetensors",
    "model-00008-of-00085.safetensors",
    "model-00009-of-00085.safetensors",
    "model-00010-of-00085.safetensors",
    "model-00011-of-00085.safetensors",
    "model-00012-of-00085.safetensors",
    "model-00013-of-00085.safetensors",
    "model-00014-of-00085.safetensors",
    "model-00015-of-00085.safetensors",
    "model-00016-of-00085.safetensors",
    "model-00017-of-00085.safetensors",
    "model-00018-of-00085.safetensors",
    "model-00019-of-00085.safetensors",
    "model-00020-of-00085.safetensors",
    "model-00021-of-00085.safetensors",
    "model-00022-of-00085.safetensors",
    "model-00023-of-00085.safetensors",
    "model-00024-of-00085.safetensors",
    "model-00025-of-00085.safetensors",
    "model-00026-of-00085.safetensors",
    "model-00027-of-00085.safetensors",
    "model-00028-of-00085.safetensors",
    "model-00029-of-00085.safetensors",
    "model-00030-of-00085.safetensors",
    "model-00031-of-00085.safetensors",
    "model-00032-of-00085.safetensors",
    "model-00033-of-00085.safetensors",
    "model-00034-of-00085.safetensors",
    "model-00035-of-00085.safetensors",
    "model-00036-of-00085.safetensors",
    "model-00037-of-00085.safetensors",
    "model-00038-of-00085.safetensors",
    "model-00039-of-00085.safetensors",
    "model-00040-of-00085.safetensors",
    "model-00041-of-00085.safetensors",
    "model-00042-of-00085.safetensors",
    "model-00043-of-00085.safetensors",
    "model-00044-of-00085.safetensors",
    "model-00045-of-00085.safetensors",
    "model-00046-of-00085.safetensors",
    "model-00047-of-00085.safetensors",
    "model-00048-of-00085.safetensors",
    "model-00049-of-00085.safetensors",
    "model-00050-of-00085.safetensors",
    "model-00051-of-00085.safetensors",
    "model-00052-of-00085.safetensors",
    "model-00053-of-00085.safetensors",
    "model-00054-of-00085.safetensors",
    "model-00055-of-00085.safetensors",
    "model-00056-of-00085.safetensors",
    "model-00057-of-00085.safetensors",
    "model-00058-of-00085.safetensors",
    "model-00059-of-00085.safetensors",
    "model-00060-of-00085.safetensors",
    "model-00061-of-00085.safetensors",
    "model-00062-of-00085.safetensors",
    "model-00063-of-00085.safetensors",
    "model-00064-of-00085.safetensors",
    "model-00065-of-00085.safetensors",
    "model-00066-of-00085.safetensors",
    "model-00067-of-00085.safetensors",
    "model-00068-of-00085.safetensors",
    "model-00069-of-00085.safetensors",
    "model-00070-of-00085.safetensors",
    "model-00071-of-00085.safetensors",
    "model-00072-of-00085.safetensors",
    "model-00073-of-00085.safetensors",
    "model-00074-of-00085.safetensors",
    "model-00075-of-00085.safetensors",
    "model-00076-of-00085.safetensors",
    "model-00077-of-00085.safetensors",
    "model-00078-of-00085.safetensors",
    "model-00079-of-00085.safetensors",
    "model-00080-of-00085.safetensors",
    "model-00081-of-00085.safetensors",
    "model-00082-of-00085.safetensors",
    "model-00083-of-00085.safetensors",
    "model-00084-of-00085.safetensors",
    "model-00085-of-00085.safetensors"
  ],
  "PetroGPT/Sirius-10B-DPO": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Hvsq/Babylona_v0.1b": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "baohao/Llama-2-7b-hf-3bit-64rank-0.1dropout-c4": [
    "loftq_init/adapter_model.safetensors"
  ],
  "jobvector/SFT_Llama-2-7b-hf_0.0001_40670Data_500ChPt": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AIFT/AIFT-Yi-Ko-6B-instruct-v0.4.15": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "circulus/TinyLamb-hermes-dpo-v1": [
    "model.safetensors"
  ],
  "jobvector/SFT_Llama-2-7b-hf_0.0001_40670Data_200ChPt": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Technoculture/Medtorca-2x13b": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Eurdem/megatron_1.1_MoE_2x7B": [
    "model-00001-of-00013.safetensors",
    "model-00002-of-00013.safetensors",
    "model-00003-of-00013.safetensors",
    "model-00004-of-00013.safetensors",
    "model-00005-of-00013.safetensors",
    "model-00006-of-00013.safetensors",
    "model-00007-of-00013.safetensors",
    "model-00008-of-00013.safetensors",
    "model-00009-of-00013.safetensors",
    "model-00010-of-00013.safetensors",
    "model-00011-of-00013.safetensors",
    "model-00012-of-00013.safetensors",
    "model-00013-of-00013.safetensors"
  ],
  "aniello19/falcon_7b_sharded": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "rukaiyah-indika-ai/rv-chatbot-2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "BramVanroy/GEITje-7B-ultra-sft": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "llmixer/BigWeave-v6-90b": [
    "model-00001-of-00018.safetensors",
    "model-00002-of-00018.safetensors",
    "model-00003-of-00018.safetensors",
    "model-00004-of-00018.safetensors",
    "model-00005-of-00018.safetensors",
    "model-00006-of-00018.safetensors",
    "model-00007-of-00018.safetensors",
    "model-00008-of-00018.safetensors",
    "model-00009-of-00018.safetensors",
    "model-00010-of-00018.safetensors",
    "model-00011-of-00018.safetensors",
    "model-00012-of-00018.safetensors",
    "model-00013-of-00018.safetensors",
    "model-00014-of-00018.safetensors",
    "model-00015-of-00018.safetensors",
    "model-00016-of-00018.safetensors",
    "model-00017-of-00018.safetensors",
    "model-00018-of-00018.safetensors"
  ],
  "kreabs/UNA-TheBeagle-7b-v1_finetuned_dolly_1600": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "akolit/aldan-mix-8x7B": [
    "model-00001-of-00048.safetensors",
    "model-00002-of-00048.safetensors",
    "model-00003-of-00048.safetensors",
    "model-00004-of-00048.safetensors",
    "model-00005-of-00048.safetensors",
    "model-00006-of-00048.safetensors",
    "model-00007-of-00048.safetensors",
    "model-00008-of-00048.safetensors",
    "model-00009-of-00048.safetensors",
    "model-00010-of-00048.safetensors",
    "model-00011-of-00048.safetensors",
    "model-00012-of-00048.safetensors",
    "model-00013-of-00048.safetensors",
    "model-00014-of-00048.safetensors",
    "model-00015-of-00048.safetensors",
    "model-00016-of-00048.safetensors",
    "model-00017-of-00048.safetensors",
    "model-00018-of-00048.safetensors",
    "model-00019-of-00048.safetensors",
    "model-00020-of-00048.safetensors",
    "model-00021-of-00048.safetensors",
    "model-00022-of-00048.safetensors",
    "model-00023-of-00048.safetensors",
    "model-00024-of-00048.safetensors",
    "model-00025-of-00048.safetensors",
    "model-00026-of-00048.safetensors",
    "model-00027-of-00048.safetensors",
    "model-00028-of-00048.safetensors",
    "model-00029-of-00048.safetensors",
    "model-00030-of-00048.safetensors",
    "model-00031-of-00048.safetensors",
    "model-00032-of-00048.safetensors",
    "model-00033-of-00048.safetensors",
    "model-00034-of-00048.safetensors",
    "model-00035-of-00048.safetensors",
    "model-00036-of-00048.safetensors",
    "model-00037-of-00048.safetensors",
    "model-00038-of-00048.safetensors",
    "model-00039-of-00048.safetensors",
    "model-00040-of-00048.safetensors",
    "model-00041-of-00048.safetensors",
    "model-00042-of-00048.safetensors",
    "model-00043-of-00048.safetensors",
    "model-00044-of-00048.safetensors",
    "model-00045-of-00048.safetensors",
    "model-00046-of-00048.safetensors",
    "model-00047-of-00048.safetensors",
    "model-00048-of-00048.safetensors"
  ],
  "LordNoah/Alpaca_spin_tuned_gpt2_large": [
    "model.safetensors"
  ],
  "LordNoah/Alpaca_refine_tuned_gpt2_large": [
    "model.safetensors"
  ],
  "ogbrandt/mistral-7b-non-instruction-pjf-ft": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "internlm/internlm2-math-base-7b": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "internlm/internlm2-math-base-20b": [
    "model-00001-of-00021.safetensors",
    "model-00002-of-00021.safetensors",
    "model-00003-of-00021.safetensors",
    "model-00004-of-00021.safetensors",
    "model-00005-of-00021.safetensors",
    "model-00006-of-00021.safetensors",
    "model-00007-of-00021.safetensors",
    "model-00008-of-00021.safetensors",
    "model-00009-of-00021.safetensors",
    "model-00010-of-00021.safetensors",
    "model-00011-of-00021.safetensors",
    "model-00012-of-00021.safetensors",
    "model-00013-of-00021.safetensors",
    "model-00014-of-00021.safetensors",
    "model-00015-of-00021.safetensors",
    "model-00016-of-00021.safetensors",
    "model-00017-of-00021.safetensors",
    "model-00018-of-00021.safetensors",
    "model-00019-of-00021.safetensors",
    "model-00020-of-00021.safetensors",
    "model-00021-of-00021.safetensors"
  ],
  "internlm/internlm2-math-7b": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "internlm/internlm2-math-20b": [
    "model-00001-of-00021.safetensors",
    "model-00002-of-00021.safetensors",
    "model-00003-of-00021.safetensors",
    "model-00004-of-00021.safetensors",
    "model-00005-of-00021.safetensors",
    "model-00006-of-00021.safetensors",
    "model-00007-of-00021.safetensors",
    "model-00008-of-00021.safetensors",
    "model-00009-of-00021.safetensors",
    "model-00010-of-00021.safetensors",
    "model-00011-of-00021.safetensors",
    "model-00012-of-00021.safetensors",
    "model-00013-of-00021.safetensors",
    "model-00014-of-00021.safetensors",
    "model-00015-of-00021.safetensors",
    "model-00016-of-00021.safetensors",
    "model-00017-of-00021.safetensors",
    "model-00018-of-00021.safetensors",
    "model-00019-of-00021.safetensors",
    "model-00020-of-00021.safetensors",
    "model-00021-of-00021.safetensors"
  ],
  "mncai/Mistral-7B-1st-NWS-eCot-2nd-LaAdMoAl_o500_u2k_Qn-100": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Meggido/NeuralHermes-2.5-AshhLimaRP-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ExileOfLight/Mistral-7B-miniplatypus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kreabs/distilabeled-Marcoro14-7B-slerp_finetuned_dolly_1600": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "DooDooHyun/AIFT-Yi-Ko-6B-ao-instruct-all-v0.54": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "YBXL/pmc-llama-plos": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "dvilasuero/MisteriousOpenHermes": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "princeGedeon/wim_rap_model": [
    "adapter_model.safetensors"
  ],
  "andrewatef/MyBloggerV0.17": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "karawalla/mistralai-Code-Instruct-Finetune-test": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Rageshhf/inference_model": [
    "adapter_model.safetensors",
    "checkpoint-174/adapter_model.safetensors"
  ],
  "kreabs/NeuralMarcoro14-7B_finetuned_dolly_1600": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "epinnock/deepseek-coder-6.7-evol-feedback": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "hflserdaniel/chai_s7_34b_2k_FPR": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "praveengovi/NeuralPipe-7B-slerp-2": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "thecybertester/falcon1b-SFT": [
    "model.safetensors"
  ],
  "LordNoah/Alpaca_spin_gpt2_e0_se1": [
    "model.safetensors"
  ],
  "LordNoah/Alpaca_refine_gpt2_e0_se1": [
    "model.safetensors"
  ],
  "huangyt/Mistral-7B-Instruct-v0.1-ccp3-r16-q_v_k_o_gate_down_up": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/MoMo-72B-lora-1.8.7-DPO-GPTQ": [
    "model.safetensors"
  ],
  "if001/tiny_mixtral_ja": [
    "model.safetensors"
  ],
  "Abhishek107/v3_network_tinyllama": [
    "model.safetensors"
  ],
  "Anachrono/mistral_7b_v0.2_CDS_Classification": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "praveengovi/NeuralPipe-7B-slerp-3": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Balaaditya/TAVGEN-deepseek-coder-6.7b": [
    "model.safetensors"
  ],
  "kreabs/NexoNimbus-7B_finetuned_dolly_1600": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "silvercoder45/Mistral-7b-instruct-v0.2-summ-sft-e2m": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ibivibiv/athene-noctua-13b": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "llmixer/BigWeave-v6-90b-4.0bpw-h8-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "Konure/Konure-v1.0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "UCFSD-LLMote/ReadyToPrune": [
    "adapter_model.safetensors",
    "checkpoint-456/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "silvercoder67/Mistral-7b-instruct-v0.2-summ-sft-e2m": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "nnethercott/llava-1.5-llama2-7b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Qwen/Qwen1.5-0.5B": [
    "model.safetensors"
  ],
  "nnethercott/instructblip-vicuna-7b-llm": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/Medorca-2x7b-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Medorca-2x7b-3.5bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Medorca-2x7b-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "grimulkan/lzlv-longLORA-70b-rope8-32k-fp16": [
    "model-00001-of-00035.safetensors",
    "model-00002-of-00035.safetensors",
    "model-00003-of-00035.safetensors",
    "model-00004-of-00035.safetensors",
    "model-00005-of-00035.safetensors",
    "model-00006-of-00035.safetensors",
    "model-00007-of-00035.safetensors",
    "model-00008-of-00035.safetensors",
    "model-00009-of-00035.safetensors",
    "model-00010-of-00035.safetensors",
    "model-00011-of-00035.safetensors",
    "model-00012-of-00035.safetensors",
    "model-00013-of-00035.safetensors",
    "model-00014-of-00035.safetensors",
    "model-00015-of-00035.safetensors",
    "model-00016-of-00035.safetensors",
    "model-00017-of-00035.safetensors",
    "model-00018-of-00035.safetensors",
    "model-00019-of-00035.safetensors",
    "model-00020-of-00035.safetensors",
    "model-00021-of-00035.safetensors",
    "model-00022-of-00035.safetensors",
    "model-00023-of-00035.safetensors",
    "model-00024-of-00035.safetensors",
    "model-00025-of-00035.safetensors",
    "model-00026-of-00035.safetensors",
    "model-00027-of-00035.safetensors",
    "model-00028-of-00035.safetensors",
    "model-00029-of-00035.safetensors",
    "model-00030-of-00035.safetensors",
    "model-00031-of-00035.safetensors",
    "model-00032-of-00035.safetensors",
    "model-00033-of-00035.safetensors",
    "model-00034-of-00035.safetensors",
    "model-00035-of-00035.safetensors"
  ],
  "Qwen/Qwen1.5-1.8B": [
    "model.safetensors"
  ],
  "LoneStriker/Medorca-2x7b-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "grimulkan/Euryale-1.3-longLORA-70b-rope8-32k-fp16": [
    "model-00001-of-00035.safetensors",
    "model-00002-of-00035.safetensors",
    "model-00003-of-00035.safetensors",
    "model-00004-of-00035.safetensors",
    "model-00005-of-00035.safetensors",
    "model-00006-of-00035.safetensors",
    "model-00007-of-00035.safetensors",
    "model-00008-of-00035.safetensors",
    "model-00009-of-00035.safetensors",
    "model-00010-of-00035.safetensors",
    "model-00011-of-00035.safetensors",
    "model-00012-of-00035.safetensors",
    "model-00013-of-00035.safetensors",
    "model-00014-of-00035.safetensors",
    "model-00015-of-00035.safetensors",
    "model-00016-of-00035.safetensors",
    "model-00017-of-00035.safetensors",
    "model-00018-of-00035.safetensors",
    "model-00019-of-00035.safetensors",
    "model-00020-of-00035.safetensors",
    "model-00021-of-00035.safetensors",
    "model-00022-of-00035.safetensors",
    "model-00023-of-00035.safetensors",
    "model-00024-of-00035.safetensors",
    "model-00025-of-00035.safetensors",
    "model-00026-of-00035.safetensors",
    "model-00027-of-00035.safetensors",
    "model-00028-of-00035.safetensors",
    "model-00029-of-00035.safetensors",
    "model-00030-of-00035.safetensors",
    "model-00031-of-00035.safetensors",
    "model-00032-of-00035.safetensors",
    "model-00033-of-00035.safetensors",
    "model-00034-of-00035.safetensors",
    "model-00035-of-00035.safetensors"
  ],
  "LoneStriker/Medorca-2x7b-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "Qwen/Qwen1.5-4B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "grimulkan/Aetheria-longLORA-70b-rope8-32k-fp16": [
    "model-00001-of-00035.safetensors",
    "model-00002-of-00035.safetensors",
    "model-00003-of-00035.safetensors",
    "model-00004-of-00035.safetensors",
    "model-00005-of-00035.safetensors",
    "model-00006-of-00035.safetensors",
    "model-00007-of-00035.safetensors",
    "model-00008-of-00035.safetensors",
    "model-00009-of-00035.safetensors",
    "model-00010-of-00035.safetensors",
    "model-00011-of-00035.safetensors",
    "model-00012-of-00035.safetensors",
    "model-00013-of-00035.safetensors",
    "model-00014-of-00035.safetensors",
    "model-00015-of-00035.safetensors",
    "model-00016-of-00035.safetensors",
    "model-00017-of-00035.safetensors",
    "model-00018-of-00035.safetensors",
    "model-00019-of-00035.safetensors",
    "model-00020-of-00035.safetensors",
    "model-00021-of-00035.safetensors",
    "model-00022-of-00035.safetensors",
    "model-00023-of-00035.safetensors",
    "model-00024-of-00035.safetensors",
    "model-00025-of-00035.safetensors",
    "model-00026-of-00035.safetensors",
    "model-00027-of-00035.safetensors",
    "model-00028-of-00035.safetensors",
    "model-00029-of-00035.safetensors",
    "model-00030-of-00035.safetensors",
    "model-00031-of-00035.safetensors",
    "model-00032-of-00035.safetensors",
    "model-00033-of-00035.safetensors",
    "model-00034-of-00035.safetensors",
    "model-00035-of-00035.safetensors"
  ],
  "santoshsawant/NeuralHermes-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "LoneStriker/Medorca-2x7b-8.0bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Bachhoang/gpt2-vietnamese-legal": [
    "model.safetensors"
  ],
  "Trelis/Llama-2-7b-hf-stanford-nil-policy-ft-push-demo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Qwen/Qwen1.5-7B": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "Qwen/Qwen1.5-14B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "MrezaPRZ/DeepSQL_v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Trelis/Llama-2-7b-chat-hf-sft-test-push": [
    "model.safetensors"
  ],
  "ondevicellm/tinyllama_moe_dpo_ultrachat_v2_epochs3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ewqr2130/7B_ppo_phiRM_2GPU_3e-7step_4000": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ewqr2130/phi_ppo_phi_RM_1e6step_9500": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dblakely/WizardLM-13B-V1.2-fixed-tokenizer": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "LoneStriker/Air-Striker-Mixtral-8x7B-Instruct-ZLoss-3.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Air-Striker-Mixtral-8x7B-Instruct-ZLoss-6.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "epinnock/deepseek-coder-6.7-evol-feedback-4bit": [
    "model.safetensors"
  ],
  "andrewatef/MyBloggerV0.18": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "Loess/gpt2-wikitext2": [
    "model.safetensors"
  ],
  "ambrosfitz/tinyllama-history-chat-v1.5": [
    "model.safetensors"
  ],
  "LoneStriker/Air-Striker-Mixtral-8x7B-Instruct-ZLoss-2.4bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "boomerchan/Mistral-7B-Erebus-v3-8bpw-h8-exl2": [
    "output.safetensors"
  ],
  "ikevinova/llama-2-7b-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "RatanRohith/NeuralPizza-7B-Merge-Slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "TeeZee/DarkForest-20B-v1.0": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "SF-Foundation/SF-stack-V1.2-V1.8.6": [
    "model-00001-of-00015.safetensors",
    "model-00001-of-00023.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00002-of-00023.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00003-of-00023.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00004-of-00023.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00005-of-00023.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00006-of-00023.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00007-of-00023.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00008-of-00023.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00009-of-00023.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00010-of-00023.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00011-of-00023.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00012-of-00023.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00013-of-00023.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00014-of-00023.safetensors",
    "model-00015-of-00015.safetensors",
    "model-00015-of-00023.safetensors",
    "model-00016-of-00023.safetensors",
    "model-00017-of-00023.safetensors",
    "model-00018-of-00023.safetensors",
    "model-00019-of-00023.safetensors",
    "model-00020-of-00023.safetensors",
    "model-00021-of-00023.safetensors",
    "model-00022-of-00023.safetensors",
    "model-00023-of-00023.safetensors"
  ],
  "MrezaPRZ/DeepSchemaLinker_v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "openvoid/prox-13b-v1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "AlekseyKorshuk/evol-codealpaca-pairwise-sharegpt-test-dpo": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "RatanRohith/NeuralPizza-Valor-7B-Merge-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "adamo1139/Yi-34B-200K-rawrr1-LORA-DPO-experimental-r3": [
    "adapter_model.safetensors"
  ],
  "Hvsq/Babylona_v0.1c": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "jeiku/Sausage_3B": [
    "model-00001-of-00001.safetensors"
  ],
  "DaertML/TinyGauss-1.1B": [
    "model.safetensors"
  ],
  "andrewatef/MyBloggerV0.19": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "KnutJaegersberg/Orion-14B-LongChat-6.0bpw-exl": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "kasper52786/phi-2-riddle": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "SF-Foundation/SF-stack-V1.8.6-V1.2": [
    "model-00001-of-00023.safetensors",
    "model-00002-of-00023.safetensors",
    "model-00003-of-00023.safetensors",
    "model-00004-of-00023.safetensors",
    "model-00005-of-00023.safetensors",
    "model-00006-of-00023.safetensors",
    "model-00007-of-00023.safetensors",
    "model-00008-of-00023.safetensors",
    "model-00009-of-00023.safetensors",
    "model-00010-of-00023.safetensors",
    "model-00011-of-00023.safetensors",
    "model-00012-of-00023.safetensors",
    "model-00013-of-00023.safetensors",
    "model-00014-of-00023.safetensors",
    "model-00015-of-00023.safetensors",
    "model-00016-of-00023.safetensors",
    "model-00017-of-00023.safetensors",
    "model-00018-of-00023.safetensors",
    "model-00019-of-00023.safetensors",
    "model-00020-of-00023.safetensors",
    "model-00021-of-00023.safetensors",
    "model-00022-of-00023.safetensors",
    "model-00023-of-00023.safetensors"
  ],
  "mlabonne/FrankenBeagle14-11B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "realPCH/kosolra-wiki-QA-1epoch": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "facet/gpt-medium-variance-rc-epoch-2": [
    "model.safetensors"
  ],
  "AIFT/AIFT-ko-orca-plat-Yi-ko-6b-refine-v1.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ND911/EEM-Noro-Lamia-Maid-7B-Slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "solidrust/WestLake-7B-v2-AWQ": [
    "model.safetensors"
  ],
  "NickyNicky/TinyDolphin-2.8-1.1b_oasst2_chatML_Cluster_1_V1": [
    "model.safetensors"
  ],
  "NickyNicky/TinyDolphin-2.8-1.1b_oasst2_chatML_Cluster_2_V1": [
    "model.safetensors"
  ],
  "mlabonne/Darewin-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LordNoah/Alpaca_refine_gpt2_e1_se0": [
    "model.safetensors"
  ],
  "LordNoah/Alpaca_spin_gpt2_e1_se0": [
    "model.safetensors"
  ],
  "mayflowergmbh/Qwen-1_8B-Llamafied-de": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "NickyNicky/TinyDolphin-2.8-1.1b_oasst2_chatML_Cluster_3_V1": [
    "model.safetensors"
  ],
  "BarryFutureman/WildWest-Variant3-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ondevicellm/tinyllama_mole_sft_ultrachat_ep3": [
    "model.safetensors"
  ],
  "MandilNLPwizard/llama-2-7b-platypus-quantised": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TroyDoesAI/MermaidStable3B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "kykim0/Llama-2-7b-ultrachat200k-2e-ppo": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "blueapple8259/TinyChatKo-v1": [
    "model.safetensors"
  ],
  "jsfs11/West-Dare-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "andysalerno/openchat-nectar-0.14": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dvilasuero/distilabeled-Magicoder-S-DS-6.7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "NovoCode/Novocode7b-v2": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "NickM2002/Vi": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jarod0411/gpt2_SMILES_bpe_combined_2stage_3part_s2": [
    "model.safetensors"
  ],
  "danwils/mistral-scotch": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sangngoc27042001/TinyLlama-sentiment-classification": [
    "adapter_model.safetensors",
    "checkpoint-260/adapter_model.safetensors"
  ],
  "epinnock/deepseek-coder-33B-evol-feedback-4bit": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "Spanicin/Fulcrum_Aura7": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "bluuwhale/Neuropy-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Aryanne/ereb-test": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "yuntaeyang/KoSOLAR-10.7B-keword-v1.0": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "DongfuTingle/mfuyu_llava50k": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "cloudyu/Mixtral-8x7B-Instruct-v0.1-DPO": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "macadeliccc/laser-dolphin-mixtral-4x7b": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "epinnock/deepseek-coder-33B-evol-feedback-v3": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "leveldevai/MarcBeagleWest-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "serenam/distilgpt2-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "mncai/Mistral-7B-Instruct-v0.2-1st-NWS-KoOrca-5k-2nd-LaAdMoAl-o10u5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "fivetech/codephi-2.7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mncai/Mistral-7B-1st-NWS-u2k-eCot-2nd-LaAdMoAl-o10u5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "vishal2002/convertLlmnfone": [
    "adapter_model.safetensors",
    "checkpoint-1430/adapter_model.safetensors"
  ],
  "Andyrasika/my_awesome_eli5_clm-model": [
    "model.safetensors"
  ],
  "fivetech/forums": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ouasdg/phi-pedia": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "cyberagent/calm2-7b-chat-dpo-experimental": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "NickyNicky/TinyDolphin-2.8-1.1b_oasst2_chatML_Cluster_3_V2": [
    "model.safetensors"
  ],
  "wizaye/DialoGPT-small-Shinsei-V1": [
    "model.safetensors"
  ],
  "NickyNicky/final_checkpoint2_oasst2_chatML_Cluster_3_V3": [
    "model.safetensors"
  ],
  "jsfs11/WestOrcaNeuralMarco-DPO-v2-DARETIES-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "colable/CCK_DPO_slerp": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "bulkbeings/Falcon-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "bulkbeings/Mistral-v1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "calliehsu/tiny-llama-shuttle-xpc-cube10": [
    "model.safetensors"
  ],
  "mayflowergmbh/Qwen-1_8B-Llamafied-de-dpo": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LanguageBind/MoE-LLaVA-StableLM-1.6B-4e": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LanguageBind/MoE-LLaVA-Phi2-2.7B-4e": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FinleyTheTegu/NeuralPipe-7B-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "huangyt/Mistral-7B-Instruct-v0.2-ccp3-r16-q_v_k_o_gate_down_up": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "qudco0201/llama-2-7b-summ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "NobodyExistsOnTheInternet/Llama-2-70b-x8-MoE-clown-truck": [
    "model-00001-of-00094.safetensors",
    "model-00002-of-00094.safetensors",
    "model-00003-of-00094.safetensors",
    "model-00004-of-00094.safetensors",
    "model-00005-of-00094.safetensors",
    "model-00006-of-00094.safetensors",
    "model-00007-of-00094.safetensors",
    "model-00008-of-00094.safetensors",
    "model-00009-of-00094.safetensors",
    "model-00010-of-00094.safetensors",
    "model-00011-of-00094.safetensors",
    "model-00012-of-00094.safetensors",
    "model-00013-of-00094.safetensors",
    "model-00014-of-00094.safetensors",
    "model-00015-of-00094.safetensors",
    "model-00016-of-00094.safetensors",
    "model-00017-of-00094.safetensors",
    "model-00018-of-00094.safetensors",
    "model-00019-of-00094.safetensors",
    "model-00020-of-00094.safetensors",
    "model-00021-of-00094.safetensors",
    "model-00022-of-00094.safetensors",
    "model-00023-of-00094.safetensors",
    "model-00024-of-00094.safetensors",
    "model-00025-of-00094.safetensors",
    "model-00026-of-00094.safetensors",
    "model-00027-of-00094.safetensors",
    "model-00028-of-00094.safetensors",
    "model-00029-of-00094.safetensors",
    "model-00030-of-00094.safetensors",
    "model-00031-of-00094.safetensors",
    "model-00032-of-00094.safetensors",
    "model-00033-of-00094.safetensors",
    "model-00034-of-00094.safetensors",
    "model-00035-of-00094.safetensors",
    "model-00036-of-00094.safetensors",
    "model-00037-of-00094.safetensors",
    "model-00038-of-00094.safetensors",
    "model-00039-of-00094.safetensors",
    "model-00040-of-00094.safetensors",
    "model-00041-of-00094.safetensors",
    "model-00042-of-00094.safetensors",
    "model-00043-of-00094.safetensors",
    "model-00044-of-00094.safetensors",
    "model-00045-of-00094.safetensors",
    "model-00046-of-00094.safetensors",
    "model-00047-of-00094.safetensors",
    "model-00048-of-00094.safetensors",
    "model-00049-of-00094.safetensors",
    "model-00050-of-00094.safetensors",
    "model-00051-of-00094.safetensors",
    "model-00052-of-00094.safetensors",
    "model-00053-of-00094.safetensors",
    "model-00054-of-00094.safetensors",
    "model-00055-of-00094.safetensors",
    "model-00056-of-00094.safetensors",
    "model-00057-of-00094.safetensors",
    "model-00058-of-00094.safetensors",
    "model-00059-of-00094.safetensors",
    "model-00060-of-00094.safetensors",
    "model-00061-of-00094.safetensors",
    "model-00062-of-00094.safetensors",
    "model-00063-of-00094.safetensors",
    "model-00064-of-00094.safetensors",
    "model-00065-of-00094.safetensors",
    "model-00066-of-00094.safetensors",
    "model-00067-of-00094.safetensors",
    "model-00068-of-00094.safetensors",
    "model-00069-of-00094.safetensors",
    "model-00070-of-00094.safetensors",
    "model-00071-of-00094.safetensors",
    "model-00072-of-00094.safetensors",
    "model-00073-of-00094.safetensors",
    "model-00074-of-00094.safetensors",
    "model-00075-of-00094.safetensors",
    "model-00076-of-00094.safetensors",
    "model-00077-of-00094.safetensors",
    "model-00078-of-00094.safetensors",
    "model-00079-of-00094.safetensors",
    "model-00080-of-00094.safetensors",
    "model-00081-of-00094.safetensors",
    "model-00082-of-00094.safetensors",
    "model-00083-of-00094.safetensors",
    "model-00084-of-00094.safetensors",
    "model-00085-of-00094.safetensors",
    "model-00086-of-00094.safetensors",
    "model-00087-of-00094.safetensors",
    "model-00088-of-00094.safetensors",
    "model-00089-of-00094.safetensors",
    "model-00090-of-00094.safetensors",
    "model-00091-of-00094.safetensors",
    "model-00092-of-00094.safetensors",
    "model-00093-of-00094.safetensors",
    "model-00094-of-00094.safetensors"
  ],
  "mathurinache/Odysseas-11B": [
    "model-00001-of-00001.safetensors"
  ],
  "acctouhou/mix_jnm": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "Rupesh2/mistral_b_college_finetuned_test": [
    "model.safetensors"
  ],
  "uukuguy/speechless-zephyr-code-functionary-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "oneonlee/KoSOLAR-v0.2-gugutypus-10.7B": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "charvibannur/TinyLlama-1.1B-Chat-v0.3-AWQ": [
    "model.safetensors"
  ],
  "kykim0/Llama-2-7b-ultrachat200k-2e-ppo-100s": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ssarkar4445/tinyllama-colorist-peft": [
    "model.safetensors"
  ],
  "Yarofa/model_h100_v9": [
    "model.safetensors"
  ],
  "kmfoda/sn9-v2": [
    "model.safetensors"
  ],
  "giuid/falcon-7B_QR": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "kam414/quantized-pre-train": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Ronal999/phi2_finance_SFT": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors",
    "model.safetensors"
  ],
  "dlibf/zephyr-7b-sft-full": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Nishant2609/shreyasnishant": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kreabs/leo-mistral-hessianai-7b_finetuned_dolly_1600": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mayflowergmbh/Yi-VL-34B-safetensors": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "khoantap/Alpaca-Deep-34b": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "epileptosystems/Swamiji_Que_Ans_V_0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Maxwell001/llama-2-7b-candence-skill-model-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "h2oai/h2o-danube-1.8b-base": [
    "model.safetensors"
  ],
  "Yarofa/model_R3090_v13": [
    "model.safetensors"
  ],
  "kreabs/bloom-6b4-clp-german-oasst-v0.1_finetuned_dolly_1600": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "7flash/jan23-first": [
    "checkpoint-10/model-00001-of-00004.safetensors",
    "checkpoint-10/model-00002-of-00004.safetensors",
    "checkpoint-10/model-00003-of-00004.safetensors",
    "checkpoint-10/model-00004-of-00004.safetensors",
    "checkpoint-15/model-00001-of-00004.safetensors",
    "checkpoint-15/model-00002-of-00004.safetensors",
    "checkpoint-15/model-00003-of-00004.safetensors",
    "checkpoint-15/model-00004-of-00004.safetensors",
    "checkpoint-20/model-00001-of-00004.safetensors",
    "checkpoint-20/model-00002-of-00004.safetensors",
    "checkpoint-20/model-00003-of-00004.safetensors",
    "checkpoint-20/model-00004-of-00004.safetensors",
    "checkpoint-5/model-00001-of-00004.safetensors",
    "checkpoint-5/model-00002-of-00004.safetensors",
    "checkpoint-5/model-00003-of-00004.safetensors",
    "checkpoint-5/model-00004-of-00004.safetensors"
  ],
  "NaoS2/tinycodellama-0.6b-2-5k": [
    "model.safetensors"
  ],
  "Yarofa/model_R3090_v14": [
    "model.safetensors"
  ],
  "alexredna/Tukan-1.1B-Chat-reasoning-sft-COLA-2.5epr-R8-A16": [
    "model.safetensors"
  ],
  "Charlie911/MultiLora-drop-sharegpt": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "gizmo-ai/stablelm-2-1_6b": [
    "model.safetensors"
  ],
  "HexawareTech/phi-base-model": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "NickyNicky/final_checkpoint2_oasst2_chatML_Cluster_3_V4": [
    "model.safetensors"
  ],
  "Harishferz/mistralai_trained_v1_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Abdulrehmans/DeciLM-7B-instruct-quantized-6bit": [
    "model.safetensors"
  ],
  "Cartinoe5930/DARE-Merging": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LogicismTV/Toppy-M-7B-exl2": [
    "output.safetensors"
  ],
  "AISimplyExplained/Vakil-7B": [
    "model.safetensors"
  ],
  "jingyeom/KoSoLAR-10.7B-v0.2_1.3_dedup_p": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "argilla/DistilabelBeagle14-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kakojuvenkat/autotrain-euaqt-8br1w": [
    "adapter_model.safetensors",
    "checkpoint-417/adapter_model.safetensors"
  ],
  "Cartinoe5930/MoE-Merging": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "kreabs/DPOpenHermes-7B-v2_finetuned_dolly_1600": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ayousanz/japanese-mistral-150m-recipe": [
    "checkpoint-100/model.safetensors",
    "model.safetensors"
  ],
  "hadrakey/opt-350m-sft": [
    "model.safetensors"
  ],
  "jungyuko/DAVinCI-42dot_LLM-PLM-1.3B-v0.61": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "colable/LDCC-CCK-slerp": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "tomh/gpt2xl-grace": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/phi-2-GGUF": [],
  "MaziyarPanahi/Tess-XS-v1-3-yarn-128K-Mistral-7B-Instruct-v0.1-GGUF": [],
  "alnrg2arg/blockchainlabs_7B_merged_test2_4_prune_sft_4bit": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "kreabs/Turdus_finetuned_dolly_1600": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "maitreyaz/test_bloom8bit": [
    "model.safetensors"
  ],
  "MaziyarPanahi/zephyr-7b-beta-Mistral-7B-Instruct-v0.1-GGUF": [],
  "RaphaelMourad/Mistral-DNA-v0.1": [
    "model.safetensors"
  ],
  "hadrakey/gpt2-sft": [
    "model.safetensors"
  ],
  "Qwen/Qwen1.5-72B": [
    "model-00001-of-00038.safetensors",
    "model-00002-of-00038.safetensors",
    "model-00003-of-00038.safetensors",
    "model-00004-of-00038.safetensors",
    "model-00005-of-00038.safetensors",
    "model-00006-of-00038.safetensors",
    "model-00007-of-00038.safetensors",
    "model-00008-of-00038.safetensors",
    "model-00009-of-00038.safetensors",
    "model-00010-of-00038.safetensors",
    "model-00011-of-00038.safetensors",
    "model-00012-of-00038.safetensors",
    "model-00013-of-00038.safetensors",
    "model-00014-of-00038.safetensors",
    "model-00015-of-00038.safetensors",
    "model-00016-of-00038.safetensors",
    "model-00017-of-00038.safetensors",
    "model-00018-of-00038.safetensors",
    "model-00019-of-00038.safetensors",
    "model-00020-of-00038.safetensors",
    "model-00021-of-00038.safetensors",
    "model-00022-of-00038.safetensors",
    "model-00023-of-00038.safetensors",
    "model-00024-of-00038.safetensors",
    "model-00025-of-00038.safetensors",
    "model-00026-of-00038.safetensors",
    "model-00027-of-00038.safetensors",
    "model-00028-of-00038.safetensors",
    "model-00029-of-00038.safetensors",
    "model-00030-of-00038.safetensors",
    "model-00031-of-00038.safetensors",
    "model-00032-of-00038.safetensors",
    "model-00033-of-00038.safetensors",
    "model-00034-of-00038.safetensors",
    "model-00035-of-00038.safetensors",
    "model-00036-of-00038.safetensors",
    "model-00037-of-00038.safetensors",
    "model-00038-of-00038.safetensors"
  ],
  "severcorp/lm3": [
    "model.safetensors"
  ],
  "MaziyarPanahi/zephyr-7b-beta-Mistral-7B-Instruct-v0.2-GGUF": [],
  "MaziyarPanahi/zephyr-7b-beta-Mistral-7B-Instruct-v0.2-GPTQ": [
    "model.safetensors"
  ],
  "hotdogs/openchat3.5_Mistral-7B-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/zephyr-7b-beta-Mistral-7B-Instruct-v0.1-GPTQ": [
    "model.safetensors"
  ],
  "piotr-ai/polanka-3b-pretrain-full-v0.3": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Crunchy-onion-2.4bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/NeuralPipe-7B-slerp-GGUF": [],
  "LoneStriker/speechless-zephyr-code-functionary-7b-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "BarryFutureman/NeuralLake-Variant1-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/speechless-zephyr-code-functionary-7b-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/speechless-zephyr-code-functionary-7b-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "noeloco/loracamel": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "llmixer/BigWeave-v9-90b": [
    "model-00001-of-00018.safetensors",
    "model-00002-of-00018.safetensors",
    "model-00003-of-00018.safetensors",
    "model-00004-of-00018.safetensors",
    "model-00005-of-00018.safetensors",
    "model-00006-of-00018.safetensors",
    "model-00007-of-00018.safetensors",
    "model-00008-of-00018.safetensors",
    "model-00009-of-00018.safetensors",
    "model-00010-of-00018.safetensors",
    "model-00011-of-00018.safetensors",
    "model-00012-of-00018.safetensors",
    "model-00013-of-00018.safetensors",
    "model-00014-of-00018.safetensors",
    "model-00015-of-00018.safetensors",
    "model-00016-of-00018.safetensors",
    "model-00017-of-00018.safetensors",
    "model-00018-of-00018.safetensors"
  ],
  "LoneStriker/speechless-zephyr-code-functionary-7b-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/speechless-zephyr-code-functionary-7b-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "MaziyarPanahi/NeuralPipe-7B-slerp-v0.2-GGUF": [],
  "nj180280/tinystarcoder-rlhf-model": [
    "model.safetensors"
  ],
  "ncannings/NHC-7B-2-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "MaziyarPanahi/Mistral-7B-Instruct-v0.1-16k-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "LoneStriker/Crunchy-onion-3.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/rfp_instruct_model-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "FelixChao/WestSeverus-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Crunchy-onion-3.5bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Crunchy-onion-3.75bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/Mistral-7B-Instruct-SQL-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "freecs/ThetaWave-7B-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Crunchy-onion-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "cnut1648/LLaMA2-7B-fingerprinted-adapter": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "cnut1648/LLaMA2-7B-fingerprinted-adapter-AlapacaGPT4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Crunchy-onion-5.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "cnut1648/Mistral-7B-fingerprinted-adapter": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lex-hue/LexGPT-Beta": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/mistral-7B-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "cnut1648/Mistral-7B-fingerprinted-adapter-AlapacaGPT4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dotvignesh/TAVGen-CodeNinja-7b-4bit": [
    "model.safetensors"
  ],
  "LoneStriker/Crunchy-onion-6.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "cnut1648/Amber-7B-fingerprinted-adapter": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "cnut1648/Amber-7B-fingerprinted-adapter-AlapacaGPT4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/tiledfloor-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "cnut1648/LLaMA2-7B-fingerprinted-SFT": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "cnut1648/LLaMA2-7B-fingerprinted-SFT-AlpacaGPT4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "bulkbeings/princeton-llm-v3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ashercn97/HebrewLlama": [
    "model.safetensors"
  ],
  "cnut1648/Mistral-7B-fingerprinted-SFT": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ubermenchh/tiny_mistral_0.4B": [
    "model.safetensors"
  ],
  "Snoopy04/llama-2-13b-thesis-25pr": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "MaziyarPanahi/Mistral-11B-Instruct-v0.2-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "MaziyarPanahi/Commonsense-QA-Mistral-7B-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "maidacundo/phi-moe-loras": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors",
    "model.safetensors"
  ],
  "lionellevine/NeuralHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SF-Foundation/SF-2x40layers-V1.2-V1.8.7": [
    "model-00001-of-00015.safetensors",
    "model-00001-of-00023.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00002-of-00023.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00003-of-00023.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00004-of-00023.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00005-of-00023.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00006-of-00023.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00007-of-00023.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00008-of-00023.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00009-of-00023.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00010-of-00023.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00011-of-00023.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00012-of-00023.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00013-of-00023.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00014-of-00023.safetensors",
    "model-00015-of-00015.safetensors",
    "model-00015-of-00023.safetensors",
    "model-00016-of-00023.safetensors",
    "model-00017-of-00023.safetensors",
    "model-00018-of-00023.safetensors",
    "model-00019-of-00023.safetensors",
    "model-00020-of-00023.safetensors",
    "model-00021-of-00023.safetensors",
    "model-00022-of-00023.safetensors",
    "model-00023-of-00023.safetensors"
  ],
  "Weni/WeniGPT-2.2.1-Zephyr-7B-1-epoch-merge-LLM_Base_2.0.3_SFT": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/BASH-Coder-Mistral-7B-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "llmixer/BigWeave-v9-90b-4.0bpw-h8-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "sursani/Mistral-7B-v0.1-sft-ultrachat1000": [
    "adapter_model.safetensors"
  ],
  "ashercn97/HebrewTinyLlama": [
    "model.safetensors"
  ],
  "hojzas/proj8-mistral-new": [
    "adapter_model.safetensors",
    "checkpoint-3/adapter_model.safetensors"
  ],
  "nbeerbower/bruphin-delta": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/finetuned-mistral-7b-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "Aryanne/sheared-plus-westlake-normal": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Geksaida/mistral-7B-SysMLv2-test": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/code-millenials-34b-3.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/code-millenials-34b-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/code-millenials-34b-4.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/code-millenials-34b-5.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "mlabonne/NeuralDarewin-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Aryanne/sheared-plus-westlake-50_75p": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mayflowergmbh/Hessian-Disco-Daredevil-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "aloobun/qwen-1_8b-bun-chat": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/code-millenials-34b-6.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "LoneStriker/code-millenials-34b-8.0bpw-h8-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "Weni/WeniGPT-2.2.1-Zephyr-7B-1-epoch-merged-LLM_Base_2.0.3_SFT": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Weni/WeniGPT-2.2.1-Zephyr-7B-1-epoch-merged-LLM_Base_2.0.3_SFT-AWQ": [
    "model.safetensors"
  ],
  "mayflowergmbh/DiscoPhoenix-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "alnrg2arg/blockchainlabs_7B_merged_test2_4_prune_sft_4bit_DPO_orca": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "nisso22/llama": [
    "checkpoint-170/adapter_model.safetensors",
    "model.safetensors"
  ],
  "BarryFutureman/WildMarcoroni-Variant1-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "BarryFutureman/WildMarcoroni-Variant2-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "liminerity/Ingot-7b-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "abacusai/MM-OV-bagel-DPO-34b-c1000-250": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "BarryFutureman/WildMarcoroni-Variant3-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Weyaxi/Einstein-openchat-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "maidacundo/text2sql_phi_molora": [
    "model.safetensors"
  ],
  "christa147/fine-tuned-recipes": [
    "model.safetensors"
  ],
  "liminerity/Ingot-7b-slerp-2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mayflowergmbh/GermanDare-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "cris177/Orca-Hermes-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "tali1/autotrain-gpt2-gpu1": [
    "adapter_model.safetensors",
    "checkpoint-141/adapter_model.safetensors"
  ],
  "christa147/recipes": [
    "model.safetensors"
  ],
  "liminerity/Ingot-7b-slerp-3": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "HeydarS/opt-350m_no_peft_v3": [
    "model.safetensors"
  ],
  "liminerity/Ingot-7b-slerp-4": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ToastyPigeon/Hermaid-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "liminerity/Ingot-7b-slerp-5": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "liminerity/Ingot-7b-slerp-6": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "HeydarS/opt-350m_no_peft_v1": [
    "model.safetensors"
  ],
  "MaziyarPanahi/Mistral-7B-Instruct-guidance-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "tali1/autotrain-gpt2-gpu3": [
    "adapter_model.safetensors",
    "checkpoint-159/adapter_model.safetensors"
  ],
  "AIFT/AIFT-ko-orca-plat-Yi-ko-6b-v1.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AIFT/AIFT-ko-orca-plat-Yi-ko-6b-v1.2-dpo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/KAI-7B-Instruct-v0.1-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "JaeyeonKang/CCK_gony": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "MaziyarPanahi/openbuddy-zephyr-7b-v14.1-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "Bsbell21/llm_instruction_generator_mistral": [
    "model.safetensors"
  ],
  "alnrg2arg/blockchainlabs_7B_merged_test2_4_sft_4bit": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "mncai/Mistral-7B-Instruct-v0.2-NWS-KoOrca-5k-LaAdMoAlQn100-pq": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/japanese-stablelm-instruct-gamma-7b-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "liminerity/Ingot-7b-slerp-7-forged": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/mistral-ft-optimized-1227-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "Locutusque/TinyMistral-248M-v2.5": [
    "model.safetensors"
  ],
  "MaziyarPanahi/zephyr-7b-sft-full-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "222limin/Ingot-7b-slerp-7-forged-mirror": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "KimByeongSu/gpt-neo-125m-lama-finetuning": [
    "model.safetensors"
  ],
  "MaziyarPanahi/Ferret_7B-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "samwoof/negated-sentiment-gpt-v1": [
    "model.safetensors"
  ],
  "tavtav/mistral-7B-markdown-chat-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/Synatra-V0.1-7B-Instruct-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "NLUHOPOE/Mistral-test-case-3": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "MaziyarPanahi/Yarn-Mistral-7b-64k-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "jsfs11/WildMBXMarconi-SLERP-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "cnut1648/Mistral-7B-fingerprinted-SFT-AlpacaGPT4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "PetroGPT/WestSeverus-7B-DPO": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hfl/chinese-mixtral": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "hfl/chinese-mixtral-instruct": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "cnut1648/Amber-7B-fingerprinted-SFT": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/GreenNode-mini-7B-v1olet-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "cnut1648/Amber-7B-fingerprinted-SFT-AlpacaGPT4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Sesgaro/picin_assist": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/notus-7b-v1-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "MaziyarPanahi/MetaMath-Mistral-7B-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "Wanfq/fusechat_v1_multi_teacher_fnan_ckpt": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Wanfq/fusechat_v1_nous_hermes_solar_teacher_fnan_ckpt": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "HeydarS/opt-1.3b_no_peft_v2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/mistral-ft-optimized-1218-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "Sharathhebbar24/math_gpt2_sft": [
    "model.safetensors"
  ],
  "starsnatched/MemGPT": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/Synatra-7B-v0.3-RP-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "G-reen/TheatreLM-m7b-v1.0-chat": [
    "model.safetensors"
  ],
  "openvoid/LexHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "BarryFutureman/ChatMarc-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kesamet/opt-125m-AWQ": [
    "model.safetensors"
  ],
  "Josephgflowers/Cinder-1.3B-Test": [
    "model.safetensors"
  ],
  "OpenBuddy/openbuddy-mixtral-7bx8-v17.1-32k": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "MaziyarPanahi/neural-chat-7b-v3-3-Slerp-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "MaziyarPanahi/ANIMA-Phi-Neptune-Mistral-7B-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "macadeliccc/SOLAR-10.7b-Instruct-dpo": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "MaziyarPanahi/neural-chat-7b-v3-2-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-keys_to_pipps_all-3e-4": [
    "model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-keys_to_pipps_2913-3e-4": [
    "model.safetensors"
  ],
  "LoneStriker/openbuddy-deepseek-10b-v17.1-4k-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/openbuddy-deepseek-10b-v17.1-4k-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "MaziyarPanahi/Tess-XS-v1-3-yarn-128K-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "LoneStriker/openbuddy-deepseek-10b-v17.1-4k-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/openbuddy-deepseek-10b-v17.1-4k-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/openbuddy-deepseek-10b-v17.1-4k-8.0bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "shiontendon/0.13B-mC4ja-75-10k": [
    "model.safetensors"
  ],
  "MaziyarPanahi/speechless-code-mistral-7b-v1.0-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "jungyuko/DAVinCI-Yi-Ko-6B-v0.61-ff-e1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Benson/Mixtral-8x7B-Instruct-v0.1-finetuned": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "jsfs11/TurdusTrixBeagle-DARETIES-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/NeuralHermes-2.5-Mistral-7B-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "vanillaOVO/supermario_v1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jan-hq/LlamaCorn-1.1B-Chat": [
    "model.safetensors"
  ],
  "microdev1/autotrain1": [
    "adapter_model.safetensors",
    "checkpoint-22/adapter_model.safetensors"
  ],
  "MaziyarPanahi/v1olet_marcoroni-go-bruins-merge-7B-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "KimByeongSu/gpt-neo-1.3B-cs-finetuning": [
    "model.safetensors"
  ],
  "MaziyarPanahi/koOpenChat-sft-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "HexawareTech/phi2-base-model": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "andysalerno/openchat-nectar-0.17": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/go-bruins-v2-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "thobuiq/openhermes-mistral-dpo-gptq": [
    "model.safetensors"
  ],
  "andykcheng/colorist-v2-merged": [
    "model.safetensors"
  ],
  "Sharathhebbar24/chat_gpt2_dpo": [
    "model.safetensors"
  ],
  "MaziyarPanahi/SciPhi-Mistral-7B-32k-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "srihariEmids/phi-2-finetuned-emids-text": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Crystalcareai/CrystalMistral-EvolOrca-Merge": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "AshishK/AK-openhathi-gptq-4bit": [
    "model.safetensors"
  ],
  "Rageshhf/mistral_inference_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "alnrg2arg/blockchainlabs_7B_merged_test2_4_sft_4bit_DPO_orca": [
    "model.safetensors"
  ],
  "hhs8746/sftest1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Liangmingxin/ThetaWave-7B-sft": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "merge-tester-31256/Mage-13b": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "MaziyarPanahi/una-cybertron-7b-v2-bf16-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "greyfoss/simple-gpt-doupo": [
    "model.safetensors"
  ],
  "shyamsubbu/nso_Mistral-7B-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dlibf/zephyr-7b-sft-full_epoch3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "philimon/tinyllama-colorist-lora": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "mayflowergmbh/Wiedervereinigung-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "philimon/tinyllama-colorist-v2": [
    "model.safetensors"
  ],
  "Geksaida/llama-2-7b-SysML_test2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rombodawg/Everyone-Coder-33b-Base": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "MaziyarPanahi/neural-chat-7b-v3-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "MaziyarPanahi/MetaMath-Cybertron-Starling-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "domie/Viviana_v1": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Athuin/tinyMedLlama": [
    "model.safetensors"
  ],
  "MaziyarPanahi/OpenHermes-2.5-neural-chat-7b-v3-1-7B-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "OpenSeneca/Seneca-50B-MoE-Chain-20240124": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "MaziyarPanahi/mindy-7b-v2-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "avemio-digital/SauerSci_Merge": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "croissantllm/CroissantLLMChat-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Nakul5202/my-project": [
    "checkpoint-3/model.safetensors",
    "model.safetensors"
  ],
  "croissantllm/tinyllamaChat-v0.1": [
    "model.safetensors"
  ],
  "adamo1139/Yi-34B-200K-AEZAKMI-RAW-2301": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "MaziyarPanahi/blossom-v3-mistral-7b-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "MaziyarPanahi/openbuddy-mistral-7b-v13.1-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "seyf1elislam/neural-Kunoichi2-7B-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ayoubkirouane/Mistral-SLERP-Merged7B-DPO": [
    "adapter_model.safetensors"
  ],
  "MaziyarPanahi/openbuddy-mistral-7b-v13-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "avemio-digital/SciSauer_Merge": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "ondevicellm/tinyllama_mole_sftv2_ultrachat_ep3": [
    "model.safetensors"
  ],
  "MaziyarPanahi/mamba-gpt-7b-v2-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "MaziyarPanahi/OpenHermes-7B-Symbolic-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "MILVLG/imp-v1-3b": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "teddy-f-47/phi-2-pl-v_0_1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "DenisTheDev/Hannah-DPO-Test": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "MaziyarPanahi/blossom-v3_1-mistral-7b-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "WintWealth/OpenHermes_ApricotTangerineScallop_HF_8_GPTQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/mamba-gpt-7b-v1-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "MaziyarPanahi/openbuddy-mistral-7b-v13-base-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "MaziyarPanahi/testllm-c2-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "FelixChao/WestSeverus-7B-DPO-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/PiVoT-10.7B-Mistral-v0.2-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "Wanfq/fusechat_v1_nous_hermes_mixtral_teacher_fnan_ckpt": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "andysalerno/openchat-nectar-0.18": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/SciPhi-Self-RAG-Mistral-7B-32k-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "lxyuan/AeolusBlend-7B-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/Mini_DPO_test02-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "MaziyarPanahi/Dans-07YahooAnswers-7b-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "huangyt/Mistral-7B-Instruct-v0.2-ccp4-r16-q_v_k_o_gate_down_up-2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "alkahestry/light-emory": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "MaziyarPanahi/pic_7B_mistral_Full_v0.2-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "Andrewwwwww/Mixtral-8x7B-Instruct-v0.1": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "Kooten/Buttercup-4x7B-4bpw-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Kooten/Buttercup-4x7B-5bpw-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Kooten/Buttercup-4x7B-6bpw-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "haris001/scv3": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "ayoubkirouane/Mistral-Depth-UP-Scaled-9B-AlpacaInstruct": [
    "adapter_model.safetensors"
  ],
  "MaziyarPanahi/Mistral-7B-v0.1-Open-Platypus-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "tifosi1709/codellama-7b-instruct-ft": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "XanderJC/phi2-sft-tldr-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/PiVoT-0.1-early-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "Augustya07/Llama-2-7b-chat-hf-sft-test-push": [
    "model.safetensors"
  ],
  "DopeorNope/Ko-Mixtral-v1.3-MoE-7Bx2": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "MaziyarPanahi/Venomia-1.1-m7-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "blueapple8259/TinyCode-python": [
    "model.safetensors"
  ],
  "Heithem777/NeuralPipe-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "kd-shared/secret-dpo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/shisa-7b-v1-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "mlabonne/Darewin-7B-v2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mycode-lucky321/tinyllama-colorcode": [
    "model.safetensors"
  ],
  "MaziyarPanahi/mistral-7b-finetuned-orca-dpo-v2-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "mayflowergmbh/DiscoPhoenix-7B-dpo": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "cloudyu/Mixtral_7Bx5_MoE_30B_DPO": [
    "model-00001-of-00013.safetensors",
    "model-00002-of-00013.safetensors",
    "model-00003-of-00013.safetensors",
    "model-00004-of-00013.safetensors",
    "model-00005-of-00013.safetensors",
    "model-00006-of-00013.safetensors",
    "model-00007-of-00013.safetensors",
    "model-00008-of-00013.safetensors",
    "model-00009-of-00013.safetensors",
    "model-00010-of-00013.safetensors",
    "model-00011-of-00013.safetensors",
    "model-00012-of-00013.safetensors",
    "model-00013-of-00013.safetensors"
  ],
  "MaziyarPanahi/zephyr-beta-math-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "jungyuko/DAVinCI-42dot_LLM-PLM-1.3B-v0.63": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "RaviNaik/Llava-Phi2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/NyakuraV2.1-m7-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "404NotF0und/phi-2-project-lunar-training": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "predictionguard/neural-chat-logic": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/Mistral-7B-claude-instruct-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "hojzas/autotrain-llama-proj8": [
    "adapter_model.safetensors",
    "checkpoint-39/adapter_model.safetensors",
    "model.safetensors"
  ],
  "thobuiq/mistral-dpo": [
    "adapter_model.safetensors"
  ],
  "MaziyarPanahi/samantha-mistral-7b-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "MrezaPRZ/StarlingSQL": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Anthonyg5005/ReMM-v2.2-L2-13B-exl2": [
    "output.safetensors"
  ],
  "ND911/Lelantos-Noro-Lamia-Maid-7B-Slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "MaziyarPanahi/SynthIA-7B-v1.3-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "wizaye/DialoGPT-small-Rick-V1": [
    "model.safetensors"
  ],
  "MaziyarPanahi/em_german_leo_mistral-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "ashishkgpian/full_phi_final": [
    "model.safetensors"
  ],
  "PeterZentai/autotrain-icm7a-oc2qm": [
    "adapter_model.safetensors",
    "checkpoint-33/adapter_model.safetensors"
  ],
  "manzoorali29/TinyLlama_QA_RE_V1": [
    "model.safetensors"
  ],
  "mayflowergmbh/Wiedervereinigung-7b-dpo": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "yevheniimaslov/Mistral-7b-persuade": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "MaziyarPanahi/dolphin-2.0-mistral-7b-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "ibivibiv/bubo-bubo-13b": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "AlexWortega/v4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/jackalope-7b-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "zhengr/MixTAO-7Bx2-MoE-Instruct-v7.0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/mistral-7b_open_platypus-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "Rageshhf/mistral_instruct_inference_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/mistral-7b-v0.1-layla-v1-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "Aryanne/sheared-plus-westlake-nearest-50_75p": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "PhilBinder/ft-llama-2-13b-imp-sub-ps": [
    "adapter_model.safetensors",
    "checkpoint-100/adapter_model.safetensors"
  ],
  "TheBigBlender/EstopianMaid": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/Mistral-Trismegistus-7B-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "ByunByun/keyword_6words_0125": [
    "adapter_model.safetensors"
  ],
  "MaziyarPanahi/mistralopithecus-v1-dpo-7b-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "ashercn97/yay": [
    "model.safetensors"
  ],
  "bartowski/internlm2-math-7b-llama": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/Mistral-T5-7B-v1-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "MaziyarPanahi/samantha-1.2-mistral-7b-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "issafuad/safesign1": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "sonu2023/Vatax-NeuralHermes-2.5-Mistral-7B-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ychen/MistralEM-base": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/WestLake-7B-v2-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/WestLake-7B-v2-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "MaziyarPanahi/SynthIA-7B-v1.5-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "LoneStriker/WestLake-7B-v2-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/WestLake-7B-v2-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "Kamyar-zeinalipour/test": [
    "model.safetensors"
  ],
  "LoneStriker/WestLake-7B-v2-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "bartowski/internlm2-math-20b-llama": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "shivarama23/OpenHathi-7B-Hi-v0.1-Base-sharded-bf16-2GB": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "MaziyarPanahi/CollectiveCognition-v1.1-Mistral-7B-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "shivarama23/OpenHathi-7B-Hi-v0.1-Base-sharded-bf16-1GB": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "Weyaxi/Draco-8x7B": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "motherduckdb/DuckDB-NSQL-7B-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/Mini_Synatra_SFT-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "sabayo/Marcaps-GPT-ft": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "bcijo/myMistral7b-finetuned": [
    "adapter_model.safetensors",
    "checkpoint-127/adapter_model.safetensors"
  ],
  "MaziyarPanahi/speechless-code-mistral-orca-7b-v1.0-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "ashercn97/avi-1.1b": [
    "model.safetensors"
  ],
  "MaziyarPanahi/samantha-mistral-instruct-7b-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "lex-hue/LexGPT-V1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "batmac/zephyr-7b-beta-mlx-4bit": [
    "model.safetensors"
  ],
  "MaziyarPanahi/Mistral-7B-model_45k6e2e4-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "kingabzpro/phi-2-role-play": [
    "adapter_model.safetensors"
  ],
  "crumb/ParaLlama-p-small": [
    "model.safetensors"
  ],
  "MaziyarPanahi/CollectiveCognition-v1-Mistral-7B-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "mii-llm/maestrale-chat-v0.2-alpha": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "NexaAI/my-fine-tuned-model-ppo": [
    "model.safetensors"
  ],
  "issafuad/mistral-7b-base": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/SynthIA-7B-v1.3-dare-0.85-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "dev137/NousResearch_Nous-Capybara-34B-exl2-3bpw-h8": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/CollectiveCognition-v1.1-Mistral-7B-dare-0.85-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "Manolo26/metis-chat-7b": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Augustya07/Llama-2-7b-chat-hf-sft-test-push_2": [
    "model.safetensors"
  ],
  "TheBloke/WestSeverus-7B-DPO-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/WestSeverus-7B-DPO-AWQ": [
    "model.safetensors"
  ],
  "macadeliccc/TheCorso-7b-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/Mini_synatra_7b_02-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "dev137/NousResearch_Nous-Capybara-34B-exl2-3.75bpw-h8": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/neural-chat-7b-v3-1-dare-0.85-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "TheBloke/WestLake-7B-v2-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/WestLake-7B-v2-AWQ": [
    "model.safetensors"
  ],
  "FPHam/Sarah_StoryTeller_13b-GPTQ": [
    "model.safetensors"
  ],
  "freecs/ThetaWave-14B-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "nbeerbower/bruphin-epsilon": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ericpolewski/TacoBeLLM": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "grimulkan/Xwin-longLORA-70b-rope8-32k-fp16": [
    "model-00001-of-00035.safetensors",
    "model-00002-of-00035.safetensors",
    "model-00003-of-00035.safetensors",
    "model-00004-of-00035.safetensors",
    "model-00005-of-00035.safetensors",
    "model-00006-of-00035.safetensors",
    "model-00007-of-00035.safetensors",
    "model-00008-of-00035.safetensors",
    "model-00009-of-00035.safetensors",
    "model-00010-of-00035.safetensors",
    "model-00011-of-00035.safetensors",
    "model-00012-of-00035.safetensors",
    "model-00013-of-00035.safetensors",
    "model-00014-of-00035.safetensors",
    "model-00015-of-00035.safetensors",
    "model-00016-of-00035.safetensors",
    "model-00017-of-00035.safetensors",
    "model-00018-of-00035.safetensors",
    "model-00019-of-00035.safetensors",
    "model-00020-of-00035.safetensors",
    "model-00021-of-00035.safetensors",
    "model-00022-of-00035.safetensors",
    "model-00023-of-00035.safetensors",
    "model-00024-of-00035.safetensors",
    "model-00025-of-00035.safetensors",
    "model-00026-of-00035.safetensors",
    "model-00027-of-00035.safetensors",
    "model-00028-of-00035.safetensors",
    "model-00029-of-00035.safetensors",
    "model-00030-of-00035.safetensors",
    "model-00031-of-00035.safetensors",
    "model-00032-of-00035.safetensors",
    "model-00033-of-00035.safetensors",
    "model-00034-of-00035.safetensors",
    "model-00035-of-00035.safetensors"
  ],
  "MaziyarPanahi/speechless-code-mistral-7b-v2.0-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "MohamedAhmedAE/codeparrot": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "dannysemi/Mixtral-8x7B-v0.1-GPTQ": [
    "model.safetensors"
  ],
  "grimulkan/Goliath-longLORA-120b-rope8-32k-fp16": [
    "model-00001-of-00025.safetensors",
    "model-00002-of-00025.safetensors",
    "model-00003-of-00025.safetensors",
    "model-00004-of-00025.safetensors",
    "model-00005-of-00025.safetensors",
    "model-00006-of-00025.safetensors",
    "model-00007-of-00025.safetensors",
    "model-00008-of-00025.safetensors",
    "model-00009-of-00025.safetensors",
    "model-00010-of-00025.safetensors",
    "model-00011-of-00025.safetensors",
    "model-00012-of-00025.safetensors",
    "model-00013-of-00025.safetensors",
    "model-00014-of-00025.safetensors",
    "model-00015-of-00025.safetensors",
    "model-00016-of-00025.safetensors",
    "model-00017-of-00025.safetensors",
    "model-00018-of-00025.safetensors",
    "model-00019-of-00025.safetensors",
    "model-00020-of-00025.safetensors",
    "model-00021-of-00025.safetensors",
    "model-00022-of-00025.safetensors",
    "model-00023-of-00025.safetensors",
    "model-00024-of-00025.safetensors",
    "model-00025-of-00025.safetensors"
  ],
  "MaziyarPanahi/WizardMath-7B-V1.1-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "TheBloke/FusionNet_34Bx2_MoE-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/FusionNet_34Bx2_MoE-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "viggneshk/autotrain-2ryiu-4fvom": [
    "adapter_model.safetensors",
    "checkpoint-12/adapter_model.safetensors"
  ],
  "MaziyarPanahi/airoboros-m-7b-3.1.2-dare-0.85-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "oivlisnet/Llama-2-7b-chat-alpaca-pt-br": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "MaziyarPanahi/zephyr-7b-alpha-dare-0.85-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "deepakachu/llama-2-7b-MEDMATCH-1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/smartyplats-7b-v2-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "sosoai/Orion-14B-Chat-safetensors": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kwchoi/DPO_mistral_7b_alpaca_0124_v1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "k1rby/BeaglePipe-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "MaziyarPanahi/LeoScorpius-7B-Chat-DPO-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "sosoai/Orion-14B-Chat-RAG-safetensors": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/Mistral-7B-golden-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "kwchoi/DPO_mistral_7b_ultra_0124_v1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Elizezen/Nocturn-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TeeZee/DarkForest-20B-v1.0-bpw8.0-h8-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "SJ-Donald/SJ-SOLAR-10.7b-DPO": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "MaziyarPanahi/Mistral-ko-7B-v0.1-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "MaziyarPanahi/una-cybertron-7b-v3-OMA-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "MaziyarPanahi/v1olet_merged_dpo_7B-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "empty-michael/cfg4.4-small": [
    "model.safetensors"
  ],
  "dddsaty/OPEN_SOLAR_KO_10.7B_DPO_Adapter_Attach": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "liminerity/Mem-Beagle-7b-slerp-v1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "adamo1139/yi-34b-200k-rawrr-dpo-2": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "andysalerno/openchat-nectar-0.19": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SF-Foundation/Mistral-7b-instruct-v0.2-summ-dpo-ed2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "netcat420/MHENN3.5": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "stash/autotrain-w1smy-cea49": [
    "adapter_model.safetensors",
    "checkpoint-12/adapter_model.safetensors"
  ],
  "liminerity/Mem-Beagle-7b-slerp-v2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jilp00/youtoks-transformers-united-v2-7B-v02": [
    "model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-keys_to_pipps_2913-1e-4": [
    "model.safetensors"
  ],
  "liminerity/Mem-Beagle-7b-slerp-v3": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Edentns/DataVortexS-10.7B-dpo-v1.2": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "jacksunwei/llama2_ag_news_causal": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "daxiongshu/Pluto_24B_DPO_63": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-keys_to_pipps_all-1e-4": [
    "model.safetensors"
  ],
  "TheBloke/Everyone-Coder-33B-Base-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/Everyone-Coder-33B-Base-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "nbeerbower/SuperBruphin-3x7B": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "obrmmk/tinycodellama-jp-0.6b-30k-v2-instruct3-CSN": [
    "model.safetensors"
  ],
  "obrmmk/tinycodellama-jp-0.6b-30k-v2-instruct3-JCSN-15k": [
    "model.safetensors"
  ],
  "ba8im/phi-2-bash": [
    "adapter_model.safetensors",
    "checkpoint-6/adapter_model.safetensors"
  ],
  "abacusai/MetaMath-Bagel-DPO-34B": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "Benson/opt-125m-awq": [
    "model.safetensors"
  ],
  "EddyGiusepe/tinyllama-ItauPortuguese-lora": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "ronluvzu1/autotrain-zb40r-1ccvc": [
    "adapter_model.safetensors",
    "checkpoint-129/adapter_model.safetensors"
  ],
  "leejuhyoeng/git-base-mathproplems2": [
    "model.safetensors"
  ],
  "jilp00/youtoks-transformers-united-v2-10.7B-v02": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "argilla/phi2-lora-distilabel-intel-orca-dpo-pairs": [
    "adapter_model.safetensors"
  ],
  "Wanfq/fusechat_v1_multi_teacher_woref_fnan_ckpt": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Steelskull/Umbra-v2.1-MoE-4x10.7": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "ITT-AF/ITT-Yi-Ko-6B-v1.0": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ibivibiv/aegolius-acadicus-v1-30b": [
    "model-00001-of-00025.safetensors",
    "model-00002-of-00025.safetensors",
    "model-00003-of-00025.safetensors",
    "model-00004-of-00025.safetensors",
    "model-00005-of-00025.safetensors",
    "model-00006-of-00025.safetensors",
    "model-00007-of-00025.safetensors",
    "model-00008-of-00025.safetensors",
    "model-00009-of-00025.safetensors",
    "model-00010-of-00025.safetensors",
    "model-00011-of-00025.safetensors",
    "model-00012-of-00025.safetensors",
    "model-00013-of-00025.safetensors",
    "model-00014-of-00025.safetensors",
    "model-00015-of-00025.safetensors",
    "model-00016-of-00025.safetensors",
    "model-00017-of-00025.safetensors",
    "model-00018-of-00025.safetensors",
    "model-00019-of-00025.safetensors",
    "model-00020-of-00025.safetensors",
    "model-00021-of-00025.safetensors",
    "model-00022-of-00025.safetensors",
    "model-00023-of-00025.safetensors",
    "model-00024-of-00025.safetensors",
    "model-00025-of-00025.safetensors"
  ],
  "thanhdaonguyen/night-time-v1.0": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "khanhnto/kyt-goat-20b": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "SanjiWatsuki/zephyrnt-3.8b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "perceptron-soup/NeuralHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lightyear-turing/TuringMM-34B-Chat": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "jeiku/longtest": [
    "model-00001-of-00001.safetensors"
  ],
  "Andrewwwwww/Mistral-7B-Instruct-v0.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LMX20012010/mistral_7b_guanaco": [
    "model.safetensors"
  ],
  "alnrg2arg/test_2_4_prune2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Sayan01/BabyVicuna-l": [
    "model.safetensors"
  ],
  "alnrg2arg/blockchainlabs_7B_merged_test2_4_sft_4bit_DPO_orca2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "jsfs11/SnorkelWestBeagle-DARETIES-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "cloudyu/Truthful_DPO_TomGrc_FusionNet_34Bx2_MoE": [
    "model-00001-of-00025.safetensors",
    "model-00002-of-00025.safetensors",
    "model-00003-of-00025.safetensors",
    "model-00004-of-00025.safetensors",
    "model-00005-of-00025.safetensors",
    "model-00006-of-00025.safetensors",
    "model-00007-of-00025.safetensors",
    "model-00008-of-00025.safetensors",
    "model-00009-of-00025.safetensors",
    "model-00010-of-00025.safetensors",
    "model-00011-of-00025.safetensors",
    "model-00012-of-00025.safetensors",
    "model-00013-of-00025.safetensors",
    "model-00014-of-00025.safetensors",
    "model-00015-of-00025.safetensors",
    "model-00016-of-00025.safetensors",
    "model-00017-of-00025.safetensors",
    "model-00018-of-00025.safetensors",
    "model-00019-of-00025.safetensors",
    "model-00020-of-00025.safetensors",
    "model-00021-of-00025.safetensors",
    "model-00022-of-00025.safetensors",
    "model-00023-of-00025.safetensors",
    "model-00024-of-00025.safetensors",
    "model-00025-of-00025.safetensors"
  ],
  "chenhugging/yi-34b-merge-slerp-v1": [
    "model-00001-of-00036.safetensors",
    "model-00002-of-00036.safetensors",
    "model-00003-of-00036.safetensors",
    "model-00004-of-00036.safetensors",
    "model-00005-of-00036.safetensors",
    "model-00006-of-00036.safetensors",
    "model-00007-of-00036.safetensors",
    "model-00008-of-00036.safetensors",
    "model-00009-of-00036.safetensors",
    "model-00010-of-00036.safetensors",
    "model-00011-of-00036.safetensors",
    "model-00012-of-00036.safetensors",
    "model-00013-of-00036.safetensors",
    "model-00014-of-00036.safetensors",
    "model-00015-of-00036.safetensors",
    "model-00016-of-00036.safetensors",
    "model-00017-of-00036.safetensors",
    "model-00018-of-00036.safetensors",
    "model-00019-of-00036.safetensors",
    "model-00020-of-00036.safetensors",
    "model-00021-of-00036.safetensors",
    "model-00022-of-00036.safetensors",
    "model-00023-of-00036.safetensors",
    "model-00024-of-00036.safetensors",
    "model-00025-of-00036.safetensors",
    "model-00026-of-00036.safetensors",
    "model-00027-of-00036.safetensors",
    "model-00028-of-00036.safetensors",
    "model-00029-of-00036.safetensors",
    "model-00030-of-00036.safetensors",
    "model-00031-of-00036.safetensors",
    "model-00032-of-00036.safetensors",
    "model-00033-of-00036.safetensors",
    "model-00034-of-00036.safetensors",
    "model-00035-of-00036.safetensors",
    "model-00036-of-00036.safetensors"
  ],
  "dvilasuero/DistilabelBeagle14-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mwitiderrick/TinyLlama-1.1B-Chat-v1.0-gsm8k": [
    "model.safetensors"
  ],
  "sethuiyer/Nandine-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "cognitivecomputations/TinyDolphin-2.8.1-1.1b": [
    "model.safetensors"
  ],
  "AIFT/AIFT-ko-orca-plat-Yi-ko-6b-v1.2-dpo-2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "CultriX/SevereNeuralBeagleTrix-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ShieldX/manovyadh-1.1B-v1": [
    "adapter_model.safetensors"
  ],
  "circulus/TinyLamb-truthy-dpo-v1": [
    "model.safetensors"
  ],
  "starsnatched/MemGPT-3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "liminerity/Mem-Beagle-7b-slerp-v4": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "fivetech/tinyMedical": [
    "model.safetensors"
  ],
  "etri-xainlp/llama2-13b-ko-pretrained-wiki": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "alnrg2arg/blockchainlabs_7B_merged_test2_4_sft_4bit_DPO_orca2_truthy": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "PipableAI/pip-SQL-7B": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "mmpc/phi-2-squad2-QA": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "thanhdaonguyen/night-time-20B-v1.0": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "liminerity/Mem-Beagle-7b-slerp-v6": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Stopwolf/Cerberus-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Edentns/DataVortexS-10.7B-dpo-v1.3": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "G-reen/TheatreLM-m7b-v1.0-DPO": [
    "model.safetensors"
  ],
  "jsfs11/WestOrcaNeural-V2-DARETIES-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "kanh1/kanha-0.1-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Shreyas0706/Zephyr-3B-Legal": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "PhilBinder/ft-llama-2-13b-imp-sub-ps-v1": [
    "adapter_model.safetensors",
    "checkpoint-255/adapter_model.safetensors"
  ],
  "SiguienteGlobal/linguistica-instruct-es": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "llmixer/BigWeave-v12-90b": [
    "model-00001-of-00018.safetensors",
    "model-00002-of-00018.safetensors",
    "model-00003-of-00018.safetensors",
    "model-00004-of-00018.safetensors",
    "model-00005-of-00018.safetensors",
    "model-00006-of-00018.safetensors",
    "model-00007-of-00018.safetensors",
    "model-00008-of-00018.safetensors",
    "model-00009-of-00018.safetensors",
    "model-00010-of-00018.safetensors",
    "model-00011-of-00018.safetensors",
    "model-00012-of-00018.safetensors",
    "model-00013-of-00018.safetensors",
    "model-00014-of-00018.safetensors",
    "model-00015-of-00018.safetensors",
    "model-00016-of-00018.safetensors",
    "model-00017-of-00018.safetensors",
    "model-00018-of-00018.safetensors"
  ],
  "vilm/Mixsmol-4x400M-v0.1-epoch1": [
    "model.safetensors"
  ],
  "Steelskull/VerA-Etheria-55b": [
    "model-00001-of-00012.safetensors",
    "model-00002-of-00012.safetensors",
    "model-00003-of-00012.safetensors",
    "model-00004-of-00012.safetensors",
    "model-00005-of-00012.safetensors",
    "model-00006-of-00012.safetensors",
    "model-00007-of-00012.safetensors",
    "model-00008-of-00012.safetensors",
    "model-00009-of-00012.safetensors",
    "model-00010-of-00012.safetensors",
    "model-00011-of-00012.safetensors",
    "model-00012-of-00012.safetensors"
  ],
  "liminerity/Mem-Beagle-7b-slerp-v7": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LBK95/Mistral-7B-DPO": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "IlyasMoutawwakil/vicuna-7b-v1.5-awq-marlin": [
    "model.safetensors"
  ],
  "tavtav/mistral-test-model3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "katydeng/katy_v3": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "LoneStriker/Everyone-Coder-33b-Base-3.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Steelskull/VerB-Etheria-55b": [
    "model-00001-of-00012.safetensors",
    "model-00002-of-00012.safetensors",
    "model-00003-of-00012.safetensors",
    "model-00004-of-00012.safetensors",
    "model-00005-of-00012.safetensors",
    "model-00006-of-00012.safetensors",
    "model-00007-of-00012.safetensors",
    "model-00008-of-00012.safetensors",
    "model-00009-of-00012.safetensors",
    "model-00010-of-00012.safetensors",
    "model-00011-of-00012.safetensors",
    "model-00012-of-00012.safetensors"
  ],
  "LoneStriker/Everyone-Coder-33b-Base-4.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/Everyone-Coder-33b-Base-4.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "lawful-good-project/llama-2-7b-ipc": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Jimmyhd/oneTextCol": [
    "checkpoint-300/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Everyone-Coder-33b-Base-5.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "llmixer/BigWeave-v12-90b-4.0bpw-h8-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "LoneStriker/Everyone-Coder-33b-Base-6.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "obrmmk/tinycodellama-jp-0.6b-30k-v2-instruct-JCAdef-CSNmix-30k": [
    "model.safetensors"
  ],
  "LoneStriker/Everyone-Coder-33b-Base-8.0bpw-h8-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "elliotthwangmsa/KimLan-phi-2_zh": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/japanese-stablelm-base-gamma-7b-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "hcy5561/my_awesome_eli5_clm-model": [
    "model.safetensors"
  ],
  "yeniceriSGK/PiBrain-TinyLlama-V1": [
    "model.safetensors"
  ],
  "MaziyarPanahi/piano-medley-7b-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "MaziyarPanahi/zephykor-ko-beta-7b-chang-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "iamkhadke/nlp2sql": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "tweetyx/test": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Shivam22182/sql_py": [
    "model.safetensors"
  ],
  "crumb/ParaLlama-p-medium": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/Rabbit-7B-DPO-Chat-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "hcy5561/gpt2_distilbert": [
    "model.safetensors"
  ],
  "Shivam22182/sqlpy2": [
    "model.safetensors"
  ],
  "MaziyarPanahi/DPOpenHermes-7B-v2-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "MaziyarPanahi/typhoon-7b-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "Rageshhf/Mistral_instruct_FI": [
    "adapter_model.safetensors",
    "checkpoint-174/adapter_model.safetensors"
  ],
  "MaziyarPanahi/speechless-mistral-six-in-one-7b-orth-1.0-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "TromeroResearch/SciMistral-V1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ozayezerceli/TinyyLlama-1.1b-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "huangyt/Breeze-7B-Instruct-v0_1-ccp4-r16-q_v_k_o_gate_down_up-2": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "MaziyarPanahi/Synatra-7B-Instruct-v0.2-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "VincentG1234/Model_1_GPT2_random1000": [
    "model.safetensors"
  ],
  "VincentG1234/Model_2_GPT2_frenchdata": [
    "model.safetensors"
  ],
  "CultriX/OmniTrixAI": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors",
    "model-1.safetensors"
  ],
  "hcy5561/distilgpt2-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "Weni/WeniGPT-2.2.1-Zephyr-7B-merge-LLM_Base_2.0.3_SFT": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Rageshhf/Mistral_instruct_FIM": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/Mini_synatra_7b_03-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "hflserdaniel/chai_s7_bagel_FPR": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "MaziyarPanahi/Mistral-7B-KNUT-v0.2-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "slava-medvedev/zelensky-gpt2-125m": [
    "model.safetensors"
  ],
  "TachyHealthResearch/Mistral-7B-Instruct-v0.1-Medical-Finetune": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Weni/WeniGPT-2.2.1-Zephyr-7B-merge-LLM_Base_2.0.3_SFT-AWQ": [
    "model.safetensors"
  ],
  "vanillaOVO/supermario_v2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "drmworld/mistral-7b-mika-vi-chloe-v0.5-checkpoint-259": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Truthful_DPO_TomGrc_FusionNet_34Bx2_MoE-2.4bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/MRAI_synatra_7B_v1-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "fblgit/UNA-34BeagleSimpleMath-32K-v1": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "LoneStriker/Truthful_DPO_TomGrc_FusionNet_34Bx2_MoE-2.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "ImSakushi/nistraal-2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Truthful_DPO_TomGrc_FusionNet_34Bx2_MoE-3.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/Mini_synata_7b_011-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "giux78/zefiro-7b-sft-qlora-ITA-v0.5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Truthful_DPO_TomGrc_FusionNet_34Bx2_MoE-4.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "deepseek-ai/deepseek-coder-7b-base-v1.5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/LeoScorpius-GreenNode-Alpaca-7B-v1-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "kmfoda/gpt2-677m": [
    "model.safetensors"
  ],
  "LoneStriker/Truthful_DPO_TomGrc_FusionNet_34Bx2_MoE-5.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "Shooosh/Llama-2-13b-finetune-test2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "deepseek-ai/deepseek-coder-7b-instruct-v1.5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/agiin-13.6B-v0.1-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "LoneStriker/Truthful_DPO_TomGrc_FusionNet_34Bx2_MoE-6.0bpw-h6-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "cloudyu/Truthful_DPO_cloudyu_Mixtral_34Bx2_MoE_60B": [
    "model-00001-of-00025.safetensors",
    "model-00002-of-00025.safetensors",
    "model-00003-of-00025.safetensors",
    "model-00004-of-00025.safetensors",
    "model-00005-of-00025.safetensors",
    "model-00006-of-00025.safetensors",
    "model-00007-of-00025.safetensors",
    "model-00008-of-00025.safetensors",
    "model-00009-of-00025.safetensors",
    "model-00010-of-00025.safetensors",
    "model-00011-of-00025.safetensors",
    "model-00012-of-00025.safetensors",
    "model-00013-of-00025.safetensors",
    "model-00014-of-00025.safetensors",
    "model-00015-of-00025.safetensors",
    "model-00016-of-00025.safetensors",
    "model-00017-of-00025.safetensors",
    "model-00018-of-00025.safetensors",
    "model-00019-of-00025.safetensors",
    "model-00020-of-00025.safetensors",
    "model-00021-of-00025.safetensors",
    "model-00022-of-00025.safetensors",
    "model-00023-of-00025.safetensors",
    "model-00024-of-00025.safetensors",
    "model-00025-of-00025.safetensors"
  ],
  "KatyTheCutie/EstopianMaid-13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/LeoScorpius-GreenNode-Platypus-7B-v1-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "RhiannaLeslie/mistr_health_checker": [
    "adapter_model.safetensors"
  ],
  "MrezaPRZ/SFT": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ITT-AF/ITT-42dot_LLM-PLM-1.3B-v1.0": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/Mistral-7B-v0.1-sharded-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "wang7776/Llama-2-7b-chat-hf-20-attention-sparsity": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Zac-Nguyen/yi-cot": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "hotdogs/FelixChao_WestSeverus-7B-DPO-v2_openchat_openchat-3.5-1210": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "AbhiPemmaraju/gpt_model": [
    "model.safetensors"
  ],
  "SADATO/furniture_Wang": [
    "adapter_model.safetensors"
  ],
  "MaziyarPanahi/dolphin-2.6-mistral-7b-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "mm0070/discord-mihau": [
    "model.safetensors"
  ],
  "SADATO/cosmetic_Wang": [
    "adapter_model.safetensors"
  ],
  "zaq-hack/Orion-14B-LongChat-bpw600-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/Tulpar-7b-v2-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "artemx/russian-mistral": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "abacusai/Smaug-34B-v0.1": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "Bsbell21/LLMPromptGen-AI": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "MaziyarPanahi/Marcoroni-neural-chat-7B-v2-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "smangrul/hugcoder": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Bytes512/Nugget": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "MaziyarPanahi/OpenHermes-2.5-neural-chat-v3-3-Slerp-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "wang7776/vicuna-7b-v1.3-attention-sparsity-20": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/MelloGPT-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "anantg/Zephyr-7b-beta-merged": [
    "model.safetensors"
  ],
  "LoneStriker/Umbra-v2.1-MoE-4x10.7-2.4bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/MetaMath-Chupacabra-7B-v2.01-Slerp-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "wang7776/Mistral-7B-Instruct-v0.2-attention-sparsity-20": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "presencesw/vicuna-7b-v1.5": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/Umbra-v2.1-MoE-4x10.7-3.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/Umbra-v2.1-MoE-4x10.7-3.5bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/Metis-0.4-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "dvilasuero/DistilabeledHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MANMEET75/Zephyr-Bharti-Fine-Tuned": [
    "adapter_model.safetensors"
  ],
  "yihang7/phi-2-dpo-full-hydrox-safe": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "AswanthCManoj/azma-phi-2-instruct-structured-peft-merge": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Umbra-v2.1-MoE-4x10.7-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/Mistral-7b-FFT-Test3-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "LoneStriker/Umbra-v2.1-MoE-4x10.7-5.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "AmirShabani/Fine-tuned-Sentiment-GIT": [
    "model.safetensors"
  ],
  "Abhishek107/v4_network_tinyllama": [
    "model.safetensors"
  ],
  "LoneStriker/Umbra-v2.1-MoE-4x10.7-6.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "Azurro/APT3-1B-Instruct-v1": [
    "model.safetensors"
  ],
  "RatanRohith/NeuralPizza-WestSeverus-7B-Merge-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "MaziyarPanahi/MetaMath-Tulpar-7b-v2-Slerp-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "MaziyarPanahi/zephyr-7b-alpha-sharded-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "mehmetcanbudak/Mistral-7B-4x400M": [
    "model.safetensors"
  ],
  "OmBayus/turk-gpt": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors",
    "model.safetensors"
  ],
  "jeiku/RPGodzilla_3.43B": [
    "model-00001-of-00001.safetensors"
  ],
  "h2oai/h2o-danube-1.8b-chat": [
    "model.safetensors"
  ],
  "MaziyarPanahi/sqlcoder-7b-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "h2oai/h2o-danube-1.8b-sft": [
    "model.safetensors"
  ],
  "4lchemistX/mia-ggufv1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "MaziyarPanahi/MythoMist-7b-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "macadeliccc/SOLAR-10.7b-Instruct-truthy-dpo": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "VioletJockey/load-dataset-spanglsih-model": [
    "model.safetensors"
  ],
  "ozayezerceli/TinyLlamax2-1.1b": [
    "model-00001-of-00001.safetensors"
  ],
  "MaziyarPanahi/bagel-dpo-7b-v0.1-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "Kooten/EstopianMaid-13B-8bpw-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Kooten/EstopianMaid-13B-6bpw-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Kooten/EstopianMaid-13B-5bpw-exl2": [
    "output.safetensors"
  ],
  "Kooten/EstopianMaid-13B-4bpw-exl2": [
    "output.safetensors"
  ],
  "stmackcat/zepb-paragraphs-dt19022024-13-merged-padding-slide-r": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "JaeyeonKang/CCK_Gony_v3": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "AlekseyKorshuk/evol-codealpaca-v1-sft-4e-5": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/openchat_3.5-16k-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "JaeyeonKang/CCK-v2.0-DPO": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "khanhnto/kyt-sheep-20b": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "hbakrim/hierarchy_by_level_mistral_7b": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Bytes512/Nugget-Small": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "MaziyarPanahi/Mistral-7B-KNUT-v0.3-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "Yarofa/model_h100_v11": [
    "model.safetensors"
  ],
  "MaziyarPanahi/MetaMath-OpenHermes-2.5-neural-chat-v3-3-Slerp-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "StarfleetAI/polaris-small": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ozayezerceli/TinyLephyr-1.77b": [
    "model-00001-of-00001.safetensors"
  ],
  "MaziyarPanahi/Marcoroni-neural-chat-7B-v1-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "jeiku/General_Purpose_3B": [
    "model-00001-of-00001.safetensors"
  ],
  "MaziyarPanahi/SauerkrautLM-7b-HerO-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "verissimomanoel/zephyr-3b-jur": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/bagel-7b-v0.1-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "MaziyarPanahi/loyal-piano-m7-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "CultriX/CombinaTrix-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/Seraph-7B-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "MaziyarPanahi/Noromaid-7b-v0.1.1-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "ambrosfitz/neural-history-chat-v1.5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/Starling-LM-11B-alpha-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "taylorbollman/codeparrot-ds": [
    "model.safetensors"
  ],
  "MaziyarPanahi/Karen_TheEditor_V2_STRICT_Mistral_7B-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "appvoid/palmer-003": [
    "model.safetensors"
  ],
  "MaziyarPanahi/shisa-base-7b-v1-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "obrmmk/tinycodellama-jp-0.6b-30k-v2-instruct3-JCAdef-CSNmix-30k": [
    "model.safetensors"
  ],
  "Edentns/DataVortexS-10.7B-dpo-v1.4": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "devhyun88/hyun-mistral-7b-orca-platypus-refine": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/OpenZephyrChat-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "yoonyoon/kb_v4.1_FA": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "wklyb1/Mistral-7b-SFT-ChineseQ4": [
    "lora/adapter_model.safetensors",
    "lora/checkpoint-100/adapter_model.safetensors",
    "lora/checkpoint-1000/adapter_model.safetensors",
    "lora/checkpoint-10000/adapter_model.safetensors",
    "lora/checkpoint-10100/adapter_model.safetensors",
    "lora/checkpoint-10200/adapter_model.safetensors",
    "lora/checkpoint-10300/adapter_model.safetensors",
    "lora/checkpoint-10400/adapter_model.safetensors",
    "lora/checkpoint-10500/adapter_model.safetensors",
    "lora/checkpoint-10600/adapter_model.safetensors",
    "lora/checkpoint-10700/adapter_model.safetensors",
    "lora/checkpoint-10800/adapter_model.safetensors",
    "lora/checkpoint-10900/adapter_model.safetensors",
    "lora/checkpoint-1100/adapter_model.safetensors",
    "lora/checkpoint-11000/adapter_model.safetensors",
    "lora/checkpoint-11100/adapter_model.safetensors",
    "lora/checkpoint-11200/adapter_model.safetensors",
    "lora/checkpoint-11300/adapter_model.safetensors",
    "lora/checkpoint-11400/adapter_model.safetensors",
    "lora/checkpoint-11500/adapter_model.safetensors",
    "lora/checkpoint-11600/adapter_model.safetensors",
    "lora/checkpoint-11700/adapter_model.safetensors",
    "lora/checkpoint-11800/adapter_model.safetensors",
    "lora/checkpoint-11900/adapter_model.safetensors",
    "lora/checkpoint-1200/adapter_model.safetensors",
    "lora/checkpoint-12000/adapter_model.safetensors",
    "lora/checkpoint-12100/adapter_model.safetensors",
    "lora/checkpoint-12200/adapter_model.safetensors",
    "lora/checkpoint-12300/adapter_model.safetensors",
    "lora/checkpoint-12400/adapter_model.safetensors",
    "lora/checkpoint-12500/adapter_model.safetensors",
    "lora/checkpoint-12600/adapter_model.safetensors",
    "lora/checkpoint-12700/adapter_model.safetensors",
    "lora/checkpoint-12800/adapter_model.safetensors",
    "lora/checkpoint-12900/adapter_model.safetensors",
    "lora/checkpoint-1300/adapter_model.safetensors",
    "lora/checkpoint-13000/adapter_model.safetensors",
    "lora/checkpoint-13100/adapter_model.safetensors",
    "lora/checkpoint-13200/adapter_model.safetensors",
    "lora/checkpoint-13300/adapter_model.safetensors",
    "lora/checkpoint-13400/adapter_model.safetensors",
    "lora/checkpoint-13500/adapter_model.safetensors",
    "lora/checkpoint-13600/adapter_model.safetensors",
    "lora/checkpoint-13700/adapter_model.safetensors",
    "lora/checkpoint-13800/adapter_model.safetensors",
    "lora/checkpoint-13900/adapter_model.safetensors",
    "lora/checkpoint-1400/adapter_model.safetensors",
    "lora/checkpoint-14000/adapter_model.safetensors",
    "lora/checkpoint-14100/adapter_model.safetensors",
    "lora/checkpoint-14200/adapter_model.safetensors",
    "lora/checkpoint-14300/adapter_model.safetensors",
    "lora/checkpoint-14400/adapter_model.safetensors",
    "lora/checkpoint-14500/adapter_model.safetensors",
    "lora/checkpoint-14600/adapter_model.safetensors",
    "lora/checkpoint-14700/adapter_model.safetensors",
    "lora/checkpoint-14800/adapter_model.safetensors",
    "lora/checkpoint-14900/adapter_model.safetensors",
    "lora/checkpoint-1500/adapter_model.safetensors",
    "lora/checkpoint-15000/adapter_model.safetensors",
    "lora/checkpoint-15100/adapter_model.safetensors",
    "lora/checkpoint-15200/adapter_model.safetensors",
    "lora/checkpoint-15300/adapter_model.safetensors",
    "lora/checkpoint-15400/adapter_model.safetensors",
    "lora/checkpoint-15500/adapter_model.safetensors",
    "lora/checkpoint-15600/adapter_model.safetensors",
    "lora/checkpoint-15700/adapter_model.safetensors",
    "lora/checkpoint-15800/adapter_model.safetensors",
    "lora/checkpoint-15900/adapter_model.safetensors",
    "lora/checkpoint-1600/adapter_model.safetensors",
    "lora/checkpoint-16000/adapter_model.safetensors",
    "lora/checkpoint-16100/adapter_model.safetensors",
    "lora/checkpoint-16200/adapter_model.safetensors",
    "lora/checkpoint-16300/adapter_model.safetensors",
    "lora/checkpoint-16400/adapter_model.safetensors",
    "lora/checkpoint-16500/adapter_model.safetensors",
    "lora/checkpoint-16600/adapter_model.safetensors",
    "lora/checkpoint-16700/adapter_model.safetensors",
    "lora/checkpoint-16800/adapter_model.safetensors",
    "lora/checkpoint-16900/adapter_model.safetensors",
    "lora/checkpoint-1700/adapter_model.safetensors",
    "lora/checkpoint-17000/adapter_model.safetensors",
    "lora/checkpoint-17100/adapter_model.safetensors",
    "lora/checkpoint-17200/adapter_model.safetensors",
    "lora/checkpoint-17300/adapter_model.safetensors",
    "lora/checkpoint-17400/adapter_model.safetensors",
    "lora/checkpoint-17500/adapter_model.safetensors",
    "lora/checkpoint-17600/adapter_model.safetensors",
    "lora/checkpoint-17700/adapter_model.safetensors",
    "lora/checkpoint-17800/adapter_model.safetensors",
    "lora/checkpoint-17900/adapter_model.safetensors",
    "lora/checkpoint-1800/adapter_model.safetensors",
    "lora/checkpoint-18000/adapter_model.safetensors",
    "lora/checkpoint-18100/adapter_model.safetensors",
    "lora/checkpoint-18200/adapter_model.safetensors",
    "lora/checkpoint-18300/adapter_model.safetensors",
    "lora/checkpoint-18400/adapter_model.safetensors",
    "lora/checkpoint-18500/adapter_model.safetensors",
    "lora/checkpoint-18600/adapter_model.safetensors",
    "lora/checkpoint-18700/adapter_model.safetensors",
    "lora/checkpoint-18800/adapter_model.safetensors",
    "lora/checkpoint-18900/adapter_model.safetensors",
    "lora/checkpoint-1900/adapter_model.safetensors",
    "lora/checkpoint-200/adapter_model.safetensors",
    "lora/checkpoint-2000/adapter_model.safetensors",
    "lora/checkpoint-2100/adapter_model.safetensors",
    "lora/checkpoint-2200/adapter_model.safetensors",
    "lora/checkpoint-2300/adapter_model.safetensors",
    "lora/checkpoint-2400/adapter_model.safetensors",
    "lora/checkpoint-2500/adapter_model.safetensors",
    "lora/checkpoint-2600/adapter_model.safetensors",
    "lora/checkpoint-2700/adapter_model.safetensors",
    "lora/checkpoint-2800/adapter_model.safetensors",
    "lora/checkpoint-2900/adapter_model.safetensors",
    "lora/checkpoint-300/adapter_model.safetensors",
    "lora/checkpoint-3000/adapter_model.safetensors",
    "lora/checkpoint-3100/adapter_model.safetensors",
    "lora/checkpoint-3200/adapter_model.safetensors",
    "lora/checkpoint-3300/adapter_model.safetensors",
    "lora/checkpoint-3400/adapter_model.safetensors",
    "lora/checkpoint-3500/adapter_model.safetensors",
    "lora/checkpoint-3600/adapter_model.safetensors",
    "lora/checkpoint-3700/adapter_model.safetensors",
    "lora/checkpoint-3800/adapter_model.safetensors",
    "lora/checkpoint-3900/adapter_model.safetensors",
    "lora/checkpoint-400/adapter_model.safetensors",
    "lora/checkpoint-4000/adapter_model.safetensors",
    "lora/checkpoint-4100/adapter_model.safetensors",
    "lora/checkpoint-4200/adapter_model.safetensors",
    "lora/checkpoint-4300/adapter_model.safetensors",
    "lora/checkpoint-4400/adapter_model.safetensors",
    "lora/checkpoint-4500/adapter_model.safetensors",
    "lora/checkpoint-4600/adapter_model.safetensors",
    "lora/checkpoint-4700/adapter_model.safetensors",
    "lora/checkpoint-4800/adapter_model.safetensors",
    "lora/checkpoint-4900/adapter_model.safetensors",
    "lora/checkpoint-500/adapter_model.safetensors",
    "lora/checkpoint-5000/adapter_model.safetensors",
    "lora/checkpoint-5100/adapter_model.safetensors",
    "lora/checkpoint-5200/adapter_model.safetensors",
    "lora/checkpoint-5300/adapter_model.safetensors",
    "lora/checkpoint-5400/adapter_model.safetensors",
    "lora/checkpoint-5500/adapter_model.safetensors",
    "lora/checkpoint-5600/adapter_model.safetensors",
    "lora/checkpoint-5700/adapter_model.safetensors",
    "lora/checkpoint-5800/adapter_model.safetensors",
    "lora/checkpoint-5900/adapter_model.safetensors",
    "lora/checkpoint-600/adapter_model.safetensors",
    "lora/checkpoint-6000/adapter_model.safetensors",
    "lora/checkpoint-6100/adapter_model.safetensors",
    "lora/checkpoint-6200/adapter_model.safetensors",
    "lora/checkpoint-6300/adapter_model.safetensors",
    "lora/checkpoint-6400/adapter_model.safetensors",
    "lora/checkpoint-6500/adapter_model.safetensors",
    "lora/checkpoint-6600/adapter_model.safetensors",
    "lora/checkpoint-6700/adapter_model.safetensors",
    "lora/checkpoint-6800/adapter_model.safetensors",
    "lora/checkpoint-6900/adapter_model.safetensors",
    "lora/checkpoint-700/adapter_model.safetensors",
    "lora/checkpoint-7000/adapter_model.safetensors",
    "lora/checkpoint-7100/adapter_model.safetensors",
    "lora/checkpoint-7200/adapter_model.safetensors",
    "lora/checkpoint-7300/adapter_model.safetensors",
    "lora/checkpoint-7400/adapter_model.safetensors",
    "lora/checkpoint-7500/adapter_model.safetensors",
    "lora/checkpoint-7600/adapter_model.safetensors",
    "lora/checkpoint-7700/adapter_model.safetensors",
    "lora/checkpoint-7800/adapter_model.safetensors",
    "lora/checkpoint-7900/adapter_model.safetensors",
    "lora/checkpoint-800/adapter_model.safetensors",
    "lora/checkpoint-8000/adapter_model.safetensors",
    "lora/checkpoint-8100/adapter_model.safetensors",
    "lora/checkpoint-8200/adapter_model.safetensors",
    "lora/checkpoint-8300/adapter_model.safetensors",
    "lora/checkpoint-8400/adapter_model.safetensors",
    "lora/checkpoint-8500/adapter_model.safetensors",
    "lora/checkpoint-8600/adapter_model.safetensors",
    "lora/checkpoint-8700/adapter_model.safetensors",
    "lora/checkpoint-8800/adapter_model.safetensors",
    "lora/checkpoint-8900/adapter_model.safetensors",
    "lora/checkpoint-900/adapter_model.safetensors",
    "lora/checkpoint-9000/adapter_model.safetensors",
    "lora/checkpoint-9100/adapter_model.safetensors",
    "lora/checkpoint-9200/adapter_model.safetensors",
    "lora/checkpoint-9300/adapter_model.safetensors",
    "lora/checkpoint-9400/adapter_model.safetensors",
    "lora/checkpoint-9500/adapter_model.safetensors",
    "lora/checkpoint-9600/adapter_model.safetensors",
    "lora/checkpoint-9700/adapter_model.safetensors",
    "lora/checkpoint-9800/adapter_model.safetensors",
    "lora/checkpoint-9900/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/Optimus-7B-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "cognitivecomputations/WestLake-7B-v2-laser": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Berf4615/news-generator-tr": [
    "model.safetensors"
  ],
  "Wowso/SOLAR-Open-platypus-CC-Handy-10.7B-v1.0-awq": [
    "model.safetensors"
  ],
  "verissimomanoel/zephyr-1b-jur": [
    "model.safetensors"
  ],
  "MaziyarPanahi/Nebula-v2-7B-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "MaziyarPanahi/ANIMA-Nectar-v2-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "SF-Foundation/finetuned-autoevaluator-train2004-20240125-222616": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-keys_to_pipps_2913-1e-3": [
    "model.safetensors"
  ],
  "MaziyarPanahi/MistralInstructLongish-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "dlibf/zephyr-7b-dpo-full_sft3epoch": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/Mistral-11B-OmniMix-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "MaziyarPanahi/SlimOpenOrca-Mistral-7B-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "dlibf/zephyr-7b-dpo-full_sft2epoch": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jtatman/tinydolphin-2.8_1b-fortuna-alpaca-v2": [
    "model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-keys_to_pipps_all-1e-3": [
    "model.safetensors"
  ],
  "MaziyarPanahi/Velara-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "Yarofa/model_h100_v12": [
    "model.safetensors"
  ],
  "zxmonent/llava-phi": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/Kant-Test-0.1-Mistral-7B-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "Heng666/opt-125m-guanaco": [
    "model.safetensors"
  ],
  "cris177/DesivoMerge0.1": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "MaziyarPanahi/CatMacaroni-Slerp-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "starsnatched/MemGPT-DPO": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/Misted-7B-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "jsfs11/WONMSeverusDevil-TIES-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "NLUHOPOE/Mistral-test-case-1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "MaziyarPanahi/Dans-TotSirocco-7b-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "mwitiderrick/TinyLlama-1.1B-intermediate-step-1431k-3T-gsms8k": [
    "model.safetensors"
  ],
  "MaziyarPanahi/test-help-steer-filtered-orig-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "microdev1/autotrain3": [
    "checkpoint-68/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jjjlyn/prohunt-llama2-ko-7b": [
    "adapter_model.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Aryanne/Westest-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "NLUHOPOE/Mistral-test-case-2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "MaziyarPanahi/HermesStar-OrcaWind-Synth-11B-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "MaziyarPanahi/Mistral-11B-OmniMix9-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "asadmasad/test": [
    "model.safetensors"
  ],
  "MaziyarPanahi/OpenHermes-2.5-neural-chat-7b-v3-2-7B-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "Wowso/SOLAR-10.7B-dpo-v1-awq": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors",
    "model.safetensors"
  ],
  "joearul/codeparrot-ds": [
    "model.safetensors"
  ],
  "jtatman/tinymistral-v2-fortuna-chatml-therabot": [
    "model.safetensors"
  ],
  "NLUHOPOE/Mistral-test-case-4": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "DanielClough/Candle_phi-2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "DanielClough/Candle_phi-2_old": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "andysalerno/cloudymixtral_sft_7Bx2_MoE": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "MaziyarPanahi/juanako-7b-UNA-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "MaziyarPanahi/Dans-AdventurousWinds-Mk2-7b-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "LoneStriker/Smaugv0.1-3.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "smartsurfer/NeuralHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Plaban81/Moe-4x7b-math-reason-code": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "LoneStriker/Smaugv0.1-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/neural-chat-11b-v3-2-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "LoneStriker/Smaugv0.1-4.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "wiez-man/phi-1_5_FT_code_typescript_merged": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "abacusai/TheProfessor-155b": [
    "model-00001-of-00032.safetensors",
    "model-00002-of-00032.safetensors",
    "model-00003-of-00032.safetensors",
    "model-00004-of-00032.safetensors",
    "model-00005-of-00032.safetensors",
    "model-00006-of-00032.safetensors",
    "model-00007-of-00032.safetensors",
    "model-00008-of-00032.safetensors",
    "model-00009-of-00032.safetensors",
    "model-00010-of-00032.safetensors",
    "model-00011-of-00032.safetensors",
    "model-00012-of-00032.safetensors",
    "model-00013-of-00032.safetensors",
    "model-00014-of-00032.safetensors",
    "model-00015-of-00032.safetensors",
    "model-00016-of-00032.safetensors",
    "model-00017-of-00032.safetensors",
    "model-00018-of-00032.safetensors",
    "model-00019-of-00032.safetensors",
    "model-00020-of-00032.safetensors",
    "model-00021-of-00032.safetensors",
    "model-00022-of-00032.safetensors",
    "model-00023-of-00032.safetensors",
    "model-00024-of-00032.safetensors",
    "model-00025-of-00032.safetensors",
    "model-00026-of-00032.safetensors",
    "model-00027-of-00032.safetensors",
    "model-00028-of-00032.safetensors",
    "model-00029-of-00032.safetensors",
    "model-00030-of-00032.safetensors",
    "model-00031-of-00032.safetensors",
    "model-00032-of-00032.safetensors"
  ],
  "LoneStriker/Smaugv0.1-5.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/japanese-stablelm-instruct-gamma-7b-Mistral-7B-Instruct-v0.1-GGUF": [],
  "allenai/OLMo-1B": [
    "model.safetensors"
  ],
  "LoneStriker/Smaugv0.1-6.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "Eteims/my_awesome_eli5_clm-model": [
    "model.safetensors"
  ],
  "jtatman/tinydolphin-2.8_1b-fortuna-alpaca": [
    "model.safetensors"
  ],
  "LoneStriker/Smaugv0.1-8.0bpw-h8-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "obrmmk/tinycodellama-jp-0.6b-30k-v2-instruct4-JCAdef-CSNmix-30k": [
    "model.safetensors"
  ],
  "MaziyarPanahi/Falkor-7b-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "MaziyarPanahi/OpenHermes-2.5-neural-chat-v3-2-Slerp-Mistral-7B-Instruct-v0.2-slerp-GGUF": [],
  "Steelskull/Lumosia-v2-MoE-4x10.7": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "moosa-ai/llama2-qlora-finetunined-kra": [
    "adapter_model.safetensors"
  ],
  "jeevana/mistral7b_group8QnA_26janV01": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "epinnock/deepseek-coder-7b-evol-feedback": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/Synatra-7B-v0.3-dpo-Mistral-7B-Instruct-v0.1-GGUF": [],
  "sonthenguyen/OpenHermes-2.5-Mistral-7B-Nectar-Anthropic-hh-RankK17-Chatml": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ChuckMcSneed/DoubleGold-v0.5-123b-32k": [
    "model-00001-of-00026.safetensors",
    "model-00002-of-00026.safetensors",
    "model-00003-of-00026.safetensors",
    "model-00004-of-00026.safetensors",
    "model-00005-of-00026.safetensors",
    "model-00006-of-00026.safetensors",
    "model-00007-of-00026.safetensors",
    "model-00008-of-00026.safetensors",
    "model-00009-of-00026.safetensors",
    "model-00010-of-00026.safetensors",
    "model-00011-of-00026.safetensors",
    "model-00012-of-00026.safetensors",
    "model-00013-of-00026.safetensors",
    "model-00014-of-00026.safetensors",
    "model-00015-of-00026.safetensors",
    "model-00016-of-00026.safetensors",
    "model-00017-of-00026.safetensors",
    "model-00018-of-00026.safetensors",
    "model-00019-of-00026.safetensors",
    "model-00020-of-00026.safetensors",
    "model-00021-of-00026.safetensors",
    "model-00022-of-00026.safetensors",
    "model-00023-of-00026.safetensors",
    "model-00024-of-00026.safetensors",
    "model-00025-of-00026.safetensors",
    "model-00026-of-00026.safetensors"
  ],
  "DooDooHyun/AIFT-Yi-Ko-6B-ao-instruct-all-v0.64": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "MaziyarPanahi/Ferret_7B-Mistral-7B-Instruct-v0.1-GGUF": [],
  "epinnock/deepseek-coder-33-evol-feedback-v1-r512": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "cfahlgren1/natural-functions": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Sharathhebbar24/code_gpt2_mini_model": [
    "model.safetensors"
  ],
  "Spanicin/Fulcrum_Aura0": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "croissantllm/CroissantCool": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ShieldX/manovyadh-1.1B-v1-chat": [
    "model.safetensors"
  ],
  "AlekseyKorshuk/evol-codealpaca-v1-sft-4e-5-dpo-3ep": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Crystalcareai/CrystalMistral_7b_v.01": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/Synatra-V0.1-7B-Instruct-Mistral-7B-Instruct-v0.1-GGUF": [],
  "NovoCode/Novocode7b-v3": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "ycros/crunchy-onion-nx": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "ondevicellm/tinyllama_mole_dpo_ep3": [
    "model.safetensors"
  ],
  "MaziyarPanahi/Yarn-Mistral-7b-64k-Mistral-7B-Instruct-v0.1-GGUF": [],
  "cloudyu/Phoenix_DPO_60B": [
    "model-00001-of-00025.safetensors",
    "model-00002-of-00025.safetensors",
    "model-00003-of-00025.safetensors",
    "model-00004-of-00025.safetensors",
    "model-00005-of-00025.safetensors",
    "model-00006-of-00025.safetensors",
    "model-00007-of-00025.safetensors",
    "model-00008-of-00025.safetensors",
    "model-00009-of-00025.safetensors",
    "model-00010-of-00025.safetensors",
    "model-00011-of-00025.safetensors",
    "model-00012-of-00025.safetensors",
    "model-00013-of-00025.safetensors",
    "model-00014-of-00025.safetensors",
    "model-00015-of-00025.safetensors",
    "model-00016-of-00025.safetensors",
    "model-00017-of-00025.safetensors",
    "model-00018-of-00025.safetensors",
    "model-00019-of-00025.safetensors",
    "model-00020-of-00025.safetensors",
    "model-00021-of-00025.safetensors",
    "model-00022-of-00025.safetensors",
    "model-00023-of-00025.safetensors",
    "model-00024-of-00025.safetensors",
    "model-00025-of-00025.safetensors"
  ],
  "SanjiWatsuki/SUS-Wizard-34B": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "andysalerno/fusionmixtral_sft_7Bx2_MoE": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "karakuri-ai/karakuri-lm-70b-chat-v0.1": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "shidowake/swal-7B-base-bnb-4bit-chatml": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/mistral-ft-optimized-1218-Mistral-7B-Instruct-v0.1-GGUF": [],
  "Steelskull/Celestria-MoE-8x10.7b": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "thanhdaonguyen/night-time-34B-v1.0": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "Phanh2532/GAML-151-500": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "marianna13/openhermes-7b-llava-instruct-665k": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "leeeed/mistralai-qa-Instruct-Finetune-v02": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ThingsSolver/translate-instruct-merge": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "openagi-project/OpenAGI-7B-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "crypticvandal/NeuralPipe-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "karakuri-ai/karakuri-lm-70b-v0.1": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "Steelskull/Etheria-55b-v0.1": [
    "model-00001-of-00012.safetensors",
    "model-00002-of-00012.safetensors",
    "model-00003-of-00012.safetensors",
    "model-00004-of-00012.safetensors",
    "model-00005-of-00012.safetensors",
    "model-00006-of-00012.safetensors",
    "model-00007-of-00012.safetensors",
    "model-00008-of-00012.safetensors",
    "model-00009-of-00012.safetensors",
    "model-00010-of-00012.safetensors",
    "model-00011-of-00012.safetensors",
    "model-00012-of-00012.safetensors"
  ],
  "metamath/my_newstitle_model": [
    "model.safetensors"
  ],
  "KnutJaegersberg/SUS-Chat-72B-4bit": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "MaziyarPanahi/Tess-XS-v1-3-yarn-128K-Mistral-7B-Instruct-v0.2-GGUF": [],
  "Eteims/cfy_model_v1": [
    "model.safetensors"
  ],
  "simonycl/llama-2-7b-hf-multi-label-wos-epoch_3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "shrijayan/biogpt": [
    "model.safetensors"
  ],
  "Eteims/cfy_model_v2": [
    "model.safetensors"
  ],
  "AntoineGourru/Mistral_drome_full": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dvilasuero/Distilabel-Nous-Capybara-7B-V1.9": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "stmackcat/zepb-paragraphs-dt19022024-14-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "wiez-man/phi-1_5_FT_cs_to_ts_merged": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "MaziyarPanahi/GreenNode-mini-7B-multilingual-v1olet-Mistral-7B-Instruct-v0.1-GGUF": [],
  "NickyNicky/Mix_TinyLlama-3x1B_oasst2_chatML_Cluster_3_2_1_V1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "sabayo/Marcaps-GPT-ft-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "pszemraj/gpt2-medium-halved": [
    "model.safetensors"
  ],
  "ITT-AF/ITT-42dot_LLM-PLM-1.3B-v2.0": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ITT-AF/ITT-Yi-Ko-6B-v2.0": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "MehdiHosseiniMoghadam/NeuralHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "colable/llama-ko-peft": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "salmasally/esg-sally": [
    "adapter_model.safetensors",
    "checkpoint-10/adapter_model.safetensors"
  ],
  "MaziyarPanahi/zephyr-7b-sft-full-Mistral-7B-Instruct-v0.1-GGUF": [],
  "sweetpablo/code_baby_llama": [
    "model.safetensors"
  ],
  "jeevana/group8qna_gpt2__26janV001": [
    "model.safetensors"
  ],
  "MaziyarPanahi/notus-7b-v1-Mistral-7B-Instruct-v0.1-GGUF": [],
  "jeevana/G8_mistral7b_qlora_1211_v02": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "yhavinga/mistral-en-nl-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/MetaMath-Mistral-7B-Mistral-7B-Instruct-v0.1-GGUF": [],
  "Bytes512/Nugget-Boss": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "NorHsangPha/shan_gpt2": [
    "model.safetensors"
  ],
  "MaziyarPanahi/SciPhi-Mistral-7B-32k-Mistral-7B-Instruct-v0.1-GGUF": [],
  "JoshVictor/llama-2-7b-chat-hf-MEDCODEX": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "HHazard/llama2-13b-qodly": [
    "adapter_model.safetensors",
    "checkpoint-48/adapter_model.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "TheBloke/EstopianMaid-13B-GPTQ": [
    "model.safetensors"
  ],
  "TheBloke/EstopianMaid-13B-AWQ": [
    "model.safetensors"
  ],
  "MaziyarPanahi/Synatra-7B-v0.3-RP-Mistral-7B-Instruct-v0.1-GGUF": [],
  "TheBloke/Etheria-55b-v0.1-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/Etheria-55b-v0.1-GPTQ": [
    "model.safetensors"
  ],
  "LoneStriker/NeuralMarcoro14-7B-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/NeuralMarcoro14-7B-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "jarod0411/zinc10M_gpt2_SMILES_bpe_combined_step1_finetune": [
    "model.safetensors"
  ],
  "SiguienteGlobal/linguistica-instruct-awq": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/NeuralMarcoro14-7B-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/NeuralMarcoro14-7B-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "SF-Foundation/finetuned-autoevaluator-train8016-20240126-154052": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Enno-Ai/Hodeva-mix-7B-v2.3-awq": [
    "model.safetensors"
  ],
  "LoneStriker/NeuralMarcoro14-7B-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "hadrakey/gpt2-hh-sft": [
    "model.safetensors"
  ],
  "finetuningsubnet/tinyllamachat": [
    "model.safetensors"
  ],
  "alnrg2arg/test3_sft_16bit": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AItestaccount/LLMPromptGen-AI": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "alnrg2arg/test3_sft_4bit": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mmpc/phi-2-text": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ibivibiv/temp_tuned_mistral": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/deepseek-coder-7b-instruct-v1.5-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/deepseek-coder-7b-instruct-v1.5-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/deepseek-coder-7b-instruct-v1.5-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/deepseek-coder-7b-instruct-v1.5-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "Prateek/mayur_v0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/deepseek-coder-7b-instruct-v1.5-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "ibivibiv/aegolius-acadicus-24b-v2": [
    "model-00001-of-00020.safetensors",
    "model-00002-of-00020.safetensors",
    "model-00003-of-00020.safetensors",
    "model-00004-of-00020.safetensors",
    "model-00005-of-00020.safetensors",
    "model-00006-of-00020.safetensors",
    "model-00007-of-00020.safetensors",
    "model-00008-of-00020.safetensors",
    "model-00009-of-00020.safetensors",
    "model-00010-of-00020.safetensors",
    "model-00011-of-00020.safetensors",
    "model-00012-of-00020.safetensors",
    "model-00013-of-00020.safetensors",
    "model-00014-of-00020.safetensors",
    "model-00015-of-00020.safetensors",
    "model-00016-of-00020.safetensors",
    "model-00017-of-00020.safetensors",
    "model-00018-of-00020.safetensors",
    "model-00019-of-00020.safetensors",
    "model-00020-of-00020.safetensors"
  ],
  "prsdm/phi-2-medquad": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "WasdAbj/gpt2-imdb-pos-v2": [
    "model.safetensors"
  ],
  "shahzebnaveed/codeparrot-ds": [
    "model.safetensors"
  ],
  "colinw2292/Writer12": [
    "adapter_model.safetensors",
    "checkpoint-1158/adapter_model.safetensors"
  ],
  "mtc/meta-llama-Llama-2-7b-hf-pubmed-summarization-1000-finetuned-no-quantization": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mtc/meta-llama-Llama-2-7b-hf-arxiv-summarization-1000-finetuned-no_quantization": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mtc/meta-llama-Llama-2-7b-hf-pubmed-summarization-10000-finetuned-no-quantization": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jc3464/llama1_65b_hi_2bit": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "wang7776/Llama-2-7b-chat-hf-10-attention-sparsity": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "wang7776/Llama-2-7b-chat-hf-30-attention-sparsity": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/NeuralHermes-2.5-Mistral-7B-Mistral-7B-Instruct-v0.1-GGUF": [],
  "jc3464/llama1_30b_hi_2bit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jc3464/llama1_13b_hi_2bit": [
    "model.safetensors"
  ],
  "jc3464/llama1_7b_hi_2bit": [
    "model.safetensors"
  ],
  "MaziyarPanahi/ANIMA-Phi-Neptune-Mistral-7B-Mistral-7B-Instruct-v0.1-GGUF": [],
  "liminerity/Memgpt-slerp-7b-1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/mindy-7b-v2-Mistral-7B-Instruct-v0.1-GGUF": [],
  "liminerity/Memgpt-slerp-7b-2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "srijanupadhyay/finetuned-llama2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/speechless-code-mistral-7b-v1.0-Mistral-7B-Instruct-v0.1-GGUF": [],
  "liminerity/Memgpt-slerp-7b-3": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "DongfuTingle/mfuyu_v1": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "Akil15/finetune_llama_v_0.1": [
    "adapter_model.safetensors"
  ],
  "deshetti/LLMPromptGen-AI": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "wang7776/vicuna-7b-v1.3-attention-sparsity-10": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "wang7776/vicuna-7b-v1.3-attention-sparsity-30": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LLMPrompGenAI/LLMPromptGen-AI": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "liminerity/Memgpt-slerp-7b-4": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "arbaazmohideen/LLMpromptGenAI": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "wang7776/Mistral-7B-Instruct-v0.2-attention-sparsity-10": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dvarma/GenLLMPrompt-AI": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "wang7776/Mistral-7B-Instruct-v0.2-attention-sparsity-30": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mrodriguezsanz/LLMPromptGen-AI": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "MaziyarPanahi/koOpenChat-sft-Mistral-7B-Instruct-v0.1-GGUF": [],
  "tourist800/mistral_2X7b": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "liminerity/Memgpt-slerp-7b-5": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "andysalerno/cloudymixtral_sft_7Bx2_MoE_0.2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "MaziyarPanahi/go-bruins-v2-Mistral-7B-Instruct-v0.1-GGUF": [],
  "deepnet/Subnet6Training": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MehdiHosseiniMoghadam/AVA-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "philivy/my-project": [
    "model.safetensors"
  ],
  "MaziyarPanahi/neural-chat-7b-v3-3-Slerp-Mistral-7B-Instruct-v0.1-GGUF": [],
  "BikeshKun/llama-2_finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Hafeez7000/Talk_ai_": [
    "model.safetensors"
  ],
  "jtatman/Dr-Samantha-Philosopher-7B-slerp": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "MaziyarPanahi/v1olet_marcoroni-go-bruins-merge-7B-Mistral-7B-Instruct-v0.1-GGUF": [],
  "terravivet/Judyv02": [
    "adapter_model.safetensors",
    "checkpoint-27/adapter_model.safetensors"
  ],
  "eren23/DistilHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/neural-chat-7b-v3-2-Mistral-7B-Instruct-v0.1-GGUF": [],
  "Sayan01/BabyVicuna-b": [
    "model.safetensors"
  ],
  "MaziyarPanahi/PiVoT-10.7B-Mistral-v0.2-Mistral-7B-Instruct-v0.1-GGUF": [],
  "MaziyarPanahi/MetaMath-Cybertron-Starling-Mistral-7B-Instruct-v0.1-GGUF": [],
  "Epiculous/llmTechChat": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Hafeez7000/talkAI": [
    "model.safetensors"
  ],
  "MaziyarPanahi/neural-chat-7b-v3-Mistral-7B-Instruct-v0.1-GGUF": [],
  "Locutusque/TinyMistral-248M-v2.5-Instruct": [
    "model.safetensors"
  ],
  "Bytes512/Chicken": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "MaziyarPanahi/WizardMath-7B-V1.1-Mistral-7B-Instruct-v0.1-GGUF": [],
  "philivy/SN9": [
    "model.safetensors"
  ],
  "liminerity/Memgpt-3x7b-MOE": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "Bytes512/Queen": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "MaziyarPanahi/Mistral-T5-7B-v1-Mistral-7B-Instruct-v0.1-GGUF": [],
  "yunconglong/Mixtral_7Bx2_MoE_13B_DPO": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "advice/Bittensor": [
    "model.safetensors"
  ],
  "MaziyarPanahi/blossom-v3-mistral-7b-Mistral-7B-Instruct-v0.1-GGUF": [],
  "amazingvince/openhermes-7b-dpo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Sayan01/BabyVicuna-s": [
    "model.safetensors"
  ],
  "MaziyarPanahi/OpenHermes-7B-Symbolic-Mistral-7B-Instruct-v0.1-GGUF": [],
  "andrewatef/MyBloggerV0.20": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "babeboii/crazyfinetunez": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "balrogbob/MiniBOB": [
    "model.safetensors"
  ],
  "mkdir700/starcoderbase1b-personal-copilot-A100-40GB-colab": [
    "model.safetensors"
  ],
  "MaziyarPanahi/mamba-gpt-7b-v2-Mistral-7B-Instruct-v0.1-GGUF": [],
  "MaziyarPanahi/blossom-v3_1-mistral-7b-Mistral-7B-Instruct-v0.1-GGUF": [],
  "WeeRobots/phi-2-chat-v05": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/vigostral-7b-chat-Mistral-7B-Instruct-v0.1-GGUF": [],
  "nitky/Superswallow-7b-v0.2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "nitky/Superswallow-13b-v0.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "nitky/Superswallow-70b-v0.2": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "joshberg65/mistral_7b_guanaco": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/openbuddy-zephyr-7b-v14.1-Mistral-7B-Instruct-v0.1-GGUF": [],
  "mkdir700/v2-starcoderbase1b-personal-copilot-A100-40GB-colab": [
    "model.safetensors"
  ],
  "finetuningsubnet/walrus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/mamba-gpt-7b-v1-Mistral-7B-Instruct-v0.1-GGUF": [],
  "MaziyarPanahi/zephykor-ko-beta-7b-chang-Mistral-7B-Instruct-v0.1-GGUF": [],
  "MaziyarPanahi/Dans-07YahooAnswers-7b-Mistral-7B-Instruct-v0.1-GGUF": [],
  "MaziyarPanahi/una-cybertron-7b-v3-OMA-Mistral-7B-Instruct-v0.1-GGUF": [],
  "EddyGiusepe/tinyllama-aira_Chatbot-lora": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "jaredjoss/pythia-160m-rlhf-pythia-70m-toxicity-model": [
    "model.safetensors"
  ],
  "cognitivecomputations/openchat-3.5-0106-laser": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jeiku/NewJeans_3.43B": [
    "model-00001-of-00001.safetensors"
  ],
  "elliotthwangmsa/phi-2_zh": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "intervitens/internlm2-limarp-chat-20b": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "obrmmk/tinycodellama-jp-0.6b-30k-v2-instruct-JCAdef-CSNmix-5k-1": [
    "model.safetensors"
  ],
  "DrNicefellow/ChatAllInOne-Mistral-7B-V1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jarod0411/zinc10M_gpt2_SMILES_bpe_combined_step1_finetune_covid": [
    "model.safetensors"
  ],
  "obrmmk/tinycodellama-jp-0.6b-30k-v2-instruct-JCAdef-CSNmix-5k-2": [
    "model.safetensors"
  ],
  "Crystalcareai/CrystalMistral_7b_v.02": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-pipps_10k-3e-4": [
    "model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-pipps_and_keys_to_it_all_10k-3e-4": [
    "model.safetensors"
  ],
  "obrmmk/tinycodellama-jp-0.6b-30k-v2-instruct-JCAdef-CSNmix-5k-3": [
    "model.safetensors"
  ],
  "Crystalcareai/CrystalMistral_7b_v.03": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jeiku/NewJeans_3B": [
    "model-00001-of-00001.safetensors"
  ],
  "Crystalcareai/CrystalMistral_7b_v.04": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "InfinityLai/opt-125m-guanaco": [
    "model.safetensors"
  ],
  "ChemPlusX/llama2-7b-ner-type2": [
    "adapter_model.safetensors"
  ],
  "dictatee/opt-125m-guanaco": [
    "model.safetensors"
  ],
  "Sailor01/opt-125m-guanaco": [
    "model.safetensors"
  ],
  "TMOU715/opt-125m-guanaco": [
    "model.safetensors"
  ],
  "frankc350/opt-125m-guanaco": [
    "model.safetensors"
  ],
  "weimenglin/opt-125m-guanaco": [
    "model.safetensors"
  ],
  "frankc350/opt-125m-sft": [
    "model.safetensors"
  ],
  "Heng666/opt-125m-sft": [
    "model.safetensors"
  ],
  "juangig6/opt-125m-guanaco": [
    "model.safetensors"
  ],
  "soaring0616/opt-125m-guanaco": [
    "model.safetensors"
  ],
  "fong33/opt-125m-guanaco": [
    "model.safetensors"
  ],
  "ackerley/opt-125m-guanaco": [
    "model.safetensors"
  ],
  "omusico/opt-125m-guanaco": [
    "model.safetensors"
  ],
  "omusico/opt-125m-sft": [
    "model.safetensors"
  ],
  "gotchu/34b-3": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "Wahlaalne/opt-125m-guanaco": [
    "model.safetensors"
  ],
  "InfinityLai/opt-350m-guanaco": [
    "model.safetensors"
  ],
  "Crystalcareai/CrystalMistral_7bv1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Askahoward/opt-125m-guanaco": [
    "model.safetensors"
  ],
  "crypt0trading/cdragon": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "noczero/mistral-7b-text-to-sql-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hbin0701/MISTRAL_7B_DPO_ROUND1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "TinyPixel/l2-chatml": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jtatman/tinydolphin-2.8_1b-samantha-alpaca": [
    "model.safetensors"
  ],
  "satpalsr/l2_full": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AgamP/LLM_Custom_1": [
    "adapter_1/adapter_model.safetensors",
    "adapter_model.safetensors"
  ],
  "LoneStriker/Etheria-55b-v0.1-3.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "sayril007/DialoGPT-small-Bot": [
    "model.safetensors"
  ],
  "jeevana/group8qna_gpt2__27janV001": [
    "model.safetensors"
  ],
  "LoneStriker/Etheria-55b-v0.1-3.5bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "aisuko/ft-distilGPT2-with-ELI5": [
    "model.safetensors"
  ],
  "LoneStriker/Etheria-55b-v0.1-4.65bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "LoneStriker/Etheria-55b-v0.1-5.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "MaziyarPanahi/openbuddy-mistral-7b-v13.1-Mistral-7B-Instruct-v0.1-GGUF": [],
  "TheBloke/Goliath-longLORA-120b-rope8-32k-fp16-AWQ": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "TheBloke/Goliath-longLORA-120b-rope8-32k-fp16-GPTQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Etheria-55b-v0.1-6.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "MaziyarPanahi/testllm-c2-Mistral-7B-Instruct-v0.1-GGUF": [],
  "kykim0/Llama-2-7b-ultrachat200k-2e-ppo-0s": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Shaleen123/orcayi": [
    "model.safetensors"
  ],
  "yoshinori-sano/NeuralHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FelixChao/Sectumsempra-7B-DPO": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AbhiPemmaraju/gpt2-QuestionAnswerModel": [
    "model.safetensors"
  ],
  "mjm4dl/slt_flng_v01": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AlekseyKorshuk/ultrachat-phi-2-sft-chatml": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "huangyt/bagel-dpo-7b-v0.1-ccp4-r16-q_v_k_o_gate_down_up-2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "xezpeleta/latxa-7b-instruct-lora": [
    "adapter_model.safetensors"
  ],
  "AlekseyKorshuk/ultrachat-phi-2-dpo-chatml": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "deepnet/Subnet6Training2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "DavionK/pretraining": [
    "model.safetensors"
  ],
  "Shaleen123/medical-yi": [
    "model.safetensors"
  ],
  "Huy280803/GPT2_Poet": [
    "model.safetensors"
  ],
  "yatsby/kogpt2-kakaochat-finetuned": [
    "model.safetensors"
  ],
  "ycros/crunchy-onion-bagel": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "Jayeshkumarjangir/falcon-2-7b-jayesh_5000-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Leonlav77/LojcMerged": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "eren23/DistiLabelOrca-TinyLLama-1.1B": [
    "model.safetensors"
  ],
  "MalikIbrar/gpt2-wikitext2": [
    "model.safetensors"
  ],
  "Yankz/TR_Model-2nd-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "anonymousspacecorp/bt-spacecorp-model": [
    "model.safetensors"
  ],
  "MaziyarPanahi/typhoon-7b-Mistral-7B-Instruct-v0.1-GGUF": [],
  "mdfarhaan/settyl_ocean_status_collab": [
    "adapter_model.safetensors",
    "checkpoint-9/adapter_model.safetensors"
  ],
  "lordseidon/openllama_7b_uncensored_gf": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "MaziyarPanahi/Mini_DPO_test02-Mistral-7B-Instruct-v0.1-GGUF": [],
  "Aymeric29bzh/SUB6MODEL": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Aymeric29bzh/SUB6MODEL-T02": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "elliotthwang/KimLan_QA-phi-2-zh": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/openbuddy-mistral-7b-v13-base-Mistral-7B-Instruct-v0.1-GGUF": [],
  "yoshinori-sano/NeuralHermes-2.5-Mistral-7B-2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "GunaKoppula/Llava-Phi2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/SciPhi-Self-RAG-Mistral-7B-32k-Mistral-7B-Instruct-v0.1-GGUF": [],
  "xezpeleta/latxa-7b-instruct": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Navyabhat/Llava-Phi2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/Mistral-7B-claude-instruct-Mistral-7B-Instruct-v0.1-GGUF": [],
  "lordseidon/llama_7b_uncensored_gf": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Ashegh-Sad-Warrior/gpt-neo-125M-code-clippy-dedup-2048-safetensors": [
    "model.safetensors"
  ],
  "MaziyarPanahi/PiVoT-0.1-early-Mistral-7B-Instruct-v0.1-GGUF": [],
  "sunnythakkar/sunny_sn6_tao": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kaitchup/Mayonnaise-4in1-01": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/dolphin-2.6-mistral-7b-Mistral-7B-Instruct-v0.1-GGUF": [],
  "sagarsdesai/vicuna-7b-v1.5-awq": [
    "model.safetensors"
  ],
  "deepnet/Subnet6Model3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kaitchup/Mayonnaise-4in1-02": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kimmeoungjun/generate_nsmc": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "JoshVictor/llama-2-7b-chat-hf-MEDCODEX1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kaitchup/Mayonnaise-4in1-03": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/openchat-3.5-0106-laser-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/openchat-3.5-0106-laser-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/openchat-3.5-0106-laser-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "Chat-Error/Tiny_Kimiko": [
    "model.safetensors"
  ],
  "yoshinori-sano/Mistral-7B-DPO": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/openchat-3.5-0106-laser-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/openchat-3.5-0106-laser-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "twhoool02/Llama2-7b-chat-HF-NF4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/WestLake-7B-v2-laser-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/WestLake-7B-v2-laser-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/WestLake-7B-v2-laser-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/WestLake-7B-v2-laser-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/WestLake-7B-v2-laser-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "Josephgflowers/Tinyllama-Cinder-1.3B-Reason-Test": [
    "model.safetensors"
  ],
  "Josephgflowers/TinyLlama-Cinder-1.3B-Test.2": [
    "model.safetensors"
  ],
  "Gille/StrangeMerges_1-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "MaziyarPanahi/Venomia-1.1-m7-Mistral-7B-Instruct-v0.1-GGUF": [],
  "alnrg2arg/test3_sft_4bit_dpo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/pic_7B_mistral_Full_v0.2-Mistral-7B-Instruct-v0.1-GGUF": [],
  "Americo/phi-1_5-finetuned-farma2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/NyakuraV2.1-m7-Mistral-7B-Instruct-v0.1-GGUF": [],
  "RashmiGN/Llama-2-model-trained": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Sharathhebbar24/ssh_1.8B": [
    "model.safetensors"
  ],
  "MaziyarPanahi/Mistral-7B-v0.1-Open-Platypus-Mistral-7B-Instruct-v0.1-GGUF": [],
  "nccsnlp/med42-70b_ct_prompt1b_ft200_v1_merged": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "harpreetsahota/DeciLM-Base-ChatTuned-Blogv0.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/piano-medley-7b-Mistral-7B-Instruct-v0.1-GGUF": [],
  "smangrul/gpt2-imdb-pos-v2": [
    "model.safetensors"
  ],
  "MaziyarPanahi/zephyr-beta-math-Mistral-7B-Instruct-v0.1-GGUF": [],
  "deepnet/Subnet6Training3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "alnrg2arg/test3_prune_sft_16bit": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "controltensor/subnet-model-3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "alnrg2arg/test3_prune_sft_4bit": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "deepnet/Subnet6Training4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/samantha-mistral-7b-Mistral-7B-Instruct-v0.1-GGUF": [],
  "antiven0m/solar-merge-awq": [
    "model.safetensors"
  ],
  "AzureBlack/Xwin-LM-70B-V0.1_Limarpv3-6bpw-8h-exl2": [
    "output-00001-of-00007.safetensors",
    "output-00002-of-00007.safetensors",
    "output-00003-of-00007.safetensors",
    "output-00004-of-00007.safetensors",
    "output-00005-of-00007.safetensors",
    "output-00006-of-00007.safetensors",
    "output-00007-of-00007.safetensors"
  ],
  "MaziyarPanahi/dolphin-2.0-mistral-7b-Mistral-7B-Instruct-v0.1-GGUF": [],
  "Sharathhebbar24/NeuralPipe-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "crodri/FlorQARAG": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Sharathhebbar24/Med_GPT2": [
    "model.safetensors"
  ],
  "dhanfort/sludgy-beer-lora1": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "nccsnlp/zephyr-7b-beta_ct_prompt1b_ft200_v1_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/mistralopithecus-v1-dpo-7b-Mistral-7B-Instruct-v0.1-GGUF": [],
  "hiiamsid/yi_34B_8k_classification": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "yujiepan/qwen-vl-tiny-random": [
    "model.safetensors"
  ],
  "aloobun/Qwen-1_8B-m4-LDJnr-combined": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/Metis-0.4-Mistral-7B-Instruct-v0.1-GGUF": [],
  "Gille/StrangeMerges_2-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "MaziyarPanahi/SynthIA-7B-v1.3-Mistral-7B-Instruct-v0.1-GGUF": [],
  "Adhi97/deeplearning-stackoverflow": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lmg-anon/vntl-7b-v0.3-hf": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hirmnm/mistral_7b_instruct_Pubmed_L-U-L-A_1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mtc/meta-llama-Llama-2-7b-hf-arxiv-summarization-10000-finetuned-no_quantization": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "weijie210/zephyr-critique-7b-score": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "macadeliccc/Laser-WestLake-2x7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "The-Face-Of-Goonery/HuginnV5.5-12.6B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AzureBlack/Xwin-LM-70B-V0.1_Jannie-6bpw-8h-exl2": [
    "output-00001-of-00007.safetensors",
    "output-00002-of-00007.safetensors",
    "output-00003-of-00007.safetensors",
    "output-00004-of-00007.safetensors",
    "output-00005-of-00007.safetensors",
    "output-00006-of-00007.safetensors",
    "output-00007-of-00007.safetensors"
  ],
  "BramVanroy/GEITje-7B-ultra": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Vijaypsb/NeuralPipe-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "ecastera/eva-mistral-turdus-7b-spanish": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/mistral-7b-finetuned-orca-dpo-v2-Mistral-7B-Instruct-v0.1-GGUF": [],
  "macadeliccc/SOLAR-2x10.7b-truthy-dpo": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "controltensor/subnet-model-4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/LeoScorpius-GreenNode-Alpaca-7B-v1-Mistral-7B-Instruct-v0.1-GGUF": [],
  "xellDart13/NebuIA-10.7B-DPO-v3": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "AzureBlack/Xwin-LM-70B-V0.1_Limarpv3-5bpw-6h-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "ewqr2130/llama2-sft-16000": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "alnrg2arg/test3_sft_16bit_dpo2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "syedmhamudulhasan/distilgpt2-wikitext2": [
    "model.safetensors"
  ],
  "MaziyarPanahi/LeoScorpius-GreenNode-Platypus-7B-v1-Mistral-7B-Instruct-v0.1-GGUF": [],
  "deepnet/Subnet6Training5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors",
    "model.safetensors"
  ],
  "MaziyarPanahi/jackalope-7b-Mistral-7B-Instruct-v0.1-GGUF": [],
  "MohamedAhmedAE/codeparrot-small": [
    "model.safetensors"
  ],
  "LoneStriker/Air-Striker-Mixtral-8x7B-Instruct-ZLoss-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "harveymannering/deepseek-coder-6.7b-instruct-finetuned-manimation": [
    "adapter_model.safetensors"
  ],
  "MaziyarPanahi/mistral-7b-v0.1-layla-v1-Mistral-7B-Instruct-v0.1-GGUF": [],
  "matrrix/gpt2-customer-service": [
    "model.safetensors"
  ],
  "macadeliccc/WestLake-7B-v2-laser-truthy-dpo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/CollectiveCognition-v1.1-Mistral-7B-Mistral-7B-Instruct-v0.1-GGUF": [],
  "50stars/TinyLlama-psy-dpo": [
    "model.safetensors"
  ],
  "starsnatched/MemGPT-DPO-2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "keisoft/sn6": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/mistral-7b-slimorcaboros-Mistral-7B-Instruct-v0.1-GGUF": [],
  "VietTung04/distilgpt2-squad": [
    "model.safetensors"
  ],
  "MaziyarPanahi/Mistral-7B-golden-Mistral-7B-Instruct-v0.1-GGUF": [],
  "StanleyOne/mistral-devign-finetune-instruct-v2-12k": [
    "model.safetensors"
  ],
  "samot-samoe/gpt-neo-sft-1000-steps": [
    "model.safetensors"
  ],
  "Weni/WeniGPT-2.2.3-Zephyr-7B-merged-LLM_Base_2.0.3_SFT": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Crackerjax2/mistralbimerged": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "jtatman/tinymistral-v2-samantha-chatml-therabot": [
    "model.safetensors"
  ],
  "Gille/StrangeMerges_3-7B-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Weni/WeniGPT-2.2.3-Zephyr-7B-LLM_Base_2.0.3_SFT-AWQ": [
    "model.safetensors"
  ],
  "jtatman/TinyMistral-248m-4x-Moe": [
    "model-00001-of-00001.safetensors"
  ],
  "circulus/Korion-14b-v1": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "circulus/Korion-14b-dpo-v1": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "kaitchup/TheMayonnaise": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "andrewatef/MyBloggerV0.21": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "johnn3101/one": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kaitchup/Mayonnaise-4in1-022": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Gille/StrangeMerges_4-7B-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "samot-samoe/gpt-neo-sft-4000-steps": [
    "model.safetensors"
  ],
  "freecs/ThetaWave-28B-v0.1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "lmg-anon/vntl-7b-v0.3.1-hf": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "controltensor/subnet-model-9": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "nbeerbower/bruphin-zeta": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "majed316/jais-13b-chat-4bit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "AzureBlack/Xwin-LM-70B-V0.1_Jannie-5bpw-6h-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "luqmanxyz/FrankenVillain-7B-v1": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "circulus/TinyLlama-hermes-v1-awq": [
    "model.safetensors"
  ],
  "circulus/TinyLlama-truthy-dpo-v1-awq": [
    "model.safetensors"
  ],
  "circulus/TinyLlama-hermes-dpo-v1-awq": [
    "model.safetensors"
  ],
  "AzureBlack/KitchenSink_103b-2.5bpw-6h-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "yunconglong/MoE_13B_DPO": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "liminerity/Memgpt-slerp-DPO": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "notadib/Mistral-7B-Instruct-v0.2-attention-sparsity-10-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "NaoS2/chico-0.6b-5k": [
    "model.safetensors"
  ],
  "M4-ai/TinyMistral-6x248M": [
    "model.safetensors"
  ],
  "parasora/0.13b-prog-ja-new-20k": [
    "model.safetensors"
  ],
  "modelwizard/peccary": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Aryanne/Mistral-3B-Instruct-v0.2-init": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "liminerity/Mem-3DPO-7b-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MehdiHosseiniMoghadam/AVA-Mistral-7B-V2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "vilm/Mixsmol-4x400M-v0.1-epoch2": [
    "model.safetensors"
  ],
  "ddh0/EstopianOrcaMaid-13b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "namirocks/mistral-class-tutor-7b-ep3": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Spanicin/Fulcrum_Aura1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "namirocks/mistral-class-shishya-7b-ep3": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "jungiebeen/nous1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Locutusque/Hercules-1.0-Mistral-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-pipps_10k-1e-4": [
    "model.safetensors"
  ],
  "aisuko/quantized-opt-125m-with-GPTQ": [
    "model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-pipps_and_keys_to_it_all_10k-1e-4": [
    "model.safetensors"
  ],
  "Spanicin/Fulcrum_Aura2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "weijie210/IKEA-7b-UC-0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "namirocks/mistral-class-shishya-all-hal-7b-ep3": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ssarkar4445/tinyllama_instruct": [
    "model.safetensors"
  ],
  "luffycodes/mistral-class-shishya-7b-ep3": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "luffycodes/mistral-class-shishya-all-hal-7b-ep3": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "zorobin/mistral-class-shishya-all-hal-7b-ep3": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "zorobin/mistral-class-shishya-7b-ep3": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "jungiebeen/nous2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "namirocks/mistral-class-shishya-all-hal-7b-ep4": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "macadeliccc/WestSeverus-7B-truthy-DPO-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Kwabs-10/Llama-2-7b-chat-finetune": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "controltensor/subnet-model-11": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Easonshi/EvolCodeLlama-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ibivibiv/temp_tuned_mistral2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Edentns/DataVortexS-10.7B-dpo-v1.5": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Edentns/DataVortexS-10.7B-dpo-v1.6": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Yarofa/model_finetunning_h100_v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ibivibiv/temp_tuned_mistral3": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "daebum/LoRA-Submit-Test": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "ouasdg/tinyllama-pedia": [
    "model.safetensors"
  ],
  "JesseGuerrero/deepseekAllDarkan": [
    "model.safetensors"
  ],
  "Yarofa/model_finetunning_h100_v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Lvxy1117/amber_fine_tune_001": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "karawalla/aqmodel_20240128": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "ibivibiv/aegolius-acadicus-34b-v3": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "Jeyong/SOLAR-10.7B-dpo-v1-awq": [
    "model.safetensors"
  ],
  "Crystalcareai/CrystalMistralv.01-fixed": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "umuthopeyildirim/fin-rwkv-169M": [
    "model.safetensors"
  ],
  "epinnock/deepseek-coder-6.7-evol-feedback-10k-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Crystalcareai/CrystalMistralv.03-fixed": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Cyborg-AI/mistralai-Code-Instruct-Finetune-test": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "silk-road/Haruhi-Zero-6B-0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "controltensor/subnet-model-12": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/WestLake-7B-v2-laser-truthy-dpo-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/WestLake-7B-v2-laser-truthy-dpo-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/WestLake-7B-v2-laser-truthy-dpo-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/WestLake-7B-v2-laser-truthy-dpo-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "npvinHnivqn/vinallama-2.7b-chat_with_EOT_token": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/WestLake-7B-v2-laser-truthy-dpo-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "npvinHnivqn/vinallama-2.7b_with_EOT_token": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Crystalcareai/CrystalMistralv1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jojo-ai-mst/MyanmarGPT-Chat": [
    "model.safetensors"
  ],
  "Yarofa/model_finetunning_h100_v3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "heavytail/kullm-mistral": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TinyPixel/mistral-ft": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "heavytail/kullm-mistral-S": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "heavytail/kullm-solar": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "heavytail/kullm-solar-S": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "PJMixers/MV01-7B-SFT-QLoRA-run_33-perscengen-only-maskinputs": [
    "adapter_model.safetensors"
  ],
  "Tijmen2/cosmosage_v1_gptq": [
    "model.safetensors"
  ],
  "aihub-app/ZySec-7B-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FernandoZzs/opt-125m-gptq-4bit": [
    "model.safetensors"
  ],
  "MarinaraSpaghetti/Doctor-Shotgun_Nous-Capybara-limarpv3-34B-4.2bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "AlekseyKorshuk/ultrachat-evolcode-phi-2-sft-chatml": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Yankz/TR_Model-3rd-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Nondzu/zephyr-speakleash-007-pl-8192-32-16-0.05": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Juuuuu/tinyllama-colorist-v2": [
    "model.safetensors"
  ],
  "Aymeric29bzh/SUB6MODEL-T03": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "karthikrathod/llm_repo_v1": [
    "adapter_model.safetensors",
    "checkpoint-114/adapter_model.safetensors"
  ],
  "LoneStriker/Midnight-Rose-70B-v1.0-2.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Midnight-Rose-70B-v1.0-3.5bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "alnrg2arg/test3_sft_16bit2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "alnrg2arg/test3_sft_4bit2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Midnight-Rose-70B-v1.0-4.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "AnyChars/ru_roleplay_m10_d3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "epinnock/deepseek-coder-6.7-evol-feedback-10k-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Midnight-Rose-70B-v1.0-4.65bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "sethuiyer/OpenDolphinHermes_Llama2_7B": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "MaziyarPanahi/mistral-7b_open_platypus-Mistral-7B-Instruct-v0.1-GGUF": [],
  "hongce-tech/NeuralHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jungyuko/DAVinCI-42dot_LLM-PLM-1.3B-v0.71": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "yunconglong/13B_MATH_DPO": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ceardai/neural_beagle": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jungyuko/DAVinCI-Yi-Ko-6B-v0.71": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "colosimo98/v5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Tamnemtf/gpt2_oscar-mini": [
    "model.safetensors"
  ],
  "LoneStriker/Midnight-Rose-70B-v1.0-5.0bpw-h6-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "kuzbara/DialoGPT-small-Kiryu": [
    "model.safetensors"
  ],
  "MaziyarPanahi/Mistral-7b-FFT-Test3-Mistral-7B-Instruct-v0.1-GGUF": [],
  "umuthopeyildirim/fin-rwkv-1b5": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "MaziyarPanahi/samantha-1.2-mistral-7b-Mistral-7B-Instruct-v0.1-GGUF": [],
  "LoneStriker/Midnight-Rose-70B-v1.0-6.0bpw-h6-exl2": [
    "output-00001-of-00007.safetensors",
    "output-00002-of-00007.safetensors",
    "output-00003-of-00007.safetensors",
    "output-00004-of-00007.safetensors",
    "output-00005-of-00007.safetensors",
    "output-00006-of-00007.safetensors",
    "output-00007-of-00007.safetensors"
  ],
  "harveymannering/deepseek-coder-6.7b-instruct-finetuned-manimation-v2": [
    "adapter_model.safetensors"
  ],
  "ankit011/phi-2-code": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "JunBro/fine-tuning-llama-2-first": [
    "adapter_model.safetensors",
    "checkpoint-10/adapter_model.safetensors"
  ],
  "MehdiHosseiniMoghadam/AVA-Mistral-7B-V3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jtatman/tinymistral-MoE-samantha-chatml-therabot": [
    "model.safetensors"
  ],
  "JunBro/fine-tuning-llama-2-second": [
    "adapter_model.safetensors",
    "checkpoint-10/adapter_model.safetensors"
  ],
  "marianna13/llava-phi-2-3b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/Mini_Synatra_SFT-Mistral-7B-Instruct-v0.1-GGUF": [],
  "MaziyarPanahi/SynthIA-7B-v1.5-Mistral-7B-Instruct-v0.1-GGUF": [],
  "JunBro/fine-tuning-llama-2-third": [
    "checkpoint-10/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "seyf1elislam/KunaiBeagle-7b": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "dvilasuero/CapMistral-7B-Instruct": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "marianna13/OpenHermes-2.5-Mistral-7B-llava-instruct-665k": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "MaziyarPanahi/OpenHermes-2.5-neural-chat-7b-v3-1-7B-Mistral-7B-Instruct-v0.1-GGUF": [],
  "JAdeojo/casperhansen-mixtral-instruct-awq-clone-dec23": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/HuginnV5.5-12.6B-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/HuginnV5.5-12.6B-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/HuginnV5.5-12.6B-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/HuginnV5.5-12.6B-6.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "paulilioaica/Hugo-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "LoneStriker/HuginnV5.5-12.6B-8.0bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "asaoka/japanese-mistral-300m-clone": [
    "model.safetensors"
  ],
  "Shaleen123/medical-yi-6b": [
    "model.safetensors"
  ],
  "aloobun/stablelm-2-1_6b-m4-LDJnr-combined": [
    "model.safetensors"
  ],
  "MaziyarPanahi/Mistral-Trismegistus-7B-Mistral-7B-Instruct-v0.1-GGUF": [],
  "TinyPixel/mistral-ft2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "BlouseJury/Mistral-7B-Discord-0.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/v1olet_merged_dpo_7B-Mistral-7B-Instruct-v0.1-GGUF": [],
  "notadib/Mistral-7B-Instruct-v0.2-attention-sparsity-30": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "eren23/NeuralDareBeagle-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "eren23/FrankenBeagle-SmallOverlap-test": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "MaziyarPanahi/japanese-stablelm-base-gamma-7b-Mistral-7B-Instruct-v0.1-GGUF": [],
  "hirmnm/mistral_7b_instruct_Pubmed_L-U-L-A_2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/LeoScorpius-7B-Chat-DPO-Mistral-7B-Instruct-v0.1-GGUF": [],
  "emilgoh/mistral-instruct-verilog": [
    "adapter_model.safetensors"
  ],
  "Feluda/Zephyr-7b-QnA": [
    "adapter_model.safetensors"
  ],
  "rony/gpt2-quantized-jokes": [
    "model.safetensors"
  ],
  "MaziyarPanahi/MelloGPT-Mistral-7B-Instruct-v0.1-GGUF": [],
  "AlpacaTeam/n3-rw": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kz919/Mistral-7B-orca-dpo-12h": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "OpenBuddy/openbuddy-mistral-7b-v17.1-32k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kz919/Mistral-7B-orca-dpo-8h": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ND911/EE-Maid-7B-Slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "MaziyarPanahi/samantha-mistral-instruct-7b-Mistral-7B-Instruct-v0.1-GGUF": [],
  "MaziyarPanahi/em_german_leo_mistral-Mistral-7B-Instruct-v0.1-GGUF": [],
  "ZainAli60/minerModel": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "godfreykaris/mistral_7b_guanaco-3": [
    "model.safetensors"
  ],
  "Gille/StrangeMerges_5-7B-ties": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Shaleen123/code-yi-6b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors",
    "model.safetensors"
  ],
  "MaziyarPanahi/Mistral-7B-model_45k6e2e4-Mistral-7B-Instruct-v0.1-GGUF": [],
  "dvilasuero/CapMistral-7B-Instruct-1epoch": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/speechless-code-mistral-orca-7b-v1.0-Mistral-7B-Instruct-v0.1-GGUF": [],
  "ndanielsen/MotorHead-Mistral-7B-v0.1": [
    "model.safetensors"
  ],
  "MatrixC7/Meidebenne-120b-v1.0": [
    "model-00001-of-00025.safetensors",
    "model-00002-of-00025.safetensors",
    "model-00003-of-00025.safetensors",
    "model-00004-of-00025.safetensors",
    "model-00005-of-00025.safetensors",
    "model-00006-of-00025.safetensors",
    "model-00007-of-00025.safetensors",
    "model-00008-of-00025.safetensors",
    "model-00009-of-00025.safetensors",
    "model-00010-of-00025.safetensors",
    "model-00011-of-00025.safetensors",
    "model-00012-of-00025.safetensors",
    "model-00013-of-00025.safetensors",
    "model-00014-of-00025.safetensors",
    "model-00015-of-00025.safetensors",
    "model-00016-of-00025.safetensors",
    "model-00017-of-00025.safetensors",
    "model-00018-of-00025.safetensors",
    "model-00019-of-00025.safetensors",
    "model-00020-of-00025.safetensors",
    "model-00021-of-00025.safetensors",
    "model-00022-of-00025.safetensors",
    "model-00023-of-00025.safetensors",
    "model-00024-of-00025.safetensors",
    "model-00025-of-00025.safetensors"
  ],
  "ND911/EE-LMaid-7B-Slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "ChemPlusX/llama2-base-ft-NER": [
    "model.safetensors"
  ],
  "MatrixC7/Meidebenne-120b-v1.0-wbcal-2.65bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "MaziyarPanahi/Rabbit-7B-DPO-Chat-Mistral-7B-Instruct-v0.1-GGUF": [],
  "Nelver28/mistral-7b-chatbj-merged": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "MaziyarPanahi/CollectiveCognition-v1-Mistral-7B-Mistral-7B-Instruct-v0.1-GGUF": [],
  "reasonwang/Llama-2-7b-Alpaca-5000": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Razor89/SarcEmp_FineTune_dialoGPT_SARC_Empathetic_Dialogues": [
    "model.safetensors"
  ],
  "artek0chumak/TestMixtral": [
    "model.safetensors"
  ],
  "MaziyarPanahi/CollectiveCognition-v1.1-Mistral-7B-dare-0.85-Mistral-7B-Instruct-v0.1-GGUF": [],
  "MaziyarPanahi/una-cybertron-7b-v2-bf16-Mistral-7B-Instruct-v0.1-GGUF": [],
  "modelwizard/bighorn": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/speechless-code-mistral-7b-v2.0-Mistral-7B-Instruct-v0.1-GGUF": [],
  "TheBloke/Tess-10.7B-v1.5b-AWQ": [
    "model.safetensors"
  ],
  "TheBloke/Tess-10.7B-v1.5b-GPTQ": [
    "model.safetensors"
  ],
  "Shaleen123/openorca-yi-6b": [
    "model.safetensors"
  ],
  "mayflowergmbh/Wiedervereinigung-7b-dpo-laser": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Crystalcareai/CrystalMistralv1-DPO": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/SynthIA-7B-v1.3-dare-0.85-Mistral-7B-Instruct-v0.1-GGUF": [],
  "mrzeiss/Rafale-PA300-Mis7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Gille/StrangeMerges_6-7B-dare_ties": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "MaziyarPanahi/neural-chat-7b-v3-1-dare-0.85-Mistral-7B-Instruct-v0.1-GGUF": [],
  "NickyNicky/TinyDolphin-2.8-1.1b_oasst2_chatML_all_Cluster_dare_ties_v1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "rony/zephyr-7b-beta-passthrough": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "MaziyarPanahi/speechless-mistral-six-in-one-7b-orth-1.0-Mistral-7B-Instruct-v0.1-GGUF": [],
  "TheBloke/Tess-34B-v1.5b-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/Tess-34B-v1.5b-GPTQ": [
    "model.safetensors"
  ],
  "tourist800/Mistral-7B-Merge-14-v0.2": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Alpaca69B/phi-2-absa-semeval-2016-3": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/speechless-mistral-dolphin-orca-platypus-samantha-7b-dare-0.85-Mistral-7B-Instruct-v0.1-GGUF": [],
  "nextai-team/Moe-4x7b-reason-code-qa": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "crumb/ParaLlama-p-micro": [
    "model.safetensors"
  ],
  "SciPhi/Sensei-7B-V2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "MaziyarPanahi/zephyr-7b-alpha-dare-0.85-Mistral-7B-Instruct-v0.1-GGUF": [],
  "AzureBlack/KitchenSink_103b-3.5bpw-6h-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "MaziyarPanahi/airoboros-m-7b-3.1.2-dare-0.85-Mistral-7B-Instruct-v0.1-GGUF": [],
  "marianna13/llava-phi-2-3b-4.36": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ToastyPigeon/CetaceousHerald-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "paulilioaica/PhiMiX-2x2B-raw": [
    "model-00001-of-00001.safetensors"
  ],
  "MaziyarPanahi/smartyplats-7b-v2-Mistral-7B-Instruct-v0.1-GGUF": [],
  "CultriX/Wernicke-7B-v8": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "flemmingmiguel/MBX-7B-v3": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Gille/StrangeMerges_7-7B-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "birgermoell/swedish-gpt-merged": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "AzureBlack/KitchenSink_103b-4.5bpw-6h-exl2": [
    "output-00001-of-00007.safetensors",
    "output-00002-of-00007.safetensors",
    "output-00003-of-00007.safetensors",
    "output-00004-of-00007.safetensors",
    "output-00005-of-00007.safetensors",
    "output-00006-of-00007.safetensors",
    "output-00007-of-00007.safetensors"
  ],
  "vectorboi/34b-finetuned-3epo": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "Gille/StrangeMerges_8-7B-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/shisa-7b-v1-Mistral-7B-Instruct-v0.1-GGUF": [],
  "GoodOlMavis/MavisGPT-small-DDLCMonika": [
    "model.safetensors"
  ],
  "Josephgflowers/Tinyllama-Cinder-1.3B-Reason-Test.2": [
    "model.safetensors"
  ],
  "MaziyarPanahi/MetaMath-Chupacabra-7B-v2.01-Slerp-Mistral-7B-Instruct-v0.1-GGUF": [],
  "NovoCode/Phi-2-DPO": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "flemmingmiguel/MBX-7B-v2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/MetaMath-Tulpar-7b-v2-Slerp-Mistral-7B-Instruct-v0.1-GGUF": [],
  "hyoo14/BioGPT_amr_nucl_epoch3": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ChuckMcSneed/WinterGoliath-123b-32k": [
    "model-00001-of-00026.safetensors",
    "model-00002-of-00026.safetensors",
    "model-00003-of-00026.safetensors",
    "model-00004-of-00026.safetensors",
    "model-00005-of-00026.safetensors",
    "model-00006-of-00026.safetensors",
    "model-00007-of-00026.safetensors",
    "model-00008-of-00026.safetensors",
    "model-00009-of-00026.safetensors",
    "model-00010-of-00026.safetensors",
    "model-00011-of-00026.safetensors",
    "model-00012-of-00026.safetensors",
    "model-00013-of-00026.safetensors",
    "model-00014-of-00026.safetensors",
    "model-00015-of-00026.safetensors",
    "model-00016-of-00026.safetensors",
    "model-00017-of-00026.safetensors",
    "model-00018-of-00026.safetensors",
    "model-00019-of-00026.safetensors",
    "model-00020-of-00026.safetensors",
    "model-00021-of-00026.safetensors",
    "model-00022-of-00026.safetensors",
    "model-00023-of-00026.safetensors",
    "model-00024-of-00026.safetensors",
    "model-00025-of-00026.safetensors",
    "model-00026-of-00026.safetensors"
  ],
  "MaziyarPanahi/Mistral-ko-7B-v0.1-Mistral-7B-Instruct-v0.1-GGUF": [],
  "ToastyPigeon/LabRabbit-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Kwabs-10/mistralai-7b-property-chat-finetune": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kwchoi/DPO_mistral_7b_ultra_0129_1k": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ToastyPigeon/TestBunny-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/DPOpenHermes-7B-v2-Mistral-7B-Instruct-v0.1-GGUF": [],
  "NickyNicky/TinyDolphin-2.8-1.1b_oasst2_chatML_all_Cluster_dare_ties_v2": [
    "model-00001-of-00001.safetensors"
  ],
  "megastudyedu/ME-7B-v1.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "megastudyedu/ME-dpo-7B-v1.0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "vectorboi/34b-finetuned-finetuned": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "Crystalcareai/CrystalMistralv2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "megastudyedu/ME-7B-v1.0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/OpenHermes-2.5-neural-chat-v3-3-Slerp-Mistral-7B-Instruct-v0.1-GGUF": [],
  "megastudyedu/ME-dpo-7B-v1.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ndanielsen/MotorHead-Mistral-7B-v0.2": [
    "model.safetensors"
  ],
  "dababy6420/autotrain-ujesz-8px56": [
    "adapter_model.safetensors",
    "checkpoint-69/adapter_model.safetensors"
  ],
  "MaziyarPanahi/MetaMath-OpenHermes-2.5-neural-chat-v3-3-Slerp-Mistral-7B-Instruct-v0.1-GGUF": [],
  "CultriX/Wernicke-7B-v9": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/bagel-dpo-7b-v0.1-Mistral-7B-Instruct-v0.1-GGUF": [],
  "jaredjoss/roberta-toxicity-classifier-pythia-160m-rlhf": [
    "model.safetensors"
  ],
  "MaziyarPanahi/Mini_synatra_7b_03-Mistral-7B-Instruct-v0.1-GGUF": [],
  "OpenBuddy/openbuddy-mistral-10b-v17.1-32k": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "MaziyarPanahi/Mistral-7B-KNUT-v0.2-Mistral-7B-Instruct-v0.1-GGUF": [],
  "gcx/qwen-test": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "LoneStriker/CodeMate-v0.1-2.65bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/CodeMate-v0.1-3.5bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "huangyt/Mistral-7B-Instruct-v0.2-ccp5-r16-q_v_k_o_gate_down_up-2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/blossom-v4-mistral-7b-Mistral-7B-Instruct-v0.1-GGUF": [],
  "LoneStriker/CodeMate-v0.1-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "noguchis/vicuna-13b-v1.5-16k_ELYZA-japanese-Llama-2-13b-instruct": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/CodeMate-v0.1-4.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "Jeyong/Synatra-10.7B-v0.4-awq": [
    "model.safetensors"
  ],
  "LoneStriker/CodeMate-v0.1-5.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/MRAI_synatra_7B_v1-Mistral-7B-Instruct-v0.1-GGUF": [],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-pipps_10k-1e-3": [
    "model.safetensors"
  ],
  "japinder007/codeparrot-ds": [
    "model.safetensors"
  ],
  "MaziyarPanahi/Mini_synata_7b_011-Mistral-7B-Instruct-v0.1-GGUF": [],
  "MarkrAI/RAG-KO-Mixtral-7Bx2-v1.1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "MaziyarPanahi/Marcoroni-neural-chat-7B-v2-Mistral-7B-Instruct-v0.1-GGUF": [],
  "MaziyarPanahi/Mistral-7B-KNUT-v0.3-Mistral-7B-Instruct-v0.1-GGUF": [],
  "jsfs11/WestOrcaDPO-7B-GTA": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Gille/StrangeMerges_9-7B-dare_ties": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Debrah/science": [
    "model.safetensors"
  ],
  "Jaehyeon222/ME-MOE-7Bx2_test": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Edentns/DataVortexS-10.7B-dpo-v1.7": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "MaziyarPanahi/Synatra-7B-Instruct-v0.2-Mistral-7B-Instruct-v0.1-GGUF": [],
  "freud-sensei/counsel_chatbot": [
    "model.safetensors"
  ],
  "ToastyPigeon/TestBunny-7B-6.0bpw-exl2": [
    "output.safetensors"
  ],
  "jtatman/TinyMistral-248m-3x-Moe": [
    "model-00001-of-00001.safetensors"
  ],
  "MaziyarPanahi/bagel-7b-v0.1-Mistral-7B-Instruct-v0.1-GGUF": [],
  "NovoCode/Metabird-7b-DPO": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "mncai/Mistral-7B-Instruct-v0.2-NWS-KoOrca-5k-LaAdMoAl-pq": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dddsaty/SOLAR-Instruct-ko-Adapter-Attach": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "LoneStriker/CodeMate-v0.1-6.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "MaziyarPanahi/CatMacaroni-Slerp-Mistral-7B-Instruct-v0.1-GGUF": [],
  "ibivibiv/multimaster-7b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/CodeMate-v0.1-8.0bpw-h8-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "MaziyarPanahi/Noromaid-7b-v0.2-Mistral-7B-Instruct-v0.1-GGUF": [],
  "Vivacem/Llemma-34B-MMIQC": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-pipps_and_keys_to_it_all_10k-1e-3": [
    "model.safetensors"
  ],
  "saishf/Nous-Lotus-10.7B": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "MaziyarPanahi/Mistral-7B-v0.1-sharded-Mistral-7B-Instruct-v0.1-GGUF": [],
  "HensonKang/NeuralHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hflserdaniel/chai_s7_bagel_50": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "MinsuKi/mistral-test": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "MaziyarPanahi/quantum-v0.01-Mistral-7B-Instruct-v0.1-GGUF": [],
  "NaoS2/chico-0.6b-10k": [
    "model.safetensors"
  ],
  "MaziyarPanahi/zephyr-7b-alpha-sharded-Mistral-7B-Instruct-v0.1-GGUF": [],
  "jsfs11/WestLakeSeverusV2-DPO-7B-DARE-TA": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Kalslice/opt125pruned": [
    "model.safetensors"
  ],
  "MaziyarPanahi/CatPPT-base-Mistral-7B-Instruct-v0.1-GGUF": [],
  "NickyNicky/cognitivecomputations_TinyDolphin-2.8-1.1b": [
    "model.safetensors"
  ],
  "MaziyarPanahi/go-bruins-v2.1.1-Mistral-7B-Instruct-v0.1-GGUF": [],
  "AIFT/AIFT-ko-orca-plat-Yi-ko-6b-v1.2-dpo-3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "elinaparajuli/HomeSchema_3_steps-finetuned": [
    "model.safetensors"
  ],
  "MaziyarPanahi/Marcoroni-neural-chat-7B-v1-Mistral-7B-Instruct-v0.1-GGUF": [],
  "dongyru/Mistral-7B-Claim-Extractor": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "domie/Viviana_V2": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "MaziyarPanahi/MythoMist-7b-Mistral-7B-Instruct-v0.1-GGUF": [],
  "Yarofa/model_pre_R3090_v15": [
    "model.safetensors"
  ],
  "MaziyarPanahi/Starling-LM-11B-alpha-Mistral-7B-Instruct-v0.1-GGUF": [],
  "cckevinn/SeeClick": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "zaenalium/indonesia-distilgpt2": [
    "model.safetensors"
  ],
  "NickyNicky/Mixtral-4x1.1B-TinyDolphin-2.8-1.1b_oasst2_chatML_Cluster": [
    "model-00001-of-00001.safetensors"
  ],
  "AIFT/AIFT-instruct-42dot_LLM-SFT-1.3B": [
    "model.safetensors"
  ],
  "MaziyarPanahi/sqlcoder-7b-Mistral-7B-Instruct-v0.1-GGUF": [],
  "suridol/NeuralPipe-7B-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Willy030125/finetuned-mistral-7b-test": [
    "adapter_model.safetensors",
    "checkpoint-5/adapter_model.safetensors"
  ],
  "Edentns/DataVortexS-10.7B-dpo-v1.8": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "MaziyarPanahi/shisa-base-7b-v1-Mistral-7B-Instruct-v0.1-GGUF": [],
  "SudiptoPramanik/Mistral_shards": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/loyal-piano-m7-Mistral-7B-Instruct-v0.1-GGUF": [],
  "SeaLLMs/SeaLLM-7B-v2": [
    "model.safetensors"
  ],
  "MaziyarPanahi/LMCocktail-Mistral-7B-v1-Mistral-7B-Instruct-v0.1-GGUF": [],
  "HanNayeoniee/LHK_44": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "MaziyarPanahi/Seraph-7B-Mistral-7B-Instruct-v0.1-GGUF": [],
  "tdh87/StoryTeller11b": [
    "model.safetensors"
  ],
  "logicker/SkkuDataScience-DPO-v2": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "MaziyarPanahi/Mistral-7B-Merge-14-v0.1-Mistral-7B-Instruct-v0.1-GGUF": [],
  "Herry443/Mistral-7B-KNUT-ref-KICS": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "muzammil-eds/tinyllama-3T-128k-JsonExtract-v1.0": [
    "model.safetensors"
  ],
  "Herry443/Mistral-7B-KNUT-ref-KICS-ARC": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/SauerkrautLM-7b-HerO-Mistral-7B-Instruct-v0.1-GGUF": [],
  "FelixChao/WestSeverus-10.7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "deepnet/Subnet6Model2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors",
    "model.safetensors"
  ],
  "Unbabel/TowerInstruct-13B-v0.1": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "MaziyarPanahi/shark_tank_ai_7_b-Mistral-7B-Instruct-v0.1-GGUF": [],
  "csabag76/sg": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Herry443/Mistral-7B-KNUT-ref-KICS-Hella": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Nishant2609/chai_llama_factory_test-Legal": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mrzeiss/Rafale-PA300-Mis7B-3k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "codellama/CodeLlama-70b-hf": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "codellama/CodeLlama-70b-Python-hf": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "codellama/CodeLlama-70b-Instruct-hf": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "jungyuko/DAVinCI-42dot_LLM-PLM-1.3B-v0.73": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/openchat_3.5-16k-Mistral-7B-Instruct-v0.1-GGUF": [],
  "suridol/NeuralPipe-7B-ties": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "paulilioaica/MoEstral-2x7B": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "DIAG-PSSeng/cicero_v2-phi1.5": [
    "model.safetensors"
  ],
  "gizmo-ai/Mixtral-8x7B-Instruct-v0.1-AWQ-alternative": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Ruiz3/Mistral-7B-Instruct-v0.2-kingshipAI": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/Noromaid-7b-v0.1.1-Mistral-7B-Instruct-v0.1-GGUF": [],
  "karthikrathod/llm_repo_v2": [
    "adapter_model.safetensors",
    "checkpoint-2/adapter_model.safetensors"
  ],
  "MaziyarPanahi/supermario-slerp-Mistral-7B-Instruct-v0.1-GGUF": [],
  "Wanfq/Abel-7B-002_distill_0.9h_woref_ckpt": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Wanfq/Abel-7B-002_distill_0.7hd_woref_ckpt": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "karthikrathod/llm_repo_v3": [
    "adapter_model.safetensors",
    "checkpoint-2/adapter_model.safetensors"
  ],
  "MaziyarPanahi/Karen_TheEditor_V2_STRICT_Mistral_7B-Mistral-7B-Instruct-v0.1-GGUF": [],
  "stmackcat/zepb-only-paragraphs-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "logicker/SkkuDataScience-DPO-v1": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "PracticeLLM/KoSOLAR-Platypus-10.7B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "alpindale/miquella-120b": [
    "model-00001-of-00024.safetensors",
    "model-00002-of-00024.safetensors",
    "model-00003-of-00024.safetensors",
    "model-00004-of-00024.safetensors",
    "model-00005-of-00024.safetensors",
    "model-00006-of-00024.safetensors",
    "model-00007-of-00024.safetensors",
    "model-00008-of-00024.safetensors",
    "model-00009-of-00024.safetensors",
    "model-00010-of-00024.safetensors",
    "model-00011-of-00024.safetensors",
    "model-00012-of-00024.safetensors",
    "model-00013-of-00024.safetensors",
    "model-00014-of-00024.safetensors",
    "model-00015-of-00024.safetensors",
    "model-00016-of-00024.safetensors",
    "model-00017-of-00024.safetensors",
    "model-00018-of-00024.safetensors",
    "model-00019-of-00024.safetensors",
    "model-00020-of-00024.safetensors",
    "model-00021-of-00024.safetensors",
    "model-00022-of-00024.safetensors",
    "model-00023-of-00024.safetensors",
    "model-00024-of-00024.safetensors"
  ],
  "logicker/SkkuDataScience-DPO-v0.5": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "llm-jp/llm-jp-13b-instruct-full-dolly_en-dolly_ja-ichikara_003_001-oasst_en-oasst_ja-v1.1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Chat-Error/7B-XXL": [
    "checkpoint-1058/adapter_model.safetensors",
    "checkpoint-529/adapter_model.safetensors"
  ],
  "jingyeom/freeze_KoSoLAR-10.7B-v0.2_1.4_dedup": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "ConvexAI/Mistral-7B-Discord-0.1-DPO": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "stmackcat/zepb-only-dt19022024-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Herry443/Mistral-7B-KNUT-ref-KICS-MMLU": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "impossibleexchange/pt25": [
    "model.safetensors"
  ],
  "DominoPizza/result-first": [
    "checkpoint-76/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "7vq0ir/alcy1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "HuggingFaceH4/mistral-7b-grok": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "llm-jp/llm-jp-13b-instruct-lora-dolly_en-dolly_ja-ichikara_003_001-oasst_en-oasst_ja-v1.1": [
    "adapter_model.safetensors"
  ],
  "zgce/acsr-v2-yi34b": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "shadowml/WestBeagle-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "HHazard/mixtral": [
    "adapter_model.safetensors",
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "Qaisarali/locai-falcon-cases-1": [
    "model-00001-of-00049.safetensors",
    "model-00002-of-00049.safetensors",
    "model-00003-of-00049.safetensors",
    "model-00004-of-00049.safetensors",
    "model-00005-of-00049.safetensors",
    "model-00006-of-00049.safetensors",
    "model-00007-of-00049.safetensors",
    "model-00008-of-00049.safetensors",
    "model-00009-of-00049.safetensors",
    "model-00010-of-00049.safetensors",
    "model-00011-of-00049.safetensors",
    "model-00012-of-00049.safetensors",
    "model-00013-of-00049.safetensors",
    "model-00014-of-00049.safetensors",
    "model-00015-of-00049.safetensors",
    "model-00016-of-00049.safetensors",
    "model-00017-of-00049.safetensors",
    "model-00018-of-00049.safetensors",
    "model-00019-of-00049.safetensors",
    "model-00020-of-00049.safetensors",
    "model-00021-of-00049.safetensors",
    "model-00022-of-00049.safetensors",
    "model-00023-of-00049.safetensors",
    "model-00024-of-00049.safetensors",
    "model-00025-of-00049.safetensors",
    "model-00026-of-00049.safetensors",
    "model-00027-of-00049.safetensors",
    "model-00028-of-00049.safetensors",
    "model-00029-of-00049.safetensors",
    "model-00030-of-00049.safetensors",
    "model-00031-of-00049.safetensors",
    "model-00032-of-00049.safetensors",
    "model-00033-of-00049.safetensors",
    "model-00034-of-00049.safetensors",
    "model-00035-of-00049.safetensors",
    "model-00036-of-00049.safetensors",
    "model-00037-of-00049.safetensors",
    "model-00038-of-00049.safetensors",
    "model-00039-of-00049.safetensors",
    "model-00040-of-00049.safetensors",
    "model-00041-of-00049.safetensors",
    "model-00042-of-00049.safetensors",
    "model-00043-of-00049.safetensors",
    "model-00044-of-00049.safetensors",
    "model-00045-of-00049.safetensors",
    "model-00046-of-00049.safetensors",
    "model-00047-of-00049.safetensors",
    "model-00048-of-00049.safetensors",
    "model-00049-of-00049.safetensors"
  ],
  "LoneStriker/openbuddy-mistral-10b-v17.1-32k-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/openbuddy-mistral-10b-v17.1-32k-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/openbuddy-mistral-10b-v17.1-32k-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/openbuddy-mistral-10b-v17.1-32k-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "hflserdaniel/chai_s7_34b_bagel_1k_10": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "LoneStriker/openbuddy-mistral-10b-v17.1-32k-8.0bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "dvilasuero/Capystral-Mistral-7B-Instruct": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/mistral-7b-v5-Mistral-7B-Instruct-v0.1-GGUF": [],
  "jdeepee/sn6": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "catbult/my_awesome_eli5_gpt-neox-20b": [
    "model.safetensors"
  ],
  "RatanRohith/NeuralPizza-7B-V0.3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "stmackcat/zepb-paragraphs-dt19022024-combined-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "musiclang/musiclang-chord-v2-4k": [
    "model.safetensors"
  ],
  "LoneStriker/natural-functions-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "lamhieu/ghost-7b-v0.9.0": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "LoneStriker/natural-functions-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "shadowml/TurdusBeagle-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "hflserdaniel/chai_s7_onebagel": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "LoneStriker/natural-functions-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/natural-functions-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/natural-functions-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "MaziyarPanahi/NSFW_DPO_Noromaid-7b-Mistral-7B-Instruct-v0.1-GGUF": [],
  "ondevicellm/tinyllama_mole_sft_routeraux_ultrachat_ep3": [
    "model.safetensors"
  ],
  "MaziyarPanahi/smol-7b-Mistral-7B-Instruct-v0.1-GGUF": [],
  "DominoPizza/ft400-first": [
    "checkpoint-570/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/ANIMA-Nectar-v2-Mistral-7B-Instruct-v0.1-GGUF": [],
  "LoneStriker/openbuddy-mistral-7b-v17.1-32k-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/openbuddy-mistral-7b-v17.1-32k-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "MaziyarPanahi/OpenZephyrChat-Mistral-7B-Instruct-v0.1-GGUF": [],
  "modelwizard/baboon": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/openbuddy-mistral-7b-v17.1-32k-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/openbuddy-mistral-7b-v17.1-32k-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/openbuddy-mistral-7b-v17.1-32k-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "MaziyarPanahi/MistralInstructLongish-Mistral-7B-Instruct-v0.1-GGUF": [],
  "Gille/MoE-StrangeMerges-2x7B": [
    "model-00001-of-00013.safetensors",
    "model-00002-of-00013.safetensors",
    "model-00003-of-00013.safetensors",
    "model-00004-of-00013.safetensors",
    "model-00005-of-00013.safetensors",
    "model-00006-of-00013.safetensors",
    "model-00007-of-00013.safetensors",
    "model-00008-of-00013.safetensors",
    "model-00009-of-00013.safetensors",
    "model-00010-of-00013.safetensors",
    "model-00011-of-00013.safetensors",
    "model-00012-of-00013.safetensors",
    "model-00013-of-00013.safetensors"
  ],
  "BhairavAmazon/gpt2-wikitext2": [
    "model.safetensors"
  ],
  "logicker/SkkuDataScience-DPO-v2-90-ckpt": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "logicker/SkkuDataScience-DPO-v2-180-ckpt": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "BlouseJury/Mistral-7B-Discord-0.1-DPO": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "logicker/SkkuDataScience-DPO-v2-270-ckpt": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "jtatman/TinyMistral-248m-v2.5-4x-Moe": [
    "model-00001-of-00001.safetensors"
  ],
  "logicker/SkkuDataScience-DPO-v2-430-ckpt": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "MaziyarPanahi/mistral-7b-dpo-v6-Mistral-7B-Instruct-v0.1-GGUF": [],
  "logicker/SkkuDataScience-DPO-v2-440-ckpt": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "typosonlr/llama-2-7b-chat-MEDMATCH_0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "controltensor/subnet-model-13": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mjschock/mamba-130m": [
    "model.safetensors"
  ],
  "testifyphili/tinyllama-esgexpert-v1": [
    "model.safetensors"
  ],
  "modelwizard/beaver": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "marianna13/llava-phi-2-3b-sharegpt4v": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "pawan2411/fused-semm6-LoRA": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "paulilioaica/PhiMiX-2x2B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/openchat-3.5-0106-Mistral-7B-Instruct-v0.1-GGUF": [],
  "migtissera/CodeLLaMA-70B-hf-fp16": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "ayushchakravarthy/gist_gptneo_untrained": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/openchat-3.5-0106-Mistral-7B-Instruct-v0.2-GGUF": [],
  "HuggingFaceH4/mistral-7b-anthropic": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "seedboxai/KafkaLM-13B-German-V0.1": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "h2oai/h2ogpt-gm-7b-mistral-chat-sft-dpo-rag-v1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ayushchakravarthy/gist-gptneo-untrained": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Mastu/gpt2-squad": [
    "model.safetensors"
  ],
  "nisten/BigCodeLlama-169b": [
    "model-00001-of-00035.safetensors",
    "model-00002-of-00035.safetensors",
    "model-00003-of-00035.safetensors",
    "model-00004-of-00035.safetensors",
    "model-00005-of-00035.safetensors",
    "model-00006-of-00035.safetensors",
    "model-00007-of-00035.safetensors",
    "model-00008-of-00035.safetensors",
    "model-00009-of-00035.safetensors",
    "model-00010-of-00035.safetensors",
    "model-00011-of-00035.safetensors",
    "model-00012-of-00035.safetensors",
    "model-00013-of-00035.safetensors",
    "model-00014-of-00035.safetensors",
    "model-00015-of-00035.safetensors",
    "model-00016-of-00035.safetensors",
    "model-00017-of-00035.safetensors",
    "model-00018-of-00035.safetensors",
    "model-00019-of-00035.safetensors",
    "model-00020-of-00035.safetensors",
    "model-00021-of-00035.safetensors",
    "model-00022-of-00035.safetensors",
    "model-00023-of-00035.safetensors",
    "model-00024-of-00035.safetensors",
    "model-00025-of-00035.safetensors",
    "model-00026-of-00035.safetensors",
    "model-00027-of-00035.safetensors",
    "model-00028-of-00035.safetensors",
    "model-00029-of-00035.safetensors",
    "model-00030-of-00035.safetensors",
    "model-00031-of-00035.safetensors",
    "model-00032-of-00035.safetensors",
    "model-00033-of-00035.safetensors",
    "model-00034-of-00035.safetensors",
    "model-00035-of-00035.safetensors"
  ],
  "djomo/MISTRALllux600-7b-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rickRossie/model_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "cognitivecomputations/TinyDolphin-2.8.2-1.1b-laser": [
    "model.safetensors"
  ],
  "seedboxai/KafkaLM-13B-German-V0.1-DPO": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "Gille/StrangeMerges_10-7B-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "seedboxai/KafkaLM-7B-German-V0.1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "testifyphili/tinyllama-esgexpert-v3": [
    "model.safetensors"
  ],
  "prsdm/llama-2-finance": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/CodeLlama-70b-Instruct-hf-2.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "shadowml/WestBeagle-7B-gen1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/CodeLlama-70b-Instruct-hf-3.5bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "denisman/sn6": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "shadowml/WestBeagle-7B-gen2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/CodeLlama-70b-Instruct-hf-4.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "controltensor/subnet-model-14": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "seedboxai/KafkaLM-7B-German-V0.1-DPO": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "shadowml/WestBeagle-7B-gen3": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "fhai50032/RolePlayLake-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "LoneStriker/CodeLlama-70b-Instruct-hf-4.65bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "LoneStriker/CodeLlama-70b-Instruct-hf-5.0bpw-h6-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "timpal0l/BeagleCatMunin": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ambrosfitz/tinyllama-history-chat-v2.0": [
    "model.safetensors"
  ],
  "shadowml/TurdusBeagle-7B-gen1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "seedboxai/KafkaLM-70B-German-V0.1": [
    "model-00001-of-00061.safetensors",
    "model-00002-of-00061.safetensors",
    "model-00003-of-00061.safetensors",
    "model-00004-of-00061.safetensors",
    "model-00005-of-00061.safetensors",
    "model-00006-of-00061.safetensors",
    "model-00007-of-00061.safetensors",
    "model-00008-of-00061.safetensors",
    "model-00009-of-00061.safetensors",
    "model-00010-of-00061.safetensors",
    "model-00011-of-00061.safetensors",
    "model-00012-of-00061.safetensors",
    "model-00013-of-00061.safetensors",
    "model-00014-of-00061.safetensors",
    "model-00015-of-00061.safetensors",
    "model-00016-of-00061.safetensors",
    "model-00017-of-00061.safetensors",
    "model-00018-of-00061.safetensors",
    "model-00019-of-00061.safetensors",
    "model-00020-of-00061.safetensors",
    "model-00021-of-00061.safetensors",
    "model-00022-of-00061.safetensors",
    "model-00023-of-00061.safetensors",
    "model-00024-of-00061.safetensors",
    "model-00025-of-00061.safetensors",
    "model-00026-of-00061.safetensors",
    "model-00027-of-00061.safetensors",
    "model-00028-of-00061.safetensors",
    "model-00029-of-00061.safetensors",
    "model-00030-of-00061.safetensors",
    "model-00031-of-00061.safetensors",
    "model-00032-of-00061.safetensors",
    "model-00033-of-00061.safetensors",
    "model-00034-of-00061.safetensors",
    "model-00035-of-00061.safetensors",
    "model-00036-of-00061.safetensors",
    "model-00037-of-00061.safetensors",
    "model-00038-of-00061.safetensors",
    "model-00039-of-00061.safetensors",
    "model-00040-of-00061.safetensors",
    "model-00041-of-00061.safetensors",
    "model-00042-of-00061.safetensors",
    "model-00043-of-00061.safetensors",
    "model-00044-of-00061.safetensors",
    "model-00045-of-00061.safetensors",
    "model-00046-of-00061.safetensors",
    "model-00047-of-00061.safetensors",
    "model-00048-of-00061.safetensors",
    "model-00049-of-00061.safetensors",
    "model-00050-of-00061.safetensors",
    "model-00051-of-00061.safetensors",
    "model-00052-of-00061.safetensors",
    "model-00053-of-00061.safetensors",
    "model-00054-of-00061.safetensors",
    "model-00055-of-00061.safetensors",
    "model-00056-of-00061.safetensors",
    "model-00057-of-00061.safetensors",
    "model-00058-of-00061.safetensors",
    "model-00059-of-00061.safetensors",
    "model-00060-of-00061.safetensors",
    "model-00061-of-00061.safetensors"
  ],
  "shadowml/TurdusBeagle-7B-gen2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "BarraHome/tinyfunctions-sft": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "shadowml/TurdusBeagle-7B-gen3": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jeiku/Long_Luna_3.43B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "samot-samoe/rugpt_gazeta-sft-4000-steps": [
    "model.safetensors"
  ],
  "controltensor/subnet-model-15": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "serpdotai/sparsetral-16x7B-v1": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "Edentns/DataVortexS-10.7B-dpo-v1.9": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Wowso/Bookworm-10.7B-v0.4-DPO-awq": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors",
    "model.safetensors"
  ],
  "AIFT/AIFT-instruct-42dot_LLM-SFT-1.3B-dpo": [
    "model.safetensors"
  ],
  "MehdiHosseiniMoghadam/AVA-Mistral-7B-V4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jsfs11/Westlakev2-7B-DPO": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jeiku/Short_Luna_3B": [
    "model-00001-of-00001.safetensors"
  ],
  "autora-doc/Llama-2-7b-chat-hf-nf4": [
    "model.safetensors"
  ],
  "shangrilar/yi-ko-6b-text2sql": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Gille/StrangeMerges_11-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "etri-xainlp/llama2-13b-sft-dpo": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "Herry443/Mistral-7B-KNUT-ref-KICS-KoCom": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MarinaraSpaghetti/intervitens_internlm2-limarp-chat-20b-6.5bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "jaredjoss/pythia-70m-toxicity-model-pythia-160m-rlhf": [
    "model.safetensors"
  ],
  "elliotthwang/new_model": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "elliotthwang/phi_2_zh": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/CodeLlama-70b-Python-hf-2.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "Byungchae/k2s3_test_0000": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jaredjoss/pythia-160m-rlhf-pythia-70m-toxicity-model-v2": [
    "model.safetensors"
  ],
  "LoneStriker/CodeLlama-70b-Python-hf-3.5bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "LoneStriker/CodeLlama-70b-Python-hf-4.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-pipps_removal-1e-3": [
    "model.safetensors"
  ],
  "andysalerno/mistral-sft-v3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/CodeLlama-70b-Python-hf-4.65bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "genne/SOLAR_dpo_v2_SFT-DPO": [
    "adapter_model.safetensors"
  ],
  "nisten/BigCodeLlama-92b": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "sanmaro6803/llama-2-ko-7b-qlora-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/CodeLlama-70b-Python-hf-5.0bpw-h6-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "dlibf/zephyr-7b-dpo-full_lr1e-7": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "marcel/phi-2-openhermes-30k": [
    "model-00001-of-00002.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00002.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "manh-linh/Viet-mistral-tken": [],
  "DrNicefellow/ChatAllInOne-Yi-34B-200K-V1": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "ITT-AF/ITT-42dot_LLM-SFT-1.3B-v1.0": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Unggi/test": [
    "model.safetensors"
  ],
  "QiYuan-tech/QiHealth-6B-Beta": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "Alpaca69B/phi-2-absa-semeval-2016": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mdroth/NeuralHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/CodeLlama-70b-Instruct-hf-6.0bpw-h6-exl2": [
    "output-00001-of-00007.safetensors",
    "output-00002-of-00007.safetensors",
    "output-00003-of-00007.safetensors",
    "output-00004-of-00007.safetensors",
    "output-00005-of-00007.safetensors",
    "output-00006-of-00007.safetensors",
    "output-00007-of-00007.safetensors"
  ],
  "modelwizard/jackal": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TomGrc/FusionNet_7Bx2_MoE_v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "avemio-digital/DiscoLM_German_7b_v1_chat": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/CodeLlama-70b-Python-hf-6.0bpw-h6-exl2": [
    "output-00001-of-00007.safetensors",
    "output-00002-of-00007.safetensors",
    "output-00003-of-00007.safetensors",
    "output-00004-of-00007.safetensors",
    "output-00005-of-00007.safetensors",
    "output-00006-of-00007.safetensors",
    "output-00007-of-00007.safetensors"
  ],
  "LHC88/TinyLlama-ClownCar": [
    "model-00001-of-00001.safetensors"
  ],
  "PotatoOff/Michel-13B": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-pipps_and_keys_to_it_all_removal-1e-3": [
    "model.safetensors"
  ],
  "yunconglong/DARE_TIES_13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ssaryssane/awesome-bagel-34b-v1": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "tensor24/sn6_model": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mncai/Mistral-7B-Instruct-v0.2-NWSKOr5k-neft5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Midnight-Rose-70B-v1.0-2.4bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "philimon/tinyllama-docker-v1": [
    "model.safetensors"
  ],
  "controltensor/subnet-model-16": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "justicea83/Llama-2-7b-chat-hf-function-calling": [
    "model.safetensors"
  ],
  "dlibf/zephyr-7b-dpo-full_lr5e-6": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "philimon/tinyllama-docker-v2": [
    "model.safetensors"
  ],
  "Crystalcareai/Crystalmistralv2.3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "karawalla/merged_model": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "colable/llama-ko-peft-v0.5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "gtsru/den": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "elinaparajuli/HomeSchema_4_steps-finetuned": [
    "model.safetensors"
  ],
  "tuantc/mistral-nips": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dlibf/zephyr-34b-sft-full_epoch1": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "OS07/CodeToText": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "shidowake/test-240128-swal-7B-hf-qlora-adaptor-merged_bnb_4bit": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "shidowake/test-240128-swal-7B-hf-qlora-adaptor-merged_bnb_4bit_revise": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kwchoi/DPO_mistral_v01_7b_ultra_0130_1k": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "anantg/mistral-7b-instruct-ft-merged": [
    "model.safetensors"
  ],
  "ZainabF/NeuralHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "bsen26/113-Purchase-Journey-Model": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "seedboxai/KafkaLM-8x7B-German-V0.1": [
    "model-00001-of-00039.safetensors",
    "model-00002-of-00039.safetensors",
    "model-00003-of-00039.safetensors",
    "model-00004-of-00039.safetensors",
    "model-00005-of-00039.safetensors",
    "model-00006-of-00039.safetensors",
    "model-00007-of-00039.safetensors",
    "model-00008-of-00039.safetensors",
    "model-00009-of-00039.safetensors",
    "model-00010-of-00039.safetensors",
    "model-00011-of-00039.safetensors",
    "model-00012-of-00039.safetensors",
    "model-00013-of-00039.safetensors",
    "model-00014-of-00039.safetensors",
    "model-00015-of-00039.safetensors",
    "model-00016-of-00039.safetensors",
    "model-00017-of-00039.safetensors",
    "model-00018-of-00039.safetensors",
    "model-00019-of-00039.safetensors",
    "model-00020-of-00039.safetensors",
    "model-00021-of-00039.safetensors",
    "model-00022-of-00039.safetensors",
    "model-00023-of-00039.safetensors",
    "model-00024-of-00039.safetensors",
    "model-00025-of-00039.safetensors",
    "model-00026-of-00039.safetensors",
    "model-00027-of-00039.safetensors",
    "model-00028-of-00039.safetensors",
    "model-00029-of-00039.safetensors",
    "model-00030-of-00039.safetensors",
    "model-00031-of-00039.safetensors",
    "model-00032-of-00039.safetensors",
    "model-00033-of-00039.safetensors",
    "model-00034-of-00039.safetensors",
    "model-00035-of-00039.safetensors",
    "model-00036-of-00039.safetensors",
    "model-00037-of-00039.safetensors",
    "model-00038-of-00039.safetensors",
    "model-00039-of-00039.safetensors"
  ],
  "SF-Foundation/finetuned-autoevaluator-train7095-20240130-060602": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ogbrandt/pjf-ft-v0-naive-merge": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Shreyas0706/stablelm-3b-4e1t_test-Legal": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "bburli/llama-2-7b-bburli-7": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "shrenikb/huggy16": [
    "model.safetensors"
  ],
  "shidowake/swal-7B-base-bnb-4bit-chatml_dequantized-fp16": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "shrenikb/huggy24": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "shrenikb/huggy32": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Cicutavirosa/mistral_b_finance_finetuned_test": [
    "model.safetensors"
  ],
  "defog/sqlcoder-70b-alpha": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "NobodyExistsOnTheInternet/code-llama-70b-python-instruct": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "Shreyas0706/stablelm-3b-4e1t_test-Legal_Sample": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "tomaszki/mistral-clone": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ChuckMcSneed/WinterGoddess-1.4x-70b-32k": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "cloudyu/19B_MATH_DPO": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Extrabass/llama-2-13b-chat-hf-light-and-ice-qa": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "nanasse/gpt2-anais": [
    "model.safetensors"
  ],
  "seedboxai/KafkaLM-8x7b-German-V0.1-DPO": [
    "model-00001-of-00039.safetensors",
    "model-00002-of-00039.safetensors",
    "model-00003-of-00039.safetensors",
    "model-00004-of-00039.safetensors",
    "model-00005-of-00039.safetensors",
    "model-00006-of-00039.safetensors",
    "model-00007-of-00039.safetensors",
    "model-00008-of-00039.safetensors",
    "model-00009-of-00039.safetensors",
    "model-00010-of-00039.safetensors",
    "model-00011-of-00039.safetensors",
    "model-00012-of-00039.safetensors",
    "model-00013-of-00039.safetensors",
    "model-00014-of-00039.safetensors",
    "model-00015-of-00039.safetensors",
    "model-00016-of-00039.safetensors",
    "model-00017-of-00039.safetensors",
    "model-00018-of-00039.safetensors",
    "model-00019-of-00039.safetensors",
    "model-00020-of-00039.safetensors",
    "model-00021-of-00039.safetensors",
    "model-00022-of-00039.safetensors",
    "model-00023-of-00039.safetensors",
    "model-00024-of-00039.safetensors",
    "model-00025-of-00039.safetensors",
    "model-00026-of-00039.safetensors",
    "model-00027-of-00039.safetensors",
    "model-00028-of-00039.safetensors",
    "model-00029-of-00039.safetensors",
    "model-00030-of-00039.safetensors",
    "model-00031-of-00039.safetensors",
    "model-00032-of-00039.safetensors",
    "model-00033-of-00039.safetensors",
    "model-00034-of-00039.safetensors",
    "model-00035-of-00039.safetensors",
    "model-00036-of-00039.safetensors",
    "model-00037-of-00039.safetensors",
    "model-00038-of-00039.safetensors",
    "model-00039-of-00039.safetensors"
  ],
  "tuantc/mistral-dpo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "adamo1139/Yi-34B-200K-AEZAKMI-RAW-2901": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "hflserdaniel/chai_s7_34b_merge": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "OEvortex/lite-hermes": [
    "model.safetensors"
  ],
  "mrzeiss/Rafale-PA300-32L-3k-Mis7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "bburli/llama-2-7b-bburli": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/CodeLlama-70b-hf-2.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "lichiareghu/output": [
    "gpt/pretraining/trained_model/model.safetensors",
    "gpt/trained_model/model.safetensors",
    "model.safetensors"
  ],
  "LoneStriker/CodeLlama-70b-hf-3.5bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "SiguienteGlobal/linguistica-instruct-2.0": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "shadowml/BeagleX-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/CodeLlama-70b-hf-4.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "ssoh/llama-2-7b-mini-ibased": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/CodeLlama-70b-hf-4.65bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "keisoft/pretrain1": [
    "model.safetensors"
  ],
  "TeamUNIVA/Komodo_6B_v1.0.0": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/CodeLlama-70b-hf-5.0bpw-h6-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "TeamUNIVA/Komodo_7B_v1.0.0": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "shadowml/Beaglake-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/CodeLlama-70b-hf-6.0bpw-h6-exl2": [
    "output-00001-of-00007.safetensors",
    "output-00002-of-00007.safetensors",
    "output-00003-of-00007.safetensors",
    "output-00004-of-00007.safetensors",
    "output-00005-of-00007.safetensors",
    "output-00006-of-00007.safetensors",
    "output-00007-of-00007.safetensors"
  ],
  "maitreyaz/OpenHathi-quantised-8bit-Base": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "shidowake/test-240128-swal-7B-hf-qlora-adaptor-qmerged-fp16": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "vilm/Mixsmol-4x400M-v0.1-epoch3": [
    "model.safetensors"
  ],
  "opencsg/opencsg-CodeLlama-34b-v0.2": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "TeamUNIVA/Komodo_7B_v1.0.1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "yleo/monacan-translator-fr-mon-1m": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "indischepartij/TinyUltra-4x1.1B-Base-Alpha": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "NobodyExistsOnTheInternet/clown-SUV-4x70b": [
    "model-00001-of-00049.safetensors",
    "model-00002-of-00049.safetensors",
    "model-00003-of-00049.safetensors",
    "model-00004-of-00049.safetensors",
    "model-00005-of-00049.safetensors",
    "model-00006-of-00049.safetensors",
    "model-00007-of-00049.safetensors",
    "model-00008-of-00049.safetensors",
    "model-00009-of-00049.safetensors",
    "model-00010-of-00049.safetensors",
    "model-00011-of-00049.safetensors",
    "model-00012-of-00049.safetensors",
    "model-00013-of-00049.safetensors",
    "model-00014-of-00049.safetensors",
    "model-00015-of-00049.safetensors",
    "model-00016-of-00049.safetensors",
    "model-00017-of-00049.safetensors",
    "model-00018-of-00049.safetensors",
    "model-00019-of-00049.safetensors",
    "model-00020-of-00049.safetensors",
    "model-00021-of-00049.safetensors",
    "model-00022-of-00049.safetensors",
    "model-00023-of-00049.safetensors",
    "model-00024-of-00049.safetensors",
    "model-00025-of-00049.safetensors",
    "model-00026-of-00049.safetensors",
    "model-00027-of-00049.safetensors",
    "model-00028-of-00049.safetensors",
    "model-00029-of-00049.safetensors",
    "model-00030-of-00049.safetensors",
    "model-00031-of-00049.safetensors",
    "model-00032-of-00049.safetensors",
    "model-00033-of-00049.safetensors",
    "model-00034-of-00049.safetensors",
    "model-00035-of-00049.safetensors",
    "model-00036-of-00049.safetensors",
    "model-00037-of-00049.safetensors",
    "model-00038-of-00049.safetensors",
    "model-00039-of-00049.safetensors",
    "model-00040-of-00049.safetensors",
    "model-00041-of-00049.safetensors",
    "model-00042-of-00049.safetensors",
    "model-00043-of-00049.safetensors",
    "model-00044-of-00049.safetensors",
    "model-00045-of-00049.safetensors",
    "model-00046-of-00049.safetensors",
    "model-00047-of-00049.safetensors",
    "model-00048-of-00049.safetensors",
    "model-00049-of-00049.safetensors"
  ],
  "nachtwindecho/mistralai-Code-Instruct-Finetune-test-RS-30012024": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FelixChao/Patronum-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "cloudyu/19B_TRUTH_DPO": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "xriminact/gpt2-ds": [
    "model.safetensors"
  ],
  "ondevicellm/tinyllama_moe_sft_routeraux_ep3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "birgermoell/Rapid-Cycling": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Trendyol/Trendyol-LLM-7b-chat-v0.1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/CodeLlama-70b-Instruct-hf-2.4bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "Trendyol/Trendyol-LLM-7b-base-v0.1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "hiig-piai/simba-v01a-peft": [
    "adapter_model.safetensors"
  ],
  "LoneStriker/CodeLlama-70b-Instruct-hf-3.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "controltensor/subnet-model-17": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rickRossie/model_instruct": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "olemeyer/drueck-small-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Gille/StrangeMerges_12-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "msy127/ft_240130_01": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "samot-samoe/rugpt_gazeta-sft-6000-steps-v01": [
    "model.safetensors"
  ],
  "Aabbhishekk/llama2-7b-function-calling-slerp": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "internlm/internlm2-chat-1_8b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "internlm/internlm2-chat-1_8b-sft": [
    "model.safetensors"
  ],
  "FounderOfHuggingface/gpt2-medium_full_e2e_nlg_t42000_e5": [
    "model.safetensors"
  ],
  "thanhnew2001/starcoder-7b-taipy26": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "justinj92/phi2-bunny": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "pepoo20/bettermodel_gpt2_wiki": [
    "model.safetensors"
  ],
  "bachngo/mis": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "pepoo20/bettermodel_gpt2_wiki_kaggle": [
    "model.safetensors"
  ],
  "LanguageBind/MoE-LLaVA-Phi2-2.7B-4e-384": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Herry443/Mistral-7B-KNUT-ref-KICS-ALL": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "openbmb/MiniCPM-V": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ITT-AF/ITT-42dot_LLM-PLM-1.3B-v3.0": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "starsnatched/MemGPT-DPO-MoE-2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "modelwizard/coati": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "152334H/miqu-1-70b-sf": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "Weyaxi/Newton-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "zaenalium/MicroMistral-Indo-400M": [
    "model.safetensors"
  ],
  "Weyaxi/Qwen-72B-Llama": [
    "model-00001-of-00026.safetensors",
    "model-00002-of-00026.safetensors",
    "model-00003-of-00026.safetensors",
    "model-00004-of-00026.safetensors",
    "model-00005-of-00026.safetensors",
    "model-00006-of-00026.safetensors",
    "model-00007-of-00026.safetensors",
    "model-00008-of-00026.safetensors",
    "model-00009-of-00026.safetensors",
    "model-00010-of-00026.safetensors",
    "model-00011-of-00026.safetensors",
    "model-00012-of-00026.safetensors",
    "model-00013-of-00026.safetensors",
    "model-00014-of-00026.safetensors",
    "model-00015-of-00026.safetensors",
    "model-00016-of-00026.safetensors",
    "model-00017-of-00026.safetensors",
    "model-00018-of-00026.safetensors",
    "model-00019-of-00026.safetensors",
    "model-00020-of-00026.safetensors",
    "model-00021-of-00026.safetensors",
    "model-00022-of-00026.safetensors",
    "model-00023-of-00026.safetensors",
    "model-00024-of-00026.safetensors",
    "model-00025-of-00026.safetensors",
    "model-00026-of-00026.safetensors"
  ],
  "kd-shared/results_dpo_zephyr": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/CodeLlama-70b-hf-2.4bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "TheBloke/CodeLlama-70B-hf-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/CodeLlama-70B-hf-GPTQ": [
    "model.safetensors"
  ],
  "Lms18/TinyLlama-alpaca": [
    "model.safetensors"
  ],
  "LoneStriker/CodeLlama-70b-hf-3.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "euclaise/Memphis-CoT-3B": [
    "model-00001-of-00001.safetensors"
  ],
  "pepoo20/normalmodel_gpt2_wiki": [
    "model.safetensors"
  ],
  "safesign/m-7b-base": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "safesign/m-8x7b-base": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "safesign/m-8x7b-instruct": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "LHC88/XPurpose-ClownCar-v0": [
    "model-00001-of-00018.safetensors",
    "model-00002-of-00018.safetensors",
    "model-00003-of-00018.safetensors",
    "model-00004-of-00018.safetensors",
    "model-00005-of-00018.safetensors",
    "model-00006-of-00018.safetensors",
    "model-00007-of-00018.safetensors",
    "model-00008-of-00018.safetensors",
    "model-00009-of-00018.safetensors",
    "model-00010-of-00018.safetensors",
    "model-00011-of-00018.safetensors",
    "model-00012-of-00018.safetensors",
    "model-00013-of-00018.safetensors",
    "model-00014-of-00018.safetensors",
    "model-00015-of-00018.safetensors",
    "model-00016-of-00018.safetensors",
    "model-00017-of-00018.safetensors",
    "model-00018-of-00018.safetensors"
  ],
  "pepoo20/normalmodel_gpt2_wiki_kaggle": [
    "model.safetensors"
  ],
  "JunBro/fine-tuning-llama-2-six": [
    "checkpoint-166/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "harpreetsahota/DeciLM-7B-Instruct-gptq-4bit-slim-orca": [
    "model.safetensors"
  ],
  "parasora/0.13b-non-prog-10k": [
    "model.safetensors"
  ],
  "dlibf/zephyr-marco13bv5-sft-full": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "floriangardin/chord_model": [
    "model.safetensors"
  ],
  "BarryFutureman/WestLakeX-7B-EvoMerge-Variant2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Qwen/Qwen1.5-1.8B-Chat": [
    "model.safetensors"
  ],
  "Qwen/Qwen1.5-4B-Chat": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Qwen/Qwen1.5-7B-Chat": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "Qwen/Qwen1.5-14B-Chat": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Qwen/Qwen1.5-72B-Chat": [
    "model-00001-of-00038.safetensors",
    "model-00002-of-00038.safetensors",
    "model-00003-of-00038.safetensors",
    "model-00004-of-00038.safetensors",
    "model-00005-of-00038.safetensors",
    "model-00006-of-00038.safetensors",
    "model-00007-of-00038.safetensors",
    "model-00008-of-00038.safetensors",
    "model-00009-of-00038.safetensors",
    "model-00010-of-00038.safetensors",
    "model-00011-of-00038.safetensors",
    "model-00012-of-00038.safetensors",
    "model-00013-of-00038.safetensors",
    "model-00014-of-00038.safetensors",
    "model-00015-of-00038.safetensors",
    "model-00016-of-00038.safetensors",
    "model-00017-of-00038.safetensors",
    "model-00018-of-00038.safetensors",
    "model-00019-of-00038.safetensors",
    "model-00020-of-00038.safetensors",
    "model-00021-of-00038.safetensors",
    "model-00022-of-00038.safetensors",
    "model-00023-of-00038.safetensors",
    "model-00024-of-00038.safetensors",
    "model-00025-of-00038.safetensors",
    "model-00026-of-00038.safetensors",
    "model-00027-of-00038.safetensors",
    "model-00028-of-00038.safetensors",
    "model-00029-of-00038.safetensors",
    "model-00030-of-00038.safetensors",
    "model-00031-of-00038.safetensors",
    "model-00032-of-00038.safetensors",
    "model-00033-of-00038.safetensors",
    "model-00034-of-00038.safetensors",
    "model-00035-of-00038.safetensors",
    "model-00036-of-00038.safetensors",
    "model-00037-of-00038.safetensors",
    "model-00038-of-00038.safetensors"
  ],
  "macadeliccc/MBX-7B-v3-DPO": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hndc/codeparrot": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "BarryFutureman/WestLakeX-7B-EvoMerge": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Yarofa/model_pre_R3090_v16": [
    "model.safetensors"
  ],
  "gokaygokay/phytia410m_desctoprompt": [
    "model.safetensors"
  ],
  "mmpc/phi-2-squad2-QA-low": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "harpreetsahota/DeciLM-7B-Instruct-gptq-2bit-slim-orca": [
    "model.safetensors"
  ],
  "yuuko-eth/Monsoon-7B-exp-1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "hrtshpdbx/llama_chat_fine_tune_mental_health": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "RobertML/nouse": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hndc/codeparrot-small": [
    "model.safetensors"
  ],
  "TheBloke/CodeLlama-70B-Instruct-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "nakodanei/Blue-Orchid-2x7b": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "philimon/tinyllama-esg-v1": [
    "model.safetensors"
  ],
  "tomaszki/nous-one": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "OS07/test_code": [
    "model.safetensors"
  ],
  "ibivibiv/hydra-moe-120b": [
    "model-00001-of-00097.safetensors",
    "model-00002-of-00097.safetensors",
    "model-00003-of-00097.safetensors",
    "model-00004-of-00097.safetensors",
    "model-00005-of-00097.safetensors",
    "model-00006-of-00097.safetensors",
    "model-00007-of-00097.safetensors",
    "model-00008-of-00097.safetensors",
    "model-00009-of-00097.safetensors",
    "model-00010-of-00097.safetensors",
    "model-00011-of-00097.safetensors",
    "model-00012-of-00097.safetensors",
    "model-00013-of-00097.safetensors",
    "model-00014-of-00097.safetensors",
    "model-00015-of-00097.safetensors",
    "model-00016-of-00097.safetensors",
    "model-00017-of-00097.safetensors",
    "model-00018-of-00097.safetensors",
    "model-00019-of-00097.safetensors",
    "model-00020-of-00097.safetensors",
    "model-00021-of-00097.safetensors",
    "model-00022-of-00097.safetensors",
    "model-00023-of-00097.safetensors",
    "model-00024-of-00097.safetensors",
    "model-00025-of-00097.safetensors",
    "model-00026-of-00097.safetensors",
    "model-00027-of-00097.safetensors",
    "model-00028-of-00097.safetensors",
    "model-00029-of-00097.safetensors",
    "model-00030-of-00097.safetensors",
    "model-00031-of-00097.safetensors",
    "model-00032-of-00097.safetensors",
    "model-00033-of-00097.safetensors",
    "model-00034-of-00097.safetensors",
    "model-00035-of-00097.safetensors",
    "model-00036-of-00097.safetensors",
    "model-00037-of-00097.safetensors",
    "model-00038-of-00097.safetensors",
    "model-00039-of-00097.safetensors",
    "model-00040-of-00097.safetensors",
    "model-00041-of-00097.safetensors",
    "model-00042-of-00097.safetensors",
    "model-00043-of-00097.safetensors",
    "model-00044-of-00097.safetensors",
    "model-00045-of-00097.safetensors",
    "model-00046-of-00097.safetensors",
    "model-00047-of-00097.safetensors",
    "model-00048-of-00097.safetensors",
    "model-00049-of-00097.safetensors",
    "model-00050-of-00097.safetensors",
    "model-00051-of-00097.safetensors",
    "model-00052-of-00097.safetensors",
    "model-00053-of-00097.safetensors",
    "model-00054-of-00097.safetensors",
    "model-00055-of-00097.safetensors",
    "model-00056-of-00097.safetensors",
    "model-00057-of-00097.safetensors",
    "model-00058-of-00097.safetensors",
    "model-00059-of-00097.safetensors",
    "model-00060-of-00097.safetensors",
    "model-00061-of-00097.safetensors",
    "model-00062-of-00097.safetensors",
    "model-00063-of-00097.safetensors",
    "model-00064-of-00097.safetensors",
    "model-00065-of-00097.safetensors",
    "model-00066-of-00097.safetensors",
    "model-00067-of-00097.safetensors",
    "model-00068-of-00097.safetensors",
    "model-00069-of-00097.safetensors",
    "model-00070-of-00097.safetensors",
    "model-00071-of-00097.safetensors",
    "model-00072-of-00097.safetensors",
    "model-00073-of-00097.safetensors",
    "model-00074-of-00097.safetensors",
    "model-00075-of-00097.safetensors",
    "model-00076-of-00097.safetensors",
    "model-00077-of-00097.safetensors",
    "model-00078-of-00097.safetensors",
    "model-00079-of-00097.safetensors",
    "model-00080-of-00097.safetensors",
    "model-00081-of-00097.safetensors",
    "model-00082-of-00097.safetensors",
    "model-00083-of-00097.safetensors",
    "model-00084-of-00097.safetensors",
    "model-00085-of-00097.safetensors",
    "model-00086-of-00097.safetensors",
    "model-00087-of-00097.safetensors",
    "model-00088-of-00097.safetensors",
    "model-00089-of-00097.safetensors",
    "model-00090-of-00097.safetensors",
    "model-00091-of-00097.safetensors",
    "model-00092-of-00097.safetensors",
    "model-00093-of-00097.safetensors",
    "model-00094-of-00097.safetensors",
    "model-00095-of-00097.safetensors",
    "model-00096-of-00097.safetensors",
    "model-00097-of-00097.safetensors"
  ],
  "ohyay12345/mytao": [
    "model.safetensors"
  ],
  "birgermoell/NeuralBeagle-Flashback": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors",
    "model-1.safetensors",
    "model-2.safetensors"
  ],
  "shradha01/codeparrot-ds": [
    "model.safetensors"
  ],
  "andrewatef/MyBloggerV0.23lora": [
    "model.safetensors"
  ],
  "aiplanet/effi-7b-original": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "TomGrc/FusionNet_34Bx2_MoE_v0.1": [
    "model-00001-of-00032.safetensors",
    "model-00002-of-00032.safetensors",
    "model-00003-of-00032.safetensors",
    "model-00004-of-00032.safetensors",
    "model-00005-of-00032.safetensors",
    "model-00006-of-00032.safetensors",
    "model-00007-of-00032.safetensors",
    "model-00008-of-00032.safetensors",
    "model-00009-of-00032.safetensors",
    "model-00010-of-00032.safetensors",
    "model-00011-of-00032.safetensors",
    "model-00012-of-00032.safetensors",
    "model-00013-of-00032.safetensors",
    "model-00014-of-00032.safetensors",
    "model-00015-of-00032.safetensors",
    "model-00016-of-00032.safetensors",
    "model-00017-of-00032.safetensors",
    "model-00018-of-00032.safetensors",
    "model-00019-of-00032.safetensors",
    "model-00020-of-00032.safetensors",
    "model-00021-of-00032.safetensors",
    "model-00022-of-00032.safetensors",
    "model-00023-of-00032.safetensors",
    "model-00024-of-00032.safetensors",
    "model-00025-of-00032.safetensors",
    "model-00026-of-00032.safetensors",
    "model-00027-of-00032.safetensors",
    "model-00028-of-00032.safetensors",
    "model-00029-of-00032.safetensors",
    "model-00030-of-00032.safetensors",
    "model-00031-of-00032.safetensors",
    "model-00032-of-00032.safetensors"
  ],
  "fhai50032/CatLake-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "NexaAIDev/TestModel": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "birgermoell/NeuralBeagle-Flashback-dare-ties": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors",
    "model-1.safetensors",
    "model-2.safetensors"
  ],
  "controltensor/subnet-model-18": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/miqu-1-70b-sf-5.0bpw-h6-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "birgermoell/Flashback-Bellman": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors",
    "model-1.safetensors",
    "model-2.safetensors"
  ],
  "LoneStriker/miqu-1-70b-sf-4.25bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "Nonnnnnmnm/gpt_test": [
    "model.safetensors"
  ],
  "LoneStriker/miqu-1-70b-sf-6.0bpw-h6-exl2": [
    "output-00001-of-00007.safetensors",
    "output-00002-of-00007.safetensors",
    "output-00003-of-00007.safetensors",
    "output-00004-of-00007.safetensors",
    "output-00005-of-00007.safetensors",
    "output-00006-of-00007.safetensors",
    "output-00007-of-00007.safetensors"
  ],
  "LoneStriker/miqu-1-70b-sf-3.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "LoneStriker/miqu-1-70b-sf-2.4bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/miqu-1-70b-sf-3.5bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "Columbia-NLP/vicuna-7b-v1.5-syn-ProLex": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "controltensor/subnet-model-19": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "netcat420/MHENN4": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "TheBloke/CodeLlama-70B-Python-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/CodeLlama-70B-Instruct-GPTQ": [
    "model.safetensors"
  ],
  "fhai50032/BeagleLake-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "tomaszki/nous-two": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "BarraHome/tinyllama-1b-alpaca": [
    "model.safetensors"
  ],
  "daekeun-ml/phi-2-upscaled-4B-instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "shadowml/FoxBeagle-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Columbia-NLP/vicuna-7b-v1.5-comb-ProLex": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "jsfs11/RandomMergeNoNorm-7B-DARETIES": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Columbia-NLP/vicuna-13b-v1.5-syn-ProLex": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "Columbia-NLP/vicuna-13b-v1.5-comb-ProLex": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "shadowml/BeagleSempra-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/miqu-1-70b-sf-2.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "jsfs11/RandomMergeNoNormWEIGHTED-7B-DARETIES": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Gille/StrangeMerges_13-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "ambrosfitz/neural-history-chat-v2.0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/miqu-1-70b-sf-4.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "Columbia-NLP/llama-2-7b-hf-syn-ProLex": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "jingyeom/KoSoLAR-10.7B-v0.2_1.4_dedup_1": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "jsfs11/RandomMergeNoNormWEIGHTED-7B-2x7BMOE": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Columbia-NLP/llama-2-7b-hf-comb-ProLex": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Columbia-NLP/llama-2-13b-hf-syn-ProLex": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "jingyeom/KoSoLAR-10.7B-v0.2_1.4_dedup": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Columbia-NLP/llama-2-13b-hf-comb-ProLex": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-pipps_removal-1e-4": [
    "model.safetensors"
  ],
  "Meggido/NeuraLake-m7-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "SharedGPT/NeuralHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "megastudyedu/M-SOLAR-10.7B-v1.3-dpo": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "zaenalium/MicroLlama-Indo-500M": [
    "model.safetensors"
  ],
  "Elizezen/Nocturn7B-GPTQ": [
    "model.safetensors"
  ],
  "Gille/StrangeMerges_14-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "dababy6420/autotrain-tw00tb00t": [
    "adapter_model.safetensors",
    "checkpoint-120/adapter_model.safetensors"
  ],
  "jeiku/Bologna_3B": [
    "model-00001-of-00001.safetensors"
  ],
  "bbokyeong/textgeneration": [
    "adapter_model.safetensors"
  ],
  "locuslab/tofu_ft_llama2-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ycros/miqu-lzlv": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "wyyadd/fork-openchat-3.5-0106-gptq": [
    "model.safetensors"
  ],
  "ogbrandt/mist7b-pjf-ft-bf16-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-pipps_and_keys_to_it_all_removal-1e-4": [
    "model.safetensors"
  ],
  "ddemilla/Mixtral-8x7B-Instruct-v0.1-coords-casing": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "liuhaotian/llava-v1.6-34b": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "ITT-AF/ITT-Yi-Ko-6B-v3.0": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Gille/StrangeMerges_15-7B-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TheBloke/CodeLlama-70B-Python-GPTQ": [
    "model.safetensors"
  ],
  "ogbrandt/mist7b-pjf-ft-dpo-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "testmod/koen-llama2-13b-sft_testver": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "testmod/koen-llama2-13b-avg_testver": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "controltensor/subnet-model-20": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kevin77x/distilgpt2-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "Edentns/DataVortexS-10.7B-dpo-v1.11": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "liuhaotian/llava-v1.6-mistral-7b": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "Gille/StrangeMerges_16-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "weijie210/zephyr-UFB-7b-sft": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "liuhaotian/llava-v1.6-vicuna-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "li-ping/merged_baichuan_filter_v0": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "olemeyer/drueck-base-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "vanillaOVO/supermario_v3": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "liuhaotian/llava-v1.6-vicuna-13b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "vanillaOVO/supermario_v4": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Envoid/BondBurger-8x7B": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "bachbouch/news-tax": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "tyson0420/stack-llama-2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Lily-Cybersecurity-7B-v0.2-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Lily-Cybersecurity-7B-v0.2-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "Tensoic/Mixtral-4x450M": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "aiplanet/effi-7b-awq": [
    "model.safetensors"
  ],
  "LoneStriker/Lily-Cybersecurity-7B-v0.2-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Lily-Cybersecurity-7B-v0.2-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "10jqk1/Mistral-7B-Instruct-v0.5-ft": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "dahwinsingularity/DahyunVision": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "LoneStriker/Lily-Cybersecurity-7B-v0.2-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "gmonsoon/TinyKambing-4x1.1B-Alpha-V2": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "niexiaoning/yi6bmodel": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "newbie-geek/tinyllama-v1-training": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "testmod/koen-llama2-13b-dpotrain_testver": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "Manirajan/tinyllama-mr_action1": [
    "model.safetensors"
  ],
  "Jasonthewhale/TAO_AI": [
    "model.safetensors"
  ],
  "Qwen/Qwen1.5-0.5B-Chat": [
    "model.safetensors"
  ],
  "shangrilar/SOLAR-KO-10.7B-text2sql": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "brianmoonkr/Moe-4x7b-test-v0.1": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "Kooten/DaringMaid-20B-V1.1-4bpw-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Kooten/DaringMaid-20B-V1.1-5bpw-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "thuan9889/llama-2-7b-cooper": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jtatman/TinyDolphin-4x-MoE": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "ibivibiv/giant-hydra-moe-240b": [
    "model-00001-of-00201.safetensors",
    "model-00002-of-00201.safetensors",
    "model-00003-of-00201.safetensors",
    "model-00004-of-00201.safetensors",
    "model-00005-of-00201.safetensors",
    "model-00006-of-00201.safetensors",
    "model-00007-of-00201.safetensors",
    "model-00008-of-00201.safetensors",
    "model-00009-of-00201.safetensors",
    "model-00010-of-00201.safetensors",
    "model-00011-of-00201.safetensors",
    "model-00012-of-00201.safetensors",
    "model-00013-of-00201.safetensors",
    "model-00014-of-00201.safetensors",
    "model-00015-of-00201.safetensors",
    "model-00016-of-00201.safetensors",
    "model-00017-of-00201.safetensors",
    "model-00018-of-00201.safetensors",
    "model-00019-of-00201.safetensors",
    "model-00020-of-00201.safetensors",
    "model-00021-of-00201.safetensors",
    "model-00022-of-00201.safetensors",
    "model-00023-of-00201.safetensors",
    "model-00024-of-00201.safetensors",
    "model-00025-of-00201.safetensors",
    "model-00026-of-00201.safetensors",
    "model-00027-of-00201.safetensors",
    "model-00028-of-00201.safetensors",
    "model-00029-of-00201.safetensors",
    "model-00030-of-00201.safetensors",
    "model-00031-of-00201.safetensors",
    "model-00032-of-00201.safetensors",
    "model-00033-of-00201.safetensors",
    "model-00034-of-00201.safetensors",
    "model-00035-of-00201.safetensors",
    "model-00036-of-00201.safetensors",
    "model-00037-of-00201.safetensors",
    "model-00038-of-00201.safetensors",
    "model-00039-of-00201.safetensors",
    "model-00040-of-00201.safetensors",
    "model-00041-of-00201.safetensors",
    "model-00042-of-00201.safetensors",
    "model-00043-of-00201.safetensors",
    "model-00044-of-00201.safetensors",
    "model-00045-of-00201.safetensors",
    "model-00046-of-00201.safetensors",
    "model-00047-of-00201.safetensors",
    "model-00048-of-00201.safetensors",
    "model-00049-of-00201.safetensors",
    "model-00050-of-00201.safetensors",
    "model-00051-of-00201.safetensors",
    "model-00052-of-00201.safetensors",
    "model-00053-of-00201.safetensors",
    "model-00054-of-00201.safetensors",
    "model-00055-of-00201.safetensors",
    "model-00056-of-00201.safetensors",
    "model-00057-of-00201.safetensors",
    "model-00058-of-00201.safetensors",
    "model-00059-of-00201.safetensors",
    "model-00060-of-00201.safetensors",
    "model-00061-of-00201.safetensors",
    "model-00062-of-00201.safetensors",
    "model-00063-of-00201.safetensors",
    "model-00064-of-00201.safetensors",
    "model-00065-of-00201.safetensors",
    "model-00066-of-00201.safetensors",
    "model-00067-of-00201.safetensors",
    "model-00068-of-00201.safetensors",
    "model-00069-of-00201.safetensors",
    "model-00070-of-00201.safetensors",
    "model-00071-of-00201.safetensors",
    "model-00072-of-00201.safetensors",
    "model-00073-of-00201.safetensors",
    "model-00074-of-00201.safetensors",
    "model-00075-of-00201.safetensors",
    "model-00076-of-00201.safetensors",
    "model-00077-of-00201.safetensors",
    "model-00078-of-00201.safetensors",
    "model-00079-of-00201.safetensors",
    "model-00080-of-00201.safetensors",
    "model-00081-of-00201.safetensors",
    "model-00082-of-00201.safetensors",
    "model-00083-of-00201.safetensors",
    "model-00084-of-00201.safetensors",
    "model-00085-of-00201.safetensors",
    "model-00086-of-00201.safetensors",
    "model-00087-of-00201.safetensors",
    "model-00088-of-00201.safetensors",
    "model-00089-of-00201.safetensors",
    "model-00090-of-00201.safetensors",
    "model-00091-of-00201.safetensors",
    "model-00092-of-00201.safetensors",
    "model-00093-of-00201.safetensors",
    "model-00094-of-00201.safetensors",
    "model-00095-of-00201.safetensors",
    "model-00096-of-00201.safetensors",
    "model-00097-of-00201.safetensors",
    "model-00098-of-00201.safetensors",
    "model-00099-of-00201.safetensors",
    "model-00100-of-00201.safetensors",
    "model-00101-of-00201.safetensors",
    "model-00102-of-00201.safetensors",
    "model-00103-of-00201.safetensors",
    "model-00104-of-00201.safetensors",
    "model-00105-of-00201.safetensors",
    "model-00106-of-00201.safetensors",
    "model-00107-of-00201.safetensors",
    "model-00108-of-00201.safetensors",
    "model-00109-of-00201.safetensors",
    "model-00110-of-00201.safetensors",
    "model-00111-of-00201.safetensors",
    "model-00112-of-00201.safetensors",
    "model-00113-of-00201.safetensors",
    "model-00114-of-00201.safetensors",
    "model-00115-of-00201.safetensors",
    "model-00116-of-00201.safetensors",
    "model-00117-of-00201.safetensors",
    "model-00118-of-00201.safetensors",
    "model-00119-of-00201.safetensors",
    "model-00120-of-00201.safetensors",
    "model-00121-of-00201.safetensors",
    "model-00122-of-00201.safetensors",
    "model-00123-of-00201.safetensors",
    "model-00124-of-00201.safetensors",
    "model-00125-of-00201.safetensors",
    "model-00126-of-00201.safetensors",
    "model-00127-of-00201.safetensors",
    "model-00128-of-00201.safetensors",
    "model-00129-of-00201.safetensors",
    "model-00130-of-00201.safetensors",
    "model-00131-of-00201.safetensors",
    "model-00132-of-00201.safetensors",
    "model-00133-of-00201.safetensors",
    "model-00134-of-00201.safetensors",
    "model-00135-of-00201.safetensors",
    "model-00136-of-00201.safetensors",
    "model-00137-of-00201.safetensors",
    "model-00138-of-00201.safetensors",
    "model-00139-of-00201.safetensors",
    "model-00140-of-00201.safetensors",
    "model-00141-of-00201.safetensors",
    "model-00142-of-00201.safetensors",
    "model-00143-of-00201.safetensors",
    "model-00144-of-00201.safetensors",
    "model-00145-of-00201.safetensors",
    "model-00146-of-00201.safetensors",
    "model-00147-of-00201.safetensors",
    "model-00148-of-00201.safetensors",
    "model-00149-of-00201.safetensors",
    "model-00150-of-00201.safetensors",
    "model-00151-of-00201.safetensors",
    "model-00152-of-00201.safetensors",
    "model-00153-of-00201.safetensors",
    "model-00154-of-00201.safetensors",
    "model-00155-of-00201.safetensors",
    "model-00156-of-00201.safetensors",
    "model-00157-of-00201.safetensors",
    "model-00158-of-00201.safetensors",
    "model-00159-of-00201.safetensors",
    "model-00160-of-00201.safetensors",
    "model-00161-of-00201.safetensors",
    "model-00162-of-00201.safetensors",
    "model-00163-of-00201.safetensors",
    "model-00164-of-00201.safetensors",
    "model-00165-of-00201.safetensors",
    "model-00166-of-00201.safetensors",
    "model-00167-of-00201.safetensors",
    "model-00168-of-00201.safetensors",
    "model-00169-of-00201.safetensors",
    "model-00170-of-00201.safetensors",
    "model-00171-of-00201.safetensors",
    "model-00172-of-00201.safetensors",
    "model-00173-of-00201.safetensors",
    "model-00174-of-00201.safetensors",
    "model-00175-of-00201.safetensors",
    "model-00176-of-00201.safetensors",
    "model-00177-of-00201.safetensors",
    "model-00178-of-00201.safetensors",
    "model-00179-of-00201.safetensors",
    "model-00180-of-00201.safetensors",
    "model-00181-of-00201.safetensors",
    "model-00182-of-00201.safetensors",
    "model-00183-of-00201.safetensors",
    "model-00184-of-00201.safetensors",
    "model-00185-of-00201.safetensors",
    "model-00186-of-00201.safetensors",
    "model-00187-of-00201.safetensors",
    "model-00188-of-00201.safetensors",
    "model-00189-of-00201.safetensors",
    "model-00190-of-00201.safetensors",
    "model-00191-of-00201.safetensors",
    "model-00192-of-00201.safetensors",
    "model-00193-of-00201.safetensors",
    "model-00194-of-00201.safetensors",
    "model-00195-of-00201.safetensors",
    "model-00196-of-00201.safetensors",
    "model-00197-of-00201.safetensors",
    "model-00198-of-00201.safetensors",
    "model-00199-of-00201.safetensors",
    "model-00200-of-00201.safetensors",
    "model-00201-of-00201.safetensors"
  ],
  "jungyuko/DAVinCI-Yi-Ko-6B-v0.8": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "souvikcmsa019/NeuralPipe-7B-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "dkandpalz/animalGPT1": [
    "model.safetensors"
  ],
  "jtatman/TinyDolphin-3x-MoE": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "unsloth/llama-2-7b-chat-bnb-4bit": [
    "model.safetensors"
  ],
  "yeniceriSGK/PiBrain-TinyLlama-V2": [
    "model.safetensors"
  ],
  "unsloth/llama-2-7b-chat": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "weijie210/IKEA-7b-UFB-0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "YouJun3627/Breeze-7B-Instruct-v0_1-4bit-mlx": [
    "model.safetensors"
  ],
  "jsfs11/MixtureofMerges-MoE-v2": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "josephZh/Breeze-7B-Instruct-v0_1-4bit-mlx": [
    "model.safetensors"
  ],
  "unsloth/codellama-7b-bnb-4bit": [
    "model.safetensors"
  ],
  "unsloth/codellama-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "saishf/West-Hermes-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "dataeaze/dataeaze-RegLLM-zephyr_7b_beta-dzcompli": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "unsloth/codellama-13b-bnb-4bit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Gryphe/Pantheon-10.7b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "eswardivi/mistral7b_telugu": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "npvinHnivqn/stablelm_zephyr_3b_with_cross_attn": [
    "model.safetensors"
  ],
  "karthikrathod/llm_repo_v5": [
    "adapter_model.safetensors",
    "checkpoint-57/adapter_model.safetensors"
  ],
  "Cheuk-Ki/temp1": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "controltensor/subnet-model-21": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "gowhyyou/bittensor-finetuning": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "shadowml/Beagwake-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "coolmaksat/otuformer": [
    "model.safetensors"
  ],
  "elliotthwang/kimLam_phi_2_zh": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Abhishek107/system_tinyllama": [
    "model.safetensors"
  ],
  "nidhishs/tinymix-8x1B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "shadowml/BeagSake-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "enricai/chat-es-merged": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Amod/Mistral-7b-therapy-ft": [
    "model.safetensors"
  ],
  "if001/tiny_mixtral_ja_instruction": [
    "model.safetensors"
  ],
  "shadowml/mibe-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Cheuk-Ki/Platypus-finetune": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "kataresearch/mixtral-id-merged": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "hflog/jsfs11-MixtureofMerges-MoE-v2": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "hflog/gpt2": [
    "model.safetensors"
  ],
  "LoneStriker/miqu-1-70b-sf-8.0bpw-h8-exl2": [
    "output-00001-of-00009.safetensors",
    "output-00002-of-00009.safetensors",
    "output-00003-of-00009.safetensors",
    "output-00004-of-00009.safetensors",
    "output-00005-of-00009.safetensors",
    "output-00006-of-00009.safetensors",
    "output-00007-of-00009.safetensors",
    "output-00008-of-00009.safetensors",
    "output-00009-of-00009.safetensors"
  ],
  "unsloth/yi-6b-bnb-4bit": [
    "model.safetensors"
  ],
  "hflog/Aabbhishekk-llama2-7b-function-calling-slerp": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "hflog/alnrg2arg-test3_sft_16bit_dpo2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hflog/h2oai-h2o-danube-1.8b-chat": [
    "model.safetensors"
  ],
  "AIJUUD/juud-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ljcnju/CodeBertForCodeTrans": [
    "model.safetensors"
  ],
  "unsloth/yi-6b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "euclaise/Memphis-scribe-3B-alpha": [
    "model-00001-of-00001.safetensors"
  ],
  "nicocolas/phixtral-2x2_8": [
    "model-00001-of-00001.safetensors"
  ],
  "rhplus0831/maid-yuzu-v1": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "qnguyen3/quan-1.8b-base-v2": [
    "model.safetensors"
  ],
  "MwangiNelson/RevisedNutribot": [
    "model.safetensors"
  ],
  "jaimin/phi2-task-classification": [
    "model.safetensors"
  ],
  "rhplus0831/maid-yuzu-v1-alter": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "zaenalium/MicroPhi-Indo": [
    "model.safetensors"
  ],
  "djomo/MISTRALllux1000-7b-inst-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rzelogag/inferno-0.0": [
    "model.safetensors"
  ],
  "Menouar/falcon7b-linear-equations-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jan-hq/stealth-rag-v1-e1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Thinkcru/mini-platypus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "djomo/MISTRALllux2000-7b-v3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "M-Mahdi-Setak/soha-bert-fa-zwnj-base": [
    "model.safetensors"
  ],
  "M-Mahdi-Setak/soha-roberta-fa-zwnj-base": [
    "model.safetensors"
  ],
  "Swapnilg915/mistral-7b-mj-finetuned": [
    "adapter_model.safetensors",
    "checkpoint-3/adapter_model.safetensors"
  ],
  "jungiebeen/nous3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hotdogs/openchat_openchat_3.5_FelixChao_WestSeverus-7B-DPO-v2-gpt4_en_th": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "hiig-piai/simba-v01a": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "parthbelose/fine_tuned_llama7B-chat_GPTQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "zaenalium/CodeGen-Indo-350M": [
    "model.safetensors"
  ],
  "impossibleexchange/pt26": [
    "model.safetensors"
  ],
  "alignment-handbook/mistral-7b-sft-constitutional-ai": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ema19/NeuralPipe-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Kooten/Pantheon-10.7b-8bpw-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Kooten/Pantheon-10.7b-6bpw-exl2": [
    "output.safetensors"
  ],
  "Kooten/Pantheon-10.7b-5bpw-exl2": [
    "output.safetensors"
  ],
  "Kooten/Pantheon-10.7b-4bpw-exl2": [
    "output.safetensors"
  ],
  "Manolo26/metis-chat-instruct-7b": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "BlahBlah314/Seraph-7b-Sum-FT-V1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "philimon/mistral-esg-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "avemio-digital/Experiment_2_ties": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "jungiebeen/nous4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "unsloth/solar-10.7b-bnb-4bit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "crumb/Llama-p-small": [
    "model.safetensors"
  ],
  "BioMistral/BioMistral-7B-AWQ-QGS128-W4-GEMM": [
    "model.safetensors"
  ],
  "LoneStriker/Pantheon-10.7b-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Pantheon-10.7b-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Pantheon-10.7b-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Pantheon-10.7b-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Pantheon-10.7b-8.0bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "mlabonne/OmniBeagle-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/openbuddy-mixtral-7bx8-v17.1-32k-2.4bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/openbuddy-mixtral-7bx8-v17.1-32k-3.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/openbuddy-mixtral-7bx8-v17.1-32k-3.5bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "kmfoda/sn9-v3": [
    "model.safetensors"
  ],
  "LoneStriker/openbuddy-mixtral-7bx8-v17.1-32k-3.75bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "NobodyExistsOnTheInternet/Medium-Rare-SFT": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "heldJan/llama-2-7b-miniplatypus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBloke/KafkaLM-70B-German-V0.1-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "TheBloke/KafkaLM-70B-German-V0.1-GPTQ": [
    "model.safetensors"
  ],
  "LoneStriker/openbuddy-mixtral-7bx8-v17.1-32k-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "enricai/chat-es-mad-merged": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Federic/LLM-to-SQL-MERGED": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "BioMistral/BioMistral-7B-AWQ-QGS128-W4-GEMV": [
    "model.safetensors"
  ],
  "LoneStriker/openbuddy-mixtral-7bx8-v17.1-32k-5.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "glc-lgh/model_reproduced_github_WHOLE_epoch_0_952": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "glc-lgh/model_reproduced_github_WHOLE_epoch_0_243": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "7vq0ir/alcy9": [
    "model.safetensors"
  ],
  "LoneStriker/openbuddy-mixtral-7bx8-v17.1-32k-6.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "mlx-community/h2o-danube-1.8b-chat-4bit-mlx": [
    "model.safetensors"
  ],
  "ewqr2130/llama_ppo_1e6step_4000": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Masterjp123/SnowyRP-FinalV1-L2-13B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ewqr2130/llama_sft_longer": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "yashnbx/tune-tinyllana-1.1b-s0": [
    "model.safetensors"
  ],
  "glc-lgh/model_reproduced_github_WHOLE_epoch_0_3": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Garsa3112/GPTFinetunedDataScience": [
    "model.safetensors"
  ],
  "rhplus0831/maid-yuzu-v1-exl2-6.0bpw-rpcal": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "NobodyExistsOnTheInternet/miqu-limarp-70b-dpo": [
    "adapter_model.safetensors",
    "model-00001-of-00008.safetensors"
  ],
  "Hack90/results": [
    "model.safetensors"
  ],
  "Mondhirch/Natural-Language-to-Cypher-2.7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "kaifahmad/Mistral-finetuned-network-QnA": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "starsnatched/MemGPT-DPO-MoE-test": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ArianAskari/NeuralHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "gjonesQ02/my_awesome_eli5_clm-model": [
    "model.safetensors"
  ],
  "adalib/full-data-CodeGPT-small-py": [
    "model.safetensors"
  ],
  "mudogruer/Llama-2-7b-hf-Sci": [
    "model.safetensors"
  ],
  "CultriX/Wernicke-7B-dpo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "adalib/full-data-codeparrot-small": [
    "model.safetensors"
  ],
  "Masterjp123/SnowyRP-FinalV1-L2-13B-GPTQ": [
    "model.safetensors"
  ],
  "Weni/WeniGPT-2.3.3-Zephyr-7B-zephyr-prompt-LLM_Base_2.0.3_SFT_reduction_variation": [
    "adapter_model.safetensors",
    "checkpoint-50/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "vwxyzjn/mistral-7b-dpo-constitutional-ai": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "gjonesQ02/WO_CausalModel": [
    "model.safetensors"
  ],
  "NexaAIDev/NewModel": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "philimon/mistral-esg-gsm-hard-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "son-of-man/HoloViolet-7B-test1": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "adalib/full-data-codeparrot": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "joshberg65/mistral_7b_Rassle": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dataautogpt3/miqu-120b": [
    "model-00001-of-00028.safetensors",
    "model-00002-of-00028.safetensors",
    "model-00003-of-00028.safetensors",
    "model-00004-of-00028.safetensors",
    "model-00005-of-00028.safetensors",
    "model-00006-of-00028.safetensors",
    "model-00007-of-00028.safetensors",
    "model-00008-of-00028.safetensors",
    "model-00009-of-00028.safetensors",
    "model-00010-of-00028.safetensors",
    "model-00011-of-00028.safetensors",
    "model-00012-of-00028.safetensors",
    "model-00013-of-00028.safetensors",
    "model-00014-of-00028.safetensors",
    "model-00015-of-00028.safetensors",
    "model-00016-of-00028.safetensors",
    "model-00017-of-00028.safetensors",
    "model-00018-of-00028.safetensors",
    "model-00019-of-00028.safetensors",
    "model-00020-of-00028.safetensors",
    "model-00021-of-00028.safetensors",
    "model-00022-of-00028.safetensors",
    "model-00023-of-00028.safetensors",
    "model-00024-of-00028.safetensors",
    "model-00025-of-00028.safetensors",
    "model-00026-of-00028.safetensors",
    "model-00027-of-00028.safetensors",
    "model-00028-of-00028.safetensors"
  ],
  "controltensor/subnet-model-22": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "traversaal-ai/traversaal-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ondevicellm/tinyllama_mole_sft_router05_ep3": [
    "model.safetensors"
  ],
  "jarod0411/zinc10M_gpt2_SMILES_bpe_combined_step1_rl_finetune_covid_b16": [
    "model.safetensors"
  ],
  "jarod0411/zinc10M_gpt2_SMILES_bpe_combined_step1_rl_finetune_covid_b64": [
    "model.safetensors"
  ],
  "jarod0411/zinc10M_gpt2_SMILES_bpe_combined_step1_rl_finetune_cancer_b64": [
    "model.safetensors"
  ],
  "jarod0411/zinc10M_gpt2_SMILES_bpe_combined_step1_rl_finetune_cancer_b16": [
    "model.safetensors"
  ],
  "hooverjac/Llama-2-70b-hf-4bit": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Abhishek107/storage_tinyllama": [
    "model.safetensors"
  ],
  "jpechg/Sour-Marcoro-12.5B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "adalib/full-data-codegen-350M-mono": [
    "model.safetensors"
  ],
  "alxcrypto/sn6-1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hammeiam/bt_nous": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors",
    "model.safetensors"
  ],
  "mlabonne/BeagleB-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "rghosh8/codellama-13b-lora-2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tomaszki/nous-three": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-pipps_removal-3e-4": [
    "model.safetensors"
  ],
  "hyeogi/Yi-9b-v1.1": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "silvainrichou/bt_sn6": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Gille/StrangeMerges_17-7B-dare_ties": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "hyeogi/SOLAR-10.7B-v1.1": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "hotdogs/FelixChao_WestSeverus-7B-DPO-v2-gpt4_en_th": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "son-of-man/HoloViolet-7B-test3": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "AIFT/AIFT-instruct-v1.3-42dot_LLM-SFT-1.3B": [
    "model.safetensors"
  ],
  "kpriyanshu256/bactrian-x-llama-7b-guard": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "mumu-97/SOLAR-KO-various-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "calliehsu/tiny-llama-shuttle-xpc-cube-en200": [
    "model.safetensors"
  ],
  "YHLam/mistral_instruct_short_finetune_attempt_4k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "IntervitensInc/intv_ai_mk2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Gille/StrangeMerges_18-7B-dare_ties": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "AIFT/AIFT-instruct-dpo-v1.3-42dot_LLM-SFT-1.3B": [
    "model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-pipps_and_keys_to_it_all_removal-3e-4": [
    "model.safetensors"
  ],
  "rhplus0831/maid-yuzu-v2": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "rhplus0831/maid-yuzu-v2-alter": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "hyeogi/SOLAR-10.7B-v1.2": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Gille/StrangeMerges_19-7B-dare_ties": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "alnrg2arg/blockchainlabs_test3_merge": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "AIFT/AIFT-ko-orca-plat-Yi-ko-6b-v1.5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "unsafetensor/mymodelkek": [],
  "jhovitor98/texte": [
    "model.safetensors"
  ],
  "lchakkei/Mistral-7B-V2-Traditional-Chinese": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "M4-ai/TinyMistral-6x248M-Instruct": [
    "model.safetensors"
  ],
  "controltensor/subnet-model-23": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "gmonsoon/TinyOmega-7x1.1B": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "asadmasad/deepseek-7b-v1.5-lora-finetuned-11k": [
    "adapter_model.safetensors"
  ],
  "colable/llama-ko-peft-v0.6": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mmpc/microsoft-phi-2-squad2-qg": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "andysalerno/rainbowfish-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "son-of-man/HoloViolet-7B-test5": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Crystalcareai/CrystalMistralv2.5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "zhengr/MixTAO-7B-Functionary": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "openbmb/MiniCPM-2B-sft-int4": [
    "model.safetensors"
  ],
  "Colby/StarCoder-3B-WoW-JSON": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ankity09/Heimer-dpo-TinyLlama-1.1B-AWQ": [
    "model.safetensors"
  ],
  "son-of-man/HoloViolet-7B-test6": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Crystalcareai/CrystalMistralv3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "BhabhaAI/Gajendra-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hiraltalsaniya/phi2-task-classification-demo": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ddemilla/Mixtral-instruct-coords-casing-awq": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rhplus0831/maid-yuzu-v2-alter-exl2-6.0bpw-rpcal": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "Jasonthewhale/TAO_AI_3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Edentns/DataVortexS-10.7B-dpo-v1.12": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "DrNicefellow/ChatAllInOne-Yi-34B-200K-V1-6.0bpw-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "bachngo/anmisv3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "a1030788/opt-125m-guanaco": [
    "model.safetensors"
  ],
  "BhabhaAI/Mistral-translation-classify": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "weijie210/zephyr-7b-dpo-reference": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "oivlisnet/Llama-2-13b-fuq-pt-br-v2-gptq": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "hangzou/distilgpt2-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "mkdir700/v3-starcoderbase1b-personal-copilot-A100-40GB-colab": [
    "model.safetensors"
  ],
  "mncai/Orion-14B-Chata-KoAlu2k": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "waldie/Kyllene-34B-v1.1-4bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "ConvexAI/Harmony-4x7B-bf16": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Bread-AI/Crumb-13B": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "bachbouch/w-3-qlora-full": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Edentns/DataVortexS-10.7B-dpo-v1.10": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "mlx-community/Mistral7B-Inst-v0.2-4bit-mlx-distilabel-capybara-dpo-7k": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors",
    "model.safetensors"
  ],
  "Crystalcareai/CrystalMistral_Beta": [
    "checkpoint-10407/adapter_model.safetensors",
    "checkpoint-3469/adapter_model.safetensors",
    "checkpoint-6938/adapter_model.safetensors"
  ],
  "LoneStriker/DistilabelBeagle14-7B-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/DistilabelBeagle14-7B-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/DistilabelBeagle14-7B-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/DistilabelBeagle14-7B-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/DistilabelBeagle14-7B-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "vitruv/vitruv_1": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "specklelab/vet-v3b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "controltensor/subnet-model-24": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sam-ezai/Breezeblossom-v4-mistral-2x7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "calliehsu/tiny-llama-shuttle-xpc-cube-en500": [
    "model.safetensors"
  ],
  "cecb/newsfinetune_mistral_full": [
    "model.safetensors"
  ],
  "roshanrai1304/llama_2_finetune_on_real_estate_data": [
    "model.safetensors"
  ],
  "parasora/0.13b-non-prog-20k": [
    "model.safetensors"
  ],
  "Lvxy1117/amber_fine_tune_ori": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "heldJan/llama-2-7b-froozen_clip": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Newton-7B-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Newton-7B-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Newton-7B-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Newton-7B-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Newton-7B-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "rhplus0831/maid-yuzu-v2-exl2-6.0bpw-rpcal": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "AshishK/AK-OpenHathi-7B-Hi-Sharded-bf16": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "Tamnemtf/llama-2-7b-vi-oscar_mini": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "doubledsbv/KafkaLM-13B-German-V0.1-AWQ": [
    "model.safetensors"
  ],
  "BlahBlah314/Seraph-7b-Const-FT-V2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TinyPixel/pth-l1": [
    "model.safetensors"
  ],
  "santoshtyss/lex-mistral-2000": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "santoshtyss/lex-mistral-1000": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "eswardivi/stablelm_telugu": [
    "model.safetensors"
  ],
  "reach-vb/miqu-1-70b-sf": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "AlekseyKorshuk/WizardCoder-1B-V1.0-dpo-beta-0.01": [
    "model.safetensors"
  ],
  "ohashi56225/phi-2-alpaca-cleaned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "vishanoberoi/Llama-2-7b-chat-hf-fine-tuned-GPTQ": [
    "model.safetensors"
  ],
  "MaziyarPanahi/Mistral-7B-Instruct-v0.1-GGUF": [],
  "UlrikKoren/test_again": [
    "checkpoint-174/adapter_model.safetensors",
    "checkpoint-261/adapter_model.safetensors",
    "checkpoint-87/adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "petitpatoche/sn6-patoche-merge-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "doubledsbv/KafkaLM-7B-German-V0.1-AWQ": [
    "model.safetensors"
  ],
  "hahahahhahhaahah/wikigeneration1": [
    "model.safetensors"
  ],
  "hahahahhahhaahah/wikigen": [
    "model.safetensors"
  ],
  "Stopwolf/DistilabelCerberus-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "ljcnju/GPT2ForCodeTrans": [
    "model.safetensors"
  ],
  "ZainabF/tinyllama-colorist-v2": [
    "model.safetensors"
  ],
  "doubledsbv/KafkaLM-7B-German-V0.1-DPO-AWQ": [
    "model.safetensors"
  ],
  "orion-penner/phi-2-test": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "UlrikKoren/llama-2-7b-pirate_collab_ed": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "BlahBlah314/Seraph-7b-Const-FT-V3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "philimon/TinyLlama-gsm8k-v1": [
    "model.safetensors"
  ],
  "kimmeoungjun/generate_emotion": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/Mistral-7B-Instruct-v0.2-GGUF": [],
  "Abhishek107/metric_tinyllama": [
    "model.safetensors"
  ],
  "gmonsoon/TinyMitha": [
    "model.safetensors"
  ],
  "heldJan/llama-2-7b-froozen_clip_mvfoul": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Herry443/Mistral-7B-KNUT-ref-ALL": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "halilibr/tinyLlama-colorist-model-v1": [
    "model.safetensors"
  ],
  "msy127/ft_240201_01": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/CodeLlama-34b-hf-GGUF": [],
  "impossibleexchange/pt27": [
    "model.safetensors"
  ],
  "KaytTech/F01-mistral7b-jan24": [
    "adapter_model.safetensors",
    "checkpoint-2/adapter_model.safetensors"
  ],
  "elliotthwangmsa/KimLam_phi_2_zh": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "AlekseyKorshuk/WizardCoder-3B-V1.0-dpo-beta-0.01": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Weni/WeniGPT-2.3.3-Zephyr-7B-zephyr-prompt-step3251-LLM_Base_2.0.3_SFT_reduction_variation": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ohashi56225/phi-1_5-alpaca-cleaned": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MarkrAI/RAG-KO-Mixtral-7Bx2-v1.15": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "tweetyx/llama-2-7b-esg-fr-v1.0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "adalib/sfepy-data-CodeGPT-small-py": [
    "model.safetensors"
  ],
  "BlahBlah314/Seraph-7b-Const-FT-V4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dev137/cognitivecomputations_dolphin-2.7-mixtral-8x7b-exl2-8bpw": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "musiclang/text-chord-predictor": [
    "model.safetensors"
  ],
  "adalib/marvin-data-CodeGPT-small-py": [
    "model.safetensors"
  ],
  "adalib/megengine-data-CodeGPT-small-py": [
    "model.safetensors"
  ],
  "adalib/sfepy-data-codeparrot-small": [
    "model.safetensors"
  ],
  "dev137/cognitivecomputations_dolphin-2.7-mixtral-8x7b-exl2-6bpw": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "Weni/WeniGPT-2.3.3-Zephyr-7B-zephyr-prompt-step3251-LLM_Base_2.0.3_SFT_reduction_variation-AWQ": [
    "model.safetensors"
  ],
  "adalib/full-data-codegen-2B-mono": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "adalib/marvin-data-codeparrot-small": [
    "model.safetensors"
  ],
  "adalib/megengine-data-codeparrot-small": [
    "model.safetensors"
  ],
  "doubledsbv/ALMA-13B-R-AWQ": [
    "model.safetensors"
  ],
  "bertin-project/bertin-gpt-j-6B-boe-summaries": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "enricai/corpus-mamaconamor-merged": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Druvith/MEDMISTRAL": [
    "adapter_model.safetensors"
  ],
  "adalib/sfepy-data-codeparrot": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mlabonne/NeuralOmni-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Mistral-7B-Instruct-v0.2-Neural-Story-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Mistral-7B-Instruct-v0.2-Neural-Story-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Mistral-7B-Instruct-v0.2-Neural-Story-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Mistral-7B-Instruct-v0.2-Neural-Story-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "bibidentuhanoi/BMO-7B-ORCA": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "adalib/marvin-data-codeparrot": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Mistral-7B-Instruct-v0.2-Neural-Story-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "BlahBlah314/Seraph-7b-Const-FT-V5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "davibelo/autotrainvicuna7b15SFT": [
    "adapter_model.safetensors",
    "checkpoint-27/adapter_model.safetensors"
  ],
  "asadmasad/lora-test-push": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sanchit-gandhi/Mistral-7B-v0.1-6-layer": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "DrNicefellow/ChatAllInOne-Yi-34B-200K-V1-4.65bpw-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "adalib/megengine-data-codeparrot": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "kam414/sft-mistral-v1": [
    "adapter_model.safetensors",
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "ondevicellm/tinyllama_mole_sft_router05_lr1e-4_ep3": [
    "model.safetensors"
  ],
  "NobodyExistsOnTheInternet/Medium-Rare-DPO-70b": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "weijie210/zephyr-7b-teacher": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "adalib/sfepy-data-codegen-350M-mono": [
    "model.safetensors"
  ],
  "adalib/sqlmodel-data-CodeGPT-small-py": [
    "model.safetensors"
  ],
  "philimon/DialoGPT-small-odia-v1": [
    "model.safetensors"
  ],
  "BlahBlah314/Seraph-7b-Enh-FT-V2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "adalib/sqlmodel-data-codeparrot-small": [
    "model.safetensors"
  ],
  "adalib/marvin-data-codegen-350M-mono": [
    "model.safetensors"
  ],
  "felixbrock/labeled_mistral_vllm": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sanchit-gandhi/distil-zephyr-1.5b-ssft": [
    "model.safetensors"
  ],
  "lchakkei/model": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "adalib/megengine-data-codegen-350M-mono": [
    "model.safetensors"
  ],
  "simonycl/llama-2-7b-hf-sharegpt-Random-0.05": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "BarraHome/zephyr-dpo-16bit-fast": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "adalib/sqlmodel-data-codeparrot": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Hack90/virus_pythia_small": [
    "model.safetensors"
  ],
  "indischepartij/OpenMia-Indo-Mistral-7b-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tarun96/haha": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "tinhpx2911/llama2_base_m1_2024": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "heldJan/llama-2-7b-froozen_mvit": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors",
    "model.safetensors"
  ],
  "Kouskousi/mistral_7b_finetuned_eval_2": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "adalib/sqlmodel-data-codegen-350M-mono": [
    "model.safetensors"
  ],
  "mandelakori/aisak-assistant": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "adalib/sfepy-data-codegen-2B-mono": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Weni/WeniGPT-2.3.3-Zephyr-7B-zephyr-prompt-step4151-LLM_Base_2.0.3_SFT_reduction_variation": [
    "adapter_model.safetensors",
    "checkpoint-3900/adapter_model.safetensors",
    "checkpoint-3950/adapter_model.safetensors",
    "checkpoint-4000/adapter_model.safetensors",
    "checkpoint-4050/adapter_model.safetensors",
    "checkpoint-4100/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Weni/WeniGPT-2.3.3-Zephyr-7B-zephyr-prompt-step4151-merge-LLM_Base_2.0.3_SFT_reduction_variation": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Loess/gpt-neo-125m": [
    "model.safetensors"
  ],
  "zzz99/output-7B-instr-1.5-our-data": [
    "adapter_model.safetensors"
  ],
  "Weni/WeniGPT-2.3.3-Zephyr-7B-merge-LLM_Base_2.0.3_SFT_reduction_variation": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "stevugnin/llama-2-7b-bics-multi_woz_v22": [
    "adapter_model.safetensors",
    "checkpoint-45/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "fblin/mistral-inmob-2": [
    "adapter_model.safetensors",
    "checkpoint-188/adapter_model.safetensors"
  ],
  "adalib/sqlmodel-sfepy-data-CodeGPT-small-py": [
    "model.safetensors"
  ],
  "Weni/WeniGPT-2.3.3-Zephyr-7B-zephyr-prompt-step4151-LLM_Base_2.0.3_SFT_reduction_variation-AWQ": [
    "model.safetensors"
  ],
  "LakoMoor/Silicon-Masha-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "adalib/sqlmodel-sfepy-megengine-data-CodeGPT-small-py": [
    "model.safetensors"
  ],
  "Weni/WeniGPT-2.3.3-Zephyr-7B-alpaca-prompt-step3742-merge-LLM_Base_2.0.3_SFT_reduction_variation": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "adalib/sqlmodel-sfepy-data-codeparrot-small": [
    "model.safetensors"
  ],
  "adalib/sqlmodel-sfepy-megengine-data-codeparrot-small": [
    "model.safetensors"
  ],
  "LoneStriker/Blue-Orchid-2x7b-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Blue-Orchid-2x7b-3.5bpw-h6-exl2": [
    "output.safetensors"
  ],
  "mrzeiss/Rafale-PA10": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "adalib/sqlmodel-sfepy-data-codegen-350M-mono": [
    "model.safetensors"
  ],
  "LoneStriker/Blue-Orchid-2x7b-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "wknehrboss/autotrain-rdceb-j7r69": [
    "adapter_model.safetensors",
    "checkpoint-6/adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Blue-Orchid-2x7b-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Blue-Orchid-2x7b-6.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/CodeLlama-34b-Python-hf-GGUF": [],
  "jtatman/tinydolphin-3x-MoE-samantha-chatml-therabot": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Blue-Orchid-2x7b-8.0bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Weni/WeniGPT-2.3.3-Zephyr-7B-alpaca-prompt-step3742-LLM_Base_2.0.3_SFT_reduction_variation-AWQ": [
    "model.safetensors"
  ],
  "Abhishek107/v1_metric_tinyllama": [
    "model.safetensors"
  ],
  "adalib/sqlmodel-sfepy-megengine-data-codegen-350M-mono": [
    "model.safetensors"
  ],
  "alxcrypto/sn6-2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dmgcsilva/PlanLLM": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ozayezerceli/CodeLlama-7b-CypherGen": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "birgermoell/BeagleCatMunin-Flashback-Bellman": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "mrzeiss/Rafale-PA50": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tomaszki/nous-four": [
    "model.safetensors"
  ],
  "adalib/sqlmodel-data-codegen-2B-mono": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mtc/mistralai-Mistral-7B-v0.1-7b-xnli-with-explanation-100-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mtc/mistralai-Mistral-7B-v0.1-7b-xsum-with-explanation-100-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mtc/mistralai-Mistral-7B-v0.1-7b-xsum-100-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mtc/mistralai-Mistral-7B-v0.1-7b-xnli-100-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rlenzen/casual-d": [
    "model.safetensors"
  ],
  "mtc/mistralai-Mistral-7B-v0.1-7b-xsum-with-explanation-75-5-epoch-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mtc/mistralai-Mistral-7B-v0.1-7b-xsum-75-5-epoch-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "doubledsbv/KafkaLM-8x7B-German-V0.1-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "amaandhada/mistral-7b-easter-egg-finetuned": [
    "adapter_model.safetensors",
    "checkpoint-240/adapter_model.safetensors"
  ],
  "petitpatoche/sn6": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "derlinzer/minkipedros": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "alxcrypto/sn6-3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "adalib/megengine-data-codegen-2B-mono": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/CodeLlama-34b-Instruct-hf-GGUF": [],
  "mtc/mistralai-Mistral-7B-v0.1-7b-xnli-with-explanation-100-5-epoch-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mtc/mistralai-Mistral-7B-v0.1-7b-xnli-100-5-epoch-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-pipps_removal-seed_211-1e-3": [
    "model.safetensors"
  ],
  "jeiku/Salami_3B": [
    "model-00001-of-00001.safetensors"
  ],
  "Finnish-NLP/llama-7b-finnish-instruct-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kitty528/Lyric-generator": [
    "model.safetensors"
  ],
  "BanglaLLM/bangla-llama-7b-base-v0.1": [
    "adapter_model.safetensors"
  ],
  "rldxyz/helloworld": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "umuthopeyildirim/fin-rwkv-430m": [
    "model.safetensors"
  ],
  "Samee-ur/NeuralPipe-7B-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "JaeyeonKang/CCK_Gony_v0.1": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "alxcrypto/sn6-15": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/miquella-120b-2.4bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "birgermoell/Munin-NeuralBeagle-Flashback-Bellman": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "LoneStriker/miquella-120b-4.0bpw-h6-exl2": [
    "output-00001-of-00007.safetensors",
    "output-00002-of-00007.safetensors",
    "output-00003-of-00007.safetensors",
    "output-00004-of-00007.safetensors",
    "output-00005-of-00007.safetensors",
    "output-00006-of-00007.safetensors",
    "output-00007-of-00007.safetensors"
  ],
  "LoneStriker/miquella-120b-4.5bpw-h6-exl2": [
    "output-00001-of-00008.safetensors",
    "output-00002-of-00008.safetensors",
    "output-00003-of-00008.safetensors",
    "output-00004-of-00008.safetensors",
    "output-00005-of-00008.safetensors",
    "output-00006-of-00008.safetensors",
    "output-00007-of-00008.safetensors",
    "output-00008-of-00008.safetensors"
  ],
  "gokaygokay/tiny_llama_chat_description_to_prompt": [
    "model.safetensors"
  ],
  "davibelo/autotrain-phi2-sft": [
    "adapter_model.safetensors",
    "checkpoint-30/adapter_model.safetensors"
  ],
  "controltensor/subnet-model-25": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/miquella-120b-3.0bpw-h6-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "kwchoi/DPO_mistral_v01_7b_ultra_0131_1k_1epoch": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "fedihamdi/tinyllama-fedi-v1": [
    "model.safetensors"
  ],
  "starsnatched/MemGPT-DPO-uncensored": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/miquella-120b-3.5bpw-h6-exl2": [
    "output-00001-of-00007.safetensors",
    "output-00002-of-00007.safetensors",
    "output-00003-of-00007.safetensors",
    "output-00004-of-00007.safetensors",
    "output-00005-of-00007.safetensors",
    "output-00006-of-00007.safetensors",
    "output-00007-of-00007.safetensors"
  ],
  "genne/lora_shargpt-koen_SFT-DPO": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "rparundekar/llama2-7b-humset": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Weni/WeniGPT-2.3.3-Zephyr-7B-zephyr-prompt-merged-LLM_Base_2.0.3_SFT_reduction_variation": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "keloniton/test1": [
    "model.safetensors"
  ],
  "davibelo/autotrain-vicuna-valendo": [
    "adapter_model.safetensors",
    "checkpoint-27/adapter_model.safetensors"
  ],
  "Kamaljp/gpt2-wiki": [
    "model.safetensors"
  ],
  "Weni/WeniGPT-2.3.3-Zephyr-7B-zephyr-prompt-merged-LLM_Base_2.0.3_SFT_reduction_variation-AWQ": [
    "model.safetensors"
  ],
  "karawalla/aqmodel_20240201": [
    "model.safetensors"
  ],
  "nakcnx/phi-2-sql-v1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "weijie210/zephyr-7b-self-refine": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "JaeyeonKang/CCK_Gony_v3.1": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "alnrg2arg/blockchainlabs_test3_seminar": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "rizla/rizla54": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "impossibleexchange/pt28": [
    "model.safetensors"
  ],
  "karawalla/aqmodel_20240201_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rizla/rizla55b": [
    "model-00001-of-00012.safetensors",
    "model-00002-of-00012.safetensors",
    "model-00003-of-00012.safetensors",
    "model-00004-of-00012.safetensors",
    "model-00005-of-00012.safetensors",
    "model-00006-of-00012.safetensors",
    "model-00007-of-00012.safetensors",
    "model-00008-of-00012.safetensors",
    "model-00009-of-00012.safetensors",
    "model-00010-of-00012.safetensors",
    "model-00011-of-00012.safetensors",
    "model-00012-of-00012.safetensors"
  ],
  "rldxyz/saymyname": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "idrah/btsn6": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Samee-ur/NeuralPipe-9B-Passthrough": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Fredh99/finetune_20240131_mistral_7b_action_input_test": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rldxyz/booooooo": [
    "model.safetensors"
  ],
  "deepestneuron/mk1": [
    "model.safetensors"
  ],
  "deepestneuron/mk2": [
    "model.safetensors"
  ],
  "rhplus0831/maid-yuzu-v3-alter": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "rhplus0831/maid-yuzu-v3": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "andysalerno/rainbowfish-v3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rldxyz/kingsqueeze": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dlibf/zephyr-7b-sft-math_code": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dlibf/zephyr-7b-sft-neft-5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "philimon/TinyLlama-gsm8k-v2": [
    "model.safetensors"
  ],
  "alchemonaut/BoreanGale-70B": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "hiiamsid/mistral_8k_epoch_4_classification": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "karawalla/aqmodel_20240202": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Rupesh2/Kgp-Llama": [
    "model.safetensors"
  ],
  "Gille/StrangeMerges_20-7B-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "xriminact/TarsDolly": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "karawalla/aqmodel_20240202_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "euclaise/Memphis-scribe-3B": [
    "model-00001-of-00001.safetensors"
  ],
  "hammeiam/bt_nous2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors",
    "model.safetensors"
  ],
  "indischepartij/MiaLatte-Indo-Mistral-7b": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "mlx-community/CodelLama7B-inst-dpo-7k-mlx": [
    "model.safetensors"
  ],
  "idrah/btsn6v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "pawan2411/fused-ESG-LoRA": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Archit001a/Updated_Model": [
    "model.safetensors"
  ],
  "TroyDoesAI/MermaidMistralDPO": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Archit001a/New_Model": [
    "model.safetensors"
  ],
  "NobodyExistsOnTheInternet/Medium-Rare-DPO-EXL2-4BPW": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "AiMavenAi/AiMaven-Prometheus": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mlabonne/NeuralOmniBeagle-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "eswardivi/phi2_bollywoodsongs": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-pipps_and_keys_to_it_all_removal-seed_211-1e-3": [
    "model.safetensors"
  ],
  "rizla/raccoon-small": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "ankhamun/tut": [
    "model.safetensors"
  ],
  "mohd43/PyGPT": [
    "model.safetensors"
  ],
  "Samee-ur/NeuralPipe-7B-slerp-DPO": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "idrah/btsn6v3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_hacked": [
    "model.safetensors"
  ],
  "rizla/raccoon-small-float32": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "jumtul/LDCC-Hyeogi.03": [
    "model-00001-of-00012.safetensors",
    "model-00002-of-00012.safetensors",
    "model-00003-of-00012.safetensors",
    "model-00004-of-00012.safetensors",
    "model-00005-of-00012.safetensors",
    "model-00006-of-00012.safetensors",
    "model-00007-of-00012.safetensors",
    "model-00008-of-00012.safetensors",
    "model-00009-of-00012.safetensors",
    "model-00010-of-00012.safetensors",
    "model-00011-of-00012.safetensors",
    "model-00012-of-00012.safetensors"
  ],
  "rhplus0831/maid-yuzu-v3-exl2-6.0bpw-rpcal": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "FounderOfHuggingface/gpt2_gen_full_dbpedia_14_t300_e5_hacked_new": [
    "model.safetensors"
  ],
  "EmbeddingStudio/query-parser-saiga-mistral-7b-lora": [
    "adapter_model.safetensors"
  ],
  "Rich-J/key17": [
    "model.safetensors"
  ],
  "JaeyeonKang/CCK_Gony_v3.3": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "Rich-J/key18": [
    "model.safetensors"
  ],
  "la-min/mistral-health-faq": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Rich-J/key19": [
    "model.safetensors"
  ],
  "Rich-J/key20": [
    "model.safetensors"
  ],
  "Rich-J/key21": [
    "model.safetensors"
  ],
  "AthenaAgent/Mockingbirdv1-merged-SFT": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Rich-J/key22": [
    "model.safetensors"
  ],
  "Rich-J/key23": [
    "model.safetensors"
  ],
  "Rich-J/key24": [
    "model.safetensors"
  ],
  "adalib/sqlmodel-sfepy-data-codegen-2B-mono": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tensorplex-labs/pretraining-sn9-01": [
    "model.safetensors"
  ],
  "tensorplex-labs/pretraining-sn9-02": [
    "model.safetensors"
  ],
  "tensorplex-labs/pretraining-sn9-03": [
    "model.safetensors"
  ],
  "tensorplex-labs/pretraining-sn9-04": [
    "model.safetensors"
  ],
  "birgermoell/Munin-NeuralBeagle-NorskGPT": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "tensorplex-labs/pretraining-sn9-05": [
    "model.safetensors"
  ],
  "tensorplex-labs/pretraining-sn9-06": [
    "model.safetensors"
  ],
  "mtc/mistralai-Mistral-7B-v0.1-7b-xsum-with-explanation-3-epoch-full-dataset-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mtc/mistralai-Mistral-7B-v0.1-7b-xsum-with-explanation-75-5-epoch-4bit-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "oneonlee/LDCC-SOLAR-gugutypus-10.7B": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "Federic/CDAgpt-llama2-7b": [
    "adapter_model.safetensors",
    "last-checkpoint/adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "hiig-piai/simba-v01-llama": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mtc/mistralai-Mistral-7B-v0.1-7b-xsum-with-explanation-75-3-epoch-4bit-full-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "zeppdev/phi2-url": [
    "model.safetensors"
  ],
  "adalib/sqlmodel-sfepy-megengine-data-codegen-2B-mono": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "yeniceriSGK/Falcon-PiBrain-V1": [
    "model.safetensors"
  ],
  "ericrisco/flor-1-3B-customerservice": [
    "model.safetensors"
  ],
  "birgermoell/WestLake-Munin-Cat-NorskGPT": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "BlahBlah314/Seraph-7b-Const-FT-V6": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "zhengr/MixTAO-7B-v1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "gizmo-ai/Yi-34B-Chat-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "v2ray/SchizoGPT-8x7B-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "marianna13/llava-phi-2-3b-sharegpt4v-sbu": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "alvwjy/Llama2-base-epic-finetuned": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "jboye/NeuralPipe-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Ashish1310/deci-finetuned-alpaca": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Charles333/catai_bert-base-uncased_new1_finetuning": [
    "adapter_model.safetensors",
    "checkpoint-100/adapter_model.safetensors"
  ],
  "alvwjy/Llama2-pretrained-epic-finetuned": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Dev2410/unsloth_4bit_mistral_imdb_model": [
    "adapter_model.safetensors"
  ],
  "mjm4dl/openchat_intent_r1v0": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ekojs/internlm2-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "rhplus0831/maid-yuzu-v3-alter-exl2-6.0bpw-rpcal": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "jamesagilesoda/Twindoc-Mistral-7B-Alpha-v0.0": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "mjm4dl/openchat_intent_r8v0": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Mik99/phi-2-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "NobodyExistsOnTheInternet/Medium-Rare-DPO-3.5bpw-EXL2": [
    "cal_data.safetensors",
    "hidden_states.safetensors",
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "thanaphatt1/SeaLLM-V2-7B-Q4-AWQ": [
    "model.safetensors"
  ],
  "SR04/my-awesome-model": [
    "model.safetensors"
  ],
  "BlahBlah314/Seraph-7b-Const-FT-V7": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Weni/WeniGPT-2.3.3-Zephyr-7B-alpaca-prompt-step6516-merge-LLM_Base_2.0.3_SFT_reduction_variation": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "timpal0l/BeagleCatMunin2": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "meggievdoever/meggie": [
    "model.safetensors"
  ],
  "Harishferz/Mistral_7B_instruction_tuned_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "arihant-neohumans/Airavata-airoboros-slerp": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "adalib/sqlmodel-sfepy-data-codeparrot": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "StrangeSX/SGX-typhoon-7B-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Weni/WeniGPT-2.3.3-Zephyr-7B-alpaca-prompt-step6516-LLM_Base_2.0.3_SFT_reduction_variation-AWQ": [
    "model.safetensors"
  ],
  "hiig-piai/simba-v01b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Weni/WeniGPT-2.3.3-Zephyr-7B-alpaca-prompt-step3500-LLM_Base_2.0.3_SFT_reduction_variation": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ConvexAI/Pelican-9b-v0.1": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "adalib/sqlmodel-sfepy-megengine-data-codeparrot": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "DopeorNope/Ko-Mixtral-v1.4-MoE-7Bx2": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "comefeel/llama2-13b-dialog-kor-merged-03": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "maitreyaz/Gajendra-8bit-Quantised": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ajzpiv97/llama-2-7b-hf-fine-tuned": [
    "checkpoint-123/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Manirajan/phi2-2b-rmf": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Weni/WeniGPT-2.3.3-Zephyr-7B-zephyr-prompt-step7701-LLM_Base_2.0.3_SFT_reduction_variation": [
    "adapter_model.safetensors",
    "checkpoint-3950/adapter_model.safetensors",
    "checkpoint-7550/adapter_model.safetensors",
    "checkpoint-7600/adapter_model.safetensors",
    "checkpoint-7650/adapter_model.safetensors",
    "checkpoint-7700/adapter_model.safetensors",
    "checkpoints/adapter_model.safetensors",
    "checkpoints/checkpoint-3950/adapter_model.safetensors",
    "checkpoints/checkpoint-7550/adapter_model.safetensors",
    "checkpoints/checkpoint-7600/adapter_model.safetensors",
    "checkpoints/checkpoint-7650/adapter_model.safetensors",
    "checkpoints/checkpoint-7700/adapter_model.safetensors",
    "checkpoints/model-00001-of-00003.safetensors",
    "checkpoints/model-00002-of-00003.safetensors",
    "checkpoints/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "impossibleexchange/pt29": [
    "model.safetensors"
  ],
  "Americo/phi-1_5-finetuned-farma3": [
    "model.safetensors"
  ],
  "timpal0l/Scandi": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "TeeZee/DarkForest-20B-v1.0-bpw4-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Weni/WeniGPT-2.3.3-Zephyr-7B-zephyr-prompt-step7701-merge-LLM_Base_2.0.3_SFT_reduction_variation": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/miquella-120b-6.0bpw-h6-exl2": [
    "output-00001-of-00011.safetensors",
    "output-00002-of-00011.safetensors",
    "output-00003-of-00011.safetensors",
    "output-00004-of-00011.safetensors",
    "output-00005-of-00011.safetensors",
    "output-00006-of-00011.safetensors",
    "output-00007-of-00011.safetensors",
    "output-00008-of-00011.safetensors",
    "output-00009-of-00011.safetensors",
    "output-00010-of-00011.safetensors",
    "output-00011-of-00011.safetensors"
  ],
  "Mlxa/TinyStories-8M-DPO": [
    "model.safetensors"
  ],
  "eswardivi/tinyllama_telugu": [
    "model.safetensors"
  ],
  "nikita-sh/LLMLingua__NousResearch-Llama-2-7b-inf": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LakoMoor/Silicon-Alice-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "kenhktsui/nano-phi-115M-v0.1": [
    "model.safetensors"
  ],
  "ibivibiv/multimaster-7b-v2": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "abhishek/autotrain-t4pdl-8fx9r": [
    "adapter_model.safetensors",
    "checkpoint-1164/adapter_model.safetensors"
  ],
  "a-gambhire/rank_llama_1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Mlxa/TinyStories-8M-DPO-2": [
    "model.safetensors"
  ],
  "merge-crew/munin-neuralbeagle-7b-density-very-high": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "fblin/mistral-inmob-2-1": [
    "adapter_model.safetensors",
    "checkpoint-376/adapter_model.safetensors"
  ],
  "merge-crew/Scandi3": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "modelwizard/argali": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "felixbrock/labeled_mistral_instruct_vllm": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "controltensor/subnet-model-26": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ondevicellm/qwen_1_8B_llamafied": [
    "model.safetensors"
  ],
  "sonthenguyen/OpenHermes-2.5-Mistral-7B-mt-bench-DPO": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "merge-crew/munin-neuralbeagle-7b-density-high": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "danfeg/Noon-Finetuned-Arabic-Semantic-Textual-Similarity": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "aim143/tinystarcoder-rlhf-model": [
    "model.safetensors"
  ],
  "swap-uniba/LLaMAntino-2-70b-hf-UltraChat-ITA": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "LoneStriker/miquella-120b-8.0bpw-h8-exl2": [
    "output-00001-of-00014.safetensors",
    "output-00002-of-00014.safetensors",
    "output-00003-of-00014.safetensors",
    "output-00004-of-00014.safetensors",
    "output-00005-of-00014.safetensors",
    "output-00006-of-00014.safetensors",
    "output-00007-of-00014.safetensors",
    "output-00008-of-00014.safetensors",
    "output-00009-of-00014.safetensors",
    "output-00010-of-00014.safetensors",
    "output-00011-of-00014.safetensors",
    "output-00012-of-00014.safetensors",
    "output-00013-of-00014.safetensors",
    "output-00014-of-00014.safetensors"
  ],
  "kwanok/Llama-2-daangn-7b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "AKILESH18/lamam": [
    "adapter_model.safetensors"
  ],
  "AKILESH18/lamam1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "rldxyz/footballislife": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "pharaouk/rak-8bit": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "abacusai/Smaug-72B-v0.1": [
    "model-00001-of-00030.safetensors",
    "model-00002-of-00030.safetensors",
    "model-00003-of-00030.safetensors",
    "model-00004-of-00030.safetensors",
    "model-00005-of-00030.safetensors",
    "model-00006-of-00030.safetensors",
    "model-00007-of-00030.safetensors",
    "model-00008-of-00030.safetensors",
    "model-00009-of-00030.safetensors",
    "model-00010-of-00030.safetensors",
    "model-00011-of-00030.safetensors",
    "model-00012-of-00030.safetensors",
    "model-00013-of-00030.safetensors",
    "model-00014-of-00030.safetensors",
    "model-00015-of-00030.safetensors",
    "model-00016-of-00030.safetensors",
    "model-00017-of-00030.safetensors",
    "model-00018-of-00030.safetensors",
    "model-00019-of-00030.safetensors",
    "model-00020-of-00030.safetensors",
    "model-00021-of-00030.safetensors",
    "model-00022-of-00030.safetensors",
    "model-00023-of-00030.safetensors",
    "model-00024-of-00030.safetensors",
    "model-00025-of-00030.safetensors",
    "model-00026-of-00030.safetensors",
    "model-00027-of-00030.safetensors",
    "model-00028-of-00030.safetensors",
    "model-00029-of-00030.safetensors",
    "model-00030-of-00030.safetensors"
  ],
  "mtc/LeoLM-leo-mistral-hessianai-7b-xnli-with-explanation-100-5-epoch-4bit-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "incomprehensible/zero": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "pharaouk/fusion-8bit": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "macadeliccc/CapyLake-7B-v2-laser": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "maitreyaz/Airavata-8bit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Danielbrdz/Barcenas-Orca-2-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rickprime/universe-001": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "pxltd/brain_v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dvilasuero/Distilabel-OpenHermes-2.5-Mistral-7B-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jan-hq/stealth-rag-v1.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "robbie0/vntl-7b-v0.3.1-hf-exl2": [
    "cal_data.safetensors",
    "hidden_states.safetensors",
    "model.safetensors"
  ],
  "tomaszki/nous-six": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hammeiam/nous": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mtc/mistralai-Mistral-7B-v0.1-7b-xsum-with-all-explanation-5-epochs-full-dataset-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "pxltd/brain_v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TeeZee/BigMaid-20B-v1.0": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "OpenBuddy/openbuddy-mixtral-7bx8-v17.3-32k": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "mjm4dl/ps_intent_7b_r16": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Synatra-Mixtral-8x7B-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rickprime/universe-002": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jayeshvpatil/tinyllama-medqa-jp-v1": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "OmniFederal/Omni-8x7B-agentsonly-full": [
    "adapter_model.safetensors",
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "devashat/244first": [
    "model.safetensors"
  ],
  "pawan2411/fused-ESG2-LoRA": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "pharaouk/fusedyi": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "chatdb/natural-sql-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "pharaouk/fusedyi-8bit": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Yemmy1000/llama-2-3b-cybersec": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "seyf1elislam/KunaiBeagle-Hermes-7b": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-pipps_removal-seed_1024-1e-3": [
    "model.safetensors"
  ],
  "something-else/HF-rwkv-3B-48-2048-ctx16384": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "afshinO/MisTral-7B-fine-tuned": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "pxltd/brain_v3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rizla/rizla-17": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "rickprime/universe-003": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "deepestneuron/mk3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ankhamun/xxxIo_oIxxx": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "zw1429/wb_ds_interview_fns": [
    "model.safetensors"
  ],
  "Weyaxi/Einstein-v2-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/TinyLlama-1.1B-Chat-v1.0-GGUF": [],
  "Josephgflowers/TinyLlama-3T-Cinder-v1.3": [
    "model.safetensors"
  ],
  "Drewskidang/SFT_Test1": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors",
    "model.safetensors"
  ],
  "tomaszki/nous-seven": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "shyamsubbu/mistral-8epoch-nso": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Aryanne/YarnLake-Swap-7B": [
    "model-00001-of-00042.safetensors",
    "model-00002-of-00042.safetensors",
    "model-00003-of-00042.safetensors",
    "model-00004-of-00042.safetensors",
    "model-00005-of-00042.safetensors",
    "model-00006-of-00042.safetensors",
    "model-00007-of-00042.safetensors",
    "model-00008-of-00042.safetensors",
    "model-00009-of-00042.safetensors",
    "model-00010-of-00042.safetensors",
    "model-00011-of-00042.safetensors",
    "model-00012-of-00042.safetensors",
    "model-00013-of-00042.safetensors",
    "model-00014-of-00042.safetensors",
    "model-00015-of-00042.safetensors",
    "model-00016-of-00042.safetensors",
    "model-00017-of-00042.safetensors",
    "model-00018-of-00042.safetensors",
    "model-00019-of-00042.safetensors",
    "model-00020-of-00042.safetensors",
    "model-00021-of-00042.safetensors",
    "model-00022-of-00042.safetensors",
    "model-00023-of-00042.safetensors",
    "model-00024-of-00042.safetensors",
    "model-00025-of-00042.safetensors",
    "model-00026-of-00042.safetensors",
    "model-00027-of-00042.safetensors",
    "model-00028-of-00042.safetensors",
    "model-00029-of-00042.safetensors",
    "model-00030-of-00042.safetensors",
    "model-00031-of-00042.safetensors",
    "model-00032-of-00042.safetensors",
    "model-00033-of-00042.safetensors",
    "model-00034-of-00042.safetensors",
    "model-00035-of-00042.safetensors",
    "model-00036-of-00042.safetensors",
    "model-00037-of-00042.safetensors",
    "model-00038-of-00042.safetensors",
    "model-00039-of-00042.safetensors",
    "model-00040-of-00042.safetensors",
    "model-00041-of-00042.safetensors",
    "model-00042-of-00042.safetensors"
  ],
  "merge-crew/munin-neuralbeagle-7b-density-low": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "TitleOS/NerdySamantha": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "oivlisnet/Llama-2-7b-chat-bode-pt-br": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "merge-crew/munin-neuralbeagle-7b-density-very-low": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "ConvexAI/Solutus-3x7B": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "Verias/DialoGPT-small-devia": [
    "model.safetensors"
  ],
  "MaziyarPanahi/Mixtral-8x7B-Instruct-v0.1-GGUF": [],
  "oivlisnet/Llama-2-7b-chat-bode-pt-br-gptq": [
    "model.safetensors"
  ],
  "merge-crew/MOE-SWE-DAN-NO-CODE": [
    "model-00001-of-00008.safetensors",
    "model-00001-of-00025.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00002-of-00025.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00003-of-00025.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00004-of-00025.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00005-of-00025.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00006-of-00025.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00007-of-00025.safetensors",
    "model-00008-of-00008.safetensors",
    "model-00008-of-00025.safetensors",
    "model-00009-of-00025.safetensors",
    "model-00010-of-00025.safetensors",
    "model-00011-of-00025.safetensors",
    "model-00012-of-00025.safetensors",
    "model-00013-of-00025.safetensors",
    "model-00014-of-00025.safetensors",
    "model-00015-of-00025.safetensors",
    "model-00016-of-00025.safetensors",
    "model-00017-of-00025.safetensors",
    "model-00018-of-00025.safetensors",
    "model-00019-of-00025.safetensors",
    "model-00020-of-00025.safetensors",
    "model-00021-of-00025.safetensors",
    "model-00022-of-00025.safetensors",
    "model-00023-of-00025.safetensors",
    "model-00024-of-00025.safetensors",
    "model-00025-of-00025.safetensors"
  ],
  "Jimmyhd/llama2TimeBook": [
    "checkpoint-512/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "saishf/Kuro-Lotus-10.7B": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "oivlisnet/Llama-2-13b-chat-bode-pt-br": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "saurabh-shah/olmo-7b-safetensors": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ConvexAI/Roundhouse-4x7B-bf16": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "karawalla/aqmodel_20240203_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "vikash06/doctorLLM": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/Llama-2-7b-chat-hf-GGUF": [],
  "NeuralNovel/Confinus-2x7B": [
    "model-00001-of-00013.safetensors",
    "model-00002-of-00013.safetensors",
    "model-00003-of-00013.safetensors",
    "model-00004-of-00013.safetensors",
    "model-00005-of-00013.safetensors",
    "model-00006-of-00013.safetensors",
    "model-00007-of-00013.safetensors",
    "model-00008-of-00013.safetensors",
    "model-00009-of-00013.safetensors",
    "model-00010-of-00013.safetensors",
    "model-00011-of-00013.safetensors",
    "model-00012-of-00013.safetensors",
    "model-00013-of-00013.safetensors"
  ],
  "saishf/West-Maid-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "mlabonne/NeuralOmniBeagle-7B-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hchung1017/beomi-llama-2-ko-7b": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "cloudyu/4bit_quant_TomGrc_FusionNet_34Bx2_MoE_v0.1_DPO": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Heng666/NeuralPipe-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "TMOU715/NeuralPipe-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "saishf/Kuno-Lake-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "oivlisnet/Llama-2-13b-chat-bode-pt-br-gptq": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "soaring0616/NeuralPipe-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "weimenglin/NeuralPipe-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "modelwizard/mink": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dictatee/NeuralPipe-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "frankc350/NeuralPipe-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "omusico/NeuralPipe-7B-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "shuaigetw/NeuralPipe-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Wahlaalne/NeuralPipe-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "MaziyarPanahi/Mixtral-8x7B-v0.1-GGUF": [],
  "Askahoward/NeuralPipe-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors",
    "model-1.safetensors"
  ],
  "fong33/NeuralPipe-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "InfinityLai/NeuralPipe-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "ND911/Franken-Maid-Slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "IntervitensInc/intv_ai_mk3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Andrewwwwww/0203_mistral-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Verias/convo-devia": [
    "model.safetensors"
  ],
  "winglian/CaptainZed": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ackerley/NeuralPipe-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Yarofa/model_pre_R_v1": [
    "model.safetensors"
  ],
  "rhplus0831/maid-yuzu-v2-mid": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "LHC88/DPOpenHermes-7B-v2-FullLaser": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Crystalcareai/CrystalMiniCPM": [
    "checkpoint-3240/model-00001-of-00002.safetensors",
    "checkpoint-3240/model-00002-of-00002.safetensors"
  ],
  "Vasanth/Beast-Soul-new": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "MaziyarPanahi/Mistral-7B-v0.1-GGUF": [],
  "MaziyarPanahi/Starling-LM-7B-alpha-GGUF": [],
  "MaziyarPanahi/zephyr-7b-beta-GGUF": [],
  "Crystalcareai/Crystalminicpm-DPO": [
    "checkpoint-1016/model-00001-of-00002.safetensors",
    "checkpoint-1016/model-00002-of-00002.safetensors",
    "checkpoint-508/model-00001-of-00002.safetensors",
    "checkpoint-508/model-00002-of-00002.safetensors",
    "checkpoint-635/model-00001-of-00002.safetensors",
    "checkpoint-635/model-00002-of-00002.safetensors",
    "checkpoint-762/model-00001-of-00002.safetensors",
    "checkpoint-762/model-00002-of-00002.safetensors",
    "checkpoint-889/model-00001-of-00002.safetensors",
    "checkpoint-889/model-00002-of-00002.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-pipps_and_keys_to_it_all_removal-seed_1024-1e-3": [
    "model.safetensors"
  ],
  "blueapple8259/TinyKo-v5-a": [
    "model.safetensors"
  ],
  "MaziyarPanahi/zephyr-7b-alpha-GGUF": [],
  "catbult/my_awesome_eli5_mlm_model": [
    "model.safetensors"
  ],
  "blueapple8259/TinyKo-v5-b": [
    "model.safetensors"
  ],
  "blueapple8259/TinyKo-v5-c": [
    "model.safetensors"
  ],
  "jsfs11/MixtureofMerges-MoE-4x7b-v3": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "LoneStriker/Blue-Orchid-2x7b-AWQ": [
    "model.safetensors"
  ],
  "MaziyarPanahi/OpenHermes-2.5-Mistral-7B-GGUF": [],
  "karawalla/aqmodel_20240204": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sarthakharne/Phi1_5-PreTrained-1-epoch": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "sarthakharne/Phi1_5-PreTrained-2-epoch": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "sarthakharne/Phi1_5-PreTrained-3-epoch": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "g-ronimo/phi-2-OpenHermes-2.5": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "sarthakharne/Phi1_5-PreTrained-4-epoch": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "sarthakharne/Phi1_5-PreTrained-5-epoch": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jeiku/Furry_Request_3B": [
    "model-00001-of-00001.safetensors"
  ],
  "LoneStriker/Blue-Orchid-2x7b-GPTQ": [
    "gptq_model-4bit-128g.safetensors"
  ],
  "MaziyarPanahi/mistral-ft-optimized-1227-GGUF": [],
  "jeiku/Soul_3B": [
    "model-00001-of-00001.safetensors"
  ],
  "MaziyarPanahi/openchat-3.5-0106-GGUF": [],
  "Qwen/Qwen1.5-72B-Chat-AWQ": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "Qwen/Qwen1.5-14B-Chat-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Qwen/Qwen1.5-7B-Chat-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Qwen/Qwen1.5-4B-Chat-AWQ": [
    "model.safetensors"
  ],
  "aassegai/llama2-legaleval-merged": [
    "model.safetensors"
  ],
  "Qwen/Qwen1.5-1.8B-Chat-AWQ": [
    "model.safetensors"
  ],
  "Qwen/Qwen1.5-0.5B-Chat-AWQ": [
    "model.safetensors"
  ],
  "HyeoGyu/kogpt_naver_10_finetuned": [
    "model.safetensors"
  ],
  "fterry/FofoNet-CatDolphin-PPT-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "cecb/newsfinetune_mistral_full_03022024": [
    "model.safetensors"
  ],
  "controltensor/subnet-model-27": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/neural-chat-7b-v3-1-GGUF": [],
  "khanhnto/kyt-goat-13b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "PipableAI/pip-SQL-1B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/openchat-3.5-1210-GGUF": [],
  "hammeiam/nous_2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/rank_zephyr_7b_v1_full-GGUF": [],
  "HyeoGyu/kogpt_sentimental_5_finetuned": [
    "model.safetensors"
  ],
  "rhplus0831/maid-yuzu-v2-mid-exl2-6.0bpw-rpcal": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "SiguienteGlobal/base": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "MaziyarPanahi/NeuralHermes-2.5-Mistral-7B-GGUF": [],
  "jondurbin/bagel-dpo-7b-v0.4": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "MaziyarPanahi/zephyr-7b-beta-nf4-fp16-upscaled-GGUF": [],
  "xriminact/TarsMeta": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/notus-7b-v1-GGUF": [],
  "Adeptschneider/merged-fine-tuned-Llama2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FINETUNERMYSTRAL/mmistral-supervised-ft-1epochs": [
    "model.safetensors"
  ],
  "petitpatoche/sn6-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/mindy-7b-v2-GGUF": [],
  "LanguageBind/MoE-LLaVA-StableLM-1.6B-4e-384": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jsfs11/HighdensityRPMerge-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/dolphin-2.6-mistral-7b-dpo-laser-GGUF": [],
  "MaziyarPanahi/mistral-ft-optimized-1218-GGUF": [],
  "Dongmo/WAMBA_Africa_2018": [
    "model.safetensors"
  ],
  "MaziyarPanahi/dolphin-2.6-mistral-7b-GGUF": [],
  "MaziyarPanahi/Kunoichi-7B-GGUF": [],
  "Locutusque/Hercules-2.0-Mistral-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "megastudyedu/M-SOLAR-10.7B-v1.4": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "MaziyarPanahi/go-bruins-v2-GGUF": [],
  "indischepartij/OpenMia-Indo-Mistral-7b-v3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mjm4dl/intent_strlng_v0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/TinyMistral-248M-SFT-v4-GGUF": [],
  "MaziyarPanahi/NeuralBeagle14-7B-GGUF": [],
  "ravithejads/teluguinstructv1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/MetaMath-Cybertron-Starling-GGUF": [],
  "HyeoGyu/kogpt_sentimental_5_finetued": [
    "model.safetensors"
  ],
  "nthngdy/pythia410m-10k-rp": [
    "model.safetensors"
  ],
  "nthngdy/hythia410m-10k_ft_bs256_500_cos_lr1e-4-rp": [
    "model.safetensors"
  ],
  "nthngdy/hythia410m-10k_ft_bs256_500_cos_lr6e-5-rp": [
    "model.safetensors"
  ],
  "nthngdy/hythia410m-10k_ft_bs256_500_cst_lr6e-5-rp": [
    "model.safetensors"
  ],
  "Isotonic/smol_llama-4x220M-MoE": [
    "model-00001-of-00001.safetensors"
  ],
  "cloudyu/TomGrc_FusionNet_34Bx2_MoE_v0.1_DPO_f16": [
    "model-00001-of-00025.safetensors",
    "model-00002-of-00025.safetensors",
    "model-00003-of-00025.safetensors",
    "model-00004-of-00025.safetensors",
    "model-00005-of-00025.safetensors",
    "model-00006-of-00025.safetensors",
    "model-00007-of-00025.safetensors",
    "model-00008-of-00025.safetensors",
    "model-00009-of-00025.safetensors",
    "model-00010-of-00025.safetensors",
    "model-00011-of-00025.safetensors",
    "model-00012-of-00025.safetensors",
    "model-00013-of-00025.safetensors",
    "model-00014-of-00025.safetensors",
    "model-00015-of-00025.safetensors",
    "model-00016-of-00025.safetensors",
    "model-00017-of-00025.safetensors",
    "model-00018-of-00025.safetensors",
    "model-00019-of-00025.safetensors",
    "model-00020-of-00025.safetensors",
    "model-00021-of-00025.safetensors",
    "model-00022-of-00025.safetensors",
    "model-00023-of-00025.safetensors",
    "model-00024-of-00025.safetensors",
    "model-00025-of-00025.safetensors"
  ],
  "ITT-AF/ITT-42dot_LLM-PLM-1.3B-dpo-v1.0": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Isotonic/AdaptLLM-4x7B-MoE": [
    "model-00001-of-00021.safetensors",
    "model-00002-of-00021.safetensors",
    "model-00003-of-00021.safetensors",
    "model-00004-of-00021.safetensors",
    "model-00005-of-00021.safetensors",
    "model-00006-of-00021.safetensors",
    "model-00007-of-00021.safetensors",
    "model-00008-of-00021.safetensors",
    "model-00009-of-00021.safetensors",
    "model-00010-of-00021.safetensors",
    "model-00011-of-00021.safetensors",
    "model-00012-of-00021.safetensors",
    "model-00013-of-00021.safetensors",
    "model-00014-of-00021.safetensors",
    "model-00015-of-00021.safetensors",
    "model-00016-of-00021.safetensors",
    "model-00017-of-00021.safetensors",
    "model-00018-of-00021.safetensors",
    "model-00019-of-00021.safetensors",
    "model-00020-of-00021.safetensors",
    "model-00021-of-00021.safetensors"
  ],
  "benchang1110/tinyllamatw": [
    "model.safetensors"
  ],
  "deepestneuron/mk4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Fufka/Kunoichi-zephyr-pl-7B": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "pxltd/brain_v5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "cmarkea/Mixtral-8x7B-Instruct-v0.1-4bit": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "incomprehensible/one": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "IntervitensInc/intv_ai_mk4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "bravemindai/2024-gui-llama2-7b-openapi-poc": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "BiniyamAjaw/llama-2-7b-finetuned-adapters": [
    "adapter_model.safetensors"
  ],
  "kitty528/article-to-song-final": [
    "model.safetensors"
  ],
  "mwalol/json-qa-sum-v1-1-1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rldxyz/neuromancer": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tomaszki/nous-eight": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/SeaLLM-7B-v2-AWQ": [
    "model.safetensors"
  ],
  "BioMistral/BioMistral-7B-SLERP": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/MetaMath-Chupacabra-7B-v2.01-Slerp-GGUF": [],
  "superfriends/frogman": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "shubham-jj/hindi_v": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "controltensor/subnet-model-28": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rhplus0831/maid-yuzu-v4": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "mayflowergmbh/Wiedervereinigung-7b-dpo-laser-AWQ": [
    "model.safetensors"
  ],
  "mayflowergmbh/Wiedervereinigung-7b-dpo-laser-5.0bpw-exl2": [
    "cal_data.safetensors",
    "hidden_states.safetensors",
    "output.safetensors"
  ],
  "MaziyarPanahi/MetaMath-Tulpar-7b-v2-Slerp-GGUF": [],
  "fterry/FofoNet-DolphinChat-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "BioMistral/BioMistral-7B-Zephyr-Beta-SLERP": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/Metis-0.4-GGUF": [],
  "tomaszki/nous-nine": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "fterry/FoFoNet-SuperMBX-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/OpenHermes-7B-Symbolic-GGUF": [],
  "MaziyarPanahi/TinyMistral-248M-v2.5-Instruct-GGUF": [],
  "ambrosfitz/tinyllama-history-chat_v0.1": [
    "model.safetensors"
  ],
  "ankhamun/xxxI-_-Ixxx": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/openchat-3.5-1210-Seraph-Slerp-GGUF": [],
  "50stars/mistral-7-psy": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "lunarsylph/mooncell": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "PrimeIntellect/nous-subnet-6-test": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "fterry/FoFoNet-SuperMayo-MBX-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/MetaMath-OpenHermes-2.5-neural-chat-v3-3-Slerp-GGUF": [],
  "kevin009/flyingllama-v1": [
    "model.safetensors"
  ],
  "MaziyarPanahi/NeuralMarcoro14-7B-GGUF": [],
  "elijahww/TinyLlama-1.1B_v0.2-merged": [
    "model.safetensors"
  ],
  "fort-capital/phi-2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "typosonlr/dolly-3b-chat-MEDMATCH_1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/Mini_DPO_test02-GGUF": [],
  "kevin009/flyingllama-v2": [
    "model.safetensors"
  ],
  "Finnish-NLP/llama-3b-finnish-v2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "BioMistral/BioMistral-7B-OpenHermes-SLERP": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Apollogeist/mixtral-8x7b-ifunny-bot": [
    "adapter_model.safetensors"
  ],
  "controltensor/subnet-model-29": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Geksaida/llama-2-7b-SysML_test3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "BioMistral/BioMistral-7B-Starling-SLERP": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Abhishek107/v2_metric_tinyllama": [
    "model.safetensors"
  ],
  "amc-madalin/OLMo-1B-instruct-alpaca_amc": [
    "model.safetensors"
  ],
  "hammeiam/nous_3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "HeydarS/opt-350m_no_peft_v11": [
    "model.safetensors"
  ],
  "AbelBekele/llama-2-7b-Amharic-pretrained": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/OPEN-SOLAR-KO-10.7B-GGUF": [],
  "AbelBekele/llama-2-7b-Amharic-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "johnhandleyd/thesa": [
    "adapter_model.safetensors"
  ],
  "MaziyarPanahi/zephyr-7b-sft-full-GGUF": [],
  "Inv/Konstanta-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Jimmyhd/llama213bTimeBook": [
    "checkpoint-344/adapter_model.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-random_removal-1e-3": [
    "model.safetensors"
  ],
  "MaziyarPanahi/zephykor-ko-beta-7b-chang-GGUF": [],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-random_removal-3e-4": [
    "model.safetensors"
  ],
  "Arman123/falcon-rw-1b-ru": [
    "adapter_model.safetensors"
  ],
  "tomaszki/nous-ten": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/typhoon-7b-GGUF": [],
  "mwalol/json_classifier_awq": [
    "model.safetensors"
  ],
  "xriminact/TarsNano": [
    "model.safetensors"
  ],
  "cais/HarmBench-Llama-2-13b-cls": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "kevinautomation/TinyLlama-1.1B-intermediate-step-1431k-3T_project_askred_model": [
    "adapter_model.safetensors"
  ],
  "denisman/sn6_0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "denisman/sn6_1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "denisman/sn6_2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "denisman/sn6_3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TETO101/Airi-70B-v3-a256-awq": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "kasper52786/StoryWeaver-7b-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "pdfleming/2-3-24": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "wolfram/miqu-1-120b": [
    "model-00001-of-00025.safetensors",
    "model-00002-of-00025.safetensors",
    "model-00003-of-00025.safetensors",
    "model-00004-of-00025.safetensors",
    "model-00005-of-00025.safetensors",
    "model-00006-of-00025.safetensors",
    "model-00007-of-00025.safetensors",
    "model-00008-of-00025.safetensors",
    "model-00009-of-00025.safetensors",
    "model-00010-of-00025.safetensors",
    "model-00011-of-00025.safetensors",
    "model-00012-of-00025.safetensors",
    "model-00013-of-00025.safetensors",
    "model-00014-of-00025.safetensors",
    "model-00015-of-00025.safetensors",
    "model-00016-of-00025.safetensors",
    "model-00017-of-00025.safetensors",
    "model-00018-of-00025.safetensors",
    "model-00019-of-00025.safetensors",
    "model-00020-of-00025.safetensors",
    "model-00021-of-00025.safetensors",
    "model-00022-of-00025.safetensors",
    "model-00023-of-00025.safetensors",
    "model-00024-of-00025.safetensors",
    "model-00025-of-00025.safetensors"
  ],
  "s3nh/Severusectum-7B-DPO": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Kquant03/Azathoth-16x7B-bf16": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "hammeiam/nous_4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "alchemonaut/QuartetAnemoi-70B-t0.0001": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "incomprehensible/two": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "deepestneuron/symbiot-001": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "cgato/Thespis-7b-v0.2-SFTTest-3Epoch": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mzbac/phi2-2x4-hf-4bit-mlx": [
    "model.safetensors"
  ],
  "ankhamun/anubis": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Drewskidang/test2": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "ankhamun/Ix_xI": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ankhamun/horus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "controltensor/subnet-model-30": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Drewskidang/test3": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "hammeiam/wimp_lo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "arieridwans/phi_2-finetuned-lyrics-v3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rickprime/universe-004": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TETO101/Airi-70B-v3-a240-awq": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "Crystalcareai/CrystalMistral": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "pxltd/brain_v6": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kenhktsui/nano-phi-115M-control-v0.1": [
    "model.safetensors"
  ],
  "rickprime/universe-005": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "superfriends/frogman-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Radiantloom/radiantloom-mixtral-8x7b-fusion-dpo": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "gotchu/season-8-13b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "eswardivi/llama2chat_telugu": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "deepestneuron/symbiot-002": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "BarraHome/zephyr-dpo-4bit": [
    "model.safetensors"
  ],
  "rldxyz/neuromancer-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "InnerI/autotrain-innerillm2": [
    "adapter_model.safetensors",
    "checkpoint-9/adapter_model.safetensors"
  ],
  "incomprehensible/three": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "gaogao8/my_awesome_eli5_clm-model": [
    "model.safetensors"
  ],
  "rickprime/universe-006": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Sensei-7B-V2-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "0x7o/authorLM-13B-v2-4bit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ewqr2130/llama_ppo_1e6_new_tokenizerstep_8000": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "controltensor/subnet-model-31": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Sensei-7B-V2-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "Xenon1/Xenon-1": [
    "checkpoint-100/adapter_model.safetensors",
    "checkpoint-1000/adapter_model.safetensors",
    "checkpoint-1100/adapter_model.safetensors",
    "checkpoint-1200/adapter_model.safetensors",
    "checkpoint-1300/adapter_model.safetensors",
    "checkpoint-1400/adapter_model.safetensors",
    "checkpoint-1500/adapter_model.safetensors",
    "checkpoint-200/adapter_model.safetensors",
    "checkpoint-300/adapter_model.safetensors",
    "checkpoint-400/adapter_model.safetensors",
    "checkpoint-500/adapter_model.safetensors",
    "checkpoint-600/adapter_model.safetensors",
    "checkpoint-700/adapter_model.safetensors",
    "checkpoint-800/adapter_model.safetensors",
    "checkpoint-900/adapter_model.safetensors",
    "final_checkpoint/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ibivibiv/multimaster-7b-v3": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "LoneStriker/Sensei-7B-V2-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "marikgoldstein/codeparrot-ds": [
    "model.safetensors"
  ],
  "LoneStriker/Sensei-7B-V2-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Sensei-7B-V2-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "kevinautomation/Llama-2-7b-hf_project_ask_reddit_model": [
    "adapter_model.safetensors"
  ],
  "Xenon1/Xenon-2": [
    "checkpoint-1000/adapter_model.safetensors",
    "checkpoint-1500/adapter_model.safetensors",
    "checkpoint-2000/adapter_model.safetensors",
    "checkpoint-2500/adapter_model.safetensors",
    "checkpoint-500/adapter_model.safetensors",
    "final_checkpoint/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Xenon1/Xenon-3": [
    "checkpoint-1000/adapter_model.safetensors",
    "checkpoint-1500/adapter_model.safetensors",
    "checkpoint-2000/adapter_model.safetensors",
    "checkpoint-500/adapter_model.safetensors",
    "final_checkpoint/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Xenon1/Xenon-4": [
    "checkpoint-1000/adapter_model.safetensors",
    "checkpoint-1500/adapter_model.safetensors",
    "checkpoint-2000/adapter_model.safetensors",
    "checkpoint-500/adapter_model.safetensors",
    "final_checkpoint/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "RajuKandasamy/marabutamil": [
    "model.safetensors"
  ],
  "lunarsylph/mooncell_v2": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "OpenBuddy/openbuddy-deepseek-67b-v15.3-4k": [
    "model-00001-of-00028.safetensors",
    "model-00002-of-00028.safetensors",
    "model-00003-of-00028.safetensors",
    "model-00004-of-00028.safetensors",
    "model-00005-of-00028.safetensors",
    "model-00006-of-00028.safetensors",
    "model-00007-of-00028.safetensors",
    "model-00008-of-00028.safetensors",
    "model-00009-of-00028.safetensors",
    "model-00010-of-00028.safetensors",
    "model-00011-of-00028.safetensors",
    "model-00012-of-00028.safetensors",
    "model-00013-of-00028.safetensors",
    "model-00014-of-00028.safetensors",
    "model-00015-of-00028.safetensors",
    "model-00016-of-00028.safetensors",
    "model-00017-of-00028.safetensors",
    "model-00018-of-00028.safetensors",
    "model-00019-of-00028.safetensors",
    "model-00020-of-00028.safetensors",
    "model-00021-of-00028.safetensors",
    "model-00022-of-00028.safetensors",
    "model-00023-of-00028.safetensors",
    "model-00024-of-00028.safetensors",
    "model-00025-of-00028.safetensors",
    "model-00026-of-00028.safetensors",
    "model-00027-of-00028.safetensors",
    "model-00028-of-00028.safetensors"
  ],
  "bart-automation/Llama-2-7b-hf_project_ask_reddit_model": [
    "adapter_model.safetensors"
  ],
  "rhplus0831/maid-yuzu-v4-exl2-6.0bpw-rpcal": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "mzbac/phi-2-2x3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Kquant03/Cognito-2x7B-bf16": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Kquant03/Nanashi-2x7B-bf16": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Shresthadev403/controlled-food-recipe-generation": [
    "model.safetensors"
  ],
  "mjkmain/gpt2-imdb-pos-v2": [
    "model.safetensors"
  ],
  "vikash06/doctorLLM10k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "pdfleming/2-4-24": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Sharathhebbar24/new_mod": [
    "model.safetensors"
  ],
  "Lucia-no/net9_key3": [
    "model.safetensors"
  ],
  "Lucia-no/net9_key1": [
    "model.safetensors"
  ],
  "BarraHome/zephyr-dpo-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Lucia-no/net9_key4": [
    "model.safetensors"
  ],
  "adonlee/Mistral_7B_SFT_DPO_v0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Lucia-no/net9_key5": [
    "model.safetensors"
  ],
  "Lucia-no/net9_key2": [
    "model.safetensors"
  ],
  "Lucia-no/net9_key6": [
    "model.safetensors"
  ],
  "Lucia-no/net9_key7": [
    "model.safetensors"
  ],
  "Lucia-no/net9_key8": [
    "model.safetensors"
  ],
  "tensorplex-labs/finetuning-sn6-1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tensorplex-labs/finetuning-sn6-2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tensorplex-labs/finetuning-sn6-3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tensorplex-labs/finetuning-sn6-5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "cloudyu/TomGrc_FusionNet_34Bx2_MoE_v0.1_full_linear_DPO": [
    "model-00001-of-00025.safetensors",
    "model-00002-of-00025.safetensors",
    "model-00003-of-00025.safetensors",
    "model-00004-of-00025.safetensors",
    "model-00005-of-00025.safetensors",
    "model-00006-of-00025.safetensors",
    "model-00007-of-00025.safetensors",
    "model-00008-of-00025.safetensors",
    "model-00009-of-00025.safetensors",
    "model-00010-of-00025.safetensors",
    "model-00011-of-00025.safetensors",
    "model-00012-of-00025.safetensors",
    "model-00013-of-00025.safetensors",
    "model-00014-of-00025.safetensors",
    "model-00015-of-00025.safetensors",
    "model-00016-of-00025.safetensors",
    "model-00017-of-00025.safetensors",
    "model-00018-of-00025.safetensors",
    "model-00019-of-00025.safetensors",
    "model-00020-of-00025.safetensors",
    "model-00021-of-00025.safetensors",
    "model-00022-of-00025.safetensors",
    "model-00023-of-00025.safetensors",
    "model-00024-of-00025.safetensors",
    "model-00025-of-00025.safetensors"
  ],
  "KnutJaegersberg/Deita-20b": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "mii-llm/maestrale-chat-v0.3-alpha": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tensorplex-labs/finetuning-sn6-4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Sharathhebbar24/new_mod_v1": [
    "model.safetensors"
  ],
  "cledoux42/JoshBot": [
    "adapter_model.safetensors",
    "checkpoint-11/adapter_model.safetensors",
    "checkpoint-22/adapter_model.safetensors",
    "checkpoint-33/adapter_model.safetensors"
  ],
  "affahrizain/gpt2-finetune-id-review-gen": [
    "model.safetensors"
  ],
  "nitky/Swallow-70b-NVE-RP": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "nitky/Swallow-70b-RP": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "smangrul/codellama-hugcoder-merged": [],
  "BemilyForever/funni": [
    "model.safetensors"
  ],
  "sujitvasanth/TheBloke-openchat-3.5-0106-GPTQ": [
    "model.safetensors"
  ],
  "Kalslice/pruned90": [
    "model.safetensors"
  ],
  "Kalslice/pruned80": [
    "model.safetensors"
  ],
  "youngbreadho/codeparrot": [
    "model.safetensors"
  ],
  "cti-ttp-18/fine-tune-llama-7b-epoch2": [
    "adapter_model.safetensors",
    "checkpoint-1918/adapter_model.safetensors"
  ],
  "la-min/sealion-health-faq": [
    "adapter_model.safetensors"
  ],
  "youngbreadho/codeparrot-small": [
    "model.safetensors"
  ],
  "nafisneehal/chandler-bot": [
    "adapter_model.safetensors",
    "checkpoint-312/adapter_model.safetensors"
  ],
  "petitpatoche/sn6-v3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "perceptron-soup/orca_mini_3B-med-dpo": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/Hercules-2.0-Mistral-7B-GGUF": [],
  "li-ping/merged_baichuan_compress_v0": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "li-ping/merged_baichuan_summary_v0": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "jondurbin/bagel-7b-v0.4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "RafaelZequeira/starcoderbase-1b-cucumber-copilot": [
    "model.safetensors"
  ],
  "andrijdavid/MeanGirl": [
    "model.safetensors"
  ],
  "tdh87/StoryTeller7bBad": [
    "model.safetensors"
  ],
  "TuringsSolutions/JediPhiPadawan": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Smaugv0.1-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jiwoochris/persona-test-13b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "mtc/LeoLM-leo-mistral-hessianai-7b-xnli-with-explanation-1000-3-epoch-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "coolmaksat/otuformer32": [
    "model.safetensors"
  ],
  "jondurbin/worthless-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "qwedsacf/btsn6-6-8": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kevin009/llamaRAGdrama": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "nextai-team/Moe-2x7b-QA-Code": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Aditya685/phi-2_riddles-evolved_epoch3": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "IntervitensInc/intv_ai_mk5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Sharathhebbar24/med_mini": [
    "model.safetensors"
  ],
  "mtc/LeoLM-leo-mistral-hessianai-7b-xnli-with-explanation-1000-3-epoch-4bit-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Aditya685/phi-2_riddles-evolved_epoch20": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Sharathhebbar24/gpt_large": [
    "model.safetensors"
  ],
  "Sharathhebbar24/gpt_large_sharded": [
    "model.safetensors"
  ],
  "Duxiaoman-DI/XuanYuan2-70B-Chat-8bit": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "saishf/Top-Western-Maid-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Sharathhebbar24/quan_sharded": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "fokyoum9/Solar_KO_ORCA_Test10": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "ABBNikit/mistral-7b-finetuned-abb-glossary-terms": [
    "adapter_model.safetensors",
    "checkpoint-100/adapter_model.safetensors"
  ],
  "ABBNikit/llama-7b-finetuned-abb-glossary-terms": [
    "adapter_model.safetensors",
    "checkpoint-100/adapter_model.safetensors"
  ],
  "nitky/Swallow-70b-RP-EX": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "rinogrego/HF-CLM-distilgpt2": [
    "model.safetensors"
  ],
  "DrishtiSharma/mixtral-8x7b-instruct-v0.1-english-to-hinglish-translation-merged": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Sharathhebbar24/quan_sharded_1.8": [
    "model.safetensors"
  ],
  "hbin0701/mistral_sdpo_ss4_wo_eos": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "IntervitensInc/intv_ai_mk6": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rinogrego/HF-CLM-distilgpt2-tok": [
    "model.safetensors"
  ],
  "cti-ttp-18/fine-tune-llama-7b-epoch3": [
    "adapter_model.safetensors",
    "checkpoint-1918/adapter_model.safetensors"
  ],
  "ankit011/phi-2.0-sql": [
    "model.safetensors"
  ],
  "nlpguy/Westgate": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "nextai-team/Moe-3x7b-QA-Code-Inst": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "mzbac/phi-2-2x3-hf-4bit-mlx": [
    "model.safetensors"
  ],
  "paulml/OmniBeagleMBX-v3-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Aditya685/Upshot-NeuralHermes-2.5-Mistral-7B-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "StrangeSX/SGX-SeaLLM-7B-v2-Mistral-7B-Instruct-v0.2-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "weijie210/zephyr-7b-UFB-pure-0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Sharathhebbar24/code_gpt2": [
    "model.safetensors"
  ],
  "sam-chami/asturGPT": [
    "model.safetensors"
  ],
  "coolmaksat/otuformer_bert": [
    "model.safetensors"
  ],
  "pdfleming/2-4-24-b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "zjunlp/chatcell-small": [
    "model.safetensors"
  ],
  "noza-kit/rinna-instruct-dolly-ja_1epoch_2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FelixChao/Faraday-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Smaug-72B-v0.1-AWQ": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Josephgflowers/Tinyllama-1.3B-Cinder-Reason-Test": [
    "model.safetensors"
  ],
  "sonthenguyen/OpenHermes-2.5-Mistral-7B-mt-bench-DPO-corrupted": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tomaszki/nous-eleven": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/miqu-1-70b-sf-GPTQ": [
    "model.safetensors"
  ],
  "impossibleexchange/pt30": [
    "model.safetensors"
  ],
  "mtc/LeoLM-leo-mistral-hessianai-7b-absinth-sanity-check_gpt-3-5_3-epochs-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mtc/LeoLM-leo-mistral-hessianai-7b-xnli-with-explanation-1000-6-epoch-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mlabonne/ArchBeagle-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mlabonne/Omnarch-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/Hercules-1.0-Mistral-7B-GGUF": [],
  "lunarsylph/mooncell_v3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "wolfram/miquliz-120b": [
    "model-00001-of-00024.safetensors",
    "model-00002-of-00024.safetensors",
    "model-00003-of-00024.safetensors",
    "model-00004-of-00024.safetensors",
    "model-00005-of-00024.safetensors",
    "model-00006-of-00024.safetensors",
    "model-00007-of-00024.safetensors",
    "model-00008-of-00024.safetensors",
    "model-00009-of-00024.safetensors",
    "model-00010-of-00024.safetensors",
    "model-00011-of-00024.safetensors",
    "model-00012-of-00024.safetensors",
    "model-00013-of-00024.safetensors",
    "model-00014-of-00024.safetensors",
    "model-00015-of-00024.safetensors",
    "model-00016-of-00024.safetensors",
    "model-00017-of-00024.safetensors",
    "model-00018-of-00024.safetensors",
    "model-00019-of-00024.safetensors",
    "model-00020-of-00024.safetensors",
    "model-00021-of-00024.safetensors",
    "model-00022-of-00024.safetensors",
    "model-00023-of-00024.safetensors",
    "model-00024-of-00024.safetensors"
  ],
  "TeeZee/DarkSapling-7B-v1.0": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "kevinautomation/mistral-7b-instruct-tune-500s_test_model": [
    "model.safetensors"
  ],
  "rickprime/universe-007": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SakuraLLM/Sakura-13B-LNovel-v0.11pre1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Abhishek107/v1_system_tinyllama": [
    "model.safetensors"
  ],
  "Josephgflowers/Tinyllama-1.3B-Cinder-Reason-Test-2": [
    "model.safetensors"
  ],
  "indischepartij/OpenMia-Indo-Mistral-7b-v3-refined": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ankhamun/imhotep": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "weijie210/zephyr-7b-UFB-ref": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "X-D-Lab/MindChat-Qwen2-4B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "X-D-Lab/MindChat-Qwen2-0_5B": [
    "model.safetensors"
  ],
  "ankhamun/osiris": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/UltraQwen-7B-GGUF": [],
  "N8Programs/Daschund": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "gianter/distilgpt2-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "pxltd/brain_v7": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "alxcrypto/minerhot16": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Qwen/Qwen1.5-72B-Chat-GPTQ-Int8": [
    "model-00001-of-00020.safetensors",
    "model-00002-of-00020.safetensors",
    "model-00003-of-00020.safetensors",
    "model-00004-of-00020.safetensors",
    "model-00005-of-00020.safetensors",
    "model-00006-of-00020.safetensors",
    "model-00007-of-00020.safetensors",
    "model-00008-of-00020.safetensors",
    "model-00009-of-00020.safetensors",
    "model-00010-of-00020.safetensors",
    "model-00011-of-00020.safetensors",
    "model-00012-of-00020.safetensors",
    "model-00013-of-00020.safetensors",
    "model-00014-of-00020.safetensors",
    "model-00015-of-00020.safetensors",
    "model-00016-of-00020.safetensors",
    "model-00017-of-00020.safetensors",
    "model-00018-of-00020.safetensors",
    "model-00019-of-00020.safetensors",
    "model-00020-of-00020.safetensors"
  ],
  "mjm4dl/intent_strlng_v01": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mtc/mistralai-Mistral-7B-v0.1-7b-xsum-with-all-explanation-3-epochs-full-dataset-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Qwen/Qwen1.5-72B-Chat-GPTQ-Int4": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "Abhishek107/v2_system_tinyllama": [
    "model.safetensors"
  ],
  "MaziyarPanahi/Sensei-7B-V1-GGUF": [],
  "LoneStriker/Smaug-72B-v0.1-GPTQ": [
    "gptq_model-4bit-128g.safetensors"
  ],
  "Qwen/Qwen1.5-14B-Chat-GPTQ-Int8": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Qwen/Qwen1.5-14B-Chat-GPTQ-Int4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Qwen/Qwen1.5-7B-Chat-GPTQ-Int8": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Qwen/Qwen1.5-7B-Chat-GPTQ-Int4": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "foundationmodels/MIMIC-medical-report": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Qwen/Qwen1.5-4B-Chat-GPTQ-Int8": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Qwen/Qwen1.5-4B-Chat-GPTQ-Int4": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "stmackcat/zepb-books-dt19022024-1-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "weijie210/zephyr-7b-critique-pairwise": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Qwen/Qwen1.5-1.8B-Chat-GPTQ-Int8": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Qwen/Qwen1.5-1.8B-Chat-GPTQ-Int4": [
    "model.safetensors"
  ],
  "Qwen/Qwen1.5-0.5B-Chat-GPTQ-Int4": [
    "model.safetensors"
  ],
  "Qwen/Qwen1.5-0.5B-Chat-GPTQ-Int8": [
    "model.safetensors"
  ],
  "rickprime/uni-007": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/distilabeled-Marcoro14-7B-slerp-GGUF": [],
  "miguelcarv/phi-2-slimorca": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "cti-ttp-18/fine-tune-llama-7b-epoch4": [
    "adapter_model.safetensors",
    "checkpoint-1918/adapter_model.safetensors"
  ],
  "SyedSherjeel/gpt2-sharegpt": [
    "model.safetensors"
  ],
  "kevinautomation/mistral-7b-instruct-tune-project_ask_reddit": [
    "model.safetensors"
  ],
  "stmackcat/zepb-books-dt19022024-2-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/distilabeled-OpenHermes-2.5-Mistral-7B-GGUF": [],
  "gotchu/season-8-13bv2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "qwedsacf/btsn6-7": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Arman123/zephyr-7b-beta-openassistant-guanaco": [
    "adapter_model.safetensors"
  ],
  "IntervitensInc/intv_ai_mk7": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mjm4dl/intent_strlng_v02": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sophosympatheia/Midnight-Rose-70B-v2.0.3": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "indischepartij/OpenMia-Indo-Engineering-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "openvoid/prox-7b-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Eric111/Mayo": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Tamnemtf/llama2-7b-vi-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "IntervitensInc/intv_ai_mk8": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "duxx/test_model_lora_25": [
    "model.safetensors"
  ],
  "qwedsacf/btsn6-m1-1": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "MaziyarPanahi/notux-8x7b-v1-GGUF": [],
  "mtc/mistralai-Mistral-7B-v0.1-7b-xsum-with-all-explanation-3-epochs-full-dataset-eot-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "stmackcat/zepb-books-dt19022024-3-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dreamgen/opus-v1.2-7b-lora-instruct_32k_128-64_6_0-000005": [
    "adapter_model.safetensors",
    "checkpoint-1008/adapter_model.safetensors",
    "checkpoint-1050/adapter_model.safetensors",
    "checkpoint-1092/adapter_model.safetensors",
    "checkpoint-1134/adapter_model.safetensors",
    "checkpoint-1176/adapter_model.safetensors",
    "checkpoint-1218/adapter_model.safetensors",
    "checkpoint-126/adapter_model.safetensors",
    "checkpoint-1260/adapter_model.safetensors",
    "checkpoint-1302/adapter_model.safetensors",
    "checkpoint-1344/adapter_model.safetensors",
    "checkpoint-168/adapter_model.safetensors",
    "checkpoint-210/adapter_model.safetensors",
    "checkpoint-252/adapter_model.safetensors",
    "checkpoint-294/adapter_model.safetensors",
    "checkpoint-336/adapter_model.safetensors",
    "checkpoint-378/adapter_model.safetensors",
    "checkpoint-42/adapter_model.safetensors",
    "checkpoint-420/adapter_model.safetensors",
    "checkpoint-462/adapter_model.safetensors",
    "checkpoint-504/adapter_model.safetensors",
    "checkpoint-546/adapter_model.safetensors",
    "checkpoint-588/adapter_model.safetensors",
    "checkpoint-630/adapter_model.safetensors",
    "checkpoint-672/adapter_model.safetensors",
    "checkpoint-714/adapter_model.safetensors",
    "checkpoint-756/adapter_model.safetensors",
    "checkpoint-798/adapter_model.safetensors",
    "checkpoint-84/adapter_model.safetensors",
    "checkpoint-840/adapter_model.safetensors",
    "checkpoint-882/adapter_model.safetensors",
    "checkpoint-924/adapter_model.safetensors",
    "checkpoint-966/adapter_model.safetensors"
  ],
  "movaxbx/OpenHermes-Emojitron-001": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "nbeerbower/maidphin": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "shi-zheng-qxhs/cutecode_pretrain": [
    "model.safetensors"
  ],
  "petitpatoche/sn6-v4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "YaTharThShaRma999/cogvlm-quantized-4bit": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "djomo/MISTRALllux1000-7b-v5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "petitpatoche/sn6-v5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mtc/mistralai-Mistral-7B-v0.1-7b-xsum-with-all-explanation-3-epochs-full-dataset-eot-2-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "s3nh/SeverusWestLake-7B-DPO": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Kyllene-34B-v1.1-3.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Karko/embryophagus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Kyllene-34B-v1.1-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Kyllene-34B-v1.1-4.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "arnavgrg/codellama-70b-instruct-nf4-fp16-upscaled": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "0xffffull/NeuralHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Kyllene-34B-v1.1-5.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "Floobin/TSwifty-SN6": [],
  "minghaowu/phi-2-OpenHermes-2.5": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Kyllene-34B-v1.1-6.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "arnavgrg/phi-2-nf4-fp16-upscaled": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "arnavgrg/mistral-7b-nf4-fp16-upscaled": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Kyllene-34B-v1.1-8.0bpw-h8-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "starsnatched/MemGPT-2B": [
    "model.safetensors"
  ],
  "mpasila/MythoMax-L2-13b-safetensors": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "tomaszki/nous-twelve": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "shazinho10/llama_email_model": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "rio-codes/Mixtral_Rio_oasst2_v1": [
    "adapter_model.safetensors"
  ],
  "MaziyarPanahi/MixTAO-7Bx2-MoE-Instruct-v7.0-GGUF": [],
  "lunarsylph/mooncell_v4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "astarostap/final-instruct-dentalqa-guanaco-phi-2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Arman123/gpt-neox-20b-openassistant-guanaco": [
    "adapter_model.safetensors"
  ],
  "Copy6852/RoboSashaModel": [
    "model.safetensors"
  ],
  "Josephgflowers/distillgpt2Cinder": [
    "model.safetensors"
  ],
  "azertick20/myth13b-no-pytorch": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "norallm/normistral-7b-scratch": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "norallm/normistral-7b-warm": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "norallm/norbloom-7b-scratch": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "arieridwans/phi_2-finetuned-lyrics-v4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "blasees/gpt2_chats_proposals": [
    "model.safetensors"
  ],
  "badoomba/pretraining": [
    "model.safetensors"
  ],
  "megastudyedu/M-SOLAR-10.7B-v1.4-dpo": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "kaitchup/TinyLlama-1.1B-intermediate-step-1431k-3T-gptq-4bit": [
    "model.safetensors"
  ],
  "Atharva-28/llama-2-7b-platypus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "duxx/test_model_lora_50": [
    "model.safetensors"
  ],
  "calliehsu/tiny-llama-shuttle-xpc-cube-en100-datax10": [
    "model.safetensors"
  ],
  "rldxyz/quantumleap": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "deepestneuron/matrix-01": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kaitchup/TinyLlama-1.1B-intermediate-step-1431k-3T-awq-4bit": [
    "model.safetensors"
  ],
  "JaeyeonKang/CCK_Asura_v1": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "shazinho10/llama_email": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "bn999/mistral-4.2B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "typeof/miqu-70b-split": [
    "model-00001-of-00723.safetensors",
    "model-00002-of-00723.safetensors",
    "model-00003-of-00723.safetensors",
    "model-00004-of-00723.safetensors",
    "model-00005-of-00723.safetensors",
    "model-00006-of-00723.safetensors",
    "model-00007-of-00723.safetensors",
    "model-00008-of-00723.safetensors",
    "model-00009-of-00723.safetensors",
    "model-00010-of-00723.safetensors",
    "model-00011-of-00723.safetensors",
    "model-00012-of-00723.safetensors",
    "model-00013-of-00723.safetensors",
    "model-00014-of-00723.safetensors",
    "model-00015-of-00723.safetensors",
    "model-00016-of-00723.safetensors",
    "model-00017-of-00723.safetensors",
    "model-00018-of-00723.safetensors",
    "model-00019-of-00723.safetensors",
    "model-00020-of-00723.safetensors",
    "model-00021-of-00723.safetensors",
    "model-00022-of-00723.safetensors",
    "model-00023-of-00723.safetensors",
    "model-00024-of-00723.safetensors",
    "model-00025-of-00723.safetensors",
    "model-00026-of-00723.safetensors",
    "model-00027-of-00723.safetensors",
    "model-00028-of-00723.safetensors",
    "model-00029-of-00723.safetensors",
    "model-00030-of-00723.safetensors",
    "model-00031-of-00723.safetensors",
    "model-00032-of-00723.safetensors",
    "model-00033-of-00723.safetensors",
    "model-00034-of-00723.safetensors",
    "model-00035-of-00723.safetensors",
    "model-00036-of-00723.safetensors",
    "model-00037-of-00723.safetensors",
    "model-00038-of-00723.safetensors",
    "model-00039-of-00723.safetensors",
    "model-00040-of-00723.safetensors",
    "model-00041-of-00723.safetensors",
    "model-00042-of-00723.safetensors",
    "model-00043-of-00723.safetensors",
    "model-00044-of-00723.safetensors",
    "model-00045-of-00723.safetensors",
    "model-00046-of-00723.safetensors",
    "model-00047-of-00723.safetensors",
    "model-00048-of-00723.safetensors",
    "model-00049-of-00723.safetensors",
    "model-00050-of-00723.safetensors",
    "model-00051-of-00723.safetensors",
    "model-00052-of-00723.safetensors",
    "model-00053-of-00723.safetensors",
    "model-00054-of-00723.safetensors",
    "model-00055-of-00723.safetensors",
    "model-00056-of-00723.safetensors",
    "model-00057-of-00723.safetensors",
    "model-00058-of-00723.safetensors",
    "model-00059-of-00723.safetensors",
    "model-00060-of-00723.safetensors",
    "model-00061-of-00723.safetensors",
    "model-00062-of-00723.safetensors",
    "model-00063-of-00723.safetensors",
    "model-00064-of-00723.safetensors",
    "model-00065-of-00723.safetensors",
    "model-00066-of-00723.safetensors",
    "model-00067-of-00723.safetensors",
    "model-00068-of-00723.safetensors",
    "model-00069-of-00723.safetensors",
    "model-00070-of-00723.safetensors",
    "model-00071-of-00723.safetensors",
    "model-00072-of-00723.safetensors",
    "model-00073-of-00723.safetensors",
    "model-00074-of-00723.safetensors",
    "model-00075-of-00723.safetensors",
    "model-00076-of-00723.safetensors",
    "model-00077-of-00723.safetensors",
    "model-00078-of-00723.safetensors",
    "model-00079-of-00723.safetensors",
    "model-00080-of-00723.safetensors",
    "model-00081-of-00723.safetensors",
    "model-00082-of-00723.safetensors",
    "model-00083-of-00723.safetensors",
    "model-00084-of-00723.safetensors",
    "model-00085-of-00723.safetensors",
    "model-00086-of-00723.safetensors",
    "model-00087-of-00723.safetensors",
    "model-00088-of-00723.safetensors",
    "model-00089-of-00723.safetensors",
    "model-00090-of-00723.safetensors",
    "model-00091-of-00723.safetensors",
    "model-00092-of-00723.safetensors",
    "model-00093-of-00723.safetensors",
    "model-00094-of-00723.safetensors",
    "model-00095-of-00723.safetensors",
    "model-00096-of-00723.safetensors",
    "model-00097-of-00723.safetensors",
    "model-00098-of-00723.safetensors",
    "model-00099-of-00723.safetensors",
    "model-00100-of-00723.safetensors",
    "model-00101-of-00723.safetensors",
    "model-00102-of-00723.safetensors",
    "model-00103-of-00723.safetensors",
    "model-00104-of-00723.safetensors",
    "model-00105-of-00723.safetensors",
    "model-00106-of-00723.safetensors",
    "model-00107-of-00723.safetensors",
    "model-00108-of-00723.safetensors",
    "model-00109-of-00723.safetensors",
    "model-00110-of-00723.safetensors",
    "model-00111-of-00723.safetensors",
    "model-00112-of-00723.safetensors",
    "model-00113-of-00723.safetensors",
    "model-00114-of-00723.safetensors",
    "model-00115-of-00723.safetensors",
    "model-00116-of-00723.safetensors",
    "model-00117-of-00723.safetensors",
    "model-00118-of-00723.safetensors",
    "model-00119-of-00723.safetensors",
    "model-00120-of-00723.safetensors",
    "model-00121-of-00723.safetensors",
    "model-00122-of-00723.safetensors",
    "model-00123-of-00723.safetensors",
    "model-00124-of-00723.safetensors",
    "model-00125-of-00723.safetensors",
    "model-00126-of-00723.safetensors",
    "model-00127-of-00723.safetensors",
    "model-00128-of-00723.safetensors",
    "model-00129-of-00723.safetensors",
    "model-00130-of-00723.safetensors",
    "model-00131-of-00723.safetensors",
    "model-00132-of-00723.safetensors",
    "model-00133-of-00723.safetensors",
    "model-00134-of-00723.safetensors",
    "model-00135-of-00723.safetensors",
    "model-00136-of-00723.safetensors",
    "model-00137-of-00723.safetensors",
    "model-00138-of-00723.safetensors",
    "model-00139-of-00723.safetensors",
    "model-00140-of-00723.safetensors",
    "model-00141-of-00723.safetensors",
    "model-00142-of-00723.safetensors",
    "model-00143-of-00723.safetensors",
    "model-00144-of-00723.safetensors",
    "model-00145-of-00723.safetensors",
    "model-00146-of-00723.safetensors",
    "model-00147-of-00723.safetensors",
    "model-00148-of-00723.safetensors",
    "model-00149-of-00723.safetensors",
    "model-00150-of-00723.safetensors",
    "model-00151-of-00723.safetensors",
    "model-00152-of-00723.safetensors",
    "model-00153-of-00723.safetensors",
    "model-00154-of-00723.safetensors",
    "model-00155-of-00723.safetensors",
    "model-00156-of-00723.safetensors",
    "model-00157-of-00723.safetensors",
    "model-00158-of-00723.safetensors",
    "model-00159-of-00723.safetensors",
    "model-00160-of-00723.safetensors",
    "model-00161-of-00723.safetensors",
    "model-00162-of-00723.safetensors",
    "model-00163-of-00723.safetensors",
    "model-00164-of-00723.safetensors",
    "model-00165-of-00723.safetensors",
    "model-00166-of-00723.safetensors",
    "model-00167-of-00723.safetensors",
    "model-00168-of-00723.safetensors",
    "model-00169-of-00723.safetensors",
    "model-00170-of-00723.safetensors",
    "model-00171-of-00723.safetensors",
    "model-00172-of-00723.safetensors",
    "model-00173-of-00723.safetensors",
    "model-00174-of-00723.safetensors",
    "model-00175-of-00723.safetensors",
    "model-00176-of-00723.safetensors",
    "model-00177-of-00723.safetensors",
    "model-00178-of-00723.safetensors",
    "model-00179-of-00723.safetensors",
    "model-00180-of-00723.safetensors",
    "model-00181-of-00723.safetensors",
    "model-00182-of-00723.safetensors",
    "model-00183-of-00723.safetensors",
    "model-00184-of-00723.safetensors",
    "model-00185-of-00723.safetensors",
    "model-00186-of-00723.safetensors",
    "model-00187-of-00723.safetensors",
    "model-00188-of-00723.safetensors",
    "model-00189-of-00723.safetensors",
    "model-00190-of-00723.safetensors",
    "model-00191-of-00723.safetensors",
    "model-00192-of-00723.safetensors",
    "model-00193-of-00723.safetensors",
    "model-00194-of-00723.safetensors",
    "model-00195-of-00723.safetensors",
    "model-00196-of-00723.safetensors",
    "model-00197-of-00723.safetensors",
    "model-00198-of-00723.safetensors",
    "model-00199-of-00723.safetensors",
    "model-00200-of-00723.safetensors",
    "model-00201-of-00723.safetensors",
    "model-00202-of-00723.safetensors",
    "model-00203-of-00723.safetensors",
    "model-00204-of-00723.safetensors",
    "model-00205-of-00723.safetensors",
    "model-00206-of-00723.safetensors",
    "model-00207-of-00723.safetensors",
    "model-00208-of-00723.safetensors",
    "model-00209-of-00723.safetensors",
    "model-00210-of-00723.safetensors",
    "model-00211-of-00723.safetensors",
    "model-00212-of-00723.safetensors",
    "model-00213-of-00723.safetensors",
    "model-00214-of-00723.safetensors",
    "model-00215-of-00723.safetensors",
    "model-00216-of-00723.safetensors",
    "model-00217-of-00723.safetensors",
    "model-00218-of-00723.safetensors",
    "model-00219-of-00723.safetensors",
    "model-00220-of-00723.safetensors",
    "model-00221-of-00723.safetensors",
    "model-00222-of-00723.safetensors",
    "model-00223-of-00723.safetensors",
    "model-00224-of-00723.safetensors",
    "model-00225-of-00723.safetensors",
    "model-00226-of-00723.safetensors",
    "model-00227-of-00723.safetensors",
    "model-00228-of-00723.safetensors",
    "model-00229-of-00723.safetensors",
    "model-00230-of-00723.safetensors",
    "model-00231-of-00723.safetensors",
    "model-00232-of-00723.safetensors",
    "model-00233-of-00723.safetensors",
    "model-00234-of-00723.safetensors",
    "model-00235-of-00723.safetensors",
    "model-00236-of-00723.safetensors",
    "model-00237-of-00723.safetensors",
    "model-00238-of-00723.safetensors",
    "model-00239-of-00723.safetensors",
    "model-00240-of-00723.safetensors",
    "model-00241-of-00723.safetensors",
    "model-00242-of-00723.safetensors",
    "model-00243-of-00723.safetensors",
    "model-00244-of-00723.safetensors",
    "model-00245-of-00723.safetensors",
    "model-00246-of-00723.safetensors",
    "model-00247-of-00723.safetensors",
    "model-00248-of-00723.safetensors",
    "model-00249-of-00723.safetensors",
    "model-00250-of-00723.safetensors",
    "model-00251-of-00723.safetensors",
    "model-00252-of-00723.safetensors",
    "model-00253-of-00723.safetensors",
    "model-00254-of-00723.safetensors",
    "model-00255-of-00723.safetensors",
    "model-00256-of-00723.safetensors",
    "model-00257-of-00723.safetensors",
    "model-00258-of-00723.safetensors",
    "model-00259-of-00723.safetensors",
    "model-00260-of-00723.safetensors",
    "model-00261-of-00723.safetensors",
    "model-00262-of-00723.safetensors",
    "model-00263-of-00723.safetensors",
    "model-00264-of-00723.safetensors",
    "model-00265-of-00723.safetensors",
    "model-00266-of-00723.safetensors",
    "model-00267-of-00723.safetensors",
    "model-00268-of-00723.safetensors",
    "model-00269-of-00723.safetensors",
    "model-00270-of-00723.safetensors",
    "model-00271-of-00723.safetensors",
    "model-00272-of-00723.safetensors",
    "model-00273-of-00723.safetensors",
    "model-00274-of-00723.safetensors",
    "model-00275-of-00723.safetensors",
    "model-00276-of-00723.safetensors",
    "model-00277-of-00723.safetensors",
    "model-00278-of-00723.safetensors",
    "model-00279-of-00723.safetensors",
    "model-00280-of-00723.safetensors",
    "model-00281-of-00723.safetensors",
    "model-00282-of-00723.safetensors",
    "model-00283-of-00723.safetensors",
    "model-00284-of-00723.safetensors",
    "model-00285-of-00723.safetensors",
    "model-00286-of-00723.safetensors",
    "model-00287-of-00723.safetensors",
    "model-00288-of-00723.safetensors",
    "model-00289-of-00723.safetensors",
    "model-00290-of-00723.safetensors",
    "model-00291-of-00723.safetensors",
    "model-00292-of-00723.safetensors",
    "model-00293-of-00723.safetensors",
    "model-00294-of-00723.safetensors",
    "model-00295-of-00723.safetensors",
    "model-00296-of-00723.safetensors",
    "model-00297-of-00723.safetensors",
    "model-00298-of-00723.safetensors",
    "model-00299-of-00723.safetensors",
    "model-00300-of-00723.safetensors",
    "model-00301-of-00723.safetensors",
    "model-00302-of-00723.safetensors",
    "model-00303-of-00723.safetensors",
    "model-00304-of-00723.safetensors",
    "model-00305-of-00723.safetensors",
    "model-00306-of-00723.safetensors",
    "model-00307-of-00723.safetensors",
    "model-00308-of-00723.safetensors",
    "model-00309-of-00723.safetensors",
    "model-00310-of-00723.safetensors",
    "model-00311-of-00723.safetensors",
    "model-00312-of-00723.safetensors",
    "model-00313-of-00723.safetensors",
    "model-00314-of-00723.safetensors",
    "model-00315-of-00723.safetensors",
    "model-00316-of-00723.safetensors",
    "model-00317-of-00723.safetensors",
    "model-00318-of-00723.safetensors",
    "model-00319-of-00723.safetensors",
    "model-00320-of-00723.safetensors",
    "model-00321-of-00723.safetensors",
    "model-00322-of-00723.safetensors",
    "model-00323-of-00723.safetensors",
    "model-00324-of-00723.safetensors",
    "model-00325-of-00723.safetensors",
    "model-00326-of-00723.safetensors",
    "model-00327-of-00723.safetensors",
    "model-00328-of-00723.safetensors",
    "model-00329-of-00723.safetensors",
    "model-00330-of-00723.safetensors",
    "model-00331-of-00723.safetensors",
    "model-00332-of-00723.safetensors",
    "model-00333-of-00723.safetensors",
    "model-00334-of-00723.safetensors",
    "model-00335-of-00723.safetensors",
    "model-00336-of-00723.safetensors",
    "model-00337-of-00723.safetensors",
    "model-00338-of-00723.safetensors",
    "model-00339-of-00723.safetensors",
    "model-00340-of-00723.safetensors",
    "model-00341-of-00723.safetensors",
    "model-00342-of-00723.safetensors",
    "model-00343-of-00723.safetensors",
    "model-00344-of-00723.safetensors",
    "model-00345-of-00723.safetensors",
    "model-00346-of-00723.safetensors",
    "model-00347-of-00723.safetensors",
    "model-00348-of-00723.safetensors",
    "model-00349-of-00723.safetensors",
    "model-00350-of-00723.safetensors",
    "model-00351-of-00723.safetensors",
    "model-00352-of-00723.safetensors",
    "model-00353-of-00723.safetensors",
    "model-00354-of-00723.safetensors",
    "model-00355-of-00723.safetensors",
    "model-00356-of-00723.safetensors",
    "model-00357-of-00723.safetensors",
    "model-00358-of-00723.safetensors",
    "model-00359-of-00723.safetensors",
    "model-00360-of-00723.safetensors",
    "model-00361-of-00723.safetensors",
    "model-00362-of-00723.safetensors",
    "model-00363-of-00723.safetensors",
    "model-00364-of-00723.safetensors",
    "model-00365-of-00723.safetensors",
    "model-00366-of-00723.safetensors",
    "model-00367-of-00723.safetensors",
    "model-00368-of-00723.safetensors",
    "model-00369-of-00723.safetensors",
    "model-00370-of-00723.safetensors",
    "model-00371-of-00723.safetensors",
    "model-00372-of-00723.safetensors",
    "model-00373-of-00723.safetensors",
    "model-00374-of-00723.safetensors",
    "model-00375-of-00723.safetensors",
    "model-00376-of-00723.safetensors",
    "model-00377-of-00723.safetensors",
    "model-00378-of-00723.safetensors",
    "model-00379-of-00723.safetensors",
    "model-00380-of-00723.safetensors",
    "model-00381-of-00723.safetensors",
    "model-00382-of-00723.safetensors",
    "model-00383-of-00723.safetensors",
    "model-00384-of-00723.safetensors",
    "model-00385-of-00723.safetensors",
    "model-00386-of-00723.safetensors",
    "model-00387-of-00723.safetensors",
    "model-00388-of-00723.safetensors",
    "model-00389-of-00723.safetensors",
    "model-00390-of-00723.safetensors",
    "model-00391-of-00723.safetensors",
    "model-00392-of-00723.safetensors",
    "model-00393-of-00723.safetensors",
    "model-00394-of-00723.safetensors",
    "model-00395-of-00723.safetensors",
    "model-00396-of-00723.safetensors",
    "model-00397-of-00723.safetensors",
    "model-00398-of-00723.safetensors",
    "model-00399-of-00723.safetensors",
    "model-00400-of-00723.safetensors",
    "model-00401-of-00723.safetensors",
    "model-00402-of-00723.safetensors",
    "model-00403-of-00723.safetensors",
    "model-00404-of-00723.safetensors",
    "model-00405-of-00723.safetensors",
    "model-00406-of-00723.safetensors",
    "model-00407-of-00723.safetensors",
    "model-00408-of-00723.safetensors",
    "model-00409-of-00723.safetensors",
    "model-00410-of-00723.safetensors",
    "model-00411-of-00723.safetensors",
    "model-00412-of-00723.safetensors",
    "model-00413-of-00723.safetensors",
    "model-00414-of-00723.safetensors",
    "model-00415-of-00723.safetensors",
    "model-00416-of-00723.safetensors",
    "model-00417-of-00723.safetensors",
    "model-00418-of-00723.safetensors",
    "model-00419-of-00723.safetensors",
    "model-00420-of-00723.safetensors",
    "model-00421-of-00723.safetensors",
    "model-00422-of-00723.safetensors",
    "model-00423-of-00723.safetensors",
    "model-00424-of-00723.safetensors",
    "model-00425-of-00723.safetensors",
    "model-00426-of-00723.safetensors",
    "model-00427-of-00723.safetensors",
    "model-00428-of-00723.safetensors",
    "model-00429-of-00723.safetensors",
    "model-00430-of-00723.safetensors",
    "model-00431-of-00723.safetensors",
    "model-00432-of-00723.safetensors",
    "model-00433-of-00723.safetensors",
    "model-00434-of-00723.safetensors",
    "model-00435-of-00723.safetensors",
    "model-00436-of-00723.safetensors",
    "model-00437-of-00723.safetensors",
    "model-00438-of-00723.safetensors",
    "model-00439-of-00723.safetensors",
    "model-00440-of-00723.safetensors",
    "model-00441-of-00723.safetensors",
    "model-00442-of-00723.safetensors",
    "model-00443-of-00723.safetensors",
    "model-00444-of-00723.safetensors",
    "model-00445-of-00723.safetensors",
    "model-00446-of-00723.safetensors",
    "model-00447-of-00723.safetensors",
    "model-00448-of-00723.safetensors",
    "model-00449-of-00723.safetensors",
    "model-00450-of-00723.safetensors",
    "model-00451-of-00723.safetensors",
    "model-00452-of-00723.safetensors",
    "model-00453-of-00723.safetensors",
    "model-00454-of-00723.safetensors",
    "model-00455-of-00723.safetensors",
    "model-00456-of-00723.safetensors",
    "model-00457-of-00723.safetensors",
    "model-00458-of-00723.safetensors",
    "model-00459-of-00723.safetensors",
    "model-00460-of-00723.safetensors",
    "model-00461-of-00723.safetensors",
    "model-00462-of-00723.safetensors",
    "model-00463-of-00723.safetensors",
    "model-00464-of-00723.safetensors",
    "model-00465-of-00723.safetensors",
    "model-00466-of-00723.safetensors",
    "model-00467-of-00723.safetensors",
    "model-00468-of-00723.safetensors",
    "model-00469-of-00723.safetensors",
    "model-00470-of-00723.safetensors",
    "model-00471-of-00723.safetensors",
    "model-00472-of-00723.safetensors",
    "model-00473-of-00723.safetensors",
    "model-00474-of-00723.safetensors",
    "model-00475-of-00723.safetensors",
    "model-00476-of-00723.safetensors",
    "model-00477-of-00723.safetensors",
    "model-00478-of-00723.safetensors",
    "model-00479-of-00723.safetensors",
    "model-00480-of-00723.safetensors",
    "model-00481-of-00723.safetensors",
    "model-00482-of-00723.safetensors",
    "model-00483-of-00723.safetensors",
    "model-00484-of-00723.safetensors",
    "model-00485-of-00723.safetensors",
    "model-00486-of-00723.safetensors",
    "model-00487-of-00723.safetensors",
    "model-00488-of-00723.safetensors",
    "model-00489-of-00723.safetensors",
    "model-00490-of-00723.safetensors",
    "model-00491-of-00723.safetensors",
    "model-00492-of-00723.safetensors",
    "model-00493-of-00723.safetensors",
    "model-00494-of-00723.safetensors",
    "model-00495-of-00723.safetensors",
    "model-00496-of-00723.safetensors",
    "model-00497-of-00723.safetensors",
    "model-00498-of-00723.safetensors",
    "model-00499-of-00723.safetensors",
    "model-00500-of-00723.safetensors",
    "model-00501-of-00723.safetensors",
    "model-00502-of-00723.safetensors",
    "model-00503-of-00723.safetensors",
    "model-00504-of-00723.safetensors",
    "model-00505-of-00723.safetensors",
    "model-00506-of-00723.safetensors",
    "model-00507-of-00723.safetensors",
    "model-00508-of-00723.safetensors",
    "model-00509-of-00723.safetensors",
    "model-00510-of-00723.safetensors",
    "model-00511-of-00723.safetensors",
    "model-00512-of-00723.safetensors",
    "model-00513-of-00723.safetensors",
    "model-00514-of-00723.safetensors",
    "model-00515-of-00723.safetensors",
    "model-00516-of-00723.safetensors",
    "model-00517-of-00723.safetensors",
    "model-00518-of-00723.safetensors",
    "model-00519-of-00723.safetensors",
    "model-00520-of-00723.safetensors",
    "model-00521-of-00723.safetensors",
    "model-00522-of-00723.safetensors",
    "model-00523-of-00723.safetensors",
    "model-00524-of-00723.safetensors",
    "model-00525-of-00723.safetensors",
    "model-00526-of-00723.safetensors",
    "model-00527-of-00723.safetensors",
    "model-00528-of-00723.safetensors",
    "model-00529-of-00723.safetensors",
    "model-00530-of-00723.safetensors",
    "model-00531-of-00723.safetensors",
    "model-00532-of-00723.safetensors",
    "model-00533-of-00723.safetensors",
    "model-00534-of-00723.safetensors",
    "model-00535-of-00723.safetensors",
    "model-00536-of-00723.safetensors",
    "model-00537-of-00723.safetensors",
    "model-00538-of-00723.safetensors",
    "model-00539-of-00723.safetensors",
    "model-00540-of-00723.safetensors",
    "model-00541-of-00723.safetensors",
    "model-00542-of-00723.safetensors",
    "model-00543-of-00723.safetensors",
    "model-00544-of-00723.safetensors",
    "model-00545-of-00723.safetensors",
    "model-00546-of-00723.safetensors",
    "model-00547-of-00723.safetensors",
    "model-00548-of-00723.safetensors",
    "model-00549-of-00723.safetensors",
    "model-00550-of-00723.safetensors",
    "model-00551-of-00723.safetensors",
    "model-00552-of-00723.safetensors",
    "model-00553-of-00723.safetensors",
    "model-00554-of-00723.safetensors",
    "model-00555-of-00723.safetensors",
    "model-00556-of-00723.safetensors",
    "model-00557-of-00723.safetensors",
    "model-00558-of-00723.safetensors",
    "model-00559-of-00723.safetensors",
    "model-00560-of-00723.safetensors",
    "model-00561-of-00723.safetensors",
    "model-00562-of-00723.safetensors",
    "model-00563-of-00723.safetensors",
    "model-00564-of-00723.safetensors",
    "model-00565-of-00723.safetensors",
    "model-00566-of-00723.safetensors",
    "model-00567-of-00723.safetensors",
    "model-00568-of-00723.safetensors",
    "model-00569-of-00723.safetensors",
    "model-00570-of-00723.safetensors",
    "model-00571-of-00723.safetensors",
    "model-00572-of-00723.safetensors",
    "model-00573-of-00723.safetensors",
    "model-00574-of-00723.safetensors",
    "model-00575-of-00723.safetensors",
    "model-00576-of-00723.safetensors",
    "model-00577-of-00723.safetensors",
    "model-00578-of-00723.safetensors",
    "model-00579-of-00723.safetensors",
    "model-00580-of-00723.safetensors",
    "model-00581-of-00723.safetensors",
    "model-00582-of-00723.safetensors",
    "model-00583-of-00723.safetensors",
    "model-00584-of-00723.safetensors",
    "model-00585-of-00723.safetensors",
    "model-00586-of-00723.safetensors",
    "model-00587-of-00723.safetensors",
    "model-00588-of-00723.safetensors",
    "model-00589-of-00723.safetensors",
    "model-00590-of-00723.safetensors",
    "model-00591-of-00723.safetensors",
    "model-00592-of-00723.safetensors",
    "model-00593-of-00723.safetensors",
    "model-00594-of-00723.safetensors",
    "model-00595-of-00723.safetensors",
    "model-00596-of-00723.safetensors",
    "model-00597-of-00723.safetensors",
    "model-00598-of-00723.safetensors",
    "model-00599-of-00723.safetensors",
    "model-00600-of-00723.safetensors",
    "model-00601-of-00723.safetensors",
    "model-00602-of-00723.safetensors",
    "model-00603-of-00723.safetensors",
    "model-00604-of-00723.safetensors",
    "model-00605-of-00723.safetensors",
    "model-00606-of-00723.safetensors",
    "model-00607-of-00723.safetensors",
    "model-00608-of-00723.safetensors",
    "model-00609-of-00723.safetensors",
    "model-00610-of-00723.safetensors",
    "model-00611-of-00723.safetensors",
    "model-00612-of-00723.safetensors",
    "model-00613-of-00723.safetensors",
    "model-00614-of-00723.safetensors",
    "model-00615-of-00723.safetensors",
    "model-00616-of-00723.safetensors",
    "model-00617-of-00723.safetensors",
    "model-00618-of-00723.safetensors",
    "model-00619-of-00723.safetensors",
    "model-00620-of-00723.safetensors",
    "model-00621-of-00723.safetensors",
    "model-00622-of-00723.safetensors",
    "model-00623-of-00723.safetensors",
    "model-00624-of-00723.safetensors",
    "model-00625-of-00723.safetensors",
    "model-00626-of-00723.safetensors",
    "model-00627-of-00723.safetensors",
    "model-00628-of-00723.safetensors",
    "model-00629-of-00723.safetensors",
    "model-00630-of-00723.safetensors",
    "model-00631-of-00723.safetensors",
    "model-00632-of-00723.safetensors",
    "model-00633-of-00723.safetensors",
    "model-00634-of-00723.safetensors",
    "model-00635-of-00723.safetensors",
    "model-00636-of-00723.safetensors",
    "model-00637-of-00723.safetensors",
    "model-00638-of-00723.safetensors",
    "model-00639-of-00723.safetensors",
    "model-00640-of-00723.safetensors",
    "model-00641-of-00723.safetensors",
    "model-00642-of-00723.safetensors",
    "model-00643-of-00723.safetensors",
    "model-00644-of-00723.safetensors",
    "model-00645-of-00723.safetensors",
    "model-00646-of-00723.safetensors",
    "model-00647-of-00723.safetensors",
    "model-00648-of-00723.safetensors",
    "model-00649-of-00723.safetensors",
    "model-00650-of-00723.safetensors",
    "model-00651-of-00723.safetensors",
    "model-00652-of-00723.safetensors",
    "model-00653-of-00723.safetensors",
    "model-00654-of-00723.safetensors",
    "model-00655-of-00723.safetensors",
    "model-00656-of-00723.safetensors",
    "model-00657-of-00723.safetensors",
    "model-00658-of-00723.safetensors",
    "model-00659-of-00723.safetensors",
    "model-00660-of-00723.safetensors",
    "model-00661-of-00723.safetensors",
    "model-00662-of-00723.safetensors",
    "model-00663-of-00723.safetensors",
    "model-00664-of-00723.safetensors",
    "model-00665-of-00723.safetensors",
    "model-00666-of-00723.safetensors",
    "model-00667-of-00723.safetensors",
    "model-00668-of-00723.safetensors",
    "model-00669-of-00723.safetensors",
    "model-00670-of-00723.safetensors",
    "model-00671-of-00723.safetensors",
    "model-00672-of-00723.safetensors",
    "model-00673-of-00723.safetensors",
    "model-00674-of-00723.safetensors",
    "model-00675-of-00723.safetensors",
    "model-00676-of-00723.safetensors",
    "model-00677-of-00723.safetensors",
    "model-00678-of-00723.safetensors",
    "model-00679-of-00723.safetensors",
    "model-00680-of-00723.safetensors",
    "model-00681-of-00723.safetensors",
    "model-00682-of-00723.safetensors",
    "model-00683-of-00723.safetensors",
    "model-00684-of-00723.safetensors",
    "model-00685-of-00723.safetensors",
    "model-00686-of-00723.safetensors",
    "model-00687-of-00723.safetensors",
    "model-00688-of-00723.safetensors",
    "model-00689-of-00723.safetensors",
    "model-00690-of-00723.safetensors",
    "model-00691-of-00723.safetensors",
    "model-00692-of-00723.safetensors",
    "model-00693-of-00723.safetensors",
    "model-00694-of-00723.safetensors",
    "model-00695-of-00723.safetensors",
    "model-00696-of-00723.safetensors",
    "model-00697-of-00723.safetensors",
    "model-00698-of-00723.safetensors",
    "model-00699-of-00723.safetensors",
    "model-00700-of-00723.safetensors",
    "model-00701-of-00723.safetensors",
    "model-00702-of-00723.safetensors",
    "model-00703-of-00723.safetensors",
    "model-00704-of-00723.safetensors",
    "model-00705-of-00723.safetensors",
    "model-00706-of-00723.safetensors",
    "model-00707-of-00723.safetensors",
    "model-00708-of-00723.safetensors",
    "model-00709-of-00723.safetensors",
    "model-00710-of-00723.safetensors",
    "model-00711-of-00723.safetensors",
    "model-00712-of-00723.safetensors",
    "model-00713-of-00723.safetensors",
    "model-00714-of-00723.safetensors",
    "model-00715-of-00723.safetensors",
    "model-00716-of-00723.safetensors",
    "model-00717-of-00723.safetensors",
    "model-00718-of-00723.safetensors",
    "model-00719-of-00723.safetensors",
    "model-00720-of-00723.safetensors",
    "model-00721-of-00723.safetensors",
    "model-00722-of-00723.safetensors",
    "model-00723-of-00723.safetensors"
  ],
  "lunarsylph/mooncell_v5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ankhamun/xxx0_0xxx": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "giprime/OOM-13B_01": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "alnrg2arg/blockchainlabs_joe_bez_seminar": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "DannySte/vicuna-7b-gptq": [
    "model.safetensors"
  ],
  "dustydecapod/Kory-0.1-11b-pre1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "XavierXin/ChineseLLM": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "BAAI/bunny-phi-2-siglip-lora": [
    "adapter_model.safetensors"
  ],
  "Onlydrinkwater/gpt2xl_format_math_520": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "XavierXin/ChineseLLM-AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dhuynh95/CodeLlama-70b-Instruct-hf": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "Kooltek68/sn9_164": [
    "model.safetensors"
  ],
  "rickprime/primetime-01": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Crystalcareai/CrystalMistral-Math": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "modelwizard/bobcat": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rickprime/portalgun": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ankhamun/xxxI0v0Ixxx": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ankhamun/xxxIO____OIxxx": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ankhamun/IIIIIIIo-oIIIIIII": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "shidowake/cyber2chat-7B-base-bnb-4bit-chatml": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Kooltek68/sn9_246": [
    "model.safetensors"
  ],
  "dddsaty/SOLAR_Merge_Adapter_DPO_Orca": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Kooltek68/sn9_231": [
    "model.safetensors"
  ],
  "Kooltek68/sn9_241": [
    "model.safetensors"
  ],
  "karawalla/accelq_ai_model_02042024_peft": [
    "model.safetensors"
  ],
  "superfriends/arbitrarian": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "B2111797/recipe_gener_v1": [
    "model.safetensors"
  ],
  "lucasjin/LLava-Qwen-1_8B-Base": [
    "model.safetensors"
  ],
  "yuuko-eth/Rain-2x7B-MoE-32k-v0.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Kooltek68/sn9_250": [
    "model.safetensors"
  ],
  "typeof/miqu-70b-12": [
    "model-00001-of-00147.safetensors",
    "model-00002-of-00147.safetensors",
    "model-00003-of-00147.safetensors",
    "model-00004-of-00147.safetensors",
    "model-00005-of-00147.safetensors",
    "model-00006-of-00147.safetensors",
    "model-00007-of-00147.safetensors",
    "model-00008-of-00147.safetensors",
    "model-00009-of-00147.safetensors",
    "model-00010-of-00147.safetensors",
    "model-00011-of-00147.safetensors",
    "model-00012-of-00147.safetensors",
    "model-00013-of-00147.safetensors",
    "model-00014-of-00147.safetensors",
    "model-00015-of-00147.safetensors",
    "model-00016-of-00147.safetensors",
    "model-00017-of-00147.safetensors",
    "model-00018-of-00147.safetensors",
    "model-00019-of-00147.safetensors",
    "model-00020-of-00147.safetensors",
    "model-00021-of-00147.safetensors",
    "model-00022-of-00147.safetensors",
    "model-00023-of-00147.safetensors",
    "model-00024-of-00147.safetensors",
    "model-00025-of-00147.safetensors",
    "model-00026-of-00147.safetensors",
    "model-00027-of-00147.safetensors",
    "model-00028-of-00147.safetensors",
    "model-00029-of-00147.safetensors",
    "model-00030-of-00147.safetensors",
    "model-00031-of-00147.safetensors",
    "model-00032-of-00147.safetensors",
    "model-00033-of-00147.safetensors",
    "model-00034-of-00147.safetensors",
    "model-00035-of-00147.safetensors",
    "model-00036-of-00147.safetensors",
    "model-00037-of-00147.safetensors",
    "model-00038-of-00147.safetensors",
    "model-00039-of-00147.safetensors",
    "model-00040-of-00147.safetensors",
    "model-00041-of-00147.safetensors",
    "model-00042-of-00147.safetensors",
    "model-00043-of-00147.safetensors",
    "model-00044-of-00147.safetensors",
    "model-00045-of-00147.safetensors",
    "model-00046-of-00147.safetensors",
    "model-00047-of-00147.safetensors",
    "model-00048-of-00147.safetensors",
    "model-00049-of-00147.safetensors",
    "model-00050-of-00147.safetensors",
    "model-00051-of-00147.safetensors",
    "model-00052-of-00147.safetensors",
    "model-00053-of-00147.safetensors",
    "model-00054-of-00147.safetensors",
    "model-00055-of-00147.safetensors",
    "model-00056-of-00147.safetensors",
    "model-00057-of-00147.safetensors",
    "model-00058-of-00147.safetensors",
    "model-00059-of-00147.safetensors",
    "model-00060-of-00147.safetensors",
    "model-00061-of-00147.safetensors",
    "model-00062-of-00147.safetensors",
    "model-00063-of-00147.safetensors",
    "model-00064-of-00147.safetensors",
    "model-00065-of-00147.safetensors",
    "model-00066-of-00147.safetensors",
    "model-00067-of-00147.safetensors",
    "model-00068-of-00147.safetensors",
    "model-00069-of-00147.safetensors",
    "model-00070-of-00147.safetensors",
    "model-00071-of-00147.safetensors",
    "model-00072-of-00147.safetensors",
    "model-00073-of-00147.safetensors",
    "model-00074-of-00147.safetensors",
    "model-00075-of-00147.safetensors",
    "model-00076-of-00147.safetensors",
    "model-00077-of-00147.safetensors",
    "model-00078-of-00147.safetensors",
    "model-00079-of-00147.safetensors",
    "model-00080-of-00147.safetensors",
    "model-00081-of-00147.safetensors",
    "model-00082-of-00147.safetensors",
    "model-00083-of-00147.safetensors",
    "model-00084-of-00147.safetensors",
    "model-00085-of-00147.safetensors",
    "model-00086-of-00147.safetensors",
    "model-00087-of-00147.safetensors",
    "model-00088-of-00147.safetensors",
    "model-00089-of-00147.safetensors",
    "model-00090-of-00147.safetensors",
    "model-00091-of-00147.safetensors",
    "model-00092-of-00147.safetensors",
    "model-00093-of-00147.safetensors",
    "model-00094-of-00147.safetensors",
    "model-00095-of-00147.safetensors",
    "model-00096-of-00147.safetensors",
    "model-00097-of-00147.safetensors",
    "model-00098-of-00147.safetensors",
    "model-00099-of-00147.safetensors",
    "model-00100-of-00147.safetensors",
    "model-00101-of-00147.safetensors",
    "model-00102-of-00147.safetensors",
    "model-00103-of-00147.safetensors",
    "model-00104-of-00147.safetensors",
    "model-00105-of-00147.safetensors",
    "model-00106-of-00147.safetensors",
    "model-00107-of-00147.safetensors",
    "model-00108-of-00147.safetensors",
    "model-00109-of-00147.safetensors",
    "model-00110-of-00147.safetensors",
    "model-00111-of-00147.safetensors",
    "model-00112-of-00147.safetensors",
    "model-00113-of-00147.safetensors",
    "model-00114-of-00147.safetensors",
    "model-00115-of-00147.safetensors",
    "model-00116-of-00147.safetensors",
    "model-00117-of-00147.safetensors",
    "model-00118-of-00147.safetensors",
    "model-00119-of-00147.safetensors",
    "model-00120-of-00147.safetensors",
    "model-00121-of-00147.safetensors",
    "model-00122-of-00147.safetensors",
    "model-00123-of-00147.safetensors",
    "model-00124-of-00147.safetensors",
    "model-00125-of-00147.safetensors",
    "model-00126-of-00147.safetensors",
    "model-00127-of-00147.safetensors",
    "model-00128-of-00147.safetensors",
    "model-00129-of-00147.safetensors",
    "model-00130-of-00147.safetensors",
    "model-00131-of-00147.safetensors",
    "model-00132-of-00147.safetensors",
    "model-00133-of-00147.safetensors",
    "model-00134-of-00147.safetensors",
    "model-00135-of-00147.safetensors",
    "model-00136-of-00147.safetensors",
    "model-00137-of-00147.safetensors",
    "model-00138-of-00147.safetensors",
    "model-00139-of-00147.safetensors",
    "model-00140-of-00147.safetensors",
    "model-00141-of-00147.safetensors",
    "model-00142-of-00147.safetensors",
    "model-00143-of-00147.safetensors",
    "model-00144-of-00147.safetensors",
    "model-00145-of-00147.safetensors",
    "model-00146-of-00147.safetensors",
    "model-00147-of-00147.safetensors"
  ],
  "Kukedlc/NeuralPipe-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "ericpolewski/Palworld-SME-13b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "CognitiveLab/Fireship-clone": [
    "checkpoint-16/model-00001-of-00003.safetensors",
    "checkpoint-16/model-00002-of-00003.safetensors",
    "checkpoint-16/model-00003-of-00003.safetensors",
    "checkpoint-8/model-00001-of-00003.safetensors",
    "checkpoint-8/model-00002-of-00003.safetensors",
    "checkpoint-8/model-00003-of-00003.safetensors"
  ],
  "Kooltek68/sn9_230": [
    "model.safetensors"
  ],
  "armaanp/gpt2-wikitext2": [
    "model.safetensors"
  ],
  "Kooltek68/sn9_229": [
    "model.safetensors"
  ],
  "Kooltek68/sn9_224": [
    "model.safetensors"
  ],
  "Kooltek68/sn9_220": [
    "model.safetensors"
  ],
  "typeof/miqu-70b-6": [
    "model-00001-of-00057.safetensors",
    "model-00002-of-00057.safetensors",
    "model-00003-of-00057.safetensors",
    "model-00004-of-00057.safetensors",
    "model-00005-of-00057.safetensors",
    "model-00006-of-00057.safetensors",
    "model-00007-of-00057.safetensors",
    "model-00008-of-00057.safetensors",
    "model-00009-of-00057.safetensors",
    "model-00010-of-00057.safetensors",
    "model-00011-of-00057.safetensors",
    "model-00012-of-00057.safetensors",
    "model-00013-of-00057.safetensors",
    "model-00014-of-00057.safetensors",
    "model-00015-of-00057.safetensors",
    "model-00016-of-00057.safetensors",
    "model-00017-of-00057.safetensors",
    "model-00018-of-00057.safetensors",
    "model-00019-of-00057.safetensors",
    "model-00020-of-00057.safetensors",
    "model-00021-of-00057.safetensors",
    "model-00022-of-00057.safetensors",
    "model-00023-of-00057.safetensors",
    "model-00024-of-00057.safetensors",
    "model-00025-of-00057.safetensors",
    "model-00026-of-00057.safetensors",
    "model-00027-of-00057.safetensors",
    "model-00028-of-00057.safetensors",
    "model-00029-of-00057.safetensors",
    "model-00030-of-00057.safetensors",
    "model-00031-of-00057.safetensors",
    "model-00032-of-00057.safetensors",
    "model-00033-of-00057.safetensors",
    "model-00034-of-00057.safetensors",
    "model-00035-of-00057.safetensors",
    "model-00036-of-00057.safetensors",
    "model-00037-of-00057.safetensors",
    "model-00038-of-00057.safetensors",
    "model-00039-of-00057.safetensors",
    "model-00040-of-00057.safetensors",
    "model-00041-of-00057.safetensors",
    "model-00042-of-00057.safetensors",
    "model-00043-of-00057.safetensors",
    "model-00044-of-00057.safetensors",
    "model-00045-of-00057.safetensors",
    "model-00046-of-00057.safetensors",
    "model-00047-of-00057.safetensors",
    "model-00048-of-00057.safetensors",
    "model-00049-of-00057.safetensors",
    "model-00050-of-00057.safetensors",
    "model-00051-of-00057.safetensors",
    "model-00052-of-00057.safetensors",
    "model-00053-of-00057.safetensors",
    "model-00054-of-00057.safetensors",
    "model-00055-of-00057.safetensors",
    "model-00056-of-00057.safetensors",
    "model-00057-of-00057.safetensors"
  ],
  "superfriends/arbitrarian-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Manirajan/tinyllama-rmf": [
    "model.safetensors"
  ],
  "CognitiveLab/Fireship-clone-hf": [
    "checkpoint-16/model-00001-of-00003.safetensors",
    "checkpoint-16/model-00002-of-00003.safetensors",
    "checkpoint-16/model-00003-of-00003.safetensors",
    "checkpoint-8/model-00001-of-00003.safetensors",
    "checkpoint-8/model-00002-of-00003.safetensors",
    "checkpoint-8/model-00003-of-00003.safetensors"
  ],
  "XavierXin/ChineseLLM-AWQ-2000": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "superfriends/arbitrarian-v3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "karawalla/ship_metadata_v02042024_peft": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "XavierXin/ChineseLLM-2000": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "sonthenguyen/OpenHermes-2.5-Mistral-7B-mt-bench-DPO-recovered": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Iliassti/NextHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sontq/pretrain_sn": [
    "model.safetensors"
  ],
  "superfriends/arbitrarian-v4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rldxyz/overlord": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "karawalla/test_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Andrewwwwww/mythalion-13b": [],
  "deepestneuron/cell-0-0-1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "bittensorenjoyer/sn6-1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tensorplex-labs/pretraining-sn9-1": [
    "model.safetensors"
  ],
  "tensorplex-labs/pretraining-sn9-2": [
    "model.safetensors"
  ],
  "tensorplex-labs/pretraining-sn9-3": [
    "model.safetensors"
  ],
  "pxltd/world_v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "paulml/NeuralOmniWestBeaglake-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "incomprehensible/01": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "IntervitensInc/intv_ai_mk9": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "p208p2002/bloom-1b1-zh-error-correction-dpo": [
    "model.safetensors"
  ],
  "petitpatoche/sn6-v6": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "petitpatoche/sn6-v7": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "aassegai/mistral-legaleval-merged": [
    "model.safetensors"
  ],
  "mjm4dl/mstrl_slt_v03": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lxsure/gemini5_2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "umarigan/gpt2-tr-wiki": [
    "model.safetensors"
  ],
  "RaphaelMourad/mixtral-dna-conserved-v0.1": [
    "model.safetensors"
  ],
  "nxn1231/yi6": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "karawalla/ship_metadata_v02042024_release": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Augustya07/Mistral-7B-Instruct-v0.2-sft-test-push_2": [
    "model.safetensors"
  ],
  "tuanna08go/sn29pre": [
    "model.safetensors"
  ],
  "Andyrasika/mistral-ft-optimized-dpo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Midnight-Rose-103B-v1.0-2.4bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "LoneStriker/Midnight-Rose-103B-v1.0-3.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "BlahBlah314/Seraph-7b-Sum-FT-V2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sontq/pretrain_sn_02": [
    "model.safetensors"
  ],
  "LoneStriker/Midnight-Rose-103B-v1.0-3.5bpw-h6-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "iGenius-AI-Team/Italia-2B-ckpt-600B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "AlekseyKorshuk/notus-casino-reviews": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/MetaMath-Bagel-DPO-34B-GGUF": [],
  "manishiitg/open-aditi-hi-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "controltensor/subnet-model-32": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Midnight-Rose-103B-v1.0-5.0bpw-h6-exl2": [
    "output-00001-of-00008.safetensors",
    "output-00002-of-00008.safetensors",
    "output-00003-of-00008.safetensors",
    "output-00004-of-00008.safetensors",
    "output-00005-of-00008.safetensors",
    "output-00006-of-00008.safetensors",
    "output-00007-of-00008.safetensors",
    "output-00008-of-00008.safetensors"
  ],
  "Crystalcareai/CrystalMistral-Py": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AIFT/AIFT-instruct-v1.6-42dot_LLM-SFT-1.3B": [
    "model.safetensors"
  ],
  "AIFT/AIFT-ko-orca-plat-Yi-ko-6b-v1.6": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kakojuvenkat/autotrain-7qwh6-2nv14": [
    "adapter_model.safetensors",
    "checkpoint-1287/adapter_model.safetensors"
  ],
  "idrah/btsn6v4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "idrah/btsn6v5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "antiven0m/finch": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "tuanna08go/sn29pre_02": [
    "model.safetensors"
  ],
  "HLTT/pretraining_v1": [
    "model.safetensors"
  ],
  "colable/llama2-ko-DPO": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "HLTT/pretraining_v2": [
    "model.safetensors"
  ],
  "Saini-Manisha/tinystarcoder-rlhf-model": [
    "model.safetensors"
  ],
  "tomaszki/nous-thirteen": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "zaq-hack/Noromaid-v0.4-Mixtral-Instruct-8x7b-Zloss-bpw400-h6-exl2-rpcal": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LitiGious/my_first_model": [
    "model.safetensors"
  ],
  "UKHSA/dsdu_hack_model": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Onii-Chan-3/Onii-Chan-3-55": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tomaszki/nous-fourteen": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hotsuyuki/gpt_0.125B_global_step4000": [
    "model.safetensors"
  ],
  "mtc/stabilityai-stablelm-2-1_6b-xsum-with-explanation-local-save-test_merged": [
    "model.safetensors"
  ],
  "manishtanwar/reuters-gpt2-text-gen": [
    "model.safetensors"
  ],
  "VERSIL91/pretrain_model": [
    "model.safetensors"
  ],
  "OmniFederal/Omni-8x7B-gating-merged": [
    "adapter_model.safetensors",
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "OmniFederal/Omni-8x7B-gating-full": [
    "adapter_model.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "hongzoh/wdqa-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "antiven0m/finch-6bpw-exl2": [
    "cal_data.safetensors",
    "hidden_states.safetensors",
    "output.safetensors"
  ],
  "ArianAskari/zephyr-7b-beta-QE-QIAR": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Onii-Chan-3/Onii-Chan-3-5555": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "superfriends/arbitrarian-v5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Meggido/NeuraLake-m7-AshhLimaRP-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lex-hue/LexGPT-V2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "dlibf/zephyr-6b-dpo-full": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "alhosseini/gathnex_phi_gath": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "paulml/NeuralOmniBeagleMBX-v3-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Kralley/Munin-7B-not-fn": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tuanna08go/sn29pre_03": [
    "model.safetensors"
  ],
  "Andrusyshyn/gpt2-pretrained-for-coq-pt": [
    "model.safetensors"
  ],
  "VERSIL91/pretrain_model_2": [
    "model.safetensors"
  ],
  "LexiconShiftInnovations/Llama2_Continued_Tokens_0_15K": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Josephgflowers/3BigReasonCinder": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Kouskousi/mistral_7b_finetuned_eval_instruct": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "VERSIL91/pretrain_model_3": [
    "model.safetensors"
  ],
  "manishiitg/open-aditi-hi-v2-awq": [
    "model.safetensors"
  ],
  "mybliss/llama-2-7b-custom-ravi-shankar": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "alhosseini/llama2_test1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ankhamun/xxxI0v_v0Ixxx": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ChuckMcSneed/Gembo-v1-70b": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "rickprime/primetime-02": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "defog/sqlcoder-7b-2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tomaszki/nous-fifteen": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "KAKA22/TableLLM-13b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "mu0gum/AIFT-42dot_LLM-PLM-1.3B-ao-instruct-all-v0.9": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "modelwizard/mule": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Farhang87/phi-2-samsum": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "rickprime/inception": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ankhamun/xxxT-Txxx": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ankhamun/xxxIU__UIxxx": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tensorplex-labs/pretraining-sn9-4": [
    "model.safetensors"
  ],
  "zaid60/newModel": [
    "model.safetensors"
  ],
  "shidowake/cyber2-7B-base-bnb-4bit-chatml": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rickprime/hal-69000": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "letan/mistral-7b-fludetector-v1": [
    "adapter_model.safetensors",
    "checkpoint-1/adapter_model.safetensors"
  ],
  "niranjan-agi/nl2_sql_model": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Lucia-no/key_1": [
    "model.safetensors"
  ],
  "Lucia-no/key_2": [
    "model.safetensors"
  ],
  "Lucia-no/key_4": [
    "model.safetensors"
  ],
  "Lucia-no/key_5": [
    "model.safetensors"
  ],
  "Lucia-no/key_6": [
    "model.safetensors"
  ],
  "Lucia-no/key_7": [
    "model.safetensors"
  ],
  "Lucia-no/key_8": [
    "model.safetensors"
  ],
  "Lucia-no/key_9": [
    "model.safetensors"
  ],
  "Lucia-no/key_10": [
    "model.safetensors"
  ],
  "SaeedNajafi/gpt2-wikitext2": [
    "model.safetensors"
  ],
  "VERSIL91/pretrain_model_4": [
    "model.safetensors"
  ],
  "Lucia-no/key_11": [
    "model.safetensors"
  ],
  "Lucia-no/key_13": [
    "model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-random_removal-1e-4": [
    "model.safetensors"
  ],
  "Enno-Ai/Hodeva-SOLAR-10.7B-awq": [
    "model.safetensors"
  ],
  "Lucia-no/key_15": [
    "model.safetensors"
  ],
  "ankhamun/IIIIIIIo_oIIIIIII": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Lucia-no/key_16": [
    "model.safetensors"
  ],
  "Weyaxi/Einstein-v3-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "BlahBlah314/Croissant_Const_FT": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "pxltd/mr_worldwide": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tomaszki/nous-sixteen": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Deepreneur/blue-lizard": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Gokuldaskumar/qwen1.5-73B-Chat": [
    "model-00001-of-00038.safetensors",
    "model-00002-of-00038.safetensors",
    "model-00003-of-00038.safetensors",
    "model-00004-of-00038.safetensors",
    "model-00005-of-00038.safetensors",
    "model-00006-of-00038.safetensors",
    "model-00007-of-00038.safetensors",
    "model-00008-of-00038.safetensors",
    "model-00009-of-00038.safetensors",
    "model-00010-of-00038.safetensors",
    "model-00011-of-00038.safetensors",
    "model-00012-of-00038.safetensors",
    "model-00013-of-00038.safetensors",
    "model-00014-of-00038.safetensors",
    "model-00015-of-00038.safetensors",
    "model-00016-of-00038.safetensors",
    "model-00017-of-00038.safetensors",
    "model-00018-of-00038.safetensors",
    "model-00019-of-00038.safetensors",
    "model-00020-of-00038.safetensors",
    "model-00021-of-00038.safetensors",
    "model-00022-of-00038.safetensors",
    "model-00023-of-00038.safetensors",
    "model-00024-of-00038.safetensors",
    "model-00025-of-00038.safetensors",
    "model-00026-of-00038.safetensors",
    "model-00027-of-00038.safetensors",
    "model-00028-of-00038.safetensors",
    "model-00029-of-00038.safetensors",
    "model-00030-of-00038.safetensors",
    "model-00031-of-00038.safetensors",
    "model-00032-of-00038.safetensors",
    "model-00033-of-00038.safetensors",
    "model-00034-of-00038.safetensors",
    "model-00035-of-00038.safetensors",
    "model-00036-of-00038.safetensors",
    "model-00037-of-00038.safetensors",
    "model-00038-of-00038.safetensors"
  ],
  "vilm/Quyen-Pro-v0.1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "IntervitensInc/intv_ai_mk10": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-only_measure_nps_as_singular_removal-1e-3": [
    "model.safetensors"
  ],
  "BlahBlah314/Croissant-Const-FT-V2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "brezzeeee/pretrain_random": [
    "model.safetensors"
  ],
  "modelwizard/owl": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ankhamun/xxxI-v_v-Ixxx": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-only_other_det_removal-1e-3": [
    "model.safetensors"
  ],
  "nielsr/cogvlm-tiny-random": [
    "model.safetensors"
  ],
  "jilp00/youtoks-animal-behavior-7B": [
    "model.safetensors"
  ],
  "IntervitensInc/intv_ai_mk11": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "acaderno/llama-2-7b-qna-tuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "duxx/test_model_lora_50_dpo": [
    "model.safetensors"
  ],
  "andrijdavid/Macaroni-v2-7b": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "BarraHome/rezephyr_merged_4bit": [
    "model.safetensors"
  ],
  "rameshakkineni/sn6001": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Qwen1.5-4B-Chat-AWQ": [
    "model.safetensors"
  ],
  "BlahBlah314/Seraph-7b-Const-FT-V8": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "louisbrulenaudet/Pearl-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "LoneStriker/Qwen1.5-7B-Chat-AWQ": [
    "model.safetensors"
  ],
  "joearul/perplex": [
    "model.safetensors"
  ],
  "SiguienteGlobal/linguistica-main": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "LoneStriker/Qwen1.5-14B-Chat-AWQ": [
    "model.safetensors"
  ],
  "VAGOsolutions/SauerkrautLM-7b-LaserChat": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sam2ai/tiny-llama-odia": [
    "adapter_model.safetensors"
  ],
  "bergr7f/instruct-Optimus-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "NeverSleep/MiquMaid-v2-70B": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "Adeptschneider/phi-2_model_with_lora_adapters": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Qwen1.5-7B-Chat-GPTQ": [
    "gptq_model-4bit-32g.safetensors"
  ],
  "LoneStriker/Qwen1.5-72B-Chat-AWQ": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "mudogruer/gpt2-chess-move-prediction": [
    "model.safetensors"
  ],
  "JonaszPotoniec/mistral-pl-owca": [
    "lora/adapter_model.safetensors",
    "safetensors/model.safetensors"
  ],
  "VincentButterfield/Jolsus-Roist": [
    "model.safetensors"
  ],
  "LoneStriker/Qwen1.5-4B-Chat-GPTQ": [
    "gptq_model-4bit-32g.safetensors"
  ],
  "impossibleexchange/pt31": [
    "model.safetensors"
  ],
  "LoneStriker/Qwen1.5-14B-Chat-GPTQ": [
    "gptq_model-4bit-32g.safetensors"
  ],
  "tomaszki/nous-seventeen": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "shi-zheng-qxhs/gpt2_oasst2_curated": [
    "model.safetensors"
  ],
  "Menouar/phi-2-basic-maths": [
    "adapter_model.safetensors"
  ],
  "lex-hue/LexGPT-V2.5": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "DrishtiSharma/mistral-7b-v0.1-english-to-hinglish-translation-merged": [
    "model.safetensors"
  ],
  "karawalla/ship-ai-v1_release": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "karawalla/aq_ai_llm_v02042024_release": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ZainAli60/llama_tune": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "StrangeSX/SGX-SeaLLM-v2-DPO": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Tonystark1/Thor": [
    "adapter_model.safetensors",
    "checkpoint-4/adapter_model.safetensors"
  ],
  "Arman123/zephyr-7b-beta-openassistant-guanaco2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "modelwizard/ox": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "shradha01/codeparrot-ds_new": [
    "model.safetensors"
  ],
  "llmixer/BigWeave-v15-103b": [
    "model-00001-of-00022.safetensors",
    "model-00002-of-00022.safetensors",
    "model-00003-of-00022.safetensors",
    "model-00004-of-00022.safetensors",
    "model-00005-of-00022.safetensors",
    "model-00006-of-00022.safetensors",
    "model-00007-of-00022.safetensors",
    "model-00008-of-00022.safetensors",
    "model-00009-of-00022.safetensors",
    "model-00010-of-00022.safetensors",
    "model-00011-of-00022.safetensors",
    "model-00012-of-00022.safetensors",
    "model-00013-of-00022.safetensors",
    "model-00014-of-00022.safetensors",
    "model-00015-of-00022.safetensors",
    "model-00016-of-00022.safetensors",
    "model-00017-of-00022.safetensors",
    "model-00018-of-00022.safetensors",
    "model-00019-of-00022.safetensors",
    "model-00020-of-00022.safetensors",
    "model-00021-of-00022.safetensors",
    "model-00022-of-00022.safetensors"
  ],
  "nnbosko/pretrain": [
    "model.safetensors"
  ],
  "02loveslollipop/Furina-2_6-phi-2": [
    "adapter_model.safetensors"
  ],
  "serpdotai/sparsetral-16x7B-v2": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "incomprehensible/007": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "arhanovich/trial123": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "jeiku/Fett-uccine_Mini_3B": [
    "model-00001-of-00001.safetensors"
  ],
  "Arman123/TinyLlama-1.1B-Chat-RU": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "BarraHome/rezephyr-dpo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "deepestneuron/cell-0-0-2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rldxyz/roboto": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Qwen1.5-72B-Chat-GPTQ": [
    "gptq_model-4bit-32g.safetensors"
  ],
  "BioMistral/BioMistral-7B-TIES": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ankhamun/xxxoU__Uoxxx": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jeiku/Kielbasa_3B": [
    "model-00001-of-00001.safetensors"
  ],
  "ankhamun/xxxI-o____x_x____o-Ixxx": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mlabonne/Beagle4": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "BioMistral/BioMistral-7B-DARE": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "InnerI/autotrain-Llama2chat": [
    "adapter_model.safetensors",
    "checkpoint-9/adapter_model.safetensors"
  ],
  "arnavgrg/microsoft-phi-2-dequantized": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ankhamun/xxxT_-_Txxx": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AlisaMenekse/ErrorCategoriesBCP": [
    "adapter_model.safetensors",
    "checkpoint-420/adapter_model.safetensors"
  ],
  "TroyDoesAI/MermaidSolar": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Metric-AI/sqlcoder34b_dpo": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "vilm/Quyen-Plus-v0.1": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "Drewskidang/DPO_Test3": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "DrAEZF6quN2YktvBc7jHxX/mS64huBq": [
    "model.safetensors"
  ],
  "Drewskidang/Dpomergebigboy": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "BoyaWu10/bunny-phi-1.5-siglip-lora": [
    "adapter_model.safetensors"
  ],
  "shradha01/codeparrot": [
    "model.safetensors"
  ],
  "weijie210/zephyr-7b-UC-0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "weijie210/zephyr-7b-UC-0-B0.5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mitultiwari/NeuralHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "BoyaWu10/bunny-stablelm-2-siglip-lora": [
    "adapter_model.safetensors"
  ],
  "BoyaWu10/bunny-stablelm-2-eva-lora": [
    "adapter_model.safetensors"
  ],
  "BoyaWu10/bunny-phi-2-eva-lora": [
    "adapter_model.safetensors"
  ],
  "BoyaWu10/bunny-phi-1.5-eva-lora": [
    "adapter_model.safetensors"
  ],
  "tuanna08go/sn09pre_10": [
    "model.safetensors"
  ],
  "Jimmyhd/llama213bLowerEpochsTimeBook": [
    "checkpoint-86/adapter_model.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "HanNayeoniee/LHK_DPO_v1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "El-Palmera/ULTRA-META2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lchakkei/model_1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "seyf1elislam/Franky_westKunai-hermes-1-7b": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Elizezen/Sapphire-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Epimachok/Vikhr-7b-instruct-awq": [
    "model.safetensors"
  ],
  "llm-jp/llm-jp-13b-dpo-lora-hh_rlhf_ja-v1.1": [
    "adapter_model.safetensors"
  ],
  "psaghafi/NeuralPipe-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "elinaparajuli/HomeSchema_3_llama-finetuned": [
    "model.safetensors"
  ],
  "mlx-community/Qwen1.5-0.5B-Chat": [
    "model.safetensors"
  ],
  "mlx-community/Qwen1.5-0.5B-Chat-4bit": [
    "model.safetensors"
  ],
  "dvilasuero/DistilabelOpenHermes-2.5-mistral-7b-mix2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "openvoid/prox-7b-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Elizezen/Sapphire-7B-GPTQ": [
    "model.safetensors"
  ],
  "shidowake/cyber2-7B-base-bnb-4bit": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "superfriends/captainplanet-v0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "macadeliccc/MarcoroCapy-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Zintoulou/finetuningqv2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Crystalcareai/CrystalQwen-1.5-7B-OLD": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "LoneStriker/wolfram_miqu-1-120b-2.4bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "KnutJaegersberg/Deita-20b-6bpw-exl": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/wolfram_miqu-1-120b-2.65bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "gadkins/Mistral-7B-Instruct-v0.1-function-calling": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/wolfram_miqu-1-120b-3.0bpw-h6-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "MarkrAI/RAG-KO-Mixtral-7Bx2-v2.0": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Bo-Ni/GPTProteinPretrained_test": [
    "model.safetensors"
  ],
  "ai-nightcoder/GPTuz-finetuned-uzwikitext": [
    "model.safetensors"
  ],
  "tyson0420/stack-llama-2-web": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/wolfram_miqu-1-120b-4.0bpw-h6-exl2": [
    "output-00001-of-00008.safetensors",
    "output-00002-of-00008.safetensors",
    "output-00003-of-00008.safetensors",
    "output-00004-of-00008.safetensors",
    "output-00005-of-00008.safetensors",
    "output-00006-of-00008.safetensors",
    "output-00007-of-00008.safetensors",
    "output-00008-of-00008.safetensors"
  ],
  "RivatLabs/casperhansen-mixtral-instruct-awq-clone-feb24": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "UjjwalP/my_awesome_eli5_clm-model": [
    "model.safetensors"
  ],
  "ENERGY-DRINK-LOVE/SOLAR_merge2": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "LoneStriker/wolfram_miqu-1-120b-5.0bpw-h6-exl2": [
    "output-00001-of-00009.safetensors",
    "output-00002-of-00009.safetensors",
    "output-00003-of-00009.safetensors",
    "output-00004-of-00009.safetensors",
    "output-00005-of-00009.safetensors",
    "output-00006-of-00009.safetensors",
    "output-00007-of-00009.safetensors",
    "output-00008-of-00009.safetensors",
    "output-00009-of-00009.safetensors"
  ],
  "karthikrathod/llm_repo_v8_10e": [
    "adapter_model.safetensors",
    "checkpoint-100/adapter_model.safetensors"
  ],
  "Karajan42/NeuralMiria-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hongzoh/wdqa-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dcipheranalytics/phi-2-pii-bbi": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mayflowergmbh/Wiedervereinigung-7b-dpo-AWQ": [
    "model.safetensors"
  ],
  "chanwit/flux-7b-base-stage-00": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "ammarzaarour/aragpt2-base-saadeh-full2": [
    "model.safetensors"
  ],
  "apatidar0/chat_style_phi-2": [
    "model.safetensors"
  ],
  "Test157t/Kunocchini-7b": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "shuvom/yuj-v1": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "torphix/stablelm-2-glados-v1": [
    "model.safetensors"
  ],
  "ddemilla/Mixtral-8x7B-Instruct-v0.1-coords-casing-fine-tuned-2-6": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "bergr7f/mathcoder-mistral-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "mitultiwari/zephyr-7B-rlhf": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "YashRawal225/Intel-3-7b-chat-finetune-german": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Unggi/tinyllama-vocab-extension": [
    "model.safetensors"
  ],
  "drkr23/fine-tuna-gpt2": [
    "adapter_model.safetensors",
    "checkpoint-5420/adapter_model.safetensors"
  ],
  "nthngdy/hythia410m-10k_raw": [
    "model.safetensors"
  ],
  "tomaszki/nous-nineteen": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Manish0611/phi2-code": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "dahwinsingularity/dahyun-coder": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "jsfs11/HighdensityRPMerge-7B-5.0bpw-exl2": [
    "cal_data.safetensors",
    "hidden_states.safetensors",
    "output.safetensors"
  ],
  "Sharathhebbar24/Mistral-7B-v0.1-sharded": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hingeankit/qlora": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jaehy12/Qwen1.5_7B_ko": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "willwade/t5-small-spoken-typo": [
    "model.safetensors"
  ],
  "nthngdy/hythia410m-10k_ft_bs256_500_cos_lr6e-4-probe": [
    "model.safetensors"
  ],
  "eswardivi/qwen1.5_1.8B_Telugu": [
    "model.safetensors"
  ],
  "qwedsacf/btsn6-06-1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jaehy12/Qwen1.5_7B_ko2": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "crazyjeannot/mistradventures": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "BlahBlah314/Seraph-7b-Const-FT-V9": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "KAKA22/TableLLM-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mu0gum/AIFT-42dot_LLM-SFT-1.3B-ao-instruct-all-v0.9": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "msalnikov/Mintaka-Mistral-7B-Instruct-v0.2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "uukuguy/speechless-mistral-hermes-code-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "win10/Qwen1.5-0.5b-Xia-Ai": [
    "model.safetensors"
  ],
  "codersan/Enlighten_Instruct_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "halilibr/tinyLlama-avansas-english-model-v1": [
    "model.safetensors"
  ],
  "FredrikBL/NeuralPipe-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "rameshakkineni/sn9001": [
    "model.safetensors"
  ],
  "ai-made-approachable/finetuning_test": [
    "adapter_model.safetensors",
    "checkpoint-3/adapter_model.safetensors"
  ],
  "giux78/zefiro-7b-dpo-qlora-ITA-v0.5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "areegtarek/patientcommunication-4bit": [
    "model.safetensors"
  ],
  "gmonsoon/TinyNesia-Base": [
    "model.safetensors"
  ],
  "Jayem-11/mistral_7b_malawi": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "ohwi/japanese-stablelm-instruct-gamma-7b-repro": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Fukurokun/MemGPT-DPO-uncensored-6.0bpw-exl2": [
    "cal_data.safetensors",
    "hidden_states.safetensors",
    "output.safetensors"
  ],
  "Doniaa/distilgpt2-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "Test157t/Pasta-Made_7b": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "teodortita/Nero-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "weijie210/zephyr-7b-dpo-maximal": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "YHLam/mistral_instruct_finetune_attempt_8k_refined_short": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Sao10K/Fimbulvetr-11B-v2-Test-14": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Unggi/tinyllama-base": [
    "model.safetensors"
  ],
  "PranavInvenics/phi2": [
    "adapter_model.safetensors",
    "checkpoint-159/adapter_model.safetensors"
  ],
  "lipcut/shizhi-twilight-7B": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "B2111797/recipe_gener_v2": [
    "model.safetensors"
  ],
  "impossibleexchange/pt32": [
    "model.safetensors"
  ],
  "aloobun/stablelm-2-bun_M4-1_6b": [
    "model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-only_measure_nps_as_singular_removal-1e-4": [
    "model.safetensors"
  ],
  "LoneStriker/bagel-dpo-7b-v0.4-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/bagel-dpo-7b-v0.4-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/bagel-dpo-7b-v0.4-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/bagel-dpo-7b-v0.4-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-only_other_det_removal-1e-4": [
    "model.safetensors"
  ],
  "LoneStriker/bagel-dpo-7b-v0.4-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "Sharathhebbar24/falcon-7b-instruct_sharded": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "alonafyshe/gpt2-wikitext2": [
    "model.safetensors"
  ],
  "MartaSamoilenko/Quantized_falcon_1b": [
    "model.safetensors"
  ],
  "LoneStriker/Quyen-Mini-v0.1-AWQ": [
    "model.safetensors"
  ],
  "kaushalpowar/llama2_finetuned2_easymonk_merged": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ConorParis32/FirstTrainedGPTCasualModel": [
    "model.safetensors"
  ],
  "Test157t/Pasta-PrimaMaid-7b": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "ConorParis32/output": [
    "model.safetensors"
  ],
  "shradha01/codesearchnet-ds": [
    "model.safetensors"
  ],
  "LoneStriker/Quyen-v0.1-AWQ": [
    "model.safetensors"
  ],
  "0x0dad0/nous_v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SaeedNajafi/gpt2-medium-wikitext2": [
    "model.safetensors"
  ],
  "PranavInvenics/phi2_v2": [
    "adapter_model.safetensors",
    "checkpoint-159/adapter_model.safetensors"
  ],
  "zaq-hack/Noromaid-v0.4-Mixtral-Instruct-8x7b-Zloss-bpw300-h6-exl2-rpcal": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Quyen-Plus-v0.1-AWQ": [
    "model.safetensors"
  ],
  "CausalLM/34b-beta": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "muzammil-eds/tinyllama-3T-64k-JSONExtractor-v2": [
    "model.safetensors"
  ],
  "LoneStriker/Quyen-Plus-v0.1-GPTQ": [
    "gptq_model-4bit-32g.safetensors"
  ],
  "SalehAhmad/Initial_Knowledge_Assessment_Test-Model-Phi2_3Epochs": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "NeverSleep/MiquMaid-v2-2x70B": [
    "model-00001-of-00026.safetensors",
    "model-00002-of-00026.safetensors",
    "model-00003-of-00026.safetensors",
    "model-00004-of-00026.safetensors",
    "model-00005-of-00026.safetensors",
    "model-00006-of-00026.safetensors",
    "model-00007-of-00026.safetensors",
    "model-00008-of-00026.safetensors",
    "model-00009-of-00026.safetensors",
    "model-00010-of-00026.safetensors",
    "model-00011-of-00026.safetensors",
    "model-00012-of-00026.safetensors",
    "model-00013-of-00026.safetensors",
    "model-00014-of-00026.safetensors",
    "model-00015-of-00026.safetensors",
    "model-00016-of-00026.safetensors",
    "model-00017-of-00026.safetensors",
    "model-00018-of-00026.safetensors",
    "model-00019-of-00026.safetensors",
    "model-00020-of-00026.safetensors",
    "model-00021-of-00026.safetensors",
    "model-00022-of-00026.safetensors",
    "model-00023-of-00026.safetensors",
    "model-00024-of-00026.safetensors",
    "model-00025-of-00026.safetensors",
    "model-00026-of-00026.safetensors"
  ],
  "MartaSamoilenko/Quantized-falcon-7b": [
    "model.safetensors"
  ],
  "Sharathhebbar24/SSH_355M": [
    "model.safetensors"
  ],
  "sophosympatheia/Midnight-Rose-103B-v2.0.3": [
    "model-00001-of-00022.safetensors",
    "model-00002-of-00022.safetensors",
    "model-00003-of-00022.safetensors",
    "model-00004-of-00022.safetensors",
    "model-00005-of-00022.safetensors",
    "model-00006-of-00022.safetensors",
    "model-00007-of-00022.safetensors",
    "model-00008-of-00022.safetensors",
    "model-00009-of-00022.safetensors",
    "model-00010-of-00022.safetensors",
    "model-00011-of-00022.safetensors",
    "model-00012-of-00022.safetensors",
    "model-00013-of-00022.safetensors",
    "model-00014-of-00022.safetensors",
    "model-00015-of-00022.safetensors",
    "model-00016-of-00022.safetensors",
    "model-00017-of-00022.safetensors",
    "model-00018-of-00022.safetensors",
    "model-00019-of-00022.safetensors",
    "model-00020-of-00022.safetensors",
    "model-00021-of-00022.safetensors",
    "model-00022-of-00022.safetensors"
  ],
  "afshinO/llama2-hf-fine-tuned": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "LoneStriker/Quyen-Pro-v0.1-AWQ": [
    "model.safetensors"
  ],
  "rlander/groovyllama": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Quyen-Pro-v0.1-GPTQ": [
    "gptq_model-4bit-32g.safetensors"
  ],
  "aligner/aligner-7b-v1.0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rhplus0831/maid-yuzu-v5": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "rhplus0831/maid-yuzu-v5-extra": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Epiculous/Fett-uccine-Long-Noodle-7B-120k-Context": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ankhamun/xxxI-o____X_0____o-Ixxx": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ankhamun/xxxooT-Tooxxx": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ankhamun/xxxI_O_v_v_O_Ixxx": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "aiplanet/effi-7b-gptq": [
    "model.safetensors"
  ],
  "TokenBender/navarna_hindi_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "gyan4u/Virtual": [
    "model.safetensors"
  ],
  "ashishkgpian/sharded_astromistral": [
    "model.safetensors"
  ],
  "abhinand/TinyLlama-1.1B-OpenHermes-2.5-Chat-v0.1-sft": [
    "model.safetensors"
  ],
  "nvidia/OpenMath-Mistral-7B-v0.1-hf": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ArmaanSeth/Llama-2-7b-chat-hf-shards-mental-health-counselling": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "w601sxs/b1ade-1b-bf16": [
    "model.safetensors"
  ],
  "intelsense/IntelsenseMistral1stPhase": [
    "model.safetensors"
  ],
  "El-Palmera/ULTRA-META-sample": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "olivertheboy/DialoGPT-WalterWhite-medium": [
    "model.safetensors"
  ],
  "rombodawg/DeepMagic-Coder-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "rhplus0831/maid-yuzu-v5-mix": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "qwedsacf/btsn6-07-2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Technoculture/MT7Bi-dpo": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "dawveed/AWS-Sage": [
    "adapter_model.safetensors"
  ],
  "zaq-hack/Noromaid-13B-0.4-DPO-bpw250-h6-exl2-rpcal": [
    "output.safetensors"
  ],
  "guibluesaturn/mistral-7b-8k-trl-lora-parser-merge": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "rldxyz/agi": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TeeZee/DarkSapling-7B-v1.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ayushayush591/open_hathi-hiQA-tunned_hindi_squad": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "RJuro/munin-neuralbeagle-SkoleGPTOpenOrca-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rickprime/primetime-03": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "andysalerno/rainbowfish-v6-lora-adapter": [
    "adapter_model.safetensors"
  ],
  "llmixer/BigWeave-v16-103b": [
    "model-00001-of-00021.safetensors",
    "model-00002-of-00021.safetensors",
    "model-00003-of-00021.safetensors",
    "model-00004-of-00021.safetensors",
    "model-00005-of-00021.safetensors",
    "model-00006-of-00021.safetensors",
    "model-00007-of-00021.safetensors",
    "model-00008-of-00021.safetensors",
    "model-00009-of-00021.safetensors",
    "model-00010-of-00021.safetensors",
    "model-00011-of-00021.safetensors",
    "model-00012-of-00021.safetensors",
    "model-00013-of-00021.safetensors",
    "model-00014-of-00021.safetensors",
    "model-00015-of-00021.safetensors",
    "model-00016-of-00021.safetensors",
    "model-00017-of-00021.safetensors",
    "model-00018-of-00021.safetensors",
    "model-00019-of-00021.safetensors",
    "model-00020-of-00021.safetensors",
    "model-00021-of-00021.safetensors"
  ],
  "rickprime/hal-69420": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ankhamun/xxW__Wxx": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "superfriends/megadog-v0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ibivibiv/alpaca-dragon-72b-v1": [
    "model-00001-of-00063.safetensors",
    "model-00002-of-00063.safetensors",
    "model-00003-of-00063.safetensors",
    "model-00004-of-00063.safetensors",
    "model-00005-of-00063.safetensors",
    "model-00006-of-00063.safetensors",
    "model-00007-of-00063.safetensors",
    "model-00008-of-00063.safetensors",
    "model-00009-of-00063.safetensors",
    "model-00010-of-00063.safetensors",
    "model-00011-of-00063.safetensors",
    "model-00012-of-00063.safetensors",
    "model-00013-of-00063.safetensors",
    "model-00014-of-00063.safetensors",
    "model-00015-of-00063.safetensors",
    "model-00016-of-00063.safetensors",
    "model-00017-of-00063.safetensors",
    "model-00018-of-00063.safetensors",
    "model-00019-of-00063.safetensors",
    "model-00020-of-00063.safetensors",
    "model-00021-of-00063.safetensors",
    "model-00022-of-00063.safetensors",
    "model-00023-of-00063.safetensors",
    "model-00024-of-00063.safetensors",
    "model-00025-of-00063.safetensors",
    "model-00026-of-00063.safetensors",
    "model-00027-of-00063.safetensors",
    "model-00028-of-00063.safetensors",
    "model-00029-of-00063.safetensors",
    "model-00030-of-00063.safetensors",
    "model-00031-of-00063.safetensors",
    "model-00032-of-00063.safetensors",
    "model-00033-of-00063.safetensors",
    "model-00034-of-00063.safetensors",
    "model-00035-of-00063.safetensors",
    "model-00036-of-00063.safetensors",
    "model-00037-of-00063.safetensors",
    "model-00038-of-00063.safetensors",
    "model-00039-of-00063.safetensors",
    "model-00040-of-00063.safetensors",
    "model-00041-of-00063.safetensors",
    "model-00042-of-00063.safetensors",
    "model-00043-of-00063.safetensors",
    "model-00044-of-00063.safetensors",
    "model-00045-of-00063.safetensors",
    "model-00046-of-00063.safetensors",
    "model-00047-of-00063.safetensors",
    "model-00048-of-00063.safetensors",
    "model-00049-of-00063.safetensors",
    "model-00050-of-00063.safetensors",
    "model-00051-of-00063.safetensors",
    "model-00052-of-00063.safetensors",
    "model-00053-of-00063.safetensors",
    "model-00054-of-00063.safetensors",
    "model-00055-of-00063.safetensors",
    "model-00056-of-00063.safetensors",
    "model-00057-of-00063.safetensors",
    "model-00058-of-00063.safetensors",
    "model-00059-of-00063.safetensors",
    "model-00060-of-00063.safetensors",
    "model-00061-of-00063.safetensors",
    "model-00062-of-00063.safetensors",
    "model-00063-of-00063.safetensors"
  ],
  "mkiani/llama-2-7b-prompt-injection-detector": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "EnteliMindDelivery/Enteli-49B": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "NeverSleep/MiquMaid-v2-2x70B-DPO": [
    "model-00001-of-00026.safetensors",
    "model-00002-of-00026.safetensors",
    "model-00003-of-00026.safetensors",
    "model-00004-of-00026.safetensors",
    "model-00005-of-00026.safetensors",
    "model-00006-of-00026.safetensors",
    "model-00007-of-00026.safetensors",
    "model-00008-of-00026.safetensors",
    "model-00009-of-00026.safetensors",
    "model-00010-of-00026.safetensors",
    "model-00011-of-00026.safetensors",
    "model-00012-of-00026.safetensors",
    "model-00013-of-00026.safetensors",
    "model-00014-of-00026.safetensors",
    "model-00015-of-00026.safetensors",
    "model-00016-of-00026.safetensors",
    "model-00017-of-00026.safetensors",
    "model-00018-of-00026.safetensors",
    "model-00019-of-00026.safetensors",
    "model-00020-of-00026.safetensors",
    "model-00021-of-00026.safetensors",
    "model-00022-of-00026.safetensors",
    "model-00023-of-00026.safetensors",
    "model-00024-of-00026.safetensors",
    "model-00025-of-00026.safetensors",
    "model-00026-of-00026.safetensors"
  ],
  "LoneStriker/miquliz-120b-2.4bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "pxltd/block": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "llmixer/BigWeave-v16-103b-4.0bpw-h6-exl2": [
    "output-00001-of-00007.safetensors",
    "output-00002-of-00007.safetensors",
    "output-00003-of-00007.safetensors",
    "output-00004-of-00007.safetensors",
    "output-00005-of-00007.safetensors",
    "output-00006-of-00007.safetensors",
    "output-00007-of-00007.safetensors"
  ],
  "minghaowu/Qwen1.5-0.5B-OpenHermes-2.5": [
    "model.safetensors"
  ],
  "ankhamun/IIIIIIIx-xIIIIIII": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "llmixer/BigWeave-v16-103b-6.0bpw-h6-exl2": [
    "output-00001-of-00010.safetensors",
    "output-00002-of-00010.safetensors",
    "output-00003-of-00010.safetensors",
    "output-00004-of-00010.safetensors",
    "output-00005-of-00010.safetensors",
    "output-00006-of-00010.safetensors",
    "output-00007-of-00010.safetensors",
    "output-00008-of-00010.safetensors",
    "output-00009-of-00010.safetensors",
    "output-00010-of-00010.safetensors"
  ],
  "LoneStriker/miquliz-120b-2.65bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "deepestneuron/money": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "superfriends/megadog-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SuccubusBot-Archive/airoboros-33b-3.1.2-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/miquliz-120b-2.9bpw-h6-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "deepestneuron/moneymoneymoney": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "gotchu/season-8-13bmerge": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/miquliz-120b-4.0bpw-h6-exl2": [
    "output-00001-of-00007.safetensors",
    "output-00002-of-00007.safetensors",
    "output-00003-of-00007.safetensors",
    "output-00004-of-00007.safetensors",
    "output-00005-of-00007.safetensors",
    "output-00006-of-00007.safetensors",
    "output-00007-of-00007.safetensors"
  ],
  "El-Palmera/ULTRA-META-CHAT": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "gotchu/season-8-13bmergev1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "superfriends/megadog-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jaehy12/qwen1.5-7b_ko3": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "decapoda-research/Antares-11b-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "incomprehensible/008": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rombodawg/DeepMagic-Coder-7b-Alt": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ankhamun/xxxooTUTooxxx": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "gotchu/season-8-solar": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Nacissu/DiabloGPT-small-Bocchers": [
    "model.safetensors"
  ],
  "ankhamun/xxxI_O_v_-_v_O_Ixxx": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "weijie210/zephyr-7b-UFB-0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "asadmasad/output-67b-11k-test": [
    "adapter_model.safetensors"
  ],
  "jumtul/LDCC-Hyeogi.04": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Onlydrinkwater/gpt2xl_language_math_520": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jan-hq/stealth-finance-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ankhamun/xxW_-_Wxx": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ankhamun/IIIIIxII0-0IIxIIIII": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tyson0420/stack_llama-clang": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "superfriends/megadog-v3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "gotchu/season-8-v2-solar": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "incomprehensible/009": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "cloudyu/60B-MoE-Coder-v2": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "LoneStriker/DeepMagic-Coder-7b-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/DeepMagic-Coder-7b-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "CHATHISTORY/0.5B-Model-1": [
    "model.safetensors"
  ],
  "LoneStriker/DeepMagic-Coder-7b-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/DeepMagic-Coder-7b-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "Aryanne/TinyllamaMix-1.1B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/DeepMagic-Coder-7b-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "andysalerno/rainbowfish-v6": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "gotchu/s8-solar-merge": [
    "model-00001-of-00002.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00002.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/DeepMagic-Coder-7b-AWQ": [
    "model.safetensors"
  ],
  "LoneStriker/DeepMagic-Coder-7b-GPTQ": [
    "gptq_model-4bit-32g.safetensors"
  ],
  "Test157t/Kunocchini-7b-128k-test": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "dhruv4real/my-causal-model-qa": [
    "model.safetensors"
  ],
  "yifeng99/nl2sql_14b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "yoonyoon/kb_v4.1_Y": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "manche/gpt2-safeguard-3": [
    "model.safetensors"
  ],
  "0x0dad0/nous_v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "cvzion/mistral-dqg-v3": [
    "adapter_model.safetensors",
    "checkpoint-39/adapter_model.safetensors"
  ],
  "rickprime/primetime-04": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dddsaty/Merge_Sakura_Solar": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "viai957/CodeLlama_7B-Fientuned": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "tsavage68/150STEPS_5e7rate_SFT_zeroshot": [
    "final_checkpoint/model-00001-of-00003.safetensors",
    "final_checkpoint/model-00002-of-00003.safetensors",
    "final_checkpoint/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "superfriends/wedgehog-v0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TheBossLevel123/TinyAITA": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "Nacissu/DiabloGPT-Large-Bocchers": [
    "model.safetensors"
  ],
  "aitamilnadu/marabutamil": [
    "model.safetensors"
  ],
  "matlok/tinyllama-cinder-openhermes-32k": [
    "model.safetensors"
  ],
  "tsavage68/175STEPS_5e7rate_SFT_zeroshot": [
    "final_checkpoint/model-00001-of-00003.safetensors",
    "final_checkpoint/model-00002-of-00003.safetensors",
    "final_checkpoint/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rickprime/hal-420": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Fredh99/finetune_mistral_7b_v0.2_action_selection": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "OpenSafetyLab/MD-Judge-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "muzammil-eds/tinyllama-3T-64k-JSONExtractor-v3": [
    "model.safetensors"
  ],
  "rombodawg/Everyone-Coder-33b-v2-Base": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "octadion/phi-2-jagr-ppg-simpkb": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mesolitica/Qwen1.5-0.5B-4096-fpf": [
    "model.safetensors"
  ],
  "brucethemoose/Yi-34B-200K-RPMerge": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "brucethemoose/Yi-34B-200K-RPMerge-exl2-31bpw": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "brucethemoose/Yi-34B-200K-RPMerge-exl2-40bpw": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "0x0dad0/nous_v3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rhplus0831/maid-yuzu-v5-mix-exl2-6.0bpw-rpcal": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "JaeyeonKang/CCK_Asura_v2": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "onur-softtech/finetune_deepseek_6.7b_exp_1_0_yaml": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors",
    "save_pretrained/model.safetensors",
    "trainer_save_model/model-00001-of-00003.safetensors",
    "trainer_save_model/model-00002-of-00003.safetensors",
    "trainer_save_model/model-00003-of-00003.safetensors"
  ],
  "areegtarek/patientcommunication-8bit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "crystalyu/llama2-13b-kor-AWQ": [
    "model.safetensors"
  ],
  "mitultiwari/mistral-7B-dpo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "JackCloudman/Senku-70B-Full-exl2-3.5bpw": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "muzammil-eds/tinyllama-3T-64k-JSONExtractor-v4": [
    "model.safetensors"
  ],
  "smrynrz20/custom_q_and_a": [
    "model.safetensors"
  ],
  "airalribalta/ALMA-Latxa-7b": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "0x0dad0/nous_v4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mzbac/phi-2-2x3-hf": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "McGill-NLP/flan-t5-base-weblinx": [
    "model.safetensors"
  ],
  "phamtungthuy/quantized_law_model_merged": [
    "model.safetensors"
  ],
  "audreyleteve/curious-muskox": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "phamtungthuy/law_model_merged": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "iGenius-AI-Team/Italia-2Bts-ckpt-20B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "EnDevSols/tinyllama-3T-64k-JSONExtractor": [
    "model.safetensors"
  ],
  "Kooten/BagelMIsteryTour-v2-8x7B-3.5bpw-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "DrishtiSharma/mixtral-8x7b-v0.1-english-to-hinglish-translation-merged": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "unsloth/yi-34b-bnb-4bit": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "IntervitensInc/intv_ai_mk12": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "DevikaSR/git-base-pokemon": [
    "model.safetensors"
  ],
  "logicker/SkkuDataScience-Qwen14B-v1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "logicker/SkkuDataScience-Qwen14B-v2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "logicker/SkkuDataScience-Qwen14B-v3": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "0x0dad0/nous_v5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hingeankit/first": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "petitpatoche/sn6-v8": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hingeankit/second": [
    "model.safetensors"
  ],
  "Jimmyhd/llama213b50RowsTimeBook": [
    "checkpoint-8/adapter_model.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "AIJUUD/juud-Mistral-7B-dpo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Kooten/BagelMIsteryTour-v2-8x7B-5bpw-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "logicker/SkkuDataScience-Qwen14B-v4": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "PranavInvenics/phi2_v3": [
    "checkpoint-159/adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "shidowake/cyber2chat-7B-base-bnb-4bit": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TokenBender/Navarna_v0_1_OpenHermes_Hindi": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sajaw/AntModel-7B-XLLM-Demo": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "airalribalta/Latxa-llama-chat-7b": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "wabu/AmpGPT2": [
    "model.safetensors"
  ],
  "jaehy12/wiznet_2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "boatymcboatface101/pretrain": [
    "model.safetensors"
  ],
  "asadmasad/output-6.7b-26k-ds-test-save-state-no-save-eval-strat": [
    "model.safetensors"
  ],
  "airalribalta/Llama-Latxa-7b": [
    "model-00001-of-00007.safetensors",
    "model-00001-of-00016.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00002-of-00016.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00003-of-00016.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00004-of-00016.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00005-of-00016.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00006-of-00016.safetensors",
    "model-00007-of-00007.safetensors",
    "model-00007-of-00016.safetensors",
    "model-00008-of-00016.safetensors",
    "model-00009-of-00016.safetensors",
    "model-00010-of-00016.safetensors",
    "model-00011-of-00016.safetensors",
    "model-00012-of-00016.safetensors",
    "model-00013-of-00016.safetensors",
    "model-00014-of-00016.safetensors",
    "model-00015-of-00016.safetensors",
    "model-00016-of-00016.safetensors"
  ],
  "sajaw/Llama-2-7B-XLLM-Demo": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "newbie-geek/new-dot-comp-v1": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "asifhaider/asif-valid-all-codellama-instruct-ft": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "indischepartij/OpenMia-Indo-Mistral-7b-v4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Kooten/Kunocchini-7b-128k-test-8bpw-exl2": [
    "output.safetensors"
  ],
  "YashRawal225/Intel-3-7b-chat-finetune-german2000": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Josephgflowers/160M-TinyLLama-Mini-Cinder": [
    "model.safetensors"
  ],
  "rodrigoasth/autotrain-snkt5-e2mzt": [
    "adapter_model.safetensors",
    "checkpoint-6/adapter_model.safetensors"
  ],
  "YHLam/mistral_instruct_finetune_attempt_8k_context": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Abhishek-1011/my_gec": [
    "adapter_model.safetensors",
    "checkpoint-18/adapter_model.safetensors"
  ],
  "Aspik101/first": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "thomaslwang/gpt2-wikitext2": [
    "model.safetensors"
  ],
  "MAsad789565/GPT2_Finetuned_v1": [
    "model.safetensors"
  ],
  "ExAi/Claire-Mistral-7B-v0.1.3-exl2-4.0": [
    "cal_data.safetensors",
    "hidden_states.safetensors",
    "output.safetensors"
  ],
  "shapermindai/pygmalion-free": [
    "model.safetensors"
  ],
  "OEvortex/HelpingAI-unvelite": [
    "model.safetensors"
  ],
  "BryanSwk/LaserPipe-7B-SLERP": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "openvoid/prox-7b-v3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "yanolja/KoSOLAR-10.7B-v0.3": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "B-O/dummy-mistral-4M": [
    "model.safetensors"
  ],
  "mitkox/sqlcoder-7b-2-2": [
    "model.safetensors"
  ],
  "Americo/phi-2-finetuned-farmatodo": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "waldie/Yi-34B-200K-AEZAKMI-RAW-2901-4bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-only_measure_nps_as_singular_removal-3e-4": [
    "model.safetensors"
  ],
  "LoneStriker/Senku-70B-Full-2.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "Ttimofeyka/MistralRP-Noromaid-NSFW-Mistral-7B-GGUF": [],
  "airalribalta/Passthrough-Latxa-Llama-LlamaCode-7b": [
    "model-00001-of-00016.safetensors",
    "model-00002-of-00016.safetensors",
    "model-00003-of-00016.safetensors",
    "model-00004-of-00016.safetensors",
    "model-00005-of-00016.safetensors",
    "model-00006-of-00016.safetensors",
    "model-00007-of-00016.safetensors",
    "model-00008-of-00016.safetensors",
    "model-00009-of-00016.safetensors",
    "model-00010-of-00016.safetensors",
    "model-00011-of-00016.safetensors",
    "model-00012-of-00016.safetensors",
    "model-00013-of-00016.safetensors",
    "model-00014-of-00016.safetensors",
    "model-00015-of-00016.safetensors",
    "model-00016-of-00016.safetensors"
  ],
  "LoneStriker/Senku-70B-Full-3.5bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-only_other_det_removal-3e-4": [
    "model.safetensors"
  ],
  "LoneStriker/DeepMagic-Coder-7b-Alt-AWQ": [
    "model.safetensors"
  ],
  "LoneStriker/DeepMagic-Coder-7b-Alt-GPTQ": [
    "gptq_model-4bit-32g.safetensors"
  ],
  "LoneStriker/Senku-70B-Full-4.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "regisss/test_model": [
    "adapter_model.safetensors",
    "model-00001-of-00061.safetensors",
    "model-00002-of-00061.safetensors",
    "model-00003-of-00061.safetensors",
    "model-00004-of-00061.safetensors",
    "model-00005-of-00061.safetensors",
    "model-00006-of-00061.safetensors",
    "model-00007-of-00061.safetensors",
    "model-00008-of-00061.safetensors",
    "model-00009-of-00061.safetensors",
    "model-00010-of-00061.safetensors",
    "model-00011-of-00061.safetensors",
    "model-00012-of-00061.safetensors",
    "model-00013-of-00061.safetensors",
    "model-00014-of-00061.safetensors",
    "model-00015-of-00061.safetensors",
    "model-00016-of-00061.safetensors",
    "model-00017-of-00061.safetensors",
    "model-00018-of-00061.safetensors",
    "model-00019-of-00061.safetensors",
    "model-00020-of-00061.safetensors",
    "model-00021-of-00061.safetensors",
    "model-00022-of-00061.safetensors",
    "model-00023-of-00061.safetensors",
    "model-00024-of-00061.safetensors",
    "model-00025-of-00061.safetensors",
    "model-00026-of-00061.safetensors",
    "model-00027-of-00061.safetensors",
    "model-00028-of-00061.safetensors",
    "model-00029-of-00061.safetensors",
    "model-00030-of-00061.safetensors",
    "model-00031-of-00061.safetensors",
    "model-00032-of-00061.safetensors",
    "model-00033-of-00061.safetensors",
    "model-00034-of-00061.safetensors",
    "model-00035-of-00061.safetensors",
    "model-00036-of-00061.safetensors",
    "model-00037-of-00061.safetensors",
    "model-00038-of-00061.safetensors",
    "model-00039-of-00061.safetensors",
    "model-00040-of-00061.safetensors",
    "model-00041-of-00061.safetensors",
    "model-00042-of-00061.safetensors",
    "model-00043-of-00061.safetensors",
    "model-00044-of-00061.safetensors",
    "model-00045-of-00061.safetensors",
    "model-00046-of-00061.safetensors",
    "model-00047-of-00061.safetensors",
    "model-00048-of-00061.safetensors",
    "model-00049-of-00061.safetensors",
    "model-00050-of-00061.safetensors",
    "model-00051-of-00061.safetensors",
    "model-00052-of-00061.safetensors",
    "model-00053-of-00061.safetensors",
    "model-00054-of-00061.safetensors",
    "model-00055-of-00061.safetensors",
    "model-00056-of-00061.safetensors",
    "model-00057-of-00061.safetensors",
    "model-00058-of-00061.safetensors",
    "model-00059-of-00061.safetensors",
    "model-00060-of-00061.safetensors",
    "model-00061-of-00061.safetensors"
  ],
  "BlackSamorez/Llama-2-70b-AQLM-2Bit-2x8-hf": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "LoneStriker/Senku-70B-Full-4.65bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "ambrosfitz/tinyllama-history-chat_v0.2": [
    "model.safetensors"
  ],
  "rodrigoasth/llama-2-7b-hf": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/DeepMagic-Coder-7b-Alt-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "ssaryssane/ssarry-truthful-13B-slerp": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "KnutJaegersberg/Deita-4b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/DeepMagic-Coder-7b-Alt-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "Jayem-11/zephyr-7b-beta_assistant_v0.2_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/DeepMagic-Coder-7b-Alt-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/DeepMagic-Coder-7b-Alt-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/DeepMagic-Coder-7b-Alt-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Senku-70B-Full-5.0bpw-h6-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "rsilveira79/TinyLlama-1.1B-soprano": [
    "model.safetensors"
  ],
  "LoneStriker/Senku-70B-Full-6.0bpw-h6-exl2": [
    "output-00001-of-00007.safetensors",
    "output-00002-of-00007.safetensors",
    "output-00003-of-00007.safetensors",
    "output-00004-of-00007.safetensors",
    "output-00005-of-00007.safetensors",
    "output-00006-of-00007.safetensors",
    "output-00007-of-00007.safetensors"
  ],
  "waldie/Etheria-55b-v0.1-2.5bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "zaq-hack/psyonic-cetacean-20B-bpw300-h6-exl2-rpcal": [
    "output.safetensors"
  ],
  "manche/gpt2-safeguard-zs": [
    "model.safetensors"
  ],
  "paulux84/autotrain-z58fs-z9tot": [
    "adapter_model.safetensors",
    "checkpoint-3/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "0x0dad0/nous_v6": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "GavinQiangLi/gpt-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "eryk-mazus/polka-1.1b-chat": [
    "model.safetensors"
  ],
  "zaq-hack/psyonic-cetacean-20B-bpw350-h6-exl2-rpcal": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "hiiamsid/mistral_yt_transcribe_classification": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Prashantmdgl9/kannada_llama_v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "manche/gpt2-safeguard-sg1": [
    "model.safetensors"
  ],
  "Crystalcareai/CrystalQwen-1.5-7B-Alpha": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "delli/mistral-7b-address-validator-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "autora-doc/Llama-2-7b-chat-hf": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "nm-testing/zephyr-beta-7b-marlin-g128": [
    "model.safetensors"
  ],
  "hmone231/mistral-burmese-health": [
    "adapter_model.safetensors"
  ],
  "macadeliccc/laser-dolphin-mixtral-2x7b-dpo-AWQ": [
    "model.safetensors"
  ],
  "MaziyarPanahi/Smaug-72B-v0.1-GPTQ": [
    "model.safetensors"
  ],
  "mitultiwari/mistral-7B-instruct-dpo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ExAi/Claire-Mistral-7B-v0.1.3-exl2-3.0": [
    "cal_data.safetensors",
    "hidden_states.safetensors",
    "output.safetensors"
  ],
  "gmonsoon/Darcy-7b": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "vrhoward/ProGen2-small-finetuned": [
    "model.safetensors"
  ],
  "ankhamun/xxxI-o____o_-_o____o-Ixxx": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "cmarvolo/llama-2-7b-fed-auto": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "0x0dad0/pretrain_v1": [
    "model.safetensors"
  ],
  "rsilveira79/Mistral-7B-soprano": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Ali-C137/heliosbrahma-falcon-7b-finetuned-mental-health-conversational": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "hanspeterlyngsoeraaschoujensen/deepseek-coder-1.3b-instruct-GPTQ": [
    "model.safetensors"
  ],
  "Ali-C137/curiousily-falcon-7b-qlora-chat-support-bot-faq": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ekojs/internlm2-20b": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "McGill-NLP/Sheared-LLaMA-1.3B-weblinx": [
    "model.safetensors"
  ],
  "McGill-NLP/Sheared-LLaMA-2.7B-weblinx": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "McGill-NLP/flan-t5-large-weblinx": [
    "model.safetensors"
  ],
  "McGill-NLP/flan-t5-xl-weblinx": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "devlocalhost/hi-tinylama": [
    "model.safetensors"
  ],
  "mdroth/codeparrot-ds": [
    "model.safetensors"
  ],
  "DrishtiSharma/phi2-english-to-hinglish-translation-merged": [
    "model.safetensors"
  ],
  "ambrosfitz/tinyllama-history-chat_v0.3": [
    "model.safetensors"
  ],
  "kewu93/NeuralHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Finnish-NLP/llama-7b-finnish-instruct-v0.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "deepestneuron/cell-0-0-3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ydang/jsd_Mistral-7B-v0.1-M2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Jimmyhd/mistral7btimebookFinetune50rows": [
    "checkpoint-6/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hanspeterlyngsoeraaschoujensen/deepseek-math-7b-instruct-GPTQ": [
    "model.safetensors"
  ],
  "rldxyz/questioninglife": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "davisalex22/GPT2-TurismEC-xl-ft": [
    "model.safetensors"
  ],
  "ayushayush591/hinolin-hiQA-tunned_chaii_con_4096": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "ankhamun/xxxI-o_p__o_-_o__q_o-Ixxx": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "louisbrulenaudet/Pearl-3x7B": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "Meggido/NeuraLake-m7-v2-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "nthngdy/hythia-410m-10k_ft-bs256-lr1e-4-cos-1k": [
    "model.safetensors"
  ],
  "lodrick-the-lafted/Grafted-Wind-Elementals-2x70B": [
    "model-00001-of-00026.safetensors",
    "model-00002-of-00026.safetensors",
    "model-00003-of-00026.safetensors",
    "model-00004-of-00026.safetensors",
    "model-00005-of-00026.safetensors",
    "model-00006-of-00026.safetensors",
    "model-00007-of-00026.safetensors",
    "model-00008-of-00026.safetensors",
    "model-00009-of-00026.safetensors",
    "model-00010-of-00026.safetensors",
    "model-00011-of-00026.safetensors",
    "model-00012-of-00026.safetensors",
    "model-00013-of-00026.safetensors",
    "model-00014-of-00026.safetensors",
    "model-00015-of-00026.safetensors",
    "model-00016-of-00026.safetensors",
    "model-00017-of-00026.safetensors",
    "model-00018-of-00026.safetensors",
    "model-00019-of-00026.safetensors",
    "model-00020-of-00026.safetensors",
    "model-00021-of-00026.safetensors",
    "model-00022-of-00026.safetensors",
    "model-00023-of-00026.safetensors",
    "model-00024-of-00026.safetensors",
    "model-00025-of-00026.safetensors",
    "model-00026-of-00026.safetensors"
  ],
  "Eric111/Roya": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Meggido/NeuraLake-m7-v2-AshhLimaRP-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ydang/jsd_Mistral-7B-v0.1-M3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "davisalex22/BLOOMTurismEC-7b1-ft": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "cancelself/Finetuned-Mistral-7B-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "asadmasad/deepseek-6-7bn-lora-finetuning-26k": [
    "adapter_model.safetensors"
  ],
  "Arman123/zephyr-7b-beta-openassistant-guanaco3": [
    "adapter_model.safetensors"
  ],
  "daekeun-ml/phi-2-ko-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "sosoai/codellama-korean-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Mit1208/phi-2-classification-sentiment-merged": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "adarshheg/llama2-13b-finetuned-100-v1": [
    "adapter_model.safetensors",
    "checkpoint-4/adapter_model.safetensors"
  ],
  "arieridwans/phi_2-finetuned-lyrics": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ssaryssane/ssary-10.7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "nicholasbien/gpt2_finetuned": [
    "model.safetensors"
  ],
  "0x0dad0/pretrain_v2": [
    "model.safetensors"
  ],
  "Unggi/ko-openhermes-mistral-7b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "davisalex22/Llama2TurismEC-7b-hf-ft": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "0x0dad0/nous_v7": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ankhamun/xxxI-Ixxx": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ankhamun/xxxIU_x_x_UIxxx": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kevinautomation/TinyLlama-1.1B-intermediate-step-1431k-3T_reddit_expert_model": [
    "model.safetensors"
  ],
  "ankhamun/xxxI-o_p__X_-_X__q_o-Ixxx": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "yoonyoon/kb_v4.1_solar": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "impossibleexchange/pt33": [
    "model.safetensors"
  ],
  "AIFT/AIFT-ko-orca-plat-Yi-ko-6b-v1.7": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "zheng438/distilgpt2-disease-syptom": [
    "model.safetensors"
  ],
  "helloYfn/eores_llama_1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rickprime/hal-j": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "thrunlab/sparse_sparse_80_percent_pretraining_warmup_20K_steps_5k": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ankhamun/IIImIIIIo-oIIIImIII": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "R0k1e/UltraLink-LM": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "SakuraLLM/Sakura-1B8-Base-v0.9.0": [
    "model.safetensors"
  ],
  "ek826/LlamaGuard-7b-4.0bpw-exl2": [
    "output.safetensors"
  ],
  "lxsure/gemini5_3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dataeaze/dataeaze-RegLLM-microsoft_phi_2-dzcompli": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ek826/LlamaGuard-7b-4.65bpw-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Everyone-Coder-33b-v2-Base-3.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "khush78/encrypted-model": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Everyone-Coder-33b-v2-Base-4.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/Everyone-Coder-33b-v2-Base-4.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Everyone-Coder-33b-v2-Base-5.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "asadmasad/deepseek-7bn-v1.5-ds-finetuning-26k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Everyone-Coder-33b-v2-Base-6.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "hmone231/mistral_burmese_health_update": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Everyone-Coder-33b-v2-Base-8.0bpw-h8-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "rickprime/primetime-05": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "nicholasbien/gpt2_finetuned-2k": [
    "model.safetensors"
  ],
  "0x0dad0/pretrain_v2_1": [
    "model.safetensors"
  ],
  "cloudyu/60B_MoE_Coder_v3": [
    "model-00001-of-00025.safetensors",
    "model-00002-of-00025.safetensors",
    "model-00003-of-00025.safetensors",
    "model-00004-of-00025.safetensors",
    "model-00005-of-00025.safetensors",
    "model-00006-of-00025.safetensors",
    "model-00007-of-00025.safetensors",
    "model-00008-of-00025.safetensors",
    "model-00009-of-00025.safetensors",
    "model-00010-of-00025.safetensors",
    "model-00011-of-00025.safetensors",
    "model-00012-of-00025.safetensors",
    "model-00013-of-00025.safetensors",
    "model-00014-of-00025.safetensors",
    "model-00015-of-00025.safetensors",
    "model-00016-of-00025.safetensors",
    "model-00017-of-00025.safetensors",
    "model-00018-of-00025.safetensors",
    "model-00019-of-00025.safetensors",
    "model-00020-of-00025.safetensors",
    "model-00021-of-00025.safetensors",
    "model-00022-of-00025.safetensors",
    "model-00023-of-00025.safetensors",
    "model-00024-of-00025.safetensors",
    "model-00025-of-00025.safetensors"
  ],
  "sashika/git-base-pokemon": [
    "model.safetensors"
  ],
  "hotsuyuki/gpt_0.125B_global_step4000_openassistant": [
    "model.safetensors"
  ],
  "IBM-DTT/sap_finetunemodel_codegeneration_misteral_10k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Anish13/pretrained_gpt2": [
    "model.safetensors"
  ],
  "Shruti9756/G24_Contract_Summarization_step3": [
    "model.safetensors"
  ],
  "RomanOrac/testing": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "solidrust/Severusectum-7B-DPO-AWQ": [
    "model.safetensors"
  ],
  "nenekochan/Yi-6B-yoruno": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "deepestneuron/cell-0-0-4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ssoh/llama-2-7b-all-strings": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "baconnier/Mistraou-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Basha738/llama2-supervised-ft-5epochs": [
    "model.safetensors"
  ],
  "ITT-AF/ITT-42dot_LLM-SFT-1.3B-v2.0": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "thomaslwang/gpt2-cybersac": [
    "model.safetensors"
  ],
  "solidrust/SeverusWestLake-7B-DPO-AWQ": [
    "model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-random_removal-seed_211-3e-4": [
    "model.safetensors"
  ],
  "anish005/mistral-reddit": [
    "model.safetensors"
  ],
  "gotchu/s8-knarf": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "Kooten/MiquMaid-v2-70B-2.4bpw-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "tsavage68/1200STEPS_5e7_0.1beta_DPO_zeroshot": [
    "final_checkpoint/model-00001-of-00003.safetensors",
    "final_checkpoint/model-00002-of-00003.safetensors",
    "final_checkpoint/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "solidrust/Kunocchini-7b-AWQ": [
    "model.safetensors"
  ],
  "ssaryssane/ssary-solar-10.7B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Kooten/MiquMaid-v2-70B-2.3bpw-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "alpindale/MiquMaid-v2-2x70B-DPO-exl2-4bpw": [
    "cal_data.safetensors",
    "hidden_states.safetensors",
    "output-00001-of-00008.safetensors",
    "output-00002-of-00008.safetensors",
    "output-00003-of-00008.safetensors",
    "output-00004-of-00008.safetensors",
    "output-00005-of-00008.safetensors",
    "output-00006-of-00008.safetensors",
    "output-00007-of-00008.safetensors",
    "output-00008-of-00008.safetensors"
  ],
  "solidrust/WestLake-7B-v2-laser-AWQ": [
    "model.safetensors"
  ],
  "akashAD/phi-1_5-finetuned-query-classify": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "YashRawal225/New-3-7b-chat-finetune-german500": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "nateraw/defog-sqlcoder-70b-alpha-awq": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "solidrust/Darcy-7b-AWQ": [
    "model.safetensors"
  ],
  "Envoid/Fish-8x7B": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "HIT-SCIR/huozi3": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "EtienneDu91/galactica-6.7b-evol-instruct-70k-GPTQ-4b": [
    "model.safetensors"
  ],
  "HIT-SCIR/huozi3-awq": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mesolitica/malaysian-Qwen1.5-0.5B-16k-instructions": [
    "model.safetensors"
  ],
  "unsloth/yi-34b-chat-bnb-4bit": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ChenDRAG/zephyr-infoNCA-preference": [
    "adapter_model.safetensors"
  ],
  "ChenDRAG/zephyr-NCA-preference": [
    "adapter_model.safetensors"
  ],
  "ChenDRAG/zephyr-NCA-reward": [
    "adapter_model.safetensors"
  ],
  "tsavage68/500STEPS_5e7_0.1beta_DPO_zeroshot": [
    "final_checkpoint/model-00001-of-00003.safetensors",
    "final_checkpoint/model-00002-of-00003.safetensors",
    "final_checkpoint/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kmyoon/mzllm-solar-10.7B": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "khanhnto/kyt-test-13b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "CultriX/MergeTrix-v3": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "manishiitg/open-aditi-hi-v1-awq": [
    "model.safetensors"
  ],
  "Shxck69/fashion": [
    "model.safetensors"
  ],
  "mobiuslabsgmbh/aanaphi2-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "weijie210/mistral_strategyqa_sft": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jobvector/SFT_Llama-2-7b-hf_0.0001_57202Data_500ChPt": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jobvector/SFT_Llama-2-7b-hf_0.0001_57202Data_200ChPt": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "iGenius-AI-Team/Italia-2Bts-ckpt-17B-wikionly": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "PranavInvenics/phi2_v4": [
    "adapter_model.safetensors",
    "checkpoint-42/adapter_model.safetensors"
  ],
  "asadmasad/ds-finetuning-test-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors",
    "model.safetensors"
  ],
  "mzbac/qwen-1.5-2x3-hf-4bit-mlx": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Pplus/results": [
    "adapter_model.safetensors"
  ],
  "iGenius-AI-Team/Italia-2Bts-ckpt-34B-wikionly": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "erfanvaredi/jais-7b-chat": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Shri2818/llama_python_v1": [
    "adapter_model.safetensors"
  ],
  "kouki13/newopenhermes1": [
    "adapter_model.safetensors",
    "checkpoint-6/adapter_model.safetensors"
  ],
  "PranavInvenics/llama_2_v1": [
    "adapter_model.safetensors",
    "checkpoint-45/adapter_model.safetensors"
  ],
  "AlexWortega/tini_llama_frezze": [
    "model.safetensors"
  ],
  "AlexWortega/tini_llama_full": [
    "model.safetensors"
  ],
  "maramzarkaoui/openhermes": [
    "adapter_model.safetensors",
    "checkpoint-6/adapter_model.safetensors"
  ],
  "DrishtiSharma/llama-pro-8b-english-to-hinglish-translation-merged": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "santoshtyss/lex-mistral-mc4-2000": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "renyiyu/llama-2-7b-bnb-4bit-dpo-unsloth-v0.1": [
    "model.safetensors"
  ],
  "JaeyeonKang/CCK_Asura_v2.1": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "qwedsacf/btsn6-08-2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "BlackSamorez/Mixtral-8x7b-AQLM-2Bit-1x16-hf": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hingeankit/qlora2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hingeankit/test1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "BlackSamorez/Mixtral-8x7b-AQLM-2Bit-1x16-hf-test-dispatch": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "marianna13/llava-phi-2-3b-siglip": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "pxltd/tikitaka": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "zhongshsh/Mixtral-CLIP-Expert-ft": [
    "model-00001-of-00022.safetensors",
    "model-00002-of-00022.safetensors",
    "model-00003-of-00022.safetensors",
    "model-00004-of-00022.safetensors",
    "model-00005-of-00022.safetensors",
    "model-00006-of-00022.safetensors",
    "model-00007-of-00022.safetensors",
    "model-00008-of-00022.safetensors",
    "model-00009-of-00022.safetensors",
    "model-00010-of-00022.safetensors",
    "model-00011-of-00022.safetensors",
    "model-00012-of-00022.safetensors",
    "model-00013-of-00022.safetensors",
    "model-00014-of-00022.safetensors",
    "model-00015-of-00022.safetensors",
    "model-00016-of-00022.safetensors",
    "model-00017-of-00022.safetensors",
    "model-00018-of-00022.safetensors",
    "model-00019-of-00022.safetensors",
    "model-00020-of-00022.safetensors",
    "model-00021-of-00022.safetensors",
    "model-00022-of-00022.safetensors"
  ],
  "ShengHongHaung/medical-everywhere-v0.1": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "aissatoubalde/lab": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jondurbin/bagel-20b-v04-llama": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "VincentG1234/gpt_test": [
    "model.safetensors"
  ],
  "Drewskidang/Mixtral-hehehe": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "jondurbin/bagel-dpo-20b-v04-llama": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "Americo/phi-2-finetuned-farmatodo3": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "bbunijieun/results": [
    "model.safetensors"
  ],
  "Kooten/MiquMaid-v2-70B-3bpw-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "mzbac/qwen-1_5-7B-2x3-hf": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "petitpatoche/sn6-v9": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Rahulrayudu/llama-2-7b-chat-farm-assit": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "0x0dad0/pretrain_v3": [
    "model.safetensors"
  ],
  "rhplus0831/maid-yuzu-v6": [
    "model-00001-of-00025.safetensors",
    "model-00002-of-00025.safetensors",
    "model-00003-of-00025.safetensors",
    "model-00004-of-00025.safetensors",
    "model-00005-of-00025.safetensors",
    "model-00006-of-00025.safetensors",
    "model-00007-of-00025.safetensors",
    "model-00008-of-00025.safetensors",
    "model-00009-of-00025.safetensors",
    "model-00010-of-00025.safetensors",
    "model-00011-of-00025.safetensors",
    "model-00012-of-00025.safetensors",
    "model-00013-of-00025.safetensors",
    "model-00014-of-00025.safetensors",
    "model-00015-of-00025.safetensors",
    "model-00016-of-00025.safetensors",
    "model-00017-of-00025.safetensors",
    "model-00018-of-00025.safetensors",
    "model-00019-of-00025.safetensors",
    "model-00020-of-00025.safetensors",
    "model-00021-of-00025.safetensors",
    "model-00022-of-00025.safetensors",
    "model-00023-of-00025.safetensors",
    "model-00024-of-00025.safetensors",
    "model-00025-of-00025.safetensors"
  ],
  "0x0dad0/pretrain_v3_1": [
    "model.safetensors"
  ],
  "AngeloMakory/UzimaBot": [
    "model.safetensors"
  ],
  "MasakiK/stack-llama-2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Tonystark1/Ultimus-Zephyr-7B": [
    "adapter_model.safetensors",
    "checkpoint-4/adapter_model.safetensors"
  ],
  "thrunlab/sparse_sparse_80_percent_pretraining_warmup_20K_0_2_steps_5k": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "khanhnto/kyt-dragon-13b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "CultriX/NeuralTrix-7B-v1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "rmihaylov/Inject-7B-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "manu/croissant_mmlu": [
    "checkpoint-275/model.safetensors",
    "checkpoint-497/model.safetensors",
    "checkpoint-533/model.safetensors",
    "checkpoint-550/model.safetensors"
  ],
  "0x0dad0/pretrain_v4_1": [
    "model.safetensors"
  ],
  "mzbac/qwen-1.5-2x3-sft-hf-4bit-mlx": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "superfriends/comic-energy-77-step6700": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jumtul/LDCC-Hyeogi.05": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "0x0dad0/pretrain_v4_2": [
    "model.safetensors"
  ],
  "bitsoko/gumzo-tiny-00": [
    "model.safetensors"
  ],
  "0x0dad0/pretrain_v3_3": [
    "model.safetensors"
  ],
  "Pplus/mistral-health-faq": [
    "adapter_model.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "vedantpalit/tinystarcoder-rlhf-model": [
    "model.safetensors"
  ],
  "tollefj/nordavind-7b-instruct-warm": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Kooten/MiquMaid-v2-70B-3.5bpw-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "mu0gum/AIFT-polyglot-ko-1.3b-ao-instruct-v0.91": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "migtissera/Tess-72B-v1.5b": [
    "model-00001-of-00030.safetensors",
    "model-00002-of-00030.safetensors",
    "model-00003-of-00030.safetensors",
    "model-00004-of-00030.safetensors",
    "model-00005-of-00030.safetensors",
    "model-00006-of-00030.safetensors",
    "model-00007-of-00030.safetensors",
    "model-00008-of-00030.safetensors",
    "model-00009-of-00030.safetensors",
    "model-00010-of-00030.safetensors",
    "model-00011-of-00030.safetensors",
    "model-00012-of-00030.safetensors",
    "model-00013-of-00030.safetensors",
    "model-00014-of-00030.safetensors",
    "model-00015-of-00030.safetensors",
    "model-00016-of-00030.safetensors",
    "model-00017-of-00030.safetensors",
    "model-00018-of-00030.safetensors",
    "model-00019-of-00030.safetensors",
    "model-00020-of-00030.safetensors",
    "model-00021-of-00030.safetensors",
    "model-00022-of-00030.safetensors",
    "model-00023-of-00030.safetensors",
    "model-00024-of-00030.safetensors",
    "model-00025-of-00030.safetensors",
    "model-00026-of-00030.safetensors",
    "model-00027-of-00030.safetensors",
    "model-00028-of-00030.safetensors",
    "model-00029-of-00030.safetensors",
    "model-00030-of-00030.safetensors"
  ],
  "LoneStriker/Wiedervereinigung-7b-dpo-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Wiedervereinigung-7b-dpo-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Wiedervereinigung-7b-dpo-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Wiedervereinigung-7b-dpo-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "user3542384468/thevoid-v0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Wiedervereinigung-7b-dpo-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "ManthanCisco/phi_Text2SQL_v1": [
    "model.safetensors"
  ],
  "sontq/pretraining_hk1": [
    "model.safetensors"
  ],
  "LoneStriker/Wiedervereinigung-7b-dpo-AWQ": [
    "model.safetensors"
  ],
  "BlahBlah314/Seraph-7b-Enh-FT-V15": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mourning-daylight/sn1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Wiedervereinigung-7b-dpo-GPTQ": [
    "gptq_model-4bit-32g.safetensors"
  ],
  "Kukedlc/Llama-7b-spanish": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "levimorin/taonet-vali1": [
    "model.safetensors"
  ],
  "levimorin/taonet-vali2": [
    "model.safetensors"
  ],
  "HeydarS/opt-350m_full_v3": [
    "model.safetensors"
  ],
  "aidonuts/corgy-001": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tomaszki/nous-twenty": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "rhplus0831/maid-yuzu-v6-exl2-6.0bpw-rpcal": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "gotchu/s8-knarf-2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Eric111/Mayoroya": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "PranavInvenics/llama_2_v2": [
    "adapter_model.safetensors",
    "checkpoint-90/adapter_model.safetensors"
  ],
  "ManthanCisco/phi_Text2SQL_v2": [
    "model.safetensors"
  ],
  "HelixAI/codellama-8bit-json-24-02-07-mkt-research-v3_epoch_7": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ThomasGerald/wozhistorychitchat": [
    "model.safetensors"
  ],
  "ThomasGerald/wozchitchat": [
    "model.safetensors"
  ],
  "ylacombe/musicgen-melody-bella-ciao": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "NeuroBridge/Airavata-GGUF": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mlx-community/Magicoder-S-DS-6.7B-MLX": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "PranavInvenics/phi2_v5": [
    "model.safetensors"
  ],
  "LoneStriker/Quyen-Pro-Max-v0.1-AWQ": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "TeeZee/falcon-180B-chat-GPTQ": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "zzz99/output-7b-26k-lora-test-afternoon": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rickprime/primetime-06": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Komala/komala1": [
    "model.safetensors"
  ],
  "tsavage68/450_STEPS_5e7_03beta_DPO_zeroshot": [
    "final_checkpoint/model-00001-of-00003.safetensors",
    "final_checkpoint/model-00002-of-00003.safetensors",
    "final_checkpoint/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ycros/BagelWorldTour-8x7B": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "idrah/btsn6v6": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "idrah/btsn6v7": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "idrah/btsn6v8": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "idrah/btsn6v9": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "idrah/btsn6v10": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mlx-community/mlx-mistral-7B-v0.1": [
    "model.safetensors"
  ],
  "smotoc/foxy_7b_lab": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "aidonuts/slurpee711-001": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "idrah/btsn6v11": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ASDuserASDASD/mistral-7b-finetuned-ultrachat": [
    "adapter_model (copy).safetensors",
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors",
    "tmp-checkpoint-3000/adapter_model.safetensors"
  ],
  "TeeZee/falcon-180B-chat-AWQ": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "hon9kon9ize/CantoneseLLM-6B-preview202402": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "aidonuts/corgy-002": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Ashishkr/Moe-4x7b-mistral-llava-instruct": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Fredh99/finetune_20240207_mistral_7b_v02_175_pos_150_neg_action_input": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tsavage68/400_STEPS_1e7_SFT_zeroshot": [
    "final_checkpoint/model-00001-of-00003.safetensors",
    "final_checkpoint/model-00002-of-00003.safetensors",
    "final_checkpoint/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "aidonuts/slurpee711-002": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hanspeterlyngsoeraaschoujensen/deepseek-math-7b-instruct-awq-Q4": [
    "model.safetensors"
  ],
  "ElderlyDed/Ladno": [
    "adapter_model.safetensors",
    "checkpoint-13/adapter_model.safetensors"
  ],
  "tomaszki/nous-twenty-one": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ManthanCisco/phi_Text2SQL_v3": [
    "model.safetensors"
  ],
  "ParunNg/phi-th-1.5b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "qwedsacf/btsn6-09-3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "aidonuts/frenchie-8900": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ankhamun/xxxI-o_p_I_X_-_X_I_q_o-Ixxx": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rickprime/primetime-007": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lillybak/QA-Physics_QLoRA-mistral-7b-50epochs-v1": [
    "model.safetensors"
  ],
  "NickyNicky/h2o-danube-1.8b-chat-sft-merge_fourier-v1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ayjays132/CustomGPT2Conversational": [
    "model.safetensors"
  ],
  "ankhamun/IIImIIIIoI-IoIIIImIII": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "GaneshD1/gpt2-wikitext2": [
    "model.safetensors"
  ],
  "asadmasad/deepseek-7bn-v1.5-ds-finetuning-26k-high-lr": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Drewskidang/DPO_DANG_AWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Test157t/Pasta-Lake-7b": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "LoneStriker/MiquMaid-v2-70B-2.4bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/MiquMaid-v2-70B-3.5bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "mohan007/moondream1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors",
    "model.safetensors"
  ],
  "LoneStriker/MiquMaid-v2-70B-4.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "CultriX/NeuralTrix-7B-dpo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/MiquMaid-v2-70B-4.65bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "TuringsSolutions/BatMistral": [
    "adapter_model.safetensors",
    "checkpoint-12/adapter_model.safetensors"
  ],
  "LoneStriker/MiquMaid-v2-70B-5.0bpw-h6-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "TuringsSolutions/BatPhi": [
    "adapter_model.safetensors",
    "checkpoint-9/adapter_model.safetensors"
  ],
  "cti-ttp-18/autotrain-fine-tune-llama-7b-v2": [
    "adapter_model.safetensors",
    "checkpoint-3836/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SakuraLLM/Sakura-1B8-Qwen2beta-v0.9": [
    "model.safetensors"
  ],
  "impossibleexchange/pt35": [
    "model.safetensors"
  ],
  "rickprime/primetime-42": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/MiquMaid-v2-70B-6.0bpw-h6-exl2": [
    "output-00001-of-00007.safetensors",
    "output-00002-of-00007.safetensors",
    "output-00003-of-00007.safetensors",
    "output-00004-of-00007.safetensors",
    "output-00005-of-00007.safetensors",
    "output-00006-of-00007.safetensors",
    "output-00007-of-00007.safetensors"
  ],
  "devlocalhost/hi-tinylama-f16-3e": [
    "model.safetensors"
  ],
  "Drewskidang/SFTAWQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "aidonuts/frenchie-10k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "gmonsoon/Qwenchana-0.5B": [
    "model.safetensors"
  ],
  "weijie210/mistral_gsm8k_sft": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sophosympatheia/Wizard-Tulu-Dolphin-70B-v1.0": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "deepestneuron/cell-0-0-6": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tsavage68/800_STEPS_1e7_SFT_zeroshot": [
    "final_checkpoint/model-00001-of-00003.safetensors",
    "final_checkpoint/model-00002-of-00003.safetensors",
    "final_checkpoint/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kennylam/Breeze-7B-Cantonese-v0.1": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "codegood/Mistral_Latest": [
    "adapter_model.safetensors"
  ],
  "sujitvasanth/vikhyatk-moondream1.1old": [
    "model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-random_removal-seed_1024-3e-4": [
    "model.safetensors"
  ],
  "tsavage68/500_STEPS_1e7_SFT_zeroshot": [
    "final_checkpoint/model-00001-of-00003.safetensors",
    "final_checkpoint/model-00002-of-00003.safetensors",
    "final_checkpoint/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hyeogi/SOLAR-10.7B-v1.3": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "nvidia/OpenMath-CodeLlama-7b-Python-hf": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "golemsystems/Llama-2-7b-chat-boost_try2": [
    "model.safetensors"
  ],
  "gmonsoon/Qwenchana-0.5B-uncensored": [
    "model.safetensors"
  ],
  "traversaal-ai/zephyr-7b-beta-5.0bpw-exl2": [
    "cal_data.safetensors",
    "hidden_states.safetensors",
    "output.safetensors"
  ],
  "SteelBear/open-llama-2-finetuing-practice": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Crystalcareai/CrystalMistral-14b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jeevana/G8_mistral7b_qlora_1211_v09feb": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "davzoku/cria-llama2-7b-v1.3-mlx": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "louisbrulenaudet/DevPearl-2x7B": [
    "model-00001-of-00012.safetensors",
    "model-00002-of-00012.safetensors",
    "model-00003-of-00012.safetensors",
    "model-00004-of-00012.safetensors",
    "model-00005-of-00012.safetensors",
    "model-00006-of-00012.safetensors",
    "model-00007-of-00012.safetensors",
    "model-00008-of-00012.safetensors",
    "model-00009-of-00012.safetensors",
    "model-00010-of-00012.safetensors",
    "model-00011-of-00012.safetensors",
    "model-00012-of-00012.safetensors"
  ],
  "davzoku/cria-llama2-7b-v1.3-q4-mlx": [
    "model.safetensors"
  ],
  "NeuroBridge/OpenHathi-7B-Hi-v0.1-GGUF": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rhplus0831/maid-yuzu-v7": [
    "model-00001-of-00048.safetensors",
    "model-00002-of-00048.safetensors",
    "model-00003-of-00048.safetensors",
    "model-00004-of-00048.safetensors",
    "model-00005-of-00048.safetensors",
    "model-00006-of-00048.safetensors",
    "model-00007-of-00048.safetensors",
    "model-00008-of-00048.safetensors",
    "model-00009-of-00048.safetensors",
    "model-00010-of-00048.safetensors",
    "model-00011-of-00048.safetensors",
    "model-00012-of-00048.safetensors",
    "model-00013-of-00048.safetensors",
    "model-00014-of-00048.safetensors",
    "model-00015-of-00048.safetensors",
    "model-00016-of-00048.safetensors",
    "model-00017-of-00048.safetensors",
    "model-00018-of-00048.safetensors",
    "model-00019-of-00048.safetensors",
    "model-00020-of-00048.safetensors",
    "model-00021-of-00048.safetensors",
    "model-00022-of-00048.safetensors",
    "model-00023-of-00048.safetensors",
    "model-00024-of-00048.safetensors",
    "model-00025-of-00048.safetensors",
    "model-00026-of-00048.safetensors",
    "model-00027-of-00048.safetensors",
    "model-00028-of-00048.safetensors",
    "model-00029-of-00048.safetensors",
    "model-00030-of-00048.safetensors",
    "model-00031-of-00048.safetensors",
    "model-00032-of-00048.safetensors",
    "model-00033-of-00048.safetensors",
    "model-00034-of-00048.safetensors",
    "model-00035-of-00048.safetensors",
    "model-00036-of-00048.safetensors",
    "model-00037-of-00048.safetensors",
    "model-00038-of-00048.safetensors",
    "model-00039-of-00048.safetensors",
    "model-00040-of-00048.safetensors",
    "model-00041-of-00048.safetensors",
    "model-00042-of-00048.safetensors",
    "model-00043-of-00048.safetensors",
    "model-00044-of-00048.safetensors",
    "model-00045-of-00048.safetensors",
    "model-00046-of-00048.safetensors",
    "model-00047-of-00048.safetensors",
    "model-00048-of-00048.safetensors"
  ],
  "dmitrybright/Mistral-7B-Instruct-v0.1-8bit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Trinity-33B-v1.0-3.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/Trinity-33B-v1.0-4.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "thomaslwang/phi-2-zwjcylk-1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Trinity-33B-v1.0-4.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Trinity-33B-v1.0-5.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "Kooten/Pasta-Lake-7b-8bpw-exl2": [
    "output.safetensors"
  ],
  "dmitrybright/Mistral-7B-Instruct-v0.1-4bit": [
    "model.safetensors"
  ],
  "LoneStriker/Trinity-33B-v1.0-6.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Trinity-33B-v1.0-8.0bpw-h8-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "Kooten/Pasta-Lake-7b-6bpw-exl2": [
    "output.safetensors"
  ],
  "crumb/GLORT2": [
    "model.safetensors"
  ],
  "renyiyu/mistral-7b-instruct-v0.2-bnb-4bit-reward-model": [
    "model.safetensors"
  ],
  "regisss/test_model_2": [
    "adapter_model.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Basha738/llama2-supervised-ft-5epochs-411": [
    "model.safetensors"
  ],
  "sanmaro6803/llama2-ko-7b-ds-qlora-sft-constlr1e-4-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "weijie210/mistral_gsm8k_sft_0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Kooten/Pasta-Lake-7b-5bpw-exl2": [
    "output.safetensors"
  ],
  "Kooten/Pasta-Lake-7b-4bpw-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Trinity-33B-v1.0-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "eswardivi/llama2_telugu": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mii-llm/maestrale-chat-v0.3-beta": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SonaliSN/MergedModelTest": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "SuYee189/my_awesome_gpt2_qa-model": [
    "model.safetensors"
  ],
  "axra/phi-2-x-0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "apailang/llama2_7b_chat_sum_mcq": [
    "adapter_model.safetensors",
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "DrishtiSharma/llama-2-13b-fp16-english-to-hinglish-translation-merged": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "rmihaylov/Inject-7B-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "perceptron-743/shakespearean-lm": [
    "model.safetensors"
  ],
  "tsavage68/1200_STEPS_1e7_03beta_DPO_zeroshot": [
    "final_checkpoint/model-00001-of-00003.safetensors",
    "final_checkpoint/model-00002-of-00003.safetensors",
    "final_checkpoint/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "marcu5fen1x/llama_2_gptembed_commaVQ": [
    "model.safetensors"
  ],
  "OpenBuddy/openbuddy-codellama-70b-v17.1-4k": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "jtatman/SciPhi-Mistral-7B-32k-sliced": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "kouki13/newopenhermes2": [
    "adapter_model.safetensors",
    "checkpoint-6/adapter_model.safetensors"
  ],
  "aiplanet/effi-13B-AWQ": [
    "model.safetensors"
  ],
  "jtatman/SciPhi-Mistral-7B-32k-sliced-smol": [
    "model-00001-of-00002.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00001-of-00004.safetensors",
    "model-00002-of-00002.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00003.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "jvdgoltz/Mistral-7B-dbnl-v0.1": [
    "adapter_model.safetensors"
  ],
  "ngxson/Vistral-7B-ChatML": [
    "checkpoint-300/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rrw-x2/KoSOLAR-10.9B-v0.5": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "rmihaylov/Inject-7B-v3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Senku-70B-Full-2.4bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "0x0dad0/pretrain_v6_1": [
    "model.safetensors"
  ],
  "0x0dad0/pretrain_v6_2": [
    "model.safetensors"
  ],
  "ZainAli60/llama_tune_2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rrw-x2/KoSOLAR-10.9B-v0.3": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "msy127/ft-240209-sft": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "amu/dpo-phi2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Radu1999/Mistral-Instruct-Ukrainian-SFT": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Isotonic/smol_llama_DialogSumm": [
    "model.safetensors"
  ],
  "RandyPulse/gpt-lex-machina-21k": [
    "model.safetensors"
  ],
  "Kooten/BagelMIsteryTour-v2-8x7B-4bpw-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "DreadPoor/BagelLake-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "rhplus0831/maid-yuzu-v7-exl2-6.0bpw-rpcal": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "Unbabel/TowerInstruct-7B-v0.2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Kooten/BagelMIsteryTour-v2-8x7B-6bpw-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "paulml/OmniBeagleSquaredMBX-v3-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Lvxy1117/amber_fine_tune_sg_part1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Novin-AI/MeduWen-Q4-PA": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Inv/Konstanta-Alpha-V2-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Rocketknight1/tiny-gpt2-with-chatml-template": [
    "model.safetensors"
  ],
  "lenbrocki/SerenaDPO_Solar_AWQ": [
    "model.safetensors"
  ],
  "TeamUNIVA/Komodo_6B_v2.0.0": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "iGenius-AI-Team/Italia-2B-ckpt-17B-wikionly": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mtc/meta-llama-Llama-2-7b-hf-arxiv-summarization-5000-last_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mtc/meta-llama-Llama-2-7b-hf-pubmed-summarization-5000-last_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "iGenius-AI-Team/Italia-2B-ckpt-34B-wikionly": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ssaryssane/ssary-only-solar-10.7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Kooten/BagelMIsteryTour-v2-8x7B-8bpw-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "PAug/llemma-7b-synthetic-lisa": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "jeevana/GenAI_QnA_Mistral7b_QLoRA_G8_FV01": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "saransh03sharma/cmumosei": [
    "model.safetensors"
  ],
  "mtc/mistralai-Mistral-7B-v0.1-arxiv-summarization-5000-last_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "uukuguy/speechless-sparsetral-mistral-16x7b-MoE": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "ThatsGroes/munin-SkoleGPTOpenOrca-7b-16bit": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Weni/Zeroshot-3.2.3-Mistral-7B-pipeline-config-AWQ": [
    "model.safetensors"
  ],
  "Weni/Zeroshot-3.2.3-Mistral-7B-pipeline-config-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-only_measure_nps_as_singular_removal-seed_211-1e-3": [
    "model.safetensors"
  ],
  "kakojuvenkat/autotrain-sryde-ssafa": [
    "adapter_model.safetensors",
    "checkpoint-13917/adapter_model.safetensors"
  ],
  "mkay8/llama2_test_2": [
    "model.safetensors"
  ],
  "jeevana/GenAI_QnA_Mistral7b_QLoRA_G8_FV02": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "vedantpalit/gpt2-rlhf-model": [
    "model.safetensors"
  ],
  "mtc/mistralai-Mistral-7B-v0.1-pubmed-summarization-5000-last_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rmihaylov/Inject-7B-v4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Eric111/caTUNABeagle": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "echoctx/nous-subnet1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Eric111/MarcoHermes": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "qwedsacf/btsn6-09-7": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/Mistral-7B-Instruct-v0.2-AWQ": [
    "model.safetensors"
  ],
  "lgodwangl/test1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tsavage68/600_STEPS_1e7_03beta_DPO_zeroshot": [
    "final_checkpoint/model-00001-of-00003.safetensors",
    "final_checkpoint/model-00002-of-00003.safetensors",
    "final_checkpoint/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lgodwangl/test2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "paulml/OmniBeagleSquaredMBX-v3-7B-v2": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "TeeZee/BigMaid-20B-v1.0-bpw8-h8-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "nm-testing/zephyr-beta-7b-gptq-g128": [
    "model.safetensors"
  ],
  "eediker/Llama-2-7b-chat-therapist": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "mjschock/mamba-370m": [
    "model.safetensors"
  ],
  "MaziyarPanahi/Mistral-7B-Instruct-v0.1-AWQ": [
    "model.safetensors"
  ],
  "RandyPulse/gpt-lex-machina-xl": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Kquant03/Samlagast-7B-bf16": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "sokpearoun/mistralai-Code-Instruct-Finetune-test": [
    "model.safetensors"
  ],
  "CultriX/NeuralTrix-V2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "twhoool02/llama-2-7b-chat-finetuned-guanaco": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mlx-community/mistral-7b-instruct-v0.1-4bit-ngs": [
    "model.safetensors"
  ],
  "mtc/meta-llama-Llama-2-13b-hf-pubmed-summarization-5000-last_merged": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Americo/phi2-finetued-farma-2epochs": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "tomaszki/nous-twenty-two": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "soij/Llama-2-7b-chat-hf-AWK-Q128_B4": [
    "model.safetensors"
  ],
  "robinsmits/Mistral-Instruct-7B-v0.2-ChatAlpacaV2": [
    "adapter_model.safetensors"
  ],
  "mjschock/mamba-790m": [
    "model.safetensors"
  ],
  "scheshmi/fine-tuned_codellama": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tolgadev/llama-2-7b-tk-mini": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "ankhamun/xxxI-o_p_I_XO_-_OX_I_q_o-Ixxx": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "deepestneuron/cell-0-0-9": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Aspik101/nous_3c": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "louisbrulenaudet/DevPearl-7B-dare-ties": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "mjschock/mamba-1.4b": [
    "model.safetensors"
  ],
  "MaziyarPanahi/Smaug-72B-v0.1-AWQ": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "tomaszki/nous-twenty-three": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "hooking-dev/hooking-126M-v1.0": [
    "model.safetensors"
  ],
  "nirmalroy/self-multi-rag": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "deepestneuron/cell-0-1-0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "pavelmarcolian/llama2-13b-echelon-support-bot-faq": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "afterpartyjohn/test1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "nvidia/OpenMath-CodeLlama-13b-Python-hf": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "nextai-team/apollo-v1-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "rinabuoy/SeaLLM-7B-Chat-Eng-Khmer-R128-E3-AGG-V3-M": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "limitium/ruGPT-3.5-13B-gptq-4bits-Kilusha": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "0x0dad0/pretrain_v8_0": [
    "model.safetensors"
  ],
  "0x0dad0/pretrain_v8_1": [
    "model.safetensors"
  ],
  "laurencer/VimGPT-CodeLlama-PythonCode-1.7m-Unsloth-1epoch-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors",
    "model.safetensors"
  ],
  "0x0dad0/pretrain_v8_2": [
    "model.safetensors"
  ],
  "seyf1elislam/WestKunai-Hermes-7b": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "dillonlaird/hf-llava-v1.6-34b": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "Crystalcareai/CrystalMistral-2x7B-Lora": [
    "checkpoint-216/adapter_model.safetensors",
    "checkpoint-217/adapter_model.safetensors"
  ],
  "Drewskidang/SFT_MISTRAL": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ChuckMcSneed/Gembo-v1.1-70b": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "karawalla/aq-ai-02092024001_release": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "nvidia/OpenMath-CodeLlama-34b-Python-hf": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "elliotthwang/KimLantext-phi-2-zh": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LHC88/LaseredHermes-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "cognitivecomputations/Samantha-120b": [
    "model-00001-of-00025.safetensors",
    "model-00002-of-00025.safetensors",
    "model-00003-of-00025.safetensors",
    "model-00004-of-00025.safetensors",
    "model-00005-of-00025.safetensors",
    "model-00006-of-00025.safetensors",
    "model-00007-of-00025.safetensors",
    "model-00008-of-00025.safetensors",
    "model-00009-of-00025.safetensors",
    "model-00010-of-00025.safetensors",
    "model-00011-of-00025.safetensors",
    "model-00012-of-00025.safetensors",
    "model-00013-of-00025.safetensors",
    "model-00014-of-00025.safetensors",
    "model-00015-of-00025.safetensors",
    "model-00016-of-00025.safetensors",
    "model-00017-of-00025.safetensors",
    "model-00018-of-00025.safetensors",
    "model-00019-of-00025.safetensors",
    "model-00020-of-00025.safetensors",
    "model-00021-of-00025.safetensors",
    "model-00022-of-00025.safetensors",
    "model-00023-of-00025.safetensors",
    "model-00024-of-00025.safetensors",
    "model-00025-of-00025.safetensors"
  ],
  "renyiyu/mistral-7b-instruct-v0.2-bnb-4bit-512-dpo": [
    "model.safetensors"
  ],
  "ankhamun/x_x": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "renyiyu/mistral-7b-instruct-v0.2-bnb-4bit-ppo-v0": [
    "model.safetensors"
  ],
  "aidonuts/marigold-001": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "aidonuts/marigold-002": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mcadoo22/MistralWoolf-7B-Instruct-v0.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "aidonuts/marigold-003": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-only_indef_articles_with_pl_nouns_removal-3e-4": [
    "model.safetensors"
  ],
  "macadeliccc/SOLAR-10.7b-Instruct-truthy-dpo-exlv2": [
    "output.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-only_indef_articles_with_pl_nouns_removal-1e-3": [
    "model.safetensors"
  ],
  "McGill-NLP/MindAct-base-weblinx": [
    "model.safetensors"
  ],
  "McGill-NLP/MindAct-large-weblinx": [
    "model.safetensors"
  ],
  "McGill-NLP/MindAct-xl-weblinx": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "aidonuts/marigold-004": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Crystalcareai/CrystalMistral-26b": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "aidonuts/fascimile-001": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ericpolewski/ASTS-PFAF": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "tt1314/llama2_7b_math-full-completion_only": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sarak7/H4_210_v1": [
    "model.safetensors"
  ],
  "tdh87/StoryTeller7b": [
    "model.safetensors"
  ],
  "Eric111/NeuTriMBX": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Locutusque/Hercules-2.5-Mistral-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "sarak7/H10_210_v1": [
    "model.safetensors"
  ],
  "a-gambhire/llama-2-7b-query-generator": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "yam-peleg/Experiment1-7B": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "Anawil/dnd-falcon-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Drewskidang/DPO4bitmerge": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Turtle344/GPT2_health_qa_myanmar": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "jeevana/GenAI_QnA_Mistral7b_QLoRA_G8_FV03": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mtc/meta-llama-Llama-2-13b-hf-arxiv-summarization-5000-last_merged": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "42blue/crawl": [
    "adapter_model.safetensors",
    "checkpoint-2/adapter_model.safetensors"
  ],
  "varundubey/firstmod": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Drewskidang/dpo_awq_mistral": [
    "model.safetensors"
  ],
  "kidyu/Moza-7B-v1.0": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "SuYee189/results": [
    "model.safetensors"
  ],
  "Test157t/Pasta-Sea-7b-128k": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "MaziyarPanahi/WizardLM-70B-V1.0-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "robinsmits/Mistral-Instruct-7B-v0.2-ChatAlpacaV2-4bit": [
    "model.safetensors"
  ],
  "aidonuts/marigold-005-ep1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rinabuoy/eng_khm_mt": [
    "model.safetensors"
  ],
  "wolfram/miquliz-120b-v2.0": [
    "model-00001-of-00025.safetensors",
    "model-00002-of-00025.safetensors",
    "model-00003-of-00025.safetensors",
    "model-00004-of-00025.safetensors",
    "model-00005-of-00025.safetensors",
    "model-00006-of-00025.safetensors",
    "model-00007-of-00025.safetensors",
    "model-00008-of-00025.safetensors",
    "model-00009-of-00025.safetensors",
    "model-00010-of-00025.safetensors",
    "model-00011-of-00025.safetensors",
    "model-00012-of-00025.safetensors",
    "model-00013-of-00025.safetensors",
    "model-00014-of-00025.safetensors",
    "model-00015-of-00025.safetensors",
    "model-00016-of-00025.safetensors",
    "model-00017-of-00025.safetensors",
    "model-00018-of-00025.safetensors",
    "model-00019-of-00025.safetensors",
    "model-00020-of-00025.safetensors",
    "model-00021-of-00025.safetensors",
    "model-00022-of-00025.safetensors",
    "model-00023-of-00025.safetensors",
    "model-00024-of-00025.safetensors",
    "model-00025-of-00025.safetensors"
  ],
  "LoneStriker/miqu-1-70b-sf-GPTQ": [
    "gptq_model-4bit-32g.safetensors"
  ],
  "khanhnto/kyt-tietest-13b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Nondzu/openchat-3.5-0106-speakleash-007-pl-8192-32-16-0.01": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "iGenius-AI-Team/Italia-2B-ckpt-61B-wikiEditorial": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "aidonuts/marigold-005-ep3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Inv/MoECPM-Untrained-4x2b": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "aidonuts/marigold-005-ep4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "iGenius-AI-Team/Italia-2B-ckpt-30B-wikiEditorial": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "tinkerface/MinerBot-small": [
    "model.safetensors"
  ],
  "qwedsacf/btsn6-10-1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "BlackSamorez/Llama-2-70b-AQLM-4Bit-2x16-hf": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Kooten/Pasta-Sea-7b-128k-8bpw-exl2": [
    "output.safetensors"
  ],
  "vicgalle/CarbonBeagle-11B-truthy": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "TeeZee/BigMaid_20B_v1.0-bpw4-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "minghaowu/Qwen1.5-1.8B-OpenHermes-2.5": [
    "model.safetensors"
  ],
  "aidonuts/marigold-006-ep4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "0x0dad0/pretrain_vv00": [
    "model.safetensors"
  ],
  "vicgalle/zephyr-7b-truthy": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "0x0dad0/pretrain_vv01": [
    "model.safetensors"
  ],
  "0x0dad0/pretrain_vv02": [
    "model.safetensors"
  ],
  "mwalol/json-deepseek-v2-1-1": [
    "model.safetensors"
  ],
  "MagdyNasr/distilgpt2-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "Drewskidang/GGUFF_AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "yam-peleg/Experiment2-7B": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "ChuGyouk/Mistral-7B-v0.1-4bit-64rank": [
    "gsm8k/adapter_model.safetensors",
    "loftq_init/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ChuGyouk/Llama-2-7b-hf-4bit-64rank": [
    "gsm8k/adapter_model.safetensors",
    "loftq_init/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "aidonuts/marigold-007-ep2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Novin-AI/MeduWen-S": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ChuGyouk/Llama-2-13b-hf-4bit-64rank": [
    "gsm8k/adapter_model.safetensors",
    "loftq_init/adapter_model.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "jacobi/capybagel-7B-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Drewskidang/Marlin-AWQ": [
    "model.safetensors"
  ],
  "aidonuts/marigold-007-ep3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "unalignment/weeeeee.0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "unalignment/weeeeee.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "aloobun/Reyna-RP-Qwen1.5-0.5B-Chat-v0.1": [
    "model.safetensors"
  ],
  "llmixer/QuartetAnemoi-70B-t0.0001-6.0bpw-h6-exl2": [
    "output-00001-of-00007.safetensors",
    "output-00002-of-00007.safetensors",
    "output-00003-of-00007.safetensors",
    "output-00004-of-00007.safetensors",
    "output-00005-of-00007.safetensors",
    "output-00006-of-00007.safetensors",
    "output-00007-of-00007.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-only_measure_nps_as_singular_removal-seed_1024-1e-3": [
    "model.safetensors"
  ],
  "datalama/gpt2-imdb-pos-v2": [
    "model.safetensors"
  ],
  "indischepartij/MiniCPM-3B-Hercules-v2.0": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "nchen909/mistral_7b_sft_15710": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "twhoool02/llama-2-7b-finetuned-guanaco-NF4-QLORA": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "aidonuts/marigold-005-dpo-ep3-ep1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "vicgalle/Mixtral-7Bx2-truthy": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "tyson0420/stack_llama_full": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Gustav0-Freind/my2x13b": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "llmixer/QuartetAnemoi-70B-t0.0001-2.5bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "JinuAugustine/phi2-gdpr": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "tomaszki/nous-twenty-four": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "aidonuts/marigold-005-dpo-ep3-ep2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Kukedlc/NeuralKukedlc-7B-Labonned": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "onur-softtech/finetune_deepspeed_deepseek_33b_exp_1_0_yaml": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors",
    "save_pretrained/model.safetensors",
    "trainer_save_model/model-00001-of-00014.safetensors",
    "trainer_save_model/model-00002-of-00014.safetensors",
    "trainer_save_model/model-00003-of-00014.safetensors",
    "trainer_save_model/model-00004-of-00014.safetensors",
    "trainer_save_model/model-00005-of-00014.safetensors",
    "trainer_save_model/model-00006-of-00014.safetensors",
    "trainer_save_model/model-00007-of-00014.safetensors",
    "trainer_save_model/model-00008-of-00014.safetensors",
    "trainer_save_model/model-00009-of-00014.safetensors",
    "trainer_save_model/model-00010-of-00014.safetensors",
    "trainer_save_model/model-00011-of-00014.safetensors",
    "trainer_save_model/model-00012-of-00014.safetensors",
    "trainer_save_model/model-00013-of-00014.safetensors",
    "trainer_save_model/model-00014-of-00014.safetensors"
  ],
  "qhar0h/mistral_test": [
    "model.safetensors"
  ],
  "tyson0420/stack_llama_fil_ai": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "llmixer/QuartetAnemoi-70B-t0.0001-4bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "LunaticPython161/CyberWitch-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "nvidia/OpenMath-Llama-2-70b-hf": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "nvidia/OpenMath-CodeLlama-70b-Python-hf": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "Kukedlc/NeuTrixOmniBe-7B-model-remix": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "PunyaModi/mistral-7b-finetuned-Midjourney-prompt-v2": [
    "adapter_model.safetensors",
    "checkpoint-5/adapter_model.safetensors"
  ],
  "fhai50032/SamChat": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "qwedsacf/btsn6-11-2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tsavage68/400STEPS_01beta_1e7_DPO_Meditron7B_zeroshot": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LunaticPython161/Lily-MoE-2x7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ankhamun/x_x-v0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "swj0419/7b_finetuned_llama2_3epoch": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Americo/phi2-finetued-farma-last": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "hbin0701/llemma_brft": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "fhai50032/xLakeChat": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "InnerI/NousResearch-Llama2-chat": [
    "adapter_model.safetensors",
    "checkpoint-18/adapter_model.safetensors"
  ],
  "caug37/TinyTim": [
    "model.safetensors"
  ],
  "luaqi/sn9_v00": [
    "model.safetensors"
  ],
  "luaqi/sn9_v01": [
    "model.safetensors"
  ],
  "InnerI/NousResearch-Llama2-7bhf": [
    "adapter_model.safetensors",
    "checkpoint-18/adapter_model.safetensors"
  ],
  "InnerI/I-NousResearch-Yarn-Mistral-7b-128k": [
    "adapter_model.safetensors",
    "checkpoint-18/adapter_model.safetensors"
  ],
  "sanjay920/cortex-small-16bit": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sudipto-ducs/llama-2-7b-miniplatypus": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rubra-ai/cortex-small-v0.1-lora": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "modelwizard/grasshopper": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "macadeliccc/OmniCorso-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "davidkim205/komt-solar-10.7b-v1": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "ankhamun/x_x-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-only_indef_articles_with_pl_nouns_removal-1e-4": [
    "model.safetensors"
  ],
  "giraffe176/Open_Hermes_Orca_Mistral-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "indischepartij/MiniCPM-3B-OpenHermes-2.5-v2": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "brucethemoose/Yi-34B-200K-RPMerge-exl2-267bpw": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "nchen909/llama1_13b_sft_20710": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "ankhamun/xo_xo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "indischepartij/MiniCPM-3B-Hephaestus": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "ArianAskari/SOLID-SFT-WoDPO-MixQV2-Zephyr-7b-beta": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "zjunlp/chatcell-base": [
    "model.safetensors"
  ],
  "modelwizard/bluejay": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tsavage68/500STEPS_1e6rate_01beta_DPO_Meditron7B_zeroshot": [
    "final_checkpoint/model-00001-of-00003.safetensors",
    "final_checkpoint/model-00002-of-00003.safetensors",
    "final_checkpoint/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Kukedlc/NeuTrixOmniBe-DPO": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ArianAskari/SOLID_SFT-WoDPO-WoMixQ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jsfs11/MixtureofMerges-MoE-4x7b-v4": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "if001/tiny_mixtral_ja_llm_jp_tk": [
    "model.safetensors"
  ],
  "tsavage68/300STEPS_5e7rate_Meditron_7B_SFT_zeroshot": [
    "final_checkpoint/model-00001-of-00003.safetensors",
    "final_checkpoint/model-00002-of-00003.safetensors",
    "final_checkpoint/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jsavva/merged_constitution": [
    "model.safetensors"
  ],
  "onur-softtech/finetune_deepspeed_deepseek_33b_exp_1_1_yaml": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors",
    "save_pretrained/model.safetensors",
    "trainer_save_model/model-00001-of-00014.safetensors",
    "trainer_save_model/model-00002-of-00014.safetensors",
    "trainer_save_model/model-00003-of-00014.safetensors",
    "trainer_save_model/model-00004-of-00014.safetensors",
    "trainer_save_model/model-00005-of-00014.safetensors",
    "trainer_save_model/model-00006-of-00014.safetensors",
    "trainer_save_model/model-00007-of-00014.safetensors",
    "trainer_save_model/model-00008-of-00014.safetensors",
    "trainer_save_model/model-00009-of-00014.safetensors",
    "trainer_save_model/model-00010-of-00014.safetensors",
    "trainer_save_model/model-00011-of-00014.safetensors",
    "trainer_save_model/model-00012-of-00014.safetensors",
    "trainer_save_model/model-00013-of-00014.safetensors",
    "trainer_save_model/model-00014-of-00014.safetensors"
  ],
  "MarkrAI/RAG-KO-Mixtral-7Bx2-v2.1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "0x0dad0/nous_nous_v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mcadoo22/MistralWoolfv02-7B-Instruct-v0.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "chenhugging/solar-sakura-carbonvillain-19b-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tsavage68/500STEPS_5e7rate_Meditron_7B_SFT_zeroshot": [
    "final_checkpoint/model-00001-of-00003.safetensors",
    "final_checkpoint/model-00002-of-00003.safetensors",
    "final_checkpoint/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "iadithyan/splitter_70b": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "jsfs11/MixtureofMerges-MoE-4x7b-v4-5.5bpw-exl2": [
    "cal_data.safetensors",
    "hidden_states.safetensors",
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "iGenius-AI-Team/Italia-2B-ckpt-95B-wikiEditorial": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "onur-softtech/finetune_deepspeed_deepseek_33b_exp_1_2_yaml": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors",
    "save_pretrained/model.safetensors",
    "trainer_save_model/model-00001-of-00014.safetensors",
    "trainer_save_model/model-00002-of-00014.safetensors",
    "trainer_save_model/model-00003-of-00014.safetensors",
    "trainer_save_model/model-00004-of-00014.safetensors",
    "trainer_save_model/model-00005-of-00014.safetensors",
    "trainer_save_model/model-00006-of-00014.safetensors",
    "trainer_save_model/model-00007-of-00014.safetensors",
    "trainer_save_model/model-00008-of-00014.safetensors",
    "trainer_save_model/model-00009-of-00014.safetensors",
    "trainer_save_model/model-00010-of-00014.safetensors",
    "trainer_save_model/model-00011-of-00014.safetensors",
    "trainer_save_model/model-00012-of-00014.safetensors",
    "trainer_save_model/model-00013-of-00014.safetensors",
    "trainer_save_model/model-00014-of-00014.safetensors"
  ],
  "yam-peleg/Experiment4-7B": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "curiousily/tiny-crypto-sentiment-analysis": [
    "model.safetensors"
  ],
  "LoneStriker/TowerInstruct-13B-v0.1-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/TowerInstruct-13B-v0.1-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/TowerInstruct-13B-v0.1-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "heldJan/llama-2-7b-froozen_mvit_test": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kevin009/babyllama": [
    "model.safetensors"
  ],
  "LoneStriker/TowerInstruct-13B-v0.1-6.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "obaidtambo/urdu_ghazals_gpt2_v2": [
    "model.safetensors"
  ],
  "LoneStriker/TowerInstruct-13B-v0.1-8.0bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "kevin009/babyllama-v0.0": [
    "model.safetensors"
  ],
  "freeCS-dot-org/OpenAGI-testing-truthyDPO-1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mikeee/openbuddy-zephyr-7b-v14.1-sharded": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "saracandu/mistral-7b-harrypotter": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sosoai/phi-2-ko-mlx": [
    "model.safetensors"
  ],
  "tyson0420/stack_llama2_1_9_ai_full": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "kevin009/babyllama-v0.1": [
    "model.safetensors"
  ],
  "louisbrulenaudet/Pearl-7B-0210-ties": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "sartmis1/Mistral-7B-Instruct-v0.2_sap_codegen_10k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "wolfram/miquliz-120b-v2.0-2.4bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "IBM-DTT/Mistral-7B-Instruct-v0.3_sap_codegen_10k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "onur-softtech/finetune_deepspeed_deepseek_33b_exp_1_3_yaml": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors",
    "save_pretrained/model.safetensors",
    "trainer_save_model/model-00001-of-00014.safetensors",
    "trainer_save_model/model-00002-of-00014.safetensors",
    "trainer_save_model/model-00003-of-00014.safetensors",
    "trainer_save_model/model-00004-of-00014.safetensors",
    "trainer_save_model/model-00005-of-00014.safetensors",
    "trainer_save_model/model-00006-of-00014.safetensors",
    "trainer_save_model/model-00007-of-00014.safetensors",
    "trainer_save_model/model-00008-of-00014.safetensors",
    "trainer_save_model/model-00009-of-00014.safetensors",
    "trainer_save_model/model-00010-of-00014.safetensors",
    "trainer_save_model/model-00011-of-00014.safetensors",
    "trainer_save_model/model-00012-of-00014.safetensors",
    "trainer_save_model/model-00013-of-00014.safetensors",
    "trainer_save_model/model-00014-of-00014.safetensors"
  ],
  "kevin009/babyllama-v0.2": [
    "model.safetensors"
  ],
  "wolfram/miquliz-120b-v2.0-2.65bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "Ash-Hun/WelSSiSKo_v3_llama-2-ko-base_text-generation": [
    "adapter_model.safetensors"
  ],
  "Aspik101/nous_m5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tyson0420/stack_llama2_5_5_ai_full": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "tomaszki/nous-twenty-five": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sonu2023/Vatax-NeuralHermes-2.5-Mistral-7B-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "vicgalle/Miqu-6B-truthy": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "nitky/Superswallow-7b-v0.3": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "nitky/Superswallow-70b-v0.3": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "skhatri/distilgpt2med": [
    "model.safetensors"
  ],
  "nitky/Superswallow-70b-RP-v0.3": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "fhai50032/TPU-XLake": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "RA457/mistral_7b_guanaco": [
    "adapter_model.safetensors"
  ],
  "Jonathan18/key1": [
    "model.safetensors"
  ],
  "TdL/test": [
    "model.safetensors"
  ],
  "xy21593/NeuralHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "wolfram/miquliz-120b-v2.0-3.0bpw-h6-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "ambet/mistral_robot_lora": [
    "adapter_model.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Za-Ra/llama-2-7b-chat-hf-4b": [
    "model.safetensors"
  ],
  "AbdulHannanMujawar/trainings": [
    "adapter_model.safetensors"
  ],
  "wolfram/miquliz-120b-v2.0-3.5bpw-h6-exl2": [
    "output-00001-of-00007.safetensors",
    "output-00002-of-00007.safetensors",
    "output-00003-of-00007.safetensors",
    "output-00004-of-00007.safetensors",
    "output-00005-of-00007.safetensors",
    "output-00006-of-00007.safetensors",
    "output-00007-of-00007.safetensors"
  ],
  "davidkim205/komt-solar-10.7b-v2": [
    "adapter_model.safetensors",
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "MaziyarPanahi/LongAlign-13B-64k-AWQ": [
    "model.safetensors"
  ],
  "veronoicc/VeroGPT-small-ServerSeeker": [
    "model.safetensors"
  ],
  "tsavage68/400STEPS_5e7rate_03beta_DPO_Meditron7B_zeroshot": [
    "final_checkpoint/model-00001-of-00003.safetensors",
    "final_checkpoint/model-00002-of-00003.safetensors",
    "final_checkpoint/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "prince-canuma/Damysus-2.7B-Chat": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "godfreykaris/mistral_7b_summarization": [
    "model.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-Full": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-Full-16": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "wolfram/miquliz-120b-v2.0-4.0bpw-h6-exl2": [
    "output-00001-of-00008.safetensors",
    "output-00002-of-00008.safetensors",
    "output-00003-of-00008.safetensors",
    "output-00004-of-00008.safetensors",
    "output-00005-of-00008.safetensors",
    "output-00006-of-00008.safetensors",
    "output-00007-of-00008.safetensors",
    "output-00008-of-00008.safetensors"
  ],
  "kapi1a/distilgpt2-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "kiranvutukuri/gpt_updated": [
    "model.safetensors"
  ],
  "onur-softtech/finetune_deepspeed_deepseek_33b_exp_1_4_yaml": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors",
    "save_pretrained/model.safetensors",
    "trainer_save_model/model-00001-of-00014.safetensors",
    "trainer_save_model/model-00002-of-00014.safetensors",
    "trainer_save_model/model-00003-of-00014.safetensors",
    "trainer_save_model/model-00004-of-00014.safetensors",
    "trainer_save_model/model-00005-of-00014.safetensors",
    "trainer_save_model/model-00006-of-00014.safetensors",
    "trainer_save_model/model-00007-of-00014.safetensors",
    "trainer_save_model/model-00008-of-00014.safetensors",
    "trainer_save_model/model-00009-of-00014.safetensors",
    "trainer_save_model/model-00010-of-00014.safetensors",
    "trainer_save_model/model-00011-of-00014.safetensors",
    "trainer_save_model/model-00012-of-00014.safetensors",
    "trainer_save_model/model-00013-of-00014.safetensors",
    "trainer_save_model/model-00014-of-00014.safetensors"
  ],
  "MaziyarPanahi/LongAlign-13B-64k-GPTQ": [
    "model.safetensors"
  ],
  "Za-Ra/llama-2-7b-chat-hf-4q": [
    "model.safetensors"
  ],
  "Test157t/HerculeanSea-7b-128k": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "LoneStriker/Tess-72B-v1.5b-AWQ": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "wolfram/miquliz-120b-v2.0-5.0bpw-h6-exl2": [
    "output-00001-of-00009.safetensors",
    "output-00002-of-00009.safetensors",
    "output-00003-of-00009.safetensors",
    "output-00004-of-00009.safetensors",
    "output-00005-of-00009.safetensors",
    "output-00006-of-00009.safetensors",
    "output-00007-of-00009.safetensors",
    "output-00008-of-00009.safetensors",
    "output-00009-of-00009.safetensors"
  ],
  "pahautelman/phi2-ner-dpo-v1": [
    "model.safetensors"
  ],
  "kevin009/babyllama-v0.4": [
    "model.safetensors"
  ],
  "EdBerg/Qwen1.5-1.8B-Chat": [
    "model.safetensors"
  ],
  "GritLM/GritLM-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SateeshAmbesange/tinystarcoder-rlhf-model": [
    "model.safetensors"
  ],
  "vicgalle/solarized-18B-truthy": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "longcule123/adapter_vistral_book_merge": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "GritLM/GritLM-8x7B": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "pahautelman/phi2-ner-sft-v1": [
    "model.safetensors"
  ],
  "Inv/Konstanta-Gamma-10.9B": [
    "model-00001-of-00012.safetensors",
    "model-00002-of-00012.safetensors",
    "model-00003-of-00012.safetensors",
    "model-00004-of-00012.safetensors",
    "model-00005-of-00012.safetensors",
    "model-00006-of-00012.safetensors",
    "model-00007-of-00012.safetensors",
    "model-00008-of-00012.safetensors",
    "model-00009-of-00012.safetensors",
    "model-00010-of-00012.safetensors",
    "model-00011-of-00012.safetensors",
    "model-00012-of-00012.safetensors"
  ],
  "louisbrulenaudet/Pearl-7B-0211-ties": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "yam-peleg/Experiment7-7B": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "tenshugai/nous0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Basha738/llama2-13B-supervised-ft-5epochs-411": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "twhoool02/Mistral-7B-v0.1-finetuned-guanaco-NF4-QLORA": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "saracandu/wizardLM-7b-harrypotter": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Arconte/Mother-V06-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Lucia-no/key_15_11": [
    "model.safetensors"
  ],
  "arlineka/manbasya_2x7b_MOE": [
    "model.safetensors"
  ],
  "Lucia-no/key_10_11": [
    "model.safetensors"
  ],
  "Lucia-no/key_11_11": [
    "model.safetensors"
  ],
  "Lucia-no/key_13_11": [
    "model.safetensors"
  ],
  "Karko/test-toasted-bunny-twins": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mcarthuradal/Malawi-Public-Health-Systems": [
    "model.safetensors"
  ],
  "vicgalle/NeuralBeagle-11B-truthy": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "LoneStriker/Tess-72B-v1.5b-GPTQ": [
    "gptq_model-4bit-32g.safetensors"
  ],
  "ToastyPigeon/Mistral-7B-v0.1-ROPE-Fix": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "codegood/Mistral_Latest_new": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "acoinster/llama-2-7b-chat-acoinster": [
    "model.safetensors"
  ],
  "saracandu/mistral-7b-harrypotter-BRIEF": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "0x0dad0/nous_nous_v2_0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Pretty-Pelican/pretty-model": [
    "model.safetensors"
  ],
  "0x0dad0/nous_nous_v2_2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Aspik101/nous1_c": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "eren23/dpo-binarized-NeuralTrix-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Novin-AI/Hermes-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "yam-peleg/Experiment8-7B": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "Aspik101/nous2_c": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "djomo/MISTRALllux2000-7b-v6": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Aspik101/nous3_c": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "0x0dad0/nous_nous_v2_1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Radu1999/MisterUkrainianDPO": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tsavage68/400STEPS_1e6rate_Mistral_SFT_zeroshot": [
    "final_checkpoint/model-00001-of-00003.safetensors",
    "final_checkpoint/model-00002-of-00003.safetensors",
    "final_checkpoint/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "max-2022/test_mistral2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Aspik101/nous4_c": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tsavage68/400STEPS_05beta_1e7rate_Meditron7B_zerozhot": [
    "final_checkpoint/model-00001-of-00003.safetensors",
    "final_checkpoint/model-00002-of-00003.safetensors",
    "final_checkpoint/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "DjeDjeB/sn6-finetuned-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Mabeck/Heidrun-Mistral-7B-base": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tsavage68/500STEPS_1e5rate_Mistral_SFT_zeroshot": [
    "final_checkpoint/model-00001-of-00003.safetensors",
    "final_checkpoint/model-00002-of-00003.safetensors",
    "final_checkpoint/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tsavage68/400STEPS_1e7rate_01beta_Mistral": [
    "final_checkpoint/model-00001-of-00003.safetensors",
    "final_checkpoint/model-00002-of-00003.safetensors",
    "final_checkpoint/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "aidonuts/catacombs-001": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tomaszki/nous-twenty-six": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Balfiky/anrtsu": [
    "model.safetensors"
  ],
  "Drewskidang/Marlin_Mixtral_HEHE": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "yam-peleg/Experiment9-7B": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "andrealexroom/LexLLMv0.0.0.x.10.6.1": [
    "checkpoint-465/model-00001-of-00003.safetensors",
    "checkpoint-465/model-00002-of-00003.safetensors",
    "checkpoint-465/model-00003-of-00003.safetensors",
    "checkpoint-558/model-00001-of-00003.safetensors",
    "checkpoint-558/model-00002-of-00003.safetensors",
    "checkpoint-558/model-00003-of-00003.safetensors"
  ],
  "djomo/MISTRALllux2000-7b-v7": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "swj0419/70b_finetuned_llama2_3epoch": [
    "model-00001-of-00061.safetensors",
    "model-00002-of-00061.safetensors",
    "model-00003-of-00061.safetensors",
    "model-00004-of-00061.safetensors",
    "model-00005-of-00061.safetensors",
    "model-00006-of-00061.safetensors",
    "model-00007-of-00061.safetensors",
    "model-00008-of-00061.safetensors",
    "model-00009-of-00061.safetensors",
    "model-00010-of-00061.safetensors",
    "model-00011-of-00061.safetensors",
    "model-00012-of-00061.safetensors",
    "model-00013-of-00061.safetensors",
    "model-00014-of-00061.safetensors",
    "model-00015-of-00061.safetensors",
    "model-00016-of-00061.safetensors",
    "model-00017-of-00061.safetensors",
    "model-00018-of-00061.safetensors",
    "model-00019-of-00061.safetensors",
    "model-00020-of-00061.safetensors",
    "model-00021-of-00061.safetensors",
    "model-00022-of-00061.safetensors",
    "model-00023-of-00061.safetensors",
    "model-00024-of-00061.safetensors",
    "model-00025-of-00061.safetensors",
    "model-00026-of-00061.safetensors",
    "model-00027-of-00061.safetensors",
    "model-00028-of-00061.safetensors",
    "model-00029-of-00061.safetensors",
    "model-00030-of-00061.safetensors",
    "model-00031-of-00061.safetensors",
    "model-00032-of-00061.safetensors",
    "model-00033-of-00061.safetensors",
    "model-00034-of-00061.safetensors",
    "model-00035-of-00061.safetensors",
    "model-00036-of-00061.safetensors",
    "model-00037-of-00061.safetensors",
    "model-00038-of-00061.safetensors",
    "model-00039-of-00061.safetensors",
    "model-00040-of-00061.safetensors",
    "model-00041-of-00061.safetensors",
    "model-00042-of-00061.safetensors",
    "model-00043-of-00061.safetensors",
    "model-00044-of-00061.safetensors",
    "model-00045-of-00061.safetensors",
    "model-00046-of-00061.safetensors",
    "model-00047-of-00061.safetensors",
    "model-00048-of-00061.safetensors",
    "model-00049-of-00061.safetensors",
    "model-00050-of-00061.safetensors",
    "model-00051-of-00061.safetensors",
    "model-00052-of-00061.safetensors",
    "model-00053-of-00061.safetensors",
    "model-00054-of-00061.safetensors",
    "model-00055-of-00061.safetensors",
    "model-00056-of-00061.safetensors",
    "model-00057-of-00061.safetensors",
    "model-00058-of-00061.safetensors",
    "model-00059-of-00061.safetensors",
    "model-00060-of-00061.safetensors",
    "model-00061-of-00061.safetensors"
  ],
  "rizla/rizla-11": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "anupk/akMistral7b": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "dfurman/phi-2-scientific-papers-base-v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hotdogs/open-uka-v1-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "mu0gum/AIFT-42dot_LLM-PLM-1.3B-ao-instruct-all-v0.91": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Steflime/zephyrEsterno3": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-100-16": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-400-16": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "AbacusResearch/haLLAwa": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "floriatea/llama-2-7b-chat-guanaco": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Lostkyd/llama-2-7b-docunstruc": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jsfs11/MoEv4Config-TestWeightedTIES-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "aidonuts/catacombs-001-ep3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Jonathan18/key_3_1": [
    "model.safetensors"
  ],
  "cassanof/maestrale-gazzetta-si1000": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "liminerity/binarized-ingotrix-slerp-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mlx-community/Qwen1.5-1.8B-Chat-4bit": [
    "model.safetensors"
  ],
  "Gille/StrangeMerges_21-7B-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "JJhooww/MistralReloadInstructionBR": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Unggi/ko-openhermes-open-llama-2-ko-7b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "aidonuts/arboretum-001-ep1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "akkky02/llama2-fine-tuned-alpaca-1000": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Crystalcareai/CrystalMistral-24B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "OpenBuddy/openbuddy-mixtral-7bx8-v18.1-32k": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "LoneStriker/miqu-1-70b-sf-5.5bpw-h6-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "dhyay/phi-2_riddles-evolved": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Beilr/llama-2-7b-chat-senti": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "murokhos/test-finetune": [
    "checkpoint-1000/model.safetensors",
    "checkpoint-1500/model.safetensors",
    "checkpoint-2000/model.safetensors",
    "checkpoint-2500/model.safetensors",
    "checkpoint-3000/model.safetensors",
    "checkpoint-500/model.safetensors",
    "model.safetensors"
  ],
  "weijie210/mistral_gsm8k_dpo_0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Kukedlc/neuronal-7b-Mlab": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "armaanp/clean-gpt2-wikitext2": [
    "model.safetensors"
  ],
  "TeeZee/DarkForest-20B-v1.1": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "B2111797/recipe_gener_v3": [
    "model.safetensors"
  ],
  "Dracones/perky-70b-v0.1": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "yam-peleg/Experiment11-7B": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "Dracones/perky-70b-v0.1_exl2_4.65bpw": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "bkangs/Tiefighter-SFT-merged-450-v0": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Dracones/perky-103b-v0.1_exl2_3.35bpw": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "Dracones/perky-103b-v0.1": [
    "model-00001-of-00021.safetensors",
    "model-00002-of-00021.safetensors",
    "model-00003-of-00021.safetensors",
    "model-00004-of-00021.safetensors",
    "model-00005-of-00021.safetensors",
    "model-00006-of-00021.safetensors",
    "model-00007-of-00021.safetensors",
    "model-00008-of-00021.safetensors",
    "model-00009-of-00021.safetensors",
    "model-00010-of-00021.safetensors",
    "model-00011-of-00021.safetensors",
    "model-00012-of-00021.safetensors",
    "model-00013-of-00021.safetensors",
    "model-00014-of-00021.safetensors",
    "model-00015-of-00021.safetensors",
    "model-00016-of-00021.safetensors",
    "model-00017-of-00021.safetensors",
    "model-00018-of-00021.safetensors",
    "model-00019-of-00021.safetensors",
    "model-00020-of-00021.safetensors",
    "model-00021-of-00021.safetensors"
  ],
  "tokoin/mistralai-Code-Instruct-Finetune-for-learning": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sAmBiT77/NexusRaven-V2-13B-awq": [
    "model.safetensors"
  ],
  "sudipto-ducs/llama-2-7b-miniguanaco": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "meizano/autotrain-6pn5d-a3pus": [
    "adapter_model.safetensors",
    "checkpoint-15/adapter_model.safetensors"
  ],
  "eren23/dpo-binarized-NeutrixOmnibe-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/vinallama-7b-AWQ": [
    "model.safetensors"
  ],
  "macintoshtran/NeuralPipe-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Ubaidbhat/Financial_Analyst": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/miquella-120b-5.0bpw-h6-exl2": [
    "output-00001-of-00009.safetensors",
    "output-00002-of-00009.safetensors",
    "output-00003-of-00009.safetensors",
    "output-00004-of-00009.safetensors",
    "output-00005-of-00009.safetensors",
    "output-00006-of-00009.safetensors",
    "output-00007-of-00009.safetensors",
    "output-00008-of-00009.safetensors",
    "output-00009-of-00009.safetensors"
  ],
  "SalmanHabeeb/qwen-llamafiles": [
    "model.safetensors"
  ],
  "TeeZee/DarkSapling-7B-v2.0": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "YashRawal225/NewfineFormatedData": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/miquella-120b-5.5bpw-h6-exl2": [
    "output-00001-of-00010.safetensors",
    "output-00002-of-00010.safetensors",
    "output-00003-of-00010.safetensors",
    "output-00004-of-00010.safetensors",
    "output-00005-of-00010.safetensors",
    "output-00006-of-00010.safetensors",
    "output-00007-of-00010.safetensors",
    "output-00008-of-00010.safetensors",
    "output-00009-of-00010.safetensors",
    "output-00010-of-00010.safetensors"
  ],
  "AbdulHannanMujawar/llama-fine-tuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "andrealexroom/LexLLMv0.0.0.x.10.6.1a": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "BlahBlah314/Seraph-7b-Enh-FT-V16": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "nakcnx/SeaLLM-2-7b-AWQ": [
    "model.safetensors"
  ],
  "ElderlyDed/LadnoAgas": [
    "adapter_model.safetensors",
    "checkpoint-18/adapter_model.safetensors"
  ],
  "bentanweihao/NeuralHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ElderlyDed/LadnoMis": [
    "adapter_model.safetensors",
    "checkpoint-14/adapter_model.safetensors"
  ],
  "scrawlsbraid/tinyllama-colorist-v1": [
    "model.safetensors"
  ],
  "rombodawg/Everyone-LLM-7b-Base": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "iGenius-AI-Team/Italia-2Bts-ckpt-47B-wikiEdiEduFi": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "XMichaelX/DialoGPT-small-akari": [
    "model.safetensors"
  ],
  "devscion/T2IPK": [
    "model.safetensors"
  ],
  "Radu1999/Mistral-Instruct-Ukrainian-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ONS-AI-RESEARCH/ONS-SOLAR-10.7B-v1.1": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "AbacusResearch/haLLAwa2": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "liminerity/Omningotex-7b-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Vikhrmodels/Vikhr-7B-instruct_0.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "y-oguchi/codeparrot-ds": [
    "model.safetensors"
  ],
  "mlabonne/NeuBeagle-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "hingeankit/model-quant": [
    "model.safetensors"
  ],
  "Eurdem/Megatron-Mx": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "paulml/NMTOB-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "paulml/DPOB-NMTOB-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Mlxa/atd-gpt2-medium": [
    "model.safetensors"
  ],
  "eren23/merged-dpo-binarized-NeutrixOmnibe-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "AlexWortega/miqu-1-70b-AQLM-2Bit-1x16-hf": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "weifar/codellama-7b-SCdetecting": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "anupk/akmixtral-v1": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "ISdept/qwen-7b-1_5-hi200-faq-ym-intents-lang": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "LuizWr2/Jana_AI": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "stmackcat/autotrain-xzg1a-3i9r2-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jaykchen/tiny": [
    "model.safetensors"
  ],
  "paulml/DPOB-INMTOB-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "nchen909/llama2_7b_sft_52580": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "nchen909/yi_6b_sft_20710": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "superdocker/anonymous-model-1": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "superdocker/anonymous-model-2": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "superdocker/anonymous-model-3": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "Guilherme34/Jennifer-uwu-modelnotlora": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tomaszki/nous-twenty-seven": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "yaofu/llama-2-7b-80k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "stmackcat/zepb-books-4-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mrbmaryam/Yarn-Mistral-7b-128k_Fine-Tuned4LogParsing-r2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Aspik101/nous7_c": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "pamanseau/sn6": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "unalignment/weeeeee.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "BarraHome/Lucie-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "cryptophantom/sn9": [
    "model.safetensors"
  ],
  "ambet/mistral-v0.2_robot_lora": [
    "adapter_model.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "twhoool02/Falcon-7B-finetuned-guanaco-NF4-QLORA": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Radu1999/Mister": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "stmackcat/zepb-books-5-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-only_indef_articles_with_pl_nouns_removal-seed_211-1e-3": [
    "model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-only_indef_articles_with_pl_nouns_removal-seed_1024-1e-3": [
    "model.safetensors"
  ],
  "nchen909/llama2_7b_sft_20710": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Basha738/llama2-13B-supervised-ft-5-epochs-351": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "paulml/OGNO-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "gture/normistral-7b-scratch-awq": [
    "model.safetensors"
  ],
  "Gmannk/autotrain-ecomm": [
    "adapter_model.safetensors",
    "checkpoint-276/adapter_model.safetensors"
  ],
  "iGenius-AI-Team/Italia-2Bts-ckpt-72B-wikiEdiEduFi": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "aidonuts/metronome-001-ep1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jikaoo8/DialoGPT-medium-joshua": [
    "DialoGPT-medium-joshua/model.safetensors",
    "model.safetensors"
  ],
  "veronoicc/DAMGPT-small-ServerSeeker": [
    "model.safetensors"
  ],
  "hahahpater/openchat-3.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/TheTop-5x7B-Instruct-P-v0.1": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "MaziyarPanahi/TheTop-5x7B-Instruct-D-v0.1": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "nisten/llava1.6-clone-dont-dl": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "hyperclouds/sn9-1": [
    "model.safetensors"
  ],
  "cassanof/maestrale-gazzetta-instruct": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "adarshheg/llama2-7b-finetuned-v1": [
    "adapter_model.safetensors",
    "checkpoint-228/adapter_model.safetensors"
  ],
  "h4rz3rk4s3/TinyParlaMintLlama-1.1B": [
    "model.safetensors"
  ],
  "MaziyarPanahi/TheTop-5x7B-Instruct-T-v0.1": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "PipableAI/Deepseek-MixtureLoss-6.7B": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Oneeb/Humanised-LLM": [
    "model.safetensors"
  ],
  "ThatsGroes/Munin-NeuralBeagle-SkoleGPT-instruct": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Komala/DialoGPT-medium": [
    "model.safetensors"
  ],
  "adarshheg/llama2-7b-finetuned-v2": [
    "adapter_model.safetensors",
    "checkpoint-282/adapter_model.safetensors"
  ],
  "Phearion/bigbrain-v0.0.1": [
    "adapter_model.safetensors",
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Test157t/Prima-Pastacles-7b": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "bailin28/gla-1B-100B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "boapps/szurkemarha-mistral": [
    "adapter_model.safetensors"
  ],
  "freeCS-dot-org/OpenAGI-testing-intelDPO-2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Guilherme34/Samanthavision-modelnotlora": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "kevin009/babyllama-v0.5": [
    "model.safetensors"
  ],
  "kyone/244_HW2_pretrain": [
    "model.safetensors"
  ],
  "MaziyarPanahi/TheTop-5x7B-Instruct-S2-v0.1": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "MesozoicMetallurgist/nous-Cambrian": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "macavins/DialoGPT-medium-Morty": [
    "model.safetensors"
  ],
  "MaziyarPanahi/TheTop-5x7B-Instruct-S3-v0.1": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "N8Programs/dachshund-alpha": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "MaziyarPanahi/TheTop-5x7B-Instruct-S4-v0.1": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "ramixpe/Qwen1.5-1.8B-Chat-erricson-demo": [
    "model.safetensors"
  ],
  "MaziyarPanahi/TheTop-5x7B-Instruct-S5-v0.1": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "ZainAli60/tuned_model": [
    "model.safetensors"
  ],
  "aidonuts/metronome-001-ep2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Aspik101/nous_c6": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kevin009/babyllama-v0.6": [
    "model.safetensors"
  ],
  "LoneStriker/Samantha-120b-2.65bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "LoneStriker/Samantha-120b-3.0bpw-h6-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "indischepartij/MiniCPM-3B-Bacchus": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "BarraHome/Lucie-7b-3e-5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Samantha-120b-3.5bpw-h6-exl2": [
    "output-00001-of-00007.safetensors",
    "output-00002-of-00007.safetensors",
    "output-00003-of-00007.safetensors",
    "output-00004-of-00007.safetensors",
    "output-00005-of-00007.safetensors",
    "output-00006-of-00007.safetensors",
    "output-00007-of-00007.safetensors"
  ],
  "giprime/OOM-13B_02": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "tomaszki/nous-twenty-eight": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Samantha-120b-4.0bpw-h6-exl2": [
    "output-00001-of-00008.safetensors",
    "output-00002-of-00008.safetensors",
    "output-00003-of-00008.safetensors",
    "output-00004-of-00008.safetensors",
    "output-00005-of-00008.safetensors",
    "output-00006-of-00008.safetensors",
    "output-00007-of-00008.safetensors",
    "output-00008-of-00008.safetensors"
  ],
  "ankhamun/x0_0x": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ankhamun/x0o_x0o": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tomaszki/nous-twenty-eight-copy": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "InnerI/InnerILLM-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Gille/StrangeMerges_22-7B-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Samantha-120b-5.0bpw-h6-exl2": [
    "output-00001-of-00009.safetensors",
    "output-00002-of-00009.safetensors",
    "output-00003-of-00009.safetensors",
    "output-00004-of-00009.safetensors",
    "output-00005-of-00009.safetensors",
    "output-00006-of-00009.safetensors",
    "output-00007-of-00009.safetensors",
    "output-00008-of-00009.safetensors",
    "output-00009-of-00009.safetensors"
  ],
  "ankhamun/PI6x_x9IP": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LHC88/DPOpenHermes-7B-v2-PerfLaser": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ankhamun/IxI0_0IxI": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ArianAskari/SOLID-SFT-DPO-MixQV2-SOLIDRejected-SFTChosen-Zephyr-7b-beta": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jeiku/Filet_3B": [
    "model-00001-of-00001.safetensors"
  ],
  "Sambosis/gpt2-wikitext2": [
    "model.safetensors"
  ],
  "jeiku/Tofu_3B": [
    "model-00001-of-00001.safetensors"
  ],
  "mlabonne/OmniTruthyBeagle-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ArianAskari/SOLID-SFT-DPO-MixQV2-SOLIDChosen-SFTRejected-Zephyr-7b-beta": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SF-Foundation/Ein-72B-v0.1-full": [
    "model-00001-of-00030.safetensors",
    "model-00002-of-00030.safetensors",
    "model-00003-of-00030.safetensors",
    "model-00004-of-00030.safetensors",
    "model-00005-of-00030.safetensors",
    "model-00006-of-00030.safetensors",
    "model-00007-of-00030.safetensors",
    "model-00008-of-00030.safetensors",
    "model-00009-of-00030.safetensors",
    "model-00010-of-00030.safetensors",
    "model-00011-of-00030.safetensors",
    "model-00012-of-00030.safetensors",
    "model-00013-of-00030.safetensors",
    "model-00014-of-00030.safetensors",
    "model-00015-of-00030.safetensors",
    "model-00016-of-00030.safetensors",
    "model-00017-of-00030.safetensors",
    "model-00018-of-00030.safetensors",
    "model-00019-of-00030.safetensors",
    "model-00020-of-00030.safetensors",
    "model-00021-of-00030.safetensors",
    "model-00022-of-00030.safetensors",
    "model-00023-of-00030.safetensors",
    "model-00024-of-00030.safetensors",
    "model-00025-of-00030.safetensors",
    "model-00026-of-00030.safetensors",
    "model-00027-of-00030.safetensors",
    "model-00028-of-00030.safetensors",
    "model-00029-of-00030.safetensors",
    "model-00030-of-00030.safetensors"
  ],
  "swj0419/7b_finetuned_llama2_600steps": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "InnerI/InnerILLM-0x00d0-Ox0dad0-nous-nous-v2.0-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "ACHRAFELOUALI/hihi2": [
    "adapter_model.safetensors",
    "checkpoint-4/adapter_model.safetensors"
  ],
  "mlabonne/OmniTruthyBeagle-7B-v0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "thrunlab/pretraining_test": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "ArianAskari/SOLID-SFT-DPO-MixQV3-SOLIDChosen-SFTRejected-Zephyr-7b-beta": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ArianAskari/SOLID-SFT-DPO-MixQV3-SOLIDRejected-SFTChosen-Zephyr-7b-beta": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "adarshheg/llama2-7b-finetuned-v3": [
    "checkpoint-72/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jeiku/Nitrals_Monster_7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Jefo18/Llama2-7B-BillReader": [
    "model.safetensors"
  ],
  "louisbrulenaudet/Pearl-34B-ties": [
    "model-00001-of-00036.safetensors",
    "model-00002-of-00036.safetensors",
    "model-00003-of-00036.safetensors",
    "model-00004-of-00036.safetensors",
    "model-00005-of-00036.safetensors",
    "model-00006-of-00036.safetensors",
    "model-00007-of-00036.safetensors",
    "model-00008-of-00036.safetensors",
    "model-00009-of-00036.safetensors",
    "model-00010-of-00036.safetensors",
    "model-00011-of-00036.safetensors",
    "model-00012-of-00036.safetensors",
    "model-00013-of-00036.safetensors",
    "model-00014-of-00036.safetensors",
    "model-00015-of-00036.safetensors",
    "model-00016-of-00036.safetensors",
    "model-00017-of-00036.safetensors",
    "model-00018-of-00036.safetensors",
    "model-00019-of-00036.safetensors",
    "model-00020-of-00036.safetensors",
    "model-00021-of-00036.safetensors",
    "model-00022-of-00036.safetensors",
    "model-00023-of-00036.safetensors",
    "model-00024-of-00036.safetensors",
    "model-00025-of-00036.safetensors",
    "model-00026-of-00036.safetensors",
    "model-00027-of-00036.safetensors",
    "model-00028-of-00036.safetensors",
    "model-00029-of-00036.safetensors",
    "model-00030-of-00036.safetensors",
    "model-00031-of-00036.safetensors",
    "model-00032-of-00036.safetensors",
    "model-00033-of-00036.safetensors",
    "model-00034-of-00036.safetensors",
    "model-00035-of-00036.safetensors",
    "model-00036-of-00036.safetensors"
  ],
  "Gille/StrangeMerges_23-7B-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "daryxx/subnet9": [
    "model.safetensors"
  ],
  "regisss/llama2-70b-fused-qkv-mlperf": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "RickMartel/GPT2_FineTuned_By_Doc_RAND_v4": [
    "model.safetensors"
  ],
  "babybirdprd/miniCPMmerge-dpo-bf16": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "adarshheg/llama2-7b-sharded-finetuned-v1": [
    "checkpoint-72/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "InnerI/InnerILLM-OpenPipe-Nous-Yarn-Mistral-optimized-1228-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "nobodyiam/fine-tuned-gpt2": [
    "model.safetensors"
  ],
  "uukuguy/speechless-thoughts-mistral-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hotdogs/open-uka-v1-1-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "saishf/Fimbulvetr-Kuro-Lotus-10.7B": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "Jimmyhd/llama213b1000rows3epochs": [
    "checkpoint-174/adapter_model.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "InnerI/InnerILLM-0x00d0-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "B2111797/recipe_gener_v4": [
    "model.safetensors"
  ],
  "Kukedlc/SuperCombo": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "aatmikgupta/gpt2_xl_movietitles": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "DreadPoor/ToppyLake-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Test157t/HerculeanSea-upd-7b-128k": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Test157t/Cetus-Sea-7b-128k": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Twilight233/llama-2-7b-chat-guanaco": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Rajesh222/phi-2_riddles-evolved": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "gmonsoon/Qwen1.5-0.5B-Donut": [
    "model.safetensors"
  ],
  "jeiku/SpaghettiOs_7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Jimmyhd/llama213bAdarshDataset": [
    "checkpoint-192/adapter_model.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Test157t/Prima-Pastacles-7b-128k": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "forag/FoRAG-L-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tarekxpc/QA_XPC_13feb": [
    "model.safetensors"
  ],
  "KnutJaegersberg/Deita-2b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Debasishiarcs/llama-2-fine-tuned-IEEE-CIS": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "worldboss/dpo-v1-finetune-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ybelkada/test-tiny-llama-unsloth": [
    "model.safetensors"
  ],
  "Test157t/Hex-Macaroniac-7b": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "quriousclick/new-dot-comp-v1": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "liminerity/Ombingstrat-dare-ties-ultra2-7b": [
    "model-00001-of-00001.safetensors"
  ],
  "worldboss/dpo-v2-worldboss-2.5-Mistral-7B-ft": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "nchen909/mistral_7b_v1_sft_52580": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "NLUHOPOE/Mistral-test-case-6-nonNoise": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Warlord-K/ava_ft_full": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "AbacusResearch/haLLAwa3": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "gmonsoon/Qwen1.5-0.5B-Horchata": [
    "model.safetensors"
  ],
  "Basha738/llama2-13B-supervised-ft-7-epochs-351": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "BlahBlah314/Seraph-7b-Enh-FT-V17": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dddsaty/KoSOLAR-10.7B_DPO_Adapter_Attach": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "adarshheg/Llama-2-13b-finetuned-v1": [
    "checkpoint-186/adapter_model.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "hyperclouds/sn9-2": [
    "model.safetensors"
  ],
  "AbacusResearch/jaLLAbi": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "aidonuts/pernicious-001-ep1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Bebing01/mistral_after_lobo_test": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "metythorn/Wizard_7B_Squad_v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "moc1pher/mistral-orient": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dddsaty/FusionNet_7Bx2_MoE_Ko_DPO_Adapter_Attach": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "aidonuts/pernicious-001-ep2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Turtle344/Myanmar_GPT_finetuned_health_qa": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "kouki13/llama2": [
    "adapter_model.safetensors",
    "checkpoint-6/adapter_model.safetensors"
  ],
  "hiig-piai/simba-v01c": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "plaguss/stablelm-2-1_6-sft-disticoder-v01": [
    "model.safetensors"
  ],
  "RaphaelMourad/mixtral-chem-v0.1": [
    "model.safetensors"
  ],
  "MaziyarPanahi/samantha-1.1-westlake-7b-AWQ": [
    "model.safetensors"
  ],
  "MaziyarPanahi/natural-sql-7b-GGUF": [],
  "yeniceriSGK/falcon-1b-pibrain-v2-1": [
    "adapter_model.safetensors"
  ],
  "Doniaa/tryMModel": [
    "model.safetensors"
  ],
  "maramzarkaoui/llama2": [
    "adapter_model.safetensors",
    "checkpoint-6/adapter_model.safetensors"
  ],
  "MaziyarPanahi/samantha-1.1-westlake-7b-GPTQ": [
    "model.safetensors"
  ],
  "Doniaa/Trial": [
    "model.safetensors"
  ],
  "Jimmyhd/llama213b1000RowsCsvData": [
    "checkpoint-174/adapter_model.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "mahiatlinux/tinyllama_custom": [
    "model.safetensors"
  ],
  "bardsai/jaskier-7b-dpo-v3.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/sqlcoder-7b-2-GGUF": [],
  "BlahBlah314/Seraph-7b-Enh-FT-V18": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mlabonne/Monarch-7B-dare": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Aspik101/nous8_c": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "xiongjie/test": [
    "model.safetensors"
  ],
  "mlabonne/Monarch-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "shadowml/OmnixBeagle-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "toshi456/llava-jp-1.3b-v1.0-siglip-so400m-patch14-384": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Menouar/saqr-7b-instruct": [
    "adapter_model.safetensors"
  ],
  "IHaBiS/maid-yuzu-v7-exl2-rpcal": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "shadowml/MBeagleX-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "merge-crew/da-sv-task-arithmetic": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "mlabonne/Monarch-7B-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Maaz911/NewModal-Falcon-1B": [
    "adapter_model.safetensors"
  ],
  "ainoob101/functionary-small-v2.2-awq": [
    "model.safetensors"
  ],
  "chtai/LHK_DPO_v1": [],
  "shadowml/MBTrix-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "aman-apollo/template-mistralInstruct-finetune": [
    "adapter_model.safetensors",
    "checkpoint-2193/adapter_model.safetensors"
  ],
  "Crazi/mel_by_genre": [
    "model.safetensors"
  ],
  "hyperclouds/sn9-3": [
    "model.safetensors"
  ],
  "ArianAskari/SOLID-SFT-DPO-MixQV4-SOLIDChosen-SFTRejected-Zephyr-7b-beta": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ArianAskari/SOLID-SFT-DPO-MixQV4-SOLIDRejected-SFTChosen-Zephyr-7b-beta": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "shadowml/NeuralNeuBeagle-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Himitsui/Kaiju-11B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "kaushalpowar/llama2_finetuned2_easymonk_refined_data2": [
    "adapter_model.safetensors"
  ],
  "nlpguy/AlloyIngot": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ElderlyDed/MistGuaco": [
    "checkpoint-532/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "nlpguy/AlloyIngotNeo": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "yeniceriSGK/falcon-1b-pibrain-v3": [
    "adapter_model.safetensors"
  ],
  "tsavage68/chat_350STEPS_1e5_SFT": [
    "final_checkpoint/model-00001-of-00003.safetensors",
    "final_checkpoint/model-00002-of-00003.safetensors",
    "final_checkpoint/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Jimmyhd/llama213b8Epochs1000Rows": [
    "checkpoint-464/adapter_model.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "B2111797/recipe_gener_v5": [
    "model.safetensors"
  ],
  "MaziyarPanahi/OmegaDolphin-103b-v0.1": [
    "model-00001-of-00055.safetensors",
    "model-00002-of-00055.safetensors",
    "model-00003-of-00055.safetensors",
    "model-00004-of-00055.safetensors",
    "model-00005-of-00055.safetensors",
    "model-00006-of-00055.safetensors",
    "model-00007-of-00055.safetensors",
    "model-00008-of-00055.safetensors",
    "model-00009-of-00055.safetensors",
    "model-00010-of-00055.safetensors",
    "model-00011-of-00055.safetensors",
    "model-00012-of-00055.safetensors",
    "model-00013-of-00055.safetensors",
    "model-00014-of-00055.safetensors",
    "model-00015-of-00055.safetensors",
    "model-00016-of-00055.safetensors",
    "model-00017-of-00055.safetensors",
    "model-00018-of-00055.safetensors",
    "model-00019-of-00055.safetensors",
    "model-00020-of-00055.safetensors",
    "model-00021-of-00055.safetensors",
    "model-00022-of-00055.safetensors",
    "model-00023-of-00055.safetensors",
    "model-00024-of-00055.safetensors",
    "model-00025-of-00055.safetensors",
    "model-00026-of-00055.safetensors",
    "model-00027-of-00055.safetensors",
    "model-00028-of-00055.safetensors",
    "model-00029-of-00055.safetensors",
    "model-00030-of-00055.safetensors",
    "model-00031-of-00055.safetensors",
    "model-00032-of-00055.safetensors",
    "model-00033-of-00055.safetensors",
    "model-00034-of-00055.safetensors",
    "model-00035-of-00055.safetensors",
    "model-00036-of-00055.safetensors",
    "model-00037-of-00055.safetensors",
    "model-00038-of-00055.safetensors",
    "model-00039-of-00055.safetensors",
    "model-00040-of-00055.safetensors",
    "model-00041-of-00055.safetensors",
    "model-00042-of-00055.safetensors",
    "model-00043-of-00055.safetensors",
    "model-00044-of-00055.safetensors",
    "model-00045-of-00055.safetensors",
    "model-00046-of-00055.safetensors",
    "model-00047-of-00055.safetensors",
    "model-00048-of-00055.safetensors",
    "model-00049-of-00055.safetensors",
    "model-00050-of-00055.safetensors",
    "model-00051-of-00055.safetensors",
    "model-00052-of-00055.safetensors",
    "model-00053-of-00055.safetensors",
    "model-00054-of-00055.safetensors",
    "model-00055-of-00055.safetensors"
  ],
  "bardsai/jaskier-7b-dpo-v3.3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Jayem-11/OpenPipe_mistral-ft-optimized-1227_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ytu-ce-cosmos/turkish-gpt2": [
    "model.safetensors"
  ],
  "collinear-ai/mistral-clinical-trials": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "RickMartel/GPT2_FT_By_NT_RAND_v5": [
    "model.safetensors"
  ],
  "Doniaa/trial2": [
    "model.safetensors"
  ],
  "arlineka/Brunhilde-2x7b-MOE-DPO-v.01.5": [
    "model-00001-of-00013.safetensors",
    "model-00002-of-00013.safetensors",
    "model-00003-of-00013.safetensors",
    "model-00004-of-00013.safetensors",
    "model-00005-of-00013.safetensors",
    "model-00006-of-00013.safetensors",
    "model-00007-of-00013.safetensors",
    "model-00008-of-00013.safetensors",
    "model-00009-of-00013.safetensors",
    "model-00010-of-00013.safetensors",
    "model-00011-of-00013.safetensors",
    "model-00012-of-00013.safetensors",
    "model-00013-of-00013.safetensors"
  ],
  "tsavage68/chat_500STEPS_1e5rate_SFT": [
    "final_checkpoint/model-00001-of-00003.safetensors",
    "final_checkpoint/model-00002-of-00003.safetensors",
    "final_checkpoint/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Lvxy1117/amber_fine_tune_sgall": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Aspik101/nous_c8": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ytu-ce-cosmos/turkish-gpt2-medium": [
    "model.safetensors"
  ],
  "ExAi/WhiteRabbitNeo-33B-v1.5-exl2-3.0": [
    "cal_data.safetensors",
    "hidden_states.safetensors",
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Aspik101/nous9_c": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tsavage68/chat_700STEPS_1e4rate_01beta_DPO": [
    "final_checkpoint/model-00001-of-00003.safetensors",
    "final_checkpoint/model-00002-of-00003.safetensors",
    "final_checkpoint/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ytu-ce-cosmos/turkish-gpt2-large": [
    "model.safetensors"
  ],
  "h4rz3rk4s3/TinyNewsLlama-1.1B": [
    "model.safetensors"
  ],
  "LoneStriker/Vistral-7B-ChatML-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Vistral-7B-ChatML-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Vistral-7B-ChatML-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Vistral-7B-ChatML-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Vistral-7B-ChatML-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "Aspik101/nous10_c": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mu0gum/AIFT-42dot_LLM-PLM-1.3B-ao-instruct-all-v1.0": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "lewtun/dummy-model": [
    "model.safetensors"
  ],
  "FractalGPT/EmbedderDecoder": [
    "model.safetensors"
  ],
  "Kalslice/prunedopt": [
    "model.safetensors"
  ],
  "yam-peleg/Experiment10-7B": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "merge-crew/da-sv-dare-ties-density-0.9": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "PaulM2000/merged_peft_model_random_42_without_up_proj_Llama-2-7b-hf": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "deepnetguy/m-657": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "deepnetguy/m-711": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "tgaddair/gpt2": [
    "model.safetensors"
  ],
  "ambet/mistral-v0.2_robot_lora_dict": [
    "adapter_model.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ojaffe/llama2-7b-tom-sandbagged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "TensaZangetsu/condensed-bert-vulnerable": [
    "model.safetensors"
  ],
  "Brendan/tod_zero_950jm4lq_9600": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "merge-crew/da-sv-dare-ties-density-0.6": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Americo/phi2-finetued-farma-13feb": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "merge-crew/da-sv-dare-ties-density-0.3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "merge-crew/da-sv-ties": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kaushalpowar/llama2_finetuned2_easymonk_refined_data3_merged": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Mixtral_7Bx5_MoE_30B-3.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Mabeck/Heidrun-Mistral-7B-chat": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "merge-crew/da-sv-slerp": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Mixtral_7Bx5_MoE_30B-4.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/Mixtral_7Bx5_MoE_30B-4.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "Envoid/Cat-8x7B": [
    "model-00001-of-00048.safetensors",
    "model-00002-of-00048.safetensors",
    "model-00003-of-00048.safetensors",
    "model-00004-of-00048.safetensors",
    "model-00005-of-00048.safetensors",
    "model-00006-of-00048.safetensors",
    "model-00007-of-00048.safetensors",
    "model-00008-of-00048.safetensors",
    "model-00009-of-00048.safetensors",
    "model-00010-of-00048.safetensors",
    "model-00011-of-00048.safetensors",
    "model-00012-of-00048.safetensors",
    "model-00013-of-00048.safetensors",
    "model-00014-of-00048.safetensors",
    "model-00015-of-00048.safetensors",
    "model-00016-of-00048.safetensors",
    "model-00017-of-00048.safetensors",
    "model-00018-of-00048.safetensors",
    "model-00019-of-00048.safetensors",
    "model-00020-of-00048.safetensors",
    "model-00021-of-00048.safetensors",
    "model-00022-of-00048.safetensors",
    "model-00023-of-00048.safetensors",
    "model-00024-of-00048.safetensors",
    "model-00025-of-00048.safetensors",
    "model-00026-of-00048.safetensors",
    "model-00027-of-00048.safetensors",
    "model-00028-of-00048.safetensors",
    "model-00029-of-00048.safetensors",
    "model-00030-of-00048.safetensors",
    "model-00031-of-00048.safetensors",
    "model-00032-of-00048.safetensors",
    "model-00033-of-00048.safetensors",
    "model-00034-of-00048.safetensors",
    "model-00035-of-00048.safetensors",
    "model-00036-of-00048.safetensors",
    "model-00037-of-00048.safetensors",
    "model-00038-of-00048.safetensors",
    "model-00039-of-00048.safetensors",
    "model-00040-of-00048.safetensors",
    "model-00041-of-00048.safetensors",
    "model-00042-of-00048.safetensors",
    "model-00043-of-00048.safetensors",
    "model-00044-of-00048.safetensors",
    "model-00045-of-00048.safetensors",
    "model-00046-of-00048.safetensors",
    "model-00047-of-00048.safetensors",
    "model-00048-of-00048.safetensors"
  ],
  "LoneStriker/Mixtral_7Bx5_MoE_30B-5.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "AyushNayak/2024-02-13-08-13-15": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "andrealexroom/LexLLMv0.0.0.x.10.6.1c": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/MiquMaid-v2-2x70B-DPO-GPTQ": [],
  "LoneStriker/Mixtral_7Bx5_MoE_30B-6.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "deepnetguy/m-720": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Mixtral_7Bx5_MoE_30B-8.0bpw-h8-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "Brendan/tod_zero_950jm4lq_16000": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Gan1108/agriparts-4": [
    "model.safetensors",
    "tmp-checkpoint-7500/model.safetensors"
  ],
  "sajjadamjad/quizz_llm_bible_KJ": [
    "model.safetensors"
  ],
  "DrishtiSharma/openhermes-2.5-mistral-7b-losstype-sigmoid-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Aspik101/nous_c7": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "DrishtiSharma/openhermes-2.5-mistral-7b-losstype-kto-pair-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "DrishtiSharma/openhermes-2.5-mistral-7b-losstype-ipo-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "yangwawa0202/Mistra-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "RickMartel/GPT2_FT_By_NT_RAND_QUANT_v6": [
    "model.safetensors"
  ],
  "Aspik101/nous11_c": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "altomek/UNA-SOLAR-10.7B-Instruct-v1.0-8bpw-EXL2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "eren23/AYA-Mistral7B-instruct-TR-4b": [
    "adapter_model.safetensors"
  ],
  "Test157t/Echidna-7b-128k": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "macadeliccc/samantha-1.1-MBX-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Xenon1/Zenith-7B": [
    "checkpoint-100/adapter_model.safetensors",
    "checkpoint-1000/adapter_model.safetensors",
    "checkpoint-1100/adapter_model.safetensors",
    "checkpoint-1200/adapter_model.safetensors",
    "checkpoint-1300/adapter_model.safetensors",
    "checkpoint-1400/adapter_model.safetensors",
    "checkpoint-1500/adapter_model.safetensors",
    "checkpoint-1600/adapter_model.safetensors",
    "checkpoint-1700/adapter_model.safetensors",
    "checkpoint-1800/adapter_model.safetensors",
    "checkpoint-1900/adapter_model.safetensors",
    "checkpoint-200/adapter_model.safetensors",
    "checkpoint-2000/adapter_model.safetensors",
    "checkpoint-2100/adapter_model.safetensors",
    "checkpoint-2200/adapter_model.safetensors",
    "checkpoint-2300/adapter_model.safetensors",
    "checkpoint-300/adapter_model.safetensors",
    "checkpoint-400/adapter_model.safetensors",
    "checkpoint-500/adapter_model.safetensors",
    "checkpoint-600/adapter_model.safetensors",
    "checkpoint-700/adapter_model.safetensors",
    "checkpoint-800/adapter_model.safetensors",
    "checkpoint-900/adapter_model.safetensors",
    "final_checkpoint/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Radu1999/MisterUkrainianZNO": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "asadmasad/ds-7-lora-finetuned": [
    "adapter_model.safetensors"
  ],
  "tsavage68/chat_500STEPS_1e7rate_SFT": [
    "final_checkpoint/model-00001-of-00003.safetensors",
    "final_checkpoint/model-00002-of-00003.safetensors",
    "final_checkpoint/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "bitw0n/consultingQwen": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "RaduGabriel/MUZ": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ibibek/tinyllama-colorist-v2": [
    "model.safetensors"
  ],
  "isaipd20/aquabot": [
    "model.safetensors"
  ],
  "LoneStriker/Solstice-11B-v1-AWQ": [
    "model.safetensors"
  ],
  "tsavage68/chat_300STEPS_1e7rate_SFT": [
    "final_checkpoint/model-00001-of-00003.safetensors",
    "final_checkpoint/model-00002-of-00003.safetensors",
    "final_checkpoint/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Jimmyhd/mistral7bTimeSheet1000Rows": [
    "checkpoint-464/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "yleo/EmertonOmniBeagle-7B-dpo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-only_other_det_removal-seed_211-1e-3": [
    "model.safetensors"
  ],
  "kanishka/smolm-autoreg-bpe-counterfactual-babylm-only_other_det_removal-seed_1024-1e-3": [
    "model.safetensors"
  ],
  "CultriX/NeuralTrix-v3-fp16": [
    "model-00001-of-00002.safetensors",
    "model-00001-of-00008.safetensors",
    "model-00002-of-00002.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Brendan/tod_zero_950jm4lq_25600": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Loewolf/Privat": [
    "model.safetensors"
  ],
  "Sayan01/BabyLlama-s": [
    "model.safetensors"
  ],
  "Ruiz3/phi-2-kingshipAIv2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Mihaiii/Bucharest-0.1": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "ek826/TheProfessor-155b-2.4bpw-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "altomek/Starling-LM-11B-alpha-8bpw-EXL2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/Yi-34B-200K-RPMerge-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "tsavage68/chat_400STEPS_1e6rate_SFT": [
    "final_checkpoint/model-00001-of-00003.safetensors",
    "final_checkpoint/model-00002-of-00003.safetensors",
    "final_checkpoint/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Sayan01/BabyLlama-b": [
    "model.safetensors"
  ],
  "akkky02/llama2-7b-adapter-alpaca-1000": [
    "model.safetensors"
  ],
  "tsavage68/chat_150STEPS_1e6rate_SFT": [
    "final_checkpoint/model-00001-of-00003.safetensors",
    "final_checkpoint/model-00002-of-00003.safetensors",
    "final_checkpoint/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "smrynrz20/models": [
    "model.safetensors"
  ],
  "LoneStriker/Yi-34B-200K-RPMerge-GPTQ": [
    "gptq_model-4bit-32g.safetensors"
  ],
  "CultriX/NeuralTrix-v3-bf16": [
    "model-00001-of-00002.safetensors",
    "model-00001-of-00008.safetensors",
    "model-00002-of-00002.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "stmackcat/zepb-cyberiada-eng-1-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "NickyNicky/OpenHermes_fourier_merge_v1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "vgel/mistral-7b-selfmerge-0-32-8-24-8-32": [
    "model-00001-of-00017.safetensors",
    "model-00002-of-00017.safetensors",
    "model-00003-of-00017.safetensors",
    "model-00004-of-00017.safetensors",
    "model-00005-of-00017.safetensors",
    "model-00006-of-00017.safetensors",
    "model-00007-of-00017.safetensors",
    "model-00008-of-00017.safetensors",
    "model-00009-of-00017.safetensors",
    "model-00010-of-00017.safetensors",
    "model-00011-of-00017.safetensors",
    "model-00012-of-00017.safetensors",
    "model-00013-of-00017.safetensors",
    "model-00014-of-00017.safetensors",
    "model-00015-of-00017.safetensors",
    "model-00016-of-00017.safetensors",
    "model-00017-of-00017.safetensors"
  ],
  "CultriX/NeuralTrix-v4-bf16": [
    "model-00001-of-00002.safetensors",
    "model-00001-of-00008.safetensors",
    "model-00002-of-00002.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "sayhan/Qwen1.5-7B-turkish-lora": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "tsavage68/chat_600STEPS_1e8rate_SFT": [
    "final_checkpoint/model-00001-of-00003.safetensors",
    "final_checkpoint/model-00002-of-00003.safetensors",
    "final_checkpoint/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "adarshheg/llama-7b-chat-finetuned-8bit": [
    "checkpoint-248/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AyushNayak/2024-02-13-21-16-43": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "MaziyarPanahi/WizardLM-Math-70B-v0.1": [
    "model-00001-of-00018.safetensors",
    "model-00002-of-00018.safetensors",
    "model-00003-of-00018.safetensors",
    "model-00004-of-00018.safetensors",
    "model-00005-of-00018.safetensors",
    "model-00006-of-00018.safetensors",
    "model-00007-of-00018.safetensors",
    "model-00008-of-00018.safetensors",
    "model-00009-of-00018.safetensors",
    "model-00010-of-00018.safetensors",
    "model-00011-of-00018.safetensors",
    "model-00012-of-00018.safetensors",
    "model-00013-of-00018.safetensors",
    "model-00014-of-00018.safetensors",
    "model-00015-of-00018.safetensors",
    "model-00016-of-00018.safetensors",
    "model-00017-of-00018.safetensors",
    "model-00018-of-00018.safetensors"
  ],
  "jaehy12/1280_solar._dpo": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "ND911/Fraken-Maid-TW-Slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "InnerI/I-OpenPipe-NH2-Solar-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Unggi/ko-metamathqa-open-llama-2-ko-7b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "deepnetguy/m-794": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jeiku/Rainbow_69_7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "peft-internal-testing/opt-125m-awq": [
    "model.safetensors"
  ],
  "MaziyarPanahi/WizardLM-Math-70B-TIES-v0.1": [
    "model-00001-of-00018.safetensors",
    "model-00002-of-00018.safetensors",
    "model-00003-of-00018.safetensors",
    "model-00004-of-00018.safetensors",
    "model-00005-of-00018.safetensors",
    "model-00006-of-00018.safetensors",
    "model-00007-of-00018.safetensors",
    "model-00008-of-00018.safetensors",
    "model-00009-of-00018.safetensors",
    "model-00010-of-00018.safetensors",
    "model-00011-of-00018.safetensors",
    "model-00012-of-00018.safetensors",
    "model-00013-of-00018.safetensors",
    "model-00014-of-00018.safetensors",
    "model-00015-of-00018.safetensors",
    "model-00016-of-00018.safetensors",
    "model-00017-of-00018.safetensors",
    "model-00018-of-00018.safetensors"
  ],
  "Brendan/tod_zero_950jm4lq_28800": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jaydeepb/gpt2-wikienron": [
    "model.safetensors"
  ],
  "ssoh/llama-2-7b-mcq": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "RickMartel/GPT2_FT_By_NT_RAND_v7": [
    "model.safetensors"
  ],
  "arkobanikUW/git-base-pokemon": [
    "model.safetensors"
  ],
  "Jimmyhd/llama7bTimeSheet": [
    "checkpoint-464/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "EdwardXu/git-base-pokemon": [
    "model.safetensors"
  ],
  "saharars/git-base-pokemon": [
    "model.safetensors"
  ],
  "dondongwonlee/v3": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "InnerI/I-Code-NousLlama7B-slerp": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "jsfs11/RandomMergeWEIGHTEDv2-7B-DARETIES": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/MiquMaid-v2-2x70B-DPO-2.4bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "seyf1elislam/KuTrix-7b": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "devashat/244-first-try": [
    "model.safetensors"
  ],
  "deepnetguy/m-937": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jsfs11/RandomMergeWEIGHTED-7B-SLERP": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "JDWebProgrammer/Mistral-MBX-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "LoneStriker/MiquMaid-v2-2x70B-DPO-3.0bpw-h6-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "jamesoneill12/dynamo-8B-v0.1-instr-de": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "deepnetguy/m-938": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "JDWebProgrammer/Mistral-CultriX-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "YHLam/mistral_instruct_finetune_attempt_8k_4k_max_input": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Envoid/Mixtral-Instruct-ITR-8x7B": [
    "model-00001-of-00048.safetensors",
    "model-00002-of-00048.safetensors",
    "model-00003-of-00048.safetensors",
    "model-00004-of-00048.safetensors",
    "model-00005-of-00048.safetensors",
    "model-00006-of-00048.safetensors",
    "model-00007-of-00048.safetensors",
    "model-00008-of-00048.safetensors",
    "model-00009-of-00048.safetensors",
    "model-00010-of-00048.safetensors",
    "model-00011-of-00048.safetensors",
    "model-00012-of-00048.safetensors",
    "model-00013-of-00048.safetensors",
    "model-00014-of-00048.safetensors",
    "model-00015-of-00048.safetensors",
    "model-00016-of-00048.safetensors",
    "model-00017-of-00048.safetensors",
    "model-00018-of-00048.safetensors",
    "model-00019-of-00048.safetensors",
    "model-00020-of-00048.safetensors",
    "model-00021-of-00048.safetensors",
    "model-00022-of-00048.safetensors",
    "model-00023-of-00048.safetensors",
    "model-00024-of-00048.safetensors",
    "model-00025-of-00048.safetensors",
    "model-00026-of-00048.safetensors",
    "model-00027-of-00048.safetensors",
    "model-00028-of-00048.safetensors",
    "model-00029-of-00048.safetensors",
    "model-00030-of-00048.safetensors",
    "model-00031-of-00048.safetensors",
    "model-00032-of-00048.safetensors",
    "model-00033-of-00048.safetensors",
    "model-00034-of-00048.safetensors",
    "model-00035-of-00048.safetensors",
    "model-00036-of-00048.safetensors",
    "model-00037-of-00048.safetensors",
    "model-00038-of-00048.safetensors",
    "model-00039-of-00048.safetensors",
    "model-00040-of-00048.safetensors",
    "model-00041-of-00048.safetensors",
    "model-00042-of-00048.safetensors",
    "model-00043-of-00048.safetensors",
    "model-00044-of-00048.safetensors",
    "model-00045-of-00048.safetensors",
    "model-00046-of-00048.safetensors",
    "model-00047-of-00048.safetensors",
    "model-00048-of-00048.safetensors"
  ],
  "ek826/TheProfessor-155b-2.21bpw-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "tsavage68/chat_1000STEPS_1e6rate_01beta_DPO": [
    "final_checkpoint/model-00001-of-00003.safetensors",
    "final_checkpoint/model-00002-of-00003.safetensors",
    "final_checkpoint/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/MiquMaid-v2-2x70B-DPO-3.5bpw-h6-exl2": [
    "output-00001-of-00007.safetensors",
    "output-00002-of-00007.safetensors",
    "output-00003-of-00007.safetensors",
    "output-00004-of-00007.safetensors",
    "output-00005-of-00007.safetensors",
    "output-00006-of-00007.safetensors",
    "output-00007-of-00007.safetensors"
  ],
  "Kukedlc/Triunvirato-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "NingLab/eCeLLM-S": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jsfs11/RandomMergeWEIGHTED-7B-SLERP-8.0bpw-exl2": [
    "cal_data.safetensors",
    "hidden_states.safetensors",
    "output.safetensors"
  ],
  "10jqk1/Mistral-7B-Instruct-SHARD-ADDTOKEN": [
    "model-00001-of-00034.safetensors",
    "model-00002-of-00034.safetensors",
    "model-00003-of-00034.safetensors",
    "model-00004-of-00034.safetensors",
    "model-00005-of-00034.safetensors",
    "model-00006-of-00034.safetensors",
    "model-00007-of-00034.safetensors",
    "model-00008-of-00034.safetensors",
    "model-00009-of-00034.safetensors",
    "model-00010-of-00034.safetensors",
    "model-00011-of-00034.safetensors",
    "model-00012-of-00034.safetensors",
    "model-00013-of-00034.safetensors",
    "model-00014-of-00034.safetensors",
    "model-00015-of-00034.safetensors",
    "model-00016-of-00034.safetensors",
    "model-00017-of-00034.safetensors",
    "model-00018-of-00034.safetensors",
    "model-00019-of-00034.safetensors",
    "model-00020-of-00034.safetensors",
    "model-00021-of-00034.safetensors",
    "model-00022-of-00034.safetensors",
    "model-00023-of-00034.safetensors",
    "model-00024-of-00034.safetensors",
    "model-00025-of-00034.safetensors",
    "model-00026-of-00034.safetensors",
    "model-00027-of-00034.safetensors",
    "model-00028-of-00034.safetensors",
    "model-00029-of-00034.safetensors",
    "model-00030-of-00034.safetensors",
    "model-00031-of-00034.safetensors",
    "model-00032-of-00034.safetensors",
    "model-00033-of-00034.safetensors",
    "model-00034-of-00034.safetensors"
  ],
  "typeof/zephyr-7b": [
    "model-00001-of-00291.safetensors",
    "model-00002-of-00291.safetensors",
    "model-00003-of-00291.safetensors",
    "model-00004-of-00291.safetensors",
    "model-00005-of-00291.safetensors",
    "model-00006-of-00291.safetensors",
    "model-00007-of-00291.safetensors",
    "model-00008-of-00291.safetensors",
    "model-00009-of-00291.safetensors",
    "model-00010-of-00291.safetensors",
    "model-00011-of-00291.safetensors",
    "model-00012-of-00291.safetensors",
    "model-00013-of-00291.safetensors",
    "model-00014-of-00291.safetensors",
    "model-00015-of-00291.safetensors",
    "model-00016-of-00291.safetensors",
    "model-00017-of-00291.safetensors",
    "model-00018-of-00291.safetensors",
    "model-00019-of-00291.safetensors",
    "model-00020-of-00291.safetensors",
    "model-00021-of-00291.safetensors",
    "model-00022-of-00291.safetensors",
    "model-00023-of-00291.safetensors",
    "model-00024-of-00291.safetensors",
    "model-00025-of-00291.safetensors",
    "model-00026-of-00291.safetensors",
    "model-00027-of-00291.safetensors",
    "model-00028-of-00291.safetensors",
    "model-00029-of-00291.safetensors",
    "model-00030-of-00291.safetensors",
    "model-00031-of-00291.safetensors",
    "model-00032-of-00291.safetensors",
    "model-00033-of-00291.safetensors",
    "model-00034-of-00291.safetensors",
    "model-00035-of-00291.safetensors",
    "model-00036-of-00291.safetensors",
    "model-00037-of-00291.safetensors",
    "model-00038-of-00291.safetensors",
    "model-00039-of-00291.safetensors",
    "model-00040-of-00291.safetensors",
    "model-00041-of-00291.safetensors",
    "model-00042-of-00291.safetensors",
    "model-00043-of-00291.safetensors",
    "model-00044-of-00291.safetensors",
    "model-00045-of-00291.safetensors",
    "model-00046-of-00291.safetensors",
    "model-00047-of-00291.safetensors",
    "model-00048-of-00291.safetensors",
    "model-00049-of-00291.safetensors",
    "model-00050-of-00291.safetensors",
    "model-00051-of-00291.safetensors",
    "model-00052-of-00291.safetensors",
    "model-00053-of-00291.safetensors",
    "model-00054-of-00291.safetensors",
    "model-00055-of-00291.safetensors",
    "model-00056-of-00291.safetensors",
    "model-00057-of-00291.safetensors",
    "model-00058-of-00291.safetensors",
    "model-00059-of-00291.safetensors",
    "model-00060-of-00291.safetensors",
    "model-00061-of-00291.safetensors",
    "model-00062-of-00291.safetensors",
    "model-00063-of-00291.safetensors",
    "model-00064-of-00291.safetensors",
    "model-00065-of-00291.safetensors",
    "model-00066-of-00291.safetensors",
    "model-00067-of-00291.safetensors",
    "model-00068-of-00291.safetensors",
    "model-00069-of-00291.safetensors",
    "model-00070-of-00291.safetensors",
    "model-00071-of-00291.safetensors",
    "model-00072-of-00291.safetensors",
    "model-00073-of-00291.safetensors",
    "model-00074-of-00291.safetensors",
    "model-00075-of-00291.safetensors",
    "model-00076-of-00291.safetensors",
    "model-00077-of-00291.safetensors",
    "model-00078-of-00291.safetensors",
    "model-00079-of-00291.safetensors",
    "model-00080-of-00291.safetensors",
    "model-00081-of-00291.safetensors",
    "model-00082-of-00291.safetensors",
    "model-00083-of-00291.safetensors",
    "model-00084-of-00291.safetensors",
    "model-00085-of-00291.safetensors",
    "model-00086-of-00291.safetensors",
    "model-00087-of-00291.safetensors",
    "model-00088-of-00291.safetensors",
    "model-00089-of-00291.safetensors",
    "model-00090-of-00291.safetensors",
    "model-00091-of-00291.safetensors",
    "model-00092-of-00291.safetensors",
    "model-00093-of-00291.safetensors",
    "model-00094-of-00291.safetensors",
    "model-00095-of-00291.safetensors",
    "model-00096-of-00291.safetensors",
    "model-00097-of-00291.safetensors",
    "model-00098-of-00291.safetensors",
    "model-00099-of-00291.safetensors",
    "model-00100-of-00291.safetensors",
    "model-00101-of-00291.safetensors",
    "model-00102-of-00291.safetensors",
    "model-00103-of-00291.safetensors",
    "model-00104-of-00291.safetensors",
    "model-00105-of-00291.safetensors",
    "model-00106-of-00291.safetensors",
    "model-00107-of-00291.safetensors",
    "model-00108-of-00291.safetensors",
    "model-00109-of-00291.safetensors",
    "model-00110-of-00291.safetensors",
    "model-00111-of-00291.safetensors",
    "model-00112-of-00291.safetensors",
    "model-00113-of-00291.safetensors",
    "model-00114-of-00291.safetensors",
    "model-00115-of-00291.safetensors",
    "model-00116-of-00291.safetensors",
    "model-00117-of-00291.safetensors",
    "model-00118-of-00291.safetensors",
    "model-00119-of-00291.safetensors",
    "model-00120-of-00291.safetensors",
    "model-00121-of-00291.safetensors",
    "model-00122-of-00291.safetensors",
    "model-00123-of-00291.safetensors",
    "model-00124-of-00291.safetensors",
    "model-00125-of-00291.safetensors",
    "model-00126-of-00291.safetensors",
    "model-00127-of-00291.safetensors",
    "model-00128-of-00291.safetensors",
    "model-00129-of-00291.safetensors",
    "model-00130-of-00291.safetensors",
    "model-00131-of-00291.safetensors",
    "model-00132-of-00291.safetensors",
    "model-00133-of-00291.safetensors",
    "model-00134-of-00291.safetensors",
    "model-00135-of-00291.safetensors",
    "model-00136-of-00291.safetensors",
    "model-00137-of-00291.safetensors",
    "model-00138-of-00291.safetensors",
    "model-00139-of-00291.safetensors",
    "model-00140-of-00291.safetensors",
    "model-00141-of-00291.safetensors",
    "model-00142-of-00291.safetensors",
    "model-00143-of-00291.safetensors",
    "model-00144-of-00291.safetensors",
    "model-00145-of-00291.safetensors",
    "model-00146-of-00291.safetensors",
    "model-00147-of-00291.safetensors",
    "model-00148-of-00291.safetensors",
    "model-00149-of-00291.safetensors",
    "model-00150-of-00291.safetensors",
    "model-00151-of-00291.safetensors",
    "model-00152-of-00291.safetensors",
    "model-00153-of-00291.safetensors",
    "model-00154-of-00291.safetensors",
    "model-00155-of-00291.safetensors",
    "model-00156-of-00291.safetensors",
    "model-00157-of-00291.safetensors",
    "model-00158-of-00291.safetensors",
    "model-00159-of-00291.safetensors",
    "model-00160-of-00291.safetensors",
    "model-00161-of-00291.safetensors",
    "model-00162-of-00291.safetensors",
    "model-00163-of-00291.safetensors",
    "model-00164-of-00291.safetensors",
    "model-00165-of-00291.safetensors",
    "model-00166-of-00291.safetensors",
    "model-00167-of-00291.safetensors",
    "model-00168-of-00291.safetensors",
    "model-00169-of-00291.safetensors",
    "model-00170-of-00291.safetensors",
    "model-00171-of-00291.safetensors",
    "model-00172-of-00291.safetensors",
    "model-00173-of-00291.safetensors",
    "model-00174-of-00291.safetensors",
    "model-00175-of-00291.safetensors",
    "model-00176-of-00291.safetensors",
    "model-00177-of-00291.safetensors",
    "model-00178-of-00291.safetensors",
    "model-00179-of-00291.safetensors",
    "model-00180-of-00291.safetensors",
    "model-00181-of-00291.safetensors",
    "model-00182-of-00291.safetensors",
    "model-00183-of-00291.safetensors",
    "model-00184-of-00291.safetensors",
    "model-00185-of-00291.safetensors",
    "model-00186-of-00291.safetensors",
    "model-00187-of-00291.safetensors",
    "model-00188-of-00291.safetensors",
    "model-00189-of-00291.safetensors",
    "model-00190-of-00291.safetensors",
    "model-00191-of-00291.safetensors",
    "model-00192-of-00291.safetensors",
    "model-00193-of-00291.safetensors",
    "model-00194-of-00291.safetensors",
    "model-00195-of-00291.safetensors",
    "model-00196-of-00291.safetensors",
    "model-00197-of-00291.safetensors",
    "model-00198-of-00291.safetensors",
    "model-00199-of-00291.safetensors",
    "model-00200-of-00291.safetensors",
    "model-00201-of-00291.safetensors",
    "model-00202-of-00291.safetensors",
    "model-00203-of-00291.safetensors",
    "model-00204-of-00291.safetensors",
    "model-00205-of-00291.safetensors",
    "model-00206-of-00291.safetensors",
    "model-00207-of-00291.safetensors",
    "model-00208-of-00291.safetensors",
    "model-00209-of-00291.safetensors",
    "model-00210-of-00291.safetensors",
    "model-00211-of-00291.safetensors",
    "model-00212-of-00291.safetensors",
    "model-00213-of-00291.safetensors",
    "model-00214-of-00291.safetensors",
    "model-00215-of-00291.safetensors",
    "model-00216-of-00291.safetensors",
    "model-00217-of-00291.safetensors",
    "model-00218-of-00291.safetensors",
    "model-00219-of-00291.safetensors",
    "model-00220-of-00291.safetensors",
    "model-00221-of-00291.safetensors",
    "model-00222-of-00291.safetensors",
    "model-00223-of-00291.safetensors",
    "model-00224-of-00291.safetensors",
    "model-00225-of-00291.safetensors",
    "model-00226-of-00291.safetensors",
    "model-00227-of-00291.safetensors",
    "model-00228-of-00291.safetensors",
    "model-00229-of-00291.safetensors",
    "model-00230-of-00291.safetensors",
    "model-00231-of-00291.safetensors",
    "model-00232-of-00291.safetensors",
    "model-00233-of-00291.safetensors",
    "model-00234-of-00291.safetensors",
    "model-00235-of-00291.safetensors",
    "model-00236-of-00291.safetensors",
    "model-00237-of-00291.safetensors",
    "model-00238-of-00291.safetensors",
    "model-00239-of-00291.safetensors",
    "model-00240-of-00291.safetensors",
    "model-00241-of-00291.safetensors",
    "model-00242-of-00291.safetensors",
    "model-00243-of-00291.safetensors",
    "model-00244-of-00291.safetensors",
    "model-00245-of-00291.safetensors",
    "model-00246-of-00291.safetensors",
    "model-00247-of-00291.safetensors",
    "model-00248-of-00291.safetensors",
    "model-00249-of-00291.safetensors",
    "model-00250-of-00291.safetensors",
    "model-00251-of-00291.safetensors",
    "model-00252-of-00291.safetensors",
    "model-00253-of-00291.safetensors",
    "model-00254-of-00291.safetensors",
    "model-00255-of-00291.safetensors",
    "model-00256-of-00291.safetensors",
    "model-00257-of-00291.safetensors",
    "model-00258-of-00291.safetensors",
    "model-00259-of-00291.safetensors",
    "model-00260-of-00291.safetensors",
    "model-00261-of-00291.safetensors",
    "model-00262-of-00291.safetensors",
    "model-00263-of-00291.safetensors",
    "model-00264-of-00291.safetensors",
    "model-00265-of-00291.safetensors",
    "model-00266-of-00291.safetensors",
    "model-00267-of-00291.safetensors",
    "model-00268-of-00291.safetensors",
    "model-00269-of-00291.safetensors",
    "model-00270-of-00291.safetensors",
    "model-00271-of-00291.safetensors",
    "model-00272-of-00291.safetensors",
    "model-00273-of-00291.safetensors",
    "model-00274-of-00291.safetensors",
    "model-00275-of-00291.safetensors",
    "model-00276-of-00291.safetensors",
    "model-00277-of-00291.safetensors",
    "model-00278-of-00291.safetensors",
    "model-00279-of-00291.safetensors",
    "model-00280-of-00291.safetensors",
    "model-00281-of-00291.safetensors",
    "model-00282-of-00291.safetensors",
    "model-00283-of-00291.safetensors",
    "model-00284-of-00291.safetensors",
    "model-00285-of-00291.safetensors",
    "model-00286-of-00291.safetensors",
    "model-00287-of-00291.safetensors",
    "model-00288-of-00291.safetensors",
    "model-00289-of-00291.safetensors",
    "model-00290-of-00291.safetensors",
    "model-00291-of-00291.safetensors"
  ],
  "NingLab/eCeLLM-L": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "NingLab/eCeLLM-M": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "brucethemoose/LargeWorldModel_LWM-Text-Chat-128K-55bpw": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "deepnetguy/m-948": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "alicecomfy/miqu-openhermes-full": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "mlabonne/NeuralMonarch-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dondongwonlee/v4": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "tsavage68/chat_150STEPS_1e7rate_01beta_DPO": [
    "final_checkpoint/model-00001-of-00003.safetensors",
    "final_checkpoint/model-00002-of-00003.safetensors",
    "final_checkpoint/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tyson0420/stack-codellama": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FelixChao/Scorpio-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dansbecker/deployment_course_model": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "myaeisan/llama-2-7b-domain-tuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "KimByeongSu/gpt-neo-125m-cs-finetuning": [
    "model.safetensors"
  ],
  "jarod0411/test_clm_mlm": [
    "model.safetensors"
  ],
  "Changgil/k2s3_test_24001": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "JONGYUN/DPO_Test": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00001-of-00005.safetensors",
    "model-00002-of-00002.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "ITT-AF/ITT-Yi-Ko-6B-v4.0": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "superdocker/anonymous-model-4": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "superdocker/anonymous-model-5": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "rahulshah9713/gpt2-wikitext2": [
    "model.safetensors"
  ],
  "kevinpro/MetaMathOctopus-7B": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "mesolitica/DPO-malaysian-tinyllama-1.1b-16k-instructions-v3": [
    "model.safetensors"
  ],
  "Deadwalker0/EvolCodeLlama": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "krisf85/myft": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Menouar/fennec-7b-alpha": [
    "adapter_model.safetensors"
  ],
  "andrealexroom/LexLLMv0.0.0.x.10.6.1d": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mzio/hedgehog-alpaca_clean_mistral-mistral_7b_lk_esn_tqk_lora-lk_untied_head-lsc_1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "superdocker/anonymous-model-6": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "superdocker/anonymous-model-7": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "YashRawal225/Instructiontune": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "DKYoon/kosolar-hermes-test": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "zolak/sn6": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ONS-AI-RESEARCH/ONS-SOLAR-10.7B-AWQ": [
    "model.safetensors"
  ],
  "B2111797/recipe_gener_v6": [
    "model.safetensors"
  ],
  "huangyt/home-ccp4-r64-q_v_k_o_gate_down_up-2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaggieZhang/try-bloomz-1b7-2": [
    "adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "apailang/llama2_7b_sum_mcq_3": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "mzio/hedgehog-mistral_7b-alpaca_clean-smd_lora_1e_3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "IBM-DTT/sap_hana_ds_FT_Model_10k_includes_0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "stmackcat/zepb-cyberiada-1-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ssoh/llama-2-7b-mcq_2_beta": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "moc1pher/mistral-orient-fine-tune-2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "RaduGabriel/MUZD": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SuYee189/gpt2-health-qa": [
    "model.safetensors"
  ],
  "Quzovsky/Maral": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "WaveCut/ruGPT-3.5-13B-4bit-bnb": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ElderlyDed/MistPhotoCheckTest": [
    "checkpoint-1/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "stmackcat/zepb-books-6-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sjunique/codeparrot-ds-accelerate": [
    "model.safetensors"
  ],
  "tsavage68/chat_200STEPS_1e6_01beta": [
    "final_checkpoint/model-00001-of-00003.safetensors",
    "final_checkpoint/model-00002-of-00003.safetensors",
    "final_checkpoint/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "arlineka/Brunhilde-13b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kaushalpowar/llama2_finetuned_4_merged": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "bardsai/jaskier-7b-dpo-v4.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jobvector/SFT_Llama-2-7b-hf_0.0001_57202Data_1600ChPt": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sravaniayyagari/new-finetuned-model": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "mtc/meta-llama-Llama-2-7b-hf-arxiv-summarization-1000-last_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "yleo/EmertonBeagle-7B-dpo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "bcse/Lumiere-120b": [
    "model-00001-of-00025.safetensors",
    "model-00002-of-00025.safetensors",
    "model-00003-of-00025.safetensors",
    "model-00004-of-00025.safetensors",
    "model-00005-of-00025.safetensors",
    "model-00006-of-00025.safetensors",
    "model-00007-of-00025.safetensors",
    "model-00008-of-00025.safetensors",
    "model-00009-of-00025.safetensors",
    "model-00010-of-00025.safetensors",
    "model-00011-of-00025.safetensors",
    "model-00012-of-00025.safetensors",
    "model-00013-of-00025.safetensors",
    "model-00014-of-00025.safetensors",
    "model-00015-of-00025.safetensors",
    "model-00016-of-00025.safetensors",
    "model-00017-of-00025.safetensors",
    "model-00018-of-00025.safetensors",
    "model-00019-of-00025.safetensors",
    "model-00020-of-00025.safetensors",
    "model-00021-of-00025.safetensors",
    "model-00022-of-00025.safetensors",
    "model-00023-of-00025.safetensors",
    "model-00024-of-00025.safetensors",
    "model-00025-of-00025.safetensors"
  ],
  "ISdept/qwen-7b-1_5-hi200-ym-intents-lang-translate": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "VictorMoses/Malawi-Public-Health-Systems": [
    "model.safetensors"
  ],
  "tyson0420/stack_codellama-7b-inst": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ISdept/qwen-7b-1_5-hi200-ym-intents-lang-translate-4bit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Trelis/llava-v1.6-mistral-7b-PATCHED": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "kevinpro/MathOctopus-MAPO-DPO-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kevinpro/MetaMathOctopus-MAPO-DPO-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "stmackcat/zepb-mk-1-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "bardsai/jaskier-7b-dpo-v4.3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LuizWr2/Jana_7b": [
    "albedobaseXL_v21.safetensors"
  ],
  "davzoku/frankencria-llama2-11b-v1.3-m.1": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "MaziyarPanahi/WestSeverus-7B-DPO-v2-GGUF": [],
  "heldJan/llama-2-7b-froozen_CLIP_test": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mtc/meta-llama-Llama-2-7b-hf-pubmed-summarization-1000-last_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "h4rz3rk4s3/TinyPoliticaLlama-1.1B-slerp": [
    "model-00001-of-00001.safetensors"
  ],
  "crestf411/daybreak-kunoichi-dpo-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "CultriX/NeuralTrix-bf16": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "yleo/EmertonMonarch-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "davzoku/frankencria-llama2-12.5b-v1.3-m.2": [
    "model-00001-of-00013.safetensors",
    "model-00002-of-00013.safetensors",
    "model-00003-of-00013.safetensors",
    "model-00004-of-00013.safetensors",
    "model-00005-of-00013.safetensors",
    "model-00006-of-00013.safetensors",
    "model-00007-of-00013.safetensors",
    "model-00008-of-00013.safetensors",
    "model-00009-of-00013.safetensors",
    "model-00010-of-00013.safetensors",
    "model-00011-of-00013.safetensors",
    "model-00012-of-00013.safetensors",
    "model-00013-of-00013.safetensors"
  ],
  "MaziyarPanahi/OGNO-7B-GGUF": [],
  "h-xw/mistral_b_finance_finetuned_test": [
    "model.safetensors"
  ],
  "CultriX/NeuralTrixlaser-bf16": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MH0386/phi-2-napoleon-bonaparte": [
    "adapter_1/adapter_model.safetensors",
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "hyperclouds/sn9-new": [
    "model.safetensors"
  ],
  "amichalski2/tinyllama-email-model-full": [
    "model.safetensors"
  ],
  "arlineka/Brunhilde-13b-v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "B-O/dummy-mistral-758k": [
    "model.safetensors"
  ],
  "Imran1/AyaChatM3.5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mlabonne/AlphaMonarch-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mtc/meta-llama-Llama-2-7b-hf-pubmed-summarization-10k-last_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "yleo/EmertonMonarch-7B-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "unsloth/tinyllama-chat-bnb-4bit": [
    "model.safetensors"
  ],
  "RadAlienware/mis2ndphasemerge140": [
    "model.safetensors"
  ],
  "unsloth/tinyllama-chat": [
    "model.safetensors"
  ],
  "mtc/meta-llama-Llama-2-7b-hf-arxiv-summarization-10k-last_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "yleo/OgnoMonarch-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "tomaszki/nous-twenty-nine": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "kaushalpowar/llama2_finetuned_5merged": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "stmackcat/zepb-mk-ger-1-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "h4rz3rk4s3/TinyPoliticaLlama-4x1.1B-nf4": [
    "model-00001-of-00001.safetensors"
  ],
  "twodgirl/Psyche-3B": [
    "adapter_model.safetensors"
  ],
  "Pretty-Pelican/pretty-new-model": [
    "model.safetensors"
  ],
  "AIMH-DHgroup/llama-2-7b-chat-paragraphs-q4-2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FelixChao/Capricorn-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "johannhartmann/Wiederchat-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Gan1108/agriparts-5": [
    "model.safetensors"
  ],
  "paulml/MoMoAlpaca-72b": [
    "model-00001-of-00082.safetensors",
    "model-00002-of-00082.safetensors",
    "model-00003-of-00082.safetensors",
    "model-00004-of-00082.safetensors",
    "model-00005-of-00082.safetensors",
    "model-00006-of-00082.safetensors",
    "model-00007-of-00082.safetensors",
    "model-00008-of-00082.safetensors",
    "model-00009-of-00082.safetensors",
    "model-00010-of-00082.safetensors",
    "model-00011-of-00082.safetensors",
    "model-00012-of-00082.safetensors",
    "model-00013-of-00082.safetensors",
    "model-00014-of-00082.safetensors",
    "model-00015-of-00082.safetensors",
    "model-00016-of-00082.safetensors",
    "model-00017-of-00082.safetensors",
    "model-00018-of-00082.safetensors",
    "model-00019-of-00082.safetensors",
    "model-00020-of-00082.safetensors",
    "model-00021-of-00082.safetensors",
    "model-00022-of-00082.safetensors",
    "model-00023-of-00082.safetensors",
    "model-00024-of-00082.safetensors",
    "model-00025-of-00082.safetensors",
    "model-00026-of-00082.safetensors",
    "model-00027-of-00082.safetensors",
    "model-00028-of-00082.safetensors",
    "model-00029-of-00082.safetensors",
    "model-00030-of-00082.safetensors",
    "model-00031-of-00082.safetensors",
    "model-00032-of-00082.safetensors",
    "model-00033-of-00082.safetensors",
    "model-00034-of-00082.safetensors",
    "model-00035-of-00082.safetensors",
    "model-00036-of-00082.safetensors",
    "model-00037-of-00082.safetensors",
    "model-00038-of-00082.safetensors",
    "model-00039-of-00082.safetensors",
    "model-00040-of-00082.safetensors",
    "model-00041-of-00082.safetensors",
    "model-00042-of-00082.safetensors",
    "model-00043-of-00082.safetensors",
    "model-00044-of-00082.safetensors",
    "model-00045-of-00082.safetensors",
    "model-00046-of-00082.safetensors",
    "model-00047-of-00082.safetensors",
    "model-00048-of-00082.safetensors",
    "model-00049-of-00082.safetensors",
    "model-00050-of-00082.safetensors",
    "model-00051-of-00082.safetensors",
    "model-00052-of-00082.safetensors",
    "model-00053-of-00082.safetensors",
    "model-00054-of-00082.safetensors",
    "model-00055-of-00082.safetensors",
    "model-00056-of-00082.safetensors",
    "model-00057-of-00082.safetensors",
    "model-00058-of-00082.safetensors",
    "model-00059-of-00082.safetensors",
    "model-00060-of-00082.safetensors",
    "model-00061-of-00082.safetensors",
    "model-00062-of-00082.safetensors",
    "model-00063-of-00082.safetensors",
    "model-00064-of-00082.safetensors",
    "model-00065-of-00082.safetensors",
    "model-00066-of-00082.safetensors",
    "model-00067-of-00082.safetensors",
    "model-00068-of-00082.safetensors",
    "model-00069-of-00082.safetensors",
    "model-00070-of-00082.safetensors",
    "model-00071-of-00082.safetensors",
    "model-00072-of-00082.safetensors",
    "model-00073-of-00082.safetensors",
    "model-00074-of-00082.safetensors",
    "model-00075-of-00082.safetensors",
    "model-00076-of-00082.safetensors",
    "model-00077-of-00082.safetensors",
    "model-00078-of-00082.safetensors",
    "model-00079-of-00082.safetensors",
    "model-00080-of-00082.safetensors",
    "model-00081-of-00082.safetensors",
    "model-00082-of-00082.safetensors"
  ],
  "pahautelman/phi2-ner-v1": [
    "model.safetensors"
  ],
  "vistagi/Mixtral-8x7b-v0.1-sft": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "dondongwonlee/v5": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "joseagmz/out": [
    "checkpoint-464/model-00001-of-00003.safetensors",
    "checkpoint-464/model-00002-of-00003.safetensors",
    "checkpoint-464/model-00003-of-00003.safetensors"
  ],
  "bcse/Eumyella-120b": [
    "model-00001-of-00025.safetensors",
    "model-00002-of-00025.safetensors",
    "model-00003-of-00025.safetensors",
    "model-00004-of-00025.safetensors",
    "model-00005-of-00025.safetensors",
    "model-00006-of-00025.safetensors",
    "model-00007-of-00025.safetensors",
    "model-00008-of-00025.safetensors",
    "model-00009-of-00025.safetensors",
    "model-00010-of-00025.safetensors",
    "model-00011-of-00025.safetensors",
    "model-00012-of-00025.safetensors",
    "model-00013-of-00025.safetensors",
    "model-00014-of-00025.safetensors",
    "model-00015-of-00025.safetensors",
    "model-00016-of-00025.safetensors",
    "model-00017-of-00025.safetensors",
    "model-00018-of-00025.safetensors",
    "model-00019-of-00025.safetensors",
    "model-00020-of-00025.safetensors",
    "model-00021-of-00025.safetensors",
    "model-00022-of-00025.safetensors",
    "model-00023-of-00025.safetensors",
    "model-00024-of-00025.safetensors",
    "model-00025-of-00025.safetensors"
  ],
  "MaziyarPanahi/Ultra-WizardLM-Miqu-120B-v0.1": [
    "model-00001-of-00031.safetensors",
    "model-00002-of-00031.safetensors",
    "model-00003-of-00031.safetensors",
    "model-00004-of-00031.safetensors",
    "model-00005-of-00031.safetensors",
    "model-00006-of-00031.safetensors",
    "model-00007-of-00031.safetensors",
    "model-00008-of-00031.safetensors",
    "model-00009-of-00031.safetensors",
    "model-00010-of-00031.safetensors",
    "model-00011-of-00031.safetensors",
    "model-00012-of-00031.safetensors",
    "model-00013-of-00031.safetensors",
    "model-00014-of-00031.safetensors",
    "model-00015-of-00031.safetensors",
    "model-00016-of-00031.safetensors",
    "model-00017-of-00031.safetensors",
    "model-00018-of-00031.safetensors",
    "model-00019-of-00031.safetensors",
    "model-00020-of-00031.safetensors",
    "model-00021-of-00031.safetensors",
    "model-00022-of-00031.safetensors",
    "model-00023-of-00031.safetensors",
    "model-00024-of-00031.safetensors",
    "model-00025-of-00031.safetensors",
    "model-00026-of-00031.safetensors",
    "model-00027-of-00031.safetensors",
    "model-00028-of-00031.safetensors",
    "model-00029-of-00031.safetensors",
    "model-00030-of-00031.safetensors",
    "model-00031-of-00031.safetensors"
  ],
  "andrealexroom/LexLLMv0.0.0.x.10.6.1e": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "h4rz3rk4s3/TinyPoliticaLlama-3x1.1B-nf4": [
    "model-00001-of-00001.safetensors"
  ],
  "LoneStriker/openbuddy-mixtral-7bx8-v18.1-32k-2.4bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "gokulraj/new_first_model": [
    "model.safetensors"
  ],
  "mattshumer/Combined-Test-14B-OpenHermes-2.5-Mistral-7B-and-dolphin-2.6-mistral-7b-dpo-laser": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/openbuddy-mixtral-7bx8-v18.1-32k-3.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "ace2105/mistral-coding-instruction": [
    "adapter_model.safetensors",
    "checkpoint-95/adapter_model.safetensors"
  ],
  "LoneStriker/openbuddy-mixtral-7bx8-v18.1-32k-3.5bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "PipableAI/pip-sql-1.3b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/openbuddy-mixtral-7bx8-v18.1-32k-3.75bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "giux78/zefiro-7b-dpo-qlora-ITA-v0.7": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/openbuddy-mixtral-7bx8-v18.1-32k-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/openbuddy-mixtral-7bx8-v18.1-32k-5.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "ThatsGroes/Dansk-NorskGPT": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/openbuddy-mixtral-7bx8-v18.1-32k-6.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "arendgb/restaurant_demo_mistral_ft_16bit": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Smaug-34B-v0.1-3.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "deepnetguy/m-1032": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "sdkramer10/active_listening_llama": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "LoneStriker/Smaug-34B-v0.1-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "deepnet/SN9-130": [
    "model.safetensors"
  ],
  "LoneStriker/Smaug-34B-v0.1-4.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Smaug-34B-v0.1-5.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "vandijklab/pythia-160m-c2s": [
    "model.safetensors"
  ],
  "LoneStriker/Smaug-34B-v0.1-6.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "LoneStriker/Smaug-34B-v0.1-8.0bpw-h8-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "wndiros/diva_em_leo_mistral_v05": [
    "model.safetensors"
  ],
  "Xenon1/Zenith-7B-dpo": [
    "checkpoint-1000/adapter_model.safetensors",
    "checkpoint-1500/adapter_model.safetensors",
    "checkpoint-2000/adapter_model.safetensors",
    "checkpoint-500/adapter_model.safetensors",
    "final_checkpoint/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "eskayML/Midjourney-Prompts-Finetuned": [
    "adapter_model.safetensors",
    "checkpoint-1/adapter_model.safetensors"
  ],
  "ek826/TheProfessor-155b-3.0bpw-exl2": [
    "output-00001-of-00007.safetensors",
    "output-00002-of-00007.safetensors",
    "output-00003-of-00007.safetensors",
    "output-00004-of-00007.safetensors",
    "output-00005-of-00007.safetensors",
    "output-00006-of-00007.safetensors",
    "output-00007-of-00007.safetensors"
  ],
  "manu/croissant_mmlu_0shot": [
    "checkpoint-1482/model.safetensors"
  ],
  "thrunlab/Mistral_Sparse": [
    "model.safetensors"
  ],
  "touqir/Cyrax-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Xenon1/Zenith-7B-dpo-v1": [
    "checkpoint-500/adapter_model.safetensors",
    "final_checkpoint/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Smaug-34B-v0.1-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "njpang95/mistralai-sample": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/Ultra-Miqu-WizardLM-120B-v0.1": [
    "model-00001-of-00031.safetensors",
    "model-00002-of-00031.safetensors",
    "model-00003-of-00031.safetensors",
    "model-00004-of-00031.safetensors",
    "model-00005-of-00031.safetensors",
    "model-00006-of-00031.safetensors",
    "model-00007-of-00031.safetensors",
    "model-00008-of-00031.safetensors",
    "model-00009-of-00031.safetensors",
    "model-00010-of-00031.safetensors",
    "model-00011-of-00031.safetensors",
    "model-00012-of-00031.safetensors",
    "model-00013-of-00031.safetensors",
    "model-00014-of-00031.safetensors",
    "model-00015-of-00031.safetensors",
    "model-00016-of-00031.safetensors",
    "model-00017-of-00031.safetensors",
    "model-00018-of-00031.safetensors",
    "model-00019-of-00031.safetensors",
    "model-00020-of-00031.safetensors",
    "model-00021-of-00031.safetensors",
    "model-00022-of-00031.safetensors",
    "model-00023-of-00031.safetensors",
    "model-00024-of-00031.safetensors",
    "model-00025-of-00031.safetensors",
    "model-00026-of-00031.safetensors",
    "model-00027-of-00031.safetensors",
    "model-00028-of-00031.safetensors",
    "model-00029-of-00031.safetensors",
    "model-00030-of-00031.safetensors",
    "model-00031-of-00031.safetensors"
  ],
  "Unggi/ko-hermes-open-solar-ko-10.7b": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "jdengjnj/distilgpt2-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "liminerity/ultra0": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Drewskidang/up": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "davidkim205/komt-solar-10.7b-sft-v1": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "openvoid/Proximus-4x7B-v1": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "SeifGad/Qwen-0.5B-Enhanced": [
    "model.safetensors"
  ],
  "Aspik101/nous13_c": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Smaug-34B-v0.1-GPTQ": [
    "gptq_model-4bit-32g.safetensors"
  ],
  "vitruv/mistral_7b_dpo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kaushalpowar/backup": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Drewskidang/up2chatml": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Josephgflowers/tinyllama-730M-test": [
    "model.safetensors"
  ],
  "Xenon1/Eclipse-13B": [
    "checkpoint-100/adapter_model.safetensors",
    "checkpoint-200/adapter_model.safetensors",
    "checkpoint-300/adapter_model.safetensors",
    "checkpoint-400/adapter_model.safetensors",
    "checkpoint-500/adapter_model.safetensors",
    "checkpoint-600/adapter_model.safetensors",
    "final_checkpoint/adapter_model.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "swj0419/7b_finetuned_llama2_300steps": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ArthurZ/small-model": [
    "model.safetensors"
  ],
  "synk/OpenHermes-4.6-Dolphin-Mistral": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Drewskidang/upawq": [
    "model.safetensors"
  ],
  "tavtav/eros-7b-test": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors",
    "model.safetensors"
  ],
  "sjalilo78/gpt2ForM2DataScaleProject": [
    "model.safetensors"
  ],
  "eastjin/all_type2_merge": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "DeepDream2045/bts-pretraining": [
    "model.safetensors"
  ],
  "Drewskidang/upawqreg": [
    "model.safetensors"
  ],
  "longcule123/adapter-14-2_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Kalslice/distilpruned": [
    "model.safetensors"
  ],
  "devashat/244-test": [
    "model.safetensors"
  ],
  "jungyuko/DAVinCI-42dot_LLM-PLM-1.3B-v1.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Masterjp123/SnowyRP-V2-13B-L2_BetaTest": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hotdogs/open-uka-v1-1-7B-python": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "serpdotai/sparsetral-16x7B-v2-SPIN_iter0": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "aloobun/Reyna-Mini-1.8B-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "sajedjalil/mistral-pregnancy-instruct": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors",
    "model.safetensors"
  ],
  "Xenon1/Zenith-7B-dpo-v2": [
    "checkpoint-500/adapter_model.safetensors",
    "final_checkpoint/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "devashat/244-py-script": [
    "model.safetensors"
  ],
  "liminerity/ultra0-reshaped1": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Xenon1/Zenith-7B-dpo-v3": [
    "checkpoint-500/adapter_model.safetensors",
    "final_checkpoint/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Kalslice/distilpruned80": [
    "model.safetensors"
  ],
  "aidonuts/enthralling-etchings-132-s600": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "adarshheg/llama-7b-chat-finetuned-4bit-std": [
    "checkpoint-496/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "aidonuts/enthralling-etchings-132-s600b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Kukedlc/NeuralLogic-7B-V": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "kyone/another_model": [
    "model.safetensors"
  ],
  "LoneStriker/Smaug-34B-v0.1-2.4bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "aidonuts/enthralling-etchings-132-s800": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "KZMTx/RedSolarSkyAdapter": [
    "adapter_model.safetensors"
  ],
  "ken-miller/tris-1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-QA-full": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "ybelkada/test-automatic-tagging": [
    "model.safetensors"
  ],
  "Drewskidang/awqguufup": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "B2111797/recipe_gener_v7": [
    "model.safetensors"
  ],
  "joseagmz/Mistral_FFT": [
    "checkpoint-32/model-00001-of-00003.safetensors",
    "checkpoint-32/model-00002-of-00003.safetensors",
    "checkpoint-32/model-00003-of-00003.safetensors"
  ],
  "tyson0420/mixtral_stack_llama": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "swj0419/7b_llama2_lyrics_1000steps": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "pawan2411/fused-ESGcombinedData-LoRA": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "aidonuts/enthralling-etchings-132-s1200": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Raven-Pro/SDmerge": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "pussup7181/ncrtc_cc": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FelixChao/Capricorn-7B-DPO": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "swj0419/7b_llama2_lyrics_2000steps": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Xenon1/Eclipse-13B-dpo": [
    "checkpoint-500/adapter_model.safetensors",
    "final_checkpoint/adapter_model.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Pplus/mistral-health-faq_log_50": [
    "adapter_model.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "joseagmz/Mistral_Medtext": [
    "checkpoint-116/model-00001-of-00003.safetensors",
    "checkpoint-116/model-00002-of-00003.safetensors",
    "checkpoint-116/model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Smaug-34B-v0.1-2.65bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Test157t/EvilxEchidna-7b": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-SA-full": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "sonthenguyen/OpenHermes-2.5-Mistral-7B-mt-bench-DPO-reversed_corrupted": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Raincleared/prosparse-llama-2-7b": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Raincleared/prosparse-llama-2-13b": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "jan-hq/stealth-finance-v1-e1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Raven-Pro/SDdpo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hmzkhnswt/tinyllama_customerSupport_hmc": [
    "model.safetensors"
  ],
  "norman-codes/transfer-learning-attempt1": [
    "model.safetensors"
  ],
  "Elizezen/Antler-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Kyllene-34B-v1.1-2.7bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "xriminact/TARSHindiLLamaModel": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "huyhuyvu01/VietLlama2_Law_Pretrain_7B": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "siumankwan23/dk1": [
    "adapter_model.safetensors",
    "checkpoint-4/adapter_model.safetensors"
  ],
  "Test157t/EvilxHexMacaroniac-7b": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "deepnetguy/m-1102": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "stmackcat/zepb-books-7-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hellomyoh/mistral_7b_ft_ko-en_v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "KomeijiForce/inbedder-opt-1.3b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "pussup7181/ncrtc_cc2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "TachyHealthResearch/Llama2-7B-Medical-Finetune_V2": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "logicker/SkkuDS-DPO-72B-v1": [
    "model-00001-of-00030.safetensors",
    "model-00002-of-00030.safetensors",
    "model-00003-of-00030.safetensors",
    "model-00004-of-00030.safetensors",
    "model-00005-of-00030.safetensors",
    "model-00006-of-00030.safetensors",
    "model-00007-of-00030.safetensors",
    "model-00008-of-00030.safetensors",
    "model-00009-of-00030.safetensors",
    "model-00010-of-00030.safetensors",
    "model-00011-of-00030.safetensors",
    "model-00012-of-00030.safetensors",
    "model-00013-of-00030.safetensors",
    "model-00014-of-00030.safetensors",
    "model-00015-of-00030.safetensors",
    "model-00016-of-00030.safetensors",
    "model-00017-of-00030.safetensors",
    "model-00018-of-00030.safetensors",
    "model-00019-of-00030.safetensors",
    "model-00020-of-00030.safetensors",
    "model-00021-of-00030.safetensors",
    "model-00022-of-00030.safetensors",
    "model-00023-of-00030.safetensors",
    "model-00024-of-00030.safetensors",
    "model-00025-of-00030.safetensors",
    "model-00026-of-00030.safetensors",
    "model-00027-of-00030.safetensors",
    "model-00028-of-00030.safetensors",
    "model-00029-of-00030.safetensors",
    "model-00030-of-00030.safetensors"
  ],
  "Tamnemtf/llama2-7b-vi-finetuned-2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ElderlyDed/MiniCPMPhotoCheck1.5K": [
    "checkpoint-10/adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "hs4jk24erfc/TinyLlama-1.1B-Chat-v1.0-bf16-push-demo": [
    "model.safetensors"
  ],
  "aidonuts/enthralling-etchings-132-s0200": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "pamanseau/sn9-4": [
    "model.safetensors"
  ],
  "thrunlab/Mistral_Sparse_refined_web_70p_2024-02-15": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "logicker/SkkuDS-DPO-72B-v2": [
    "model-00001-of-00030.safetensors",
    "model-00002-of-00030.safetensors",
    "model-00003-of-00030.safetensors",
    "model-00004-of-00030.safetensors",
    "model-00005-of-00030.safetensors",
    "model-00006-of-00030.safetensors",
    "model-00007-of-00030.safetensors",
    "model-00008-of-00030.safetensors",
    "model-00009-of-00030.safetensors",
    "model-00010-of-00030.safetensors",
    "model-00011-of-00030.safetensors",
    "model-00012-of-00030.safetensors",
    "model-00013-of-00030.safetensors",
    "model-00014-of-00030.safetensors",
    "model-00015-of-00030.safetensors",
    "model-00016-of-00030.safetensors",
    "model-00017-of-00030.safetensors",
    "model-00018-of-00030.safetensors",
    "model-00019-of-00030.safetensors",
    "model-00020-of-00030.safetensors",
    "model-00021-of-00030.safetensors",
    "model-00022-of-00030.safetensors",
    "model-00023-of-00030.safetensors",
    "model-00024-of-00030.safetensors",
    "model-00025-of-00030.safetensors",
    "model-00026-of-00030.safetensors",
    "model-00027-of-00030.safetensors",
    "model-00028-of-00030.safetensors",
    "model-00029-of-00030.safetensors",
    "model-00030-of-00030.safetensors"
  ],
  "thrunlab/mistral_sparse_80__graceful_reg_50_pt_200": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ElderlyDed/MiniCPMPhotoCheck1.5KV2": [
    "checkpoint-5/adapter_model.safetensors",
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Aspik101/nous_c5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Eunju2834/aicomment_kogpt2": [
    "model.safetensors"
  ],
  "quriousclick/tinyllama-v1-training": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "logicker/SkkuDS-DPO-72B-v3": [
    "model-00001-of-00030.safetensors",
    "model-00002-of-00030.safetensors",
    "model-00003-of-00030.safetensors",
    "model-00004-of-00030.safetensors",
    "model-00005-of-00030.safetensors",
    "model-00006-of-00030.safetensors",
    "model-00007-of-00030.safetensors",
    "model-00008-of-00030.safetensors",
    "model-00009-of-00030.safetensors",
    "model-00010-of-00030.safetensors",
    "model-00011-of-00030.safetensors",
    "model-00012-of-00030.safetensors",
    "model-00013-of-00030.safetensors",
    "model-00014-of-00030.safetensors",
    "model-00015-of-00030.safetensors",
    "model-00016-of-00030.safetensors",
    "model-00017-of-00030.safetensors",
    "model-00018-of-00030.safetensors",
    "model-00019-of-00030.safetensors",
    "model-00020-of-00030.safetensors",
    "model-00021-of-00030.safetensors",
    "model-00022-of-00030.safetensors",
    "model-00023-of-00030.safetensors",
    "model-00024-of-00030.safetensors",
    "model-00025-of-00030.safetensors",
    "model-00026-of-00030.safetensors",
    "model-00027-of-00030.safetensors",
    "model-00028-of-00030.safetensors",
    "model-00029-of-00030.safetensors",
    "model-00030-of-00030.safetensors"
  ],
  "michelknoop21/logivertgeitje": [
    "adapter_model.safetensors",
    "checkpoint-36/adapter_model.safetensors"
  ],
  "nlpguy/AlloyIngotNeoX": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Doniaa/trial512": [
    "model.safetensors"
  ],
  "kouki13/facebook": [
    "adapter_model.safetensors",
    "checkpoint-6/adapter_model.safetensors"
  ],
  "ElderlyDed/MistPhotoCheck1.5K": [
    "checkpoint-5/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "thrunlab/mistral_sparse_80__graceful_reg_50_pt_2000": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sravaniayyagari/new-tuned-model": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Doniaa/distilroberta-base-finetuned-wikitext2": [
    "model.safetensors"
  ],
  "kouki13/facebook2": [
    "adapter_model.safetensors",
    "checkpoint-1/adapter_model.safetensors"
  ],
  "aghorbani/bank-tx-cat-opt-125m": [
    "model.safetensors"
  ],
  "Raven-Pro/candymoe": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Yuma42/KangalKhan-Sapphire-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "logicker/SkkuDS-DPO-72B-v4": [
    "model-00001-of-00030.safetensors",
    "model-00002-of-00030.safetensors",
    "model-00003-of-00030.safetensors",
    "model-00004-of-00030.safetensors",
    "model-00005-of-00030.safetensors",
    "model-00006-of-00030.safetensors",
    "model-00007-of-00030.safetensors",
    "model-00008-of-00030.safetensors",
    "model-00009-of-00030.safetensors",
    "model-00010-of-00030.safetensors",
    "model-00011-of-00030.safetensors",
    "model-00012-of-00030.safetensors",
    "model-00013-of-00030.safetensors",
    "model-00014-of-00030.safetensors",
    "model-00015-of-00030.safetensors",
    "model-00016-of-00030.safetensors",
    "model-00017-of-00030.safetensors",
    "model-00018-of-00030.safetensors",
    "model-00019-of-00030.safetensors",
    "model-00020-of-00030.safetensors",
    "model-00021-of-00030.safetensors",
    "model-00022-of-00030.safetensors",
    "model-00023-of-00030.safetensors",
    "model-00024-of-00030.safetensors",
    "model-00025-of-00030.safetensors",
    "model-00026-of-00030.safetensors",
    "model-00027-of-00030.safetensors",
    "model-00028-of-00030.safetensors",
    "model-00029-of-00030.safetensors",
    "model-00030-of-00030.safetensors"
  ],
  "tyson0420/mixtral_stack_llama2_code": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "DT12the/Math-Mixtral-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "kouki13/facebook3": [
    "adapter_model.safetensors",
    "checkpoint-6/adapter_model.safetensors"
  ],
  "tsavage68/chat_1000STEPS_1e5rate_01beta_DPO": [
    "final_checkpoint/model-00001-of-00003.safetensors",
    "final_checkpoint/model-00002-of-00003.safetensors",
    "final_checkpoint/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ArianAskari/SOLID-SFT-WoDPO-MixQV2-v2-Zephyr-7b-beta": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kouki13/facebook4": [
    "adapter_model.safetensors",
    "checkpoint-2/adapter_model.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-NQA-full": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "tsavage68/chat_1000STEPS_1e6_03beta_DPO": [
    "final_checkpoint/model-00001-of-00003.safetensors",
    "final_checkpoint/model-00002-of-00003.safetensors",
    "final_checkpoint/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rhplus0831/maid-yuzu-v8": [
    "model-00001-of-00048.safetensors",
    "model-00002-of-00048.safetensors",
    "model-00003-of-00048.safetensors",
    "model-00004-of-00048.safetensors",
    "model-00005-of-00048.safetensors",
    "model-00006-of-00048.safetensors",
    "model-00007-of-00048.safetensors",
    "model-00008-of-00048.safetensors",
    "model-00009-of-00048.safetensors",
    "model-00010-of-00048.safetensors",
    "model-00011-of-00048.safetensors",
    "model-00012-of-00048.safetensors",
    "model-00013-of-00048.safetensors",
    "model-00014-of-00048.safetensors",
    "model-00015-of-00048.safetensors",
    "model-00016-of-00048.safetensors",
    "model-00017-of-00048.safetensors",
    "model-00018-of-00048.safetensors",
    "model-00019-of-00048.safetensors",
    "model-00020-of-00048.safetensors",
    "model-00021-of-00048.safetensors",
    "model-00022-of-00048.safetensors",
    "model-00023-of-00048.safetensors",
    "model-00024-of-00048.safetensors",
    "model-00025-of-00048.safetensors",
    "model-00026-of-00048.safetensors",
    "model-00027-of-00048.safetensors",
    "model-00028-of-00048.safetensors",
    "model-00029-of-00048.safetensors",
    "model-00030-of-00048.safetensors",
    "model-00031-of-00048.safetensors",
    "model-00032-of-00048.safetensors",
    "model-00033-of-00048.safetensors",
    "model-00034-of-00048.safetensors",
    "model-00035-of-00048.safetensors",
    "model-00036-of-00048.safetensors",
    "model-00037-of-00048.safetensors",
    "model-00038-of-00048.safetensors",
    "model-00039-of-00048.safetensors",
    "model-00040-of-00048.safetensors",
    "model-00041-of-00048.safetensors",
    "model-00042-of-00048.safetensors",
    "model-00043-of-00048.safetensors",
    "model-00044-of-00048.safetensors",
    "model-00045-of-00048.safetensors",
    "model-00046-of-00048.safetensors",
    "model-00047-of-00048.safetensors",
    "model-00048-of-00048.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-Full-3epoch": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "tomaszki/nous-thirty": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "rAIfle/ohno-8x7B-fp16": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "christianbaluti/gptmodel": [
    "model.safetensors"
  ],
  "Sukjin/l2c_qdpo_3e-6_49920": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "sana280/LLama2_Fine_Tuning": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "samyak24jain/gpt2-wikitext-2-raw-v1": [
    "model.safetensors"
  ],
  "MaziyarPanahi/Mega-Miqu-WizardLM-190B-v0.1": [
    "model-00001-of-00049.safetensors",
    "model-00002-of-00049.safetensors",
    "model-00003-of-00049.safetensors",
    "model-00004-of-00049.safetensors",
    "model-00005-of-00049.safetensors",
    "model-00006-of-00049.safetensors",
    "model-00007-of-00049.safetensors",
    "model-00008-of-00049.safetensors",
    "model-00009-of-00049.safetensors",
    "model-00010-of-00049.safetensors",
    "model-00011-of-00049.safetensors",
    "model-00012-of-00049.safetensors",
    "model-00013-of-00049.safetensors",
    "model-00014-of-00049.safetensors",
    "model-00015-of-00049.safetensors",
    "model-00016-of-00049.safetensors",
    "model-00017-of-00049.safetensors",
    "model-00018-of-00049.safetensors",
    "model-00019-of-00049.safetensors",
    "model-00020-of-00049.safetensors",
    "model-00021-of-00049.safetensors",
    "model-00022-of-00049.safetensors",
    "model-00023-of-00049.safetensors",
    "model-00024-of-00049.safetensors",
    "model-00025-of-00049.safetensors",
    "model-00026-of-00049.safetensors",
    "model-00027-of-00049.safetensors",
    "model-00028-of-00049.safetensors",
    "model-00029-of-00049.safetensors",
    "model-00030-of-00049.safetensors",
    "model-00031-of-00049.safetensors",
    "model-00032-of-00049.safetensors",
    "model-00033-of-00049.safetensors",
    "model-00034-of-00049.safetensors",
    "model-00035-of-00049.safetensors",
    "model-00036-of-00049.safetensors",
    "model-00037-of-00049.safetensors",
    "model-00038-of-00049.safetensors",
    "model-00039-of-00049.safetensors",
    "model-00040-of-00049.safetensors",
    "model-00041-of-00049.safetensors",
    "model-00042-of-00049.safetensors",
    "model-00043-of-00049.safetensors",
    "model-00044-of-00049.safetensors",
    "model-00045-of-00049.safetensors",
    "model-00046-of-00049.safetensors",
    "model-00047-of-00049.safetensors",
    "model-00048-of-00049.safetensors",
    "model-00049-of-00049.safetensors"
  ],
  "metterian/llama-pro-ko-8b": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "DT12the/Math-Mixtral-7B-Dare": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Doniaa/distilroberta-base-DoniaTrials514": [
    "model.safetensors"
  ],
  "tomaszki/nous-thirty-copy": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "AstraMindAI/AstraQuasar-4B": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "yaofu/llama-2-13b-64k": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Basha738/llama2-13B-supervised-ft-10-epochs-351": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "asadmasad/ds-6-7-ds-finetuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "IEEEVITPune-AI-Team/ChatbotAlpha0.7": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Sukjin/l2c_qdpo_3e-6_LATEST": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "shidowake/swal-13B-base-bnb-4bit-chatml-revise3": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "rhplus0831/maid-yuzu-v8-alter": [
    "model-00001-of-00048.safetensors",
    "model-00002-of-00048.safetensors",
    "model-00003-of-00048.safetensors",
    "model-00004-of-00048.safetensors",
    "model-00005-of-00048.safetensors",
    "model-00006-of-00048.safetensors",
    "model-00007-of-00048.safetensors",
    "model-00008-of-00048.safetensors",
    "model-00009-of-00048.safetensors",
    "model-00010-of-00048.safetensors",
    "model-00011-of-00048.safetensors",
    "model-00012-of-00048.safetensors",
    "model-00013-of-00048.safetensors",
    "model-00014-of-00048.safetensors",
    "model-00015-of-00048.safetensors",
    "model-00016-of-00048.safetensors",
    "model-00017-of-00048.safetensors",
    "model-00018-of-00048.safetensors",
    "model-00019-of-00048.safetensors",
    "model-00020-of-00048.safetensors",
    "model-00021-of-00048.safetensors",
    "model-00022-of-00048.safetensors",
    "model-00023-of-00048.safetensors",
    "model-00024-of-00048.safetensors",
    "model-00025-of-00048.safetensors",
    "model-00026-of-00048.safetensors",
    "model-00027-of-00048.safetensors",
    "model-00028-of-00048.safetensors",
    "model-00029-of-00048.safetensors",
    "model-00030-of-00048.safetensors",
    "model-00031-of-00048.safetensors",
    "model-00032-of-00048.safetensors",
    "model-00033-of-00048.safetensors",
    "model-00034-of-00048.safetensors",
    "model-00035-of-00048.safetensors",
    "model-00036-of-00048.safetensors",
    "model-00037-of-00048.safetensors",
    "model-00038-of-00048.safetensors",
    "model-00039-of-00048.safetensors",
    "model-00040-of-00048.safetensors",
    "model-00041-of-00048.safetensors",
    "model-00042-of-00048.safetensors",
    "model-00043-of-00048.safetensors",
    "model-00044-of-00048.safetensors",
    "model-00045-of-00048.safetensors",
    "model-00046-of-00048.safetensors",
    "model-00047-of-00048.safetensors",
    "model-00048-of-00048.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-SA-FPB-full": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-SA-ESG-full": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "B2111797/recipe_gener_v8": [
    "model.safetensors"
  ],
  "elliotthwang/KimLanpuretext-phi-2-zh": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "yleo/ParrotOgno-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "RaduGabriel/Mistral-Instruct-Ukrainian-SFT": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "DT12the/Arithmo2-Mixtral-7B-Dare": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "ugshanyu/nice": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Wtzwho/Prometh-MOEM-32-tiny": [
    "model-00001-of-00025.safetensors",
    "model-00002-of-00025.safetensors",
    "model-00003-of-00025.safetensors",
    "model-00004-of-00025.safetensors",
    "model-00005-of-00025.safetensors",
    "model-00006-of-00025.safetensors",
    "model-00007-of-00025.safetensors",
    "model-00008-of-00025.safetensors",
    "model-00009-of-00025.safetensors",
    "model-00010-of-00025.safetensors",
    "model-00011-of-00025.safetensors",
    "model-00012-of-00025.safetensors",
    "model-00013-of-00025.safetensors",
    "model-00014-of-00025.safetensors",
    "model-00015-of-00025.safetensors",
    "model-00016-of-00025.safetensors",
    "model-00017-of-00025.safetensors",
    "model-00018-of-00025.safetensors",
    "model-00019-of-00025.safetensors",
    "model-00020-of-00025.safetensors",
    "model-00021-of-00025.safetensors",
    "model-00022-of-00025.safetensors",
    "model-00023-of-00025.safetensors",
    "model-00024-of-00025.safetensors",
    "model-00025-of-00025.safetensors"
  ],
  "shahzebnaveed/NeuralHermes-2.5-Mistral-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AlisaMenekse/BCPErrorCategoriesModel": [
    "adapter_model.safetensors",
    "checkpoint-61/adapter_model.safetensors"
  ],
  "DT12the/Llemma-Mixtral-7B-Dare": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "rmihaylov/Inject-7B-v5": [
    "model.safetensors"
  ],
  "Elkhayyat17/lora-llama2-Med": [
    "adapter_model.safetensors"
  ],
  "aidonuts/speedy-cactus-7575": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Brendan/tod_zero_fuohx0d2_32000": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Morningheart/commentary-generator": [
    "model.safetensors"
  ],
  "TeeZee/DarkForest-20B-v2.0": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "LoneStriker/Fimbulvetr-11B-v2-Test-14-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Fimbulvetr-11B-v2-Test-14-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "uukuguy/speechless-thoughts-mistral-7b-v1.0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Fimbulvetr-11B-v2-Test-14-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "RaduGabriel/SirUkrainian": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "LoneStriker/Fimbulvetr-11B-v2-Test-14-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Fimbulvetr-11B-v2-Test-14-8.0bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/Fimbulvetr-11B-v2-Test-14-AWQ": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Fimbulvetr-11B-v2-Test-14-GPTQ": [
    "gptq_model-4bit-32g.safetensors"
  ],
  "c-demartino/llama2-7b-chat-p-q4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "llmixer/BigWeave-v18-108b": [
    "model-00001-of-00023.safetensors",
    "model-00002-of-00023.safetensors",
    "model-00003-of-00023.safetensors",
    "model-00004-of-00023.safetensors",
    "model-00005-of-00023.safetensors",
    "model-00006-of-00023.safetensors",
    "model-00007-of-00023.safetensors",
    "model-00008-of-00023.safetensors",
    "model-00009-of-00023.safetensors",
    "model-00010-of-00023.safetensors",
    "model-00011-of-00023.safetensors",
    "model-00012-of-00023.safetensors",
    "model-00013-of-00023.safetensors",
    "model-00014-of-00023.safetensors",
    "model-00015-of-00023.safetensors",
    "model-00016-of-00023.safetensors",
    "model-00017-of-00023.safetensors",
    "model-00018-of-00023.safetensors",
    "model-00019-of-00023.safetensors",
    "model-00020-of-00023.safetensors",
    "model-00021-of-00023.safetensors",
    "model-00022-of-00023.safetensors",
    "model-00023-of-00023.safetensors"
  ],
  "llmixer/BigWeave-v20-110b": [
    "model-00001-of-00023.safetensors",
    "model-00002-of-00023.safetensors",
    "model-00003-of-00023.safetensors",
    "model-00004-of-00023.safetensors",
    "model-00005-of-00023.safetensors",
    "model-00006-of-00023.safetensors",
    "model-00007-of-00023.safetensors",
    "model-00008-of-00023.safetensors",
    "model-00009-of-00023.safetensors",
    "model-00010-of-00023.safetensors",
    "model-00011-of-00023.safetensors",
    "model-00012-of-00023.safetensors",
    "model-00013-of-00023.safetensors",
    "model-00014-of-00023.safetensors",
    "model-00015-of-00023.safetensors",
    "model-00016-of-00023.safetensors",
    "model-00017-of-00023.safetensors",
    "model-00018-of-00023.safetensors",
    "model-00019-of-00023.safetensors",
    "model-00020-of-00023.safetensors",
    "model-00021-of-00023.safetensors",
    "model-00022-of-00023.safetensors",
    "model-00023-of-00023.safetensors"
  ],
  "MaziyarPanahi/Ultra-WizardLM-120B-v0.1": [
    "model-00001-of-00025.safetensors",
    "model-00002-of-00025.safetensors",
    "model-00003-of-00025.safetensors",
    "model-00004-of-00025.safetensors",
    "model-00005-of-00025.safetensors",
    "model-00006-of-00025.safetensors",
    "model-00007-of-00025.safetensors",
    "model-00008-of-00025.safetensors",
    "model-00009-of-00025.safetensors",
    "model-00010-of-00025.safetensors",
    "model-00011-of-00025.safetensors",
    "model-00012-of-00025.safetensors",
    "model-00013-of-00025.safetensors",
    "model-00014-of-00025.safetensors",
    "model-00015-of-00025.safetensors",
    "model-00016-of-00025.safetensors",
    "model-00017-of-00025.safetensors",
    "model-00018-of-00025.safetensors",
    "model-00019-of-00025.safetensors",
    "model-00020-of-00025.safetensors",
    "model-00021-of-00025.safetensors",
    "model-00022-of-00025.safetensors",
    "model-00023-of-00025.safetensors",
    "model-00024-of-00025.safetensors",
    "model-00025-of-00025.safetensors"
  ],
  "RaduGabriel/SirUkrainian2.0": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "CreitinGameplays/elisa-chan-gpt2-medium-v2": [
    "model.safetensors"
  ],
  "Sukjin/l2c_qdpo_1e-8_LATEST": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "thrunlab/Mistral_Sparse_refined_web_50p_2024-02-15": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Sukjin/l2c_qdpo_5e-7_LATEST": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Neuranest/Qwen-1.5-0.5B-toolcall": [
    "model.safetensors"
  ],
  "sakkke/mistralai-Code-Instruct-Finetune-test": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "BarraHome/Wistral-7B-Instruct-v0.3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "aidonuts/speedy-cactus-7575-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "El-chapoo/S_Mixtral": [
    "model.safetensors"
  ],
  "paulml/DPO-Monarch7B": [
    "checkpoint-42/adapter_model.safetensors",
    "checkpoint-43/adapter_model.safetensors"
  ],
  "lunarsylph/mooncell_v6": [
    "model-00001-of-00003.safetensors",
    "model-00001-of-00004.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00003.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "deepnetguy/m-1292": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "llmixer/BigWeave-v18-108b-4.0bpw-h6-exl2": [
    "output-00001-of-00007.safetensors",
    "output-00002-of-00007.safetensors",
    "output-00003-of-00007.safetensors",
    "output-00004-of-00007.safetensors",
    "output-00005-of-00007.safetensors",
    "output-00006-of-00007.safetensors",
    "output-00007-of-00007.safetensors"
  ],
  "llmixer/BigWeave-v20-110b-4.0bpw-h6-exl2": [
    "output-00001-of-00007.safetensors",
    "output-00002-of-00007.safetensors",
    "output-00003-of-00007.safetensors",
    "output-00004-of-00007.safetensors",
    "output-00005-of-00007.safetensors",
    "output-00006-of-00007.safetensors",
    "output-00007-of-00007.safetensors"
  ],
  "prithviraj-maurya/deleteme": [
    "adapter_model.safetensors"
  ],
  "mayflowergmbh/Wiederchat-7b-dpo": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "BarraHome/Wistral-7B-Instruct-v0.4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jerikk/vda_fine_tuned_1": [
    "model.safetensors"
  ],
  "laibaazam/fyp-small-v1": [
    "model.safetensors"
  ],
  "deepnetguy/m-1321": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "RickMartel/GPT2_FT_By_NT_RAND_v9": [
    "model.safetensors"
  ],
  "ankhamun/x0o0x": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/KafkaLM-8x7b-German-V0.1-DPO-2.4bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "TeeZee/DarkForest-20B-v2.0-bpw8-h8-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "Eric111/AlphaMayo": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "LoneStriker/KafkaLM-8x7b-German-V0.1-DPO-3.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/Mega-Miqu-WizardLM-190B-v0.2": [
    "model-00001-of-00039.safetensors",
    "model-00002-of-00039.safetensors",
    "model-00003-of-00039.safetensors",
    "model-00004-of-00039.safetensors",
    "model-00005-of-00039.safetensors",
    "model-00006-of-00039.safetensors",
    "model-00007-of-00039.safetensors",
    "model-00008-of-00039.safetensors",
    "model-00009-of-00039.safetensors",
    "model-00010-of-00039.safetensors",
    "model-00011-of-00039.safetensors",
    "model-00012-of-00039.safetensors",
    "model-00013-of-00039.safetensors",
    "model-00014-of-00039.safetensors",
    "model-00015-of-00039.safetensors",
    "model-00016-of-00039.safetensors",
    "model-00017-of-00039.safetensors",
    "model-00018-of-00039.safetensors",
    "model-00019-of-00039.safetensors",
    "model-00020-of-00039.safetensors",
    "model-00021-of-00039.safetensors",
    "model-00022-of-00039.safetensors",
    "model-00023-of-00039.safetensors",
    "model-00024-of-00039.safetensors",
    "model-00025-of-00039.safetensors",
    "model-00026-of-00039.safetensors",
    "model-00027-of-00039.safetensors",
    "model-00028-of-00039.safetensors",
    "model-00029-of-00039.safetensors",
    "model-00030-of-00039.safetensors",
    "model-00031-of-00039.safetensors",
    "model-00032-of-00039.safetensors",
    "model-00033-of-00039.safetensors",
    "model-00034-of-00039.safetensors",
    "model-00035-of-00039.safetensors",
    "model-00036-of-00039.safetensors",
    "model-00037-of-00039.safetensors",
    "model-00038-of-00039.safetensors",
    "model-00039-of-00039.safetensors"
  ],
  "ankhamun/x0o0_0x0o": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/KafkaLM-8x7b-German-V0.1-DPO-3.5bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "Kquant03/Buttercup-4x7B-V2-bf16": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "LoneStriker/KafkaLM-8x7b-German-V0.1-DPO-3.75bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "hyperclouds/sn9": [
    "model.safetensors"
  ],
  "ankhamun/PoI6x_x9IoP": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "aidonuts/forthright-smooch-141-s200": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SuYee189/myanmar-gpt-health-faq": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "LoneStriker/KafkaLM-8x7b-German-V0.1-DPO-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/Kyllene-34B-v1.1-2.75bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/Kyllene-34B-v1.1-2.8bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/KafkaLM-8x7b-German-V0.1-DPO-5.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "deepnetguy/m-1422": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "tsavage68/chat_1000STEPS_1e7_03beta_DPO": [
    "final_checkpoint/model-00001-of-00003.safetensors",
    "final_checkpoint/model-00002-of-00003.safetensors",
    "final_checkpoint/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/KafkaLM-8x7b-German-V0.1-DPO-6.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "mateussj/tinyllama-moe-2x1.1B": [
    "model-00001-of-00001.safetensors"
  ],
  "rmihaylov/Inject-7B-v6": [
    "model.safetensors"
  ],
  "sonthenguyen/OpenHermes-2.5-Mistral-7B-mt-bench-DPO-original-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "devashat/244-pretrained": [
    "model.safetensors"
  ],
  "SuYee189/myanmar-gpt-health-faq1": [
    "model.safetensors"
  ],
  "hamel/code-llama-test": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jeiku/Cookie_7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TeeZee/DarkForest-20B-v2.0-bpw4-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "Kquant03/Buttercup-4x7B-V2-laser": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "deepnetguy/t-1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Sukjin/l2c_qdpo_5e-9_LATEST": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Eric111/CatunaMayo": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "NilanE/karasu-web": [
    "model.safetensors"
  ],
  "mayflowergmbh/Wiederchat-7b-dpo-laser": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "yleo/ParrotMathOgno-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "yleo/ParrotMOgno-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jeiku/Paranoid_Android_7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "wndiros/diva_em_leo_mistral_v06": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors",
    "model.safetensors"
  ],
  "deepnetguy/t-2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "aidonuts/forthright-smooch-141-s800": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tomaszki/nous-thirty-one": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "NilanE/karasu-translation": [
    "model.safetensors"
  ],
  "tomaszki/nous-thirty-one-copy": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "aidonuts/forthright-smooch-141-s1000": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jspr/miqurelian-120b": [
    "model-00001-of-00025.safetensors",
    "model-00002-of-00025.safetensors",
    "model-00003-of-00025.safetensors",
    "model-00004-of-00025.safetensors",
    "model-00005-of-00025.safetensors",
    "model-00006-of-00025.safetensors",
    "model-00007-of-00025.safetensors",
    "model-00008-of-00025.safetensors",
    "model-00009-of-00025.safetensors",
    "model-00010-of-00025.safetensors",
    "model-00011-of-00025.safetensors",
    "model-00012-of-00025.safetensors",
    "model-00013-of-00025.safetensors",
    "model-00014-of-00025.safetensors",
    "model-00015-of-00025.safetensors",
    "model-00016-of-00025.safetensors",
    "model-00017-of-00025.safetensors",
    "model-00018-of-00025.safetensors",
    "model-00019-of-00025.safetensors",
    "model-00020-of-00025.safetensors",
    "model-00021-of-00025.safetensors",
    "model-00022-of-00025.safetensors",
    "model-00023-of-00025.safetensors",
    "model-00024-of-00025.safetensors",
    "model-00025-of-00025.safetensors"
  ],
  "onlinex/stablelm-2-zephyr-1_6b-gptq-4bit": [
    "model.safetensors"
  ],
  "superdocker/anonymous-model-8": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "RickMartel/GPT2_FT_By_NT_RAND_v10": [
    "model.safetensors"
  ],
  "lingchensanwen/mistralai-Instruct-Finetune-salience-Feb15": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "BrandonZYW/opt-1.3b-InBedder": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "BrandonZYW/opt-2.7b-InBedder": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "macadeliccc/DrKlaus-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "SeifGad/FB-xglm-Nuclear": [
    "model.safetensors"
  ],
  "NilanE/karasu-translation-2": [
    "model.safetensors"
  ],
  "jeiku/NarrativeNexus_7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "TeeZee/llama-2-7B-pirate-speech-QLORA": [
    "model.safetensors"
  ],
  "NurtureAI/minicpm-2b-sft-bf16-llamafied-16k": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mzbac/phi-2-2x4-hf": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lunarsylph/mooncell_v7": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "IbuNai/origami-7b-v0.2-init": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "ThomasGerald/multiwoz_with_ground_truth_act": [
    "model.safetensors"
  ],
  "DatadudeDev/BibleBERT": [
    "adapter_model.safetensors",
    "checkpoint-1590/adapter_model.safetensors"
  ],
  "tsavage68/chat_1000STEPS_1e7rate_01beta_DPO": [
    "final_checkpoint/model-00001-of-00003.safetensors",
    "final_checkpoint/model-00002-of-00003.safetensors",
    "final_checkpoint/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Niraya666/phi-1_5-1_3B-lora-funcall-0215": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "NLUHOPOE/test-case-0": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "InnerI/A-I-0xtom-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "jaehy12/jh_10.7B_come": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "aisuko/opt-125m-awq": [
    "model.safetensors"
  ],
  "kubwa/Phi-2-sql-merge-slerp": [
    "model-00001-of-00001.safetensors"
  ],
  "tsavage68/chat_1000STEPS_1e7_05beta_DPO": [
    "final_checkpoint/model-00001-of-00003.safetensors",
    "final_checkpoint/model-00002-of-00003.safetensors",
    "final_checkpoint/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kubwa/code-llama-text-to-sql-xgen-7b-8k-merge-slerp": [
    "model-00001-of-00001.safetensors"
  ],
  "aloobun/Reyna-Mini-1.8B-v0.2": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "systemk/origami-7b-v0.2-init": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-NQA-ARI-full": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Drewskidang/DPO_RAG_UP": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-NQA-EXT-full": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "tsavage68/chat_1000STEPS_1e7rate_SFT_SFT": [
    "final_checkpoint/model-00001-of-00003.safetensors",
    "final_checkpoint/model-00002-of-00003.safetensors",
    "final_checkpoint/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jsfs11/RandomMergeNormWEIGHTEDv3-7B-TIES": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Drewskidang/GGUFF_DPO_STAR": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Basha738/llama2-13B-supervised-eos-ft-10-epochs-351": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-NQA-COM-full": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "thrunlab/Mistral_Sparse_refined_web_relu_2024-02-15": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dbandrews/mistral-v3-dpo-db20c9b7-8db0-4937-a8b6-65ff4aa77ebf-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "greatakela/mistral_instruct_classifyFPB_full_240215": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "huyhuyvu01/Vinallama-Law-Pretrain_7B": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "thrunlab/Mistral_Sparse_refined_web_50p_debugging_2024-02-15": [
    "model.safetensors"
  ],
  "JaeyeonKang/CCK_Asura_v1.1.0": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "thrunlab/Mistral_Sparse_refined_web_90p_2024-02-15": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lunarsylph/mooncell_v8": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lunarsylph/mooncell_v9": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-TQA-full": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Sukjin/l2c_w3_qdpo_5e-7_LATEST": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "tsavage68/chat_1000STEPS_1e6rate_SFT_SFT": [
    "final_checkpoint/model-00001-of-00003.safetensors",
    "final_checkpoint/model-00002-of-00003.safetensors",
    "final_checkpoint/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Lienid/nous-finetune-model": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kubwa/sqlcoder-llama-2-ko-7b-merge-slerp": [
    "model-00001-of-00001.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-QA-MCQA-full": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "giraffe176/Open_Maid_Samantha_Hermes_Orca": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ethensanchez/MiniLlamaTest": [
    "checkpoint-1594/model.safetensors",
    "checkpoint-810/model.safetensors"
  ],
  "ankhamun/PoI60x_x09IoP": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "vishnukv/llama2-3b-4k": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-QA-EQA-full": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "jisukim8873/falcon-7B-case-6": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "obamaTeo/mistral-finetune-16bit-ver3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "suyashhchougule/cl_clinton_axolotl_merge": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "lunarsylph/mooncell_v10": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "chienweichang/Breeze-7B-Instruct-64k-v0_1-TaiwanChat": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "hingeankit/llm_v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "deepnetguy/t-1505": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Raven-Pro/4bit": [
    "model.safetensors"
  ],
  "itsyasin2002ai/yaseen-codeparrot-ds": [
    "model.safetensors"
  ],
  "Charles333/gpt2_fintuned_json_data": [
    "model.safetensors"
  ],
  "tsavage68/chat_1000STEPS_1e6_05beta_DPO": [
    "final_checkpoint/model-00001-of-00003.safetensors",
    "final_checkpoint/model-00002-of-00003.safetensors",
    "final_checkpoint/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "longcule123/adapter-14-2_merged_162": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "DT12the/Intel-Slerp-Mixtral-7B-Dare": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "sravaniayyagari/llama2-finetuned-model-latest": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "ArthurZ/mamba-130m": [
    "model.safetensors"
  ],
  "Sukjin/l2c_w3_qdpo_7e-7_LATEST": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "fzzhang/Marcoroni-neural-chat-7B-v2_gsm8k_merged": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Fukurokun/MemGPT-DPO-MoE-2-mem-6.0bpw-exl2": [
    "cal_data.safetensors",
    "hidden_states.safetensors",
    "hidden_states_temp.safetensors"
  ],
  "chakradharkowsik/codellama-7b-instruct-hf-2Gb-sharded": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "deepnetguy/t-1506": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "worldboss/tinyllama-1.8B-Chat-elbowai-ft": [
    "adapter_model.safetensors",
    "checkpoint-408/adapter_model.safetensors"
  ],
  "rhplus0831/maid-yuzu-v8-exl2-3.5bpw-rpcal": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-QA-BQA-full": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Aspik101/nous14_c": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jaehy12/jh_new_2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "arhanovich/cnf123": [
    "model-00001-of-00017.safetensors",
    "model-00002-of-00017.safetensors",
    "model-00003-of-00017.safetensors",
    "model-00004-of-00017.safetensors",
    "model-00005-of-00017.safetensors",
    "model-00006-of-00017.safetensors",
    "model-00007-of-00017.safetensors",
    "model-00008-of-00017.safetensors",
    "model-00009-of-00017.safetensors",
    "model-00010-of-00017.safetensors",
    "model-00011-of-00017.safetensors",
    "model-00012-of-00017.safetensors",
    "model-00013-of-00017.safetensors",
    "model-00014-of-00017.safetensors",
    "model-00015-of-00017.safetensors",
    "model-00016-of-00017.safetensors",
    "model-00017-of-00017.safetensors"
  ],
  "jucasoliveira/tgs-model": [
    "model.safetensors"
  ],
  "Daniil0209/llama-2-7b-code-tuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Brackly/malawi_quantized_model": [
    "model.safetensors"
  ],
  "jungyuko/DAVinCI-Yi-Ko-6B-v1.1": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "fzzhang/mistralv1_gsm8k_merged": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "andrealexroom/LexLLMv0.0.0.x.10.7a": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "thrunlab/Mistral_Sparse_refined_web_90p_2024-02-16": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "thrunlab/Mistral_Sparse_refined_web_50p_2024-02-16": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "thrunlab/Mistral_Sparse_refined_web_relu_2024-02-16": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "worldboss/tinyllama-1.8B-Chat-nia-elbowai-ft-v2": [
    "adapter_model.safetensors",
    "checkpoint-2/adapter_model.safetensors"
  ],
  "bardsai/jaskier-7b-dpo-v5.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "isha1/sap_abap_ft_model_orig_150": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "thrunlab/Mistral_Sparse_refined_web_70p_2024-02-16": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AdityaLavaniya/TinyLlama-Fitness-Instructor": [
    "model.safetensors"
  ],
  "chienweichang/Breeze-7B-Instruct-v0_1-TaiwanChat": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "Menouar/saqr-7b-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ConvexAI/Luminex-34B-v0.1": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "occiglot/occiglot-7b-eu5": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "rhplus0831/maid-yuzu-v8-alter-exl2-3.5bpw-rpcal": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "corneille97/llama-2-7b-4bits-turbo": [
    "model.safetensors"
  ],
  "FloVolo/mistral-flo-finetune-2-T4": [
    "adapter_model.safetensors"
  ],
  "rmihaylov/Inject-7B-v7": [
    "model.safetensors"
  ],
  "maramzarkaoui/facebook1": [
    "adapter_model.safetensors",
    "checkpoint-60/adapter_model.safetensors"
  ],
  "sam749/Airavata-GGUF": [],
  "rwh/tensor": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "shahzebnaveed/NeuralPipe-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "jaehy12/jh_new_2_epochs10": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "p1atdev/dart-base-random": [
    "model.safetensors"
  ],
  "shahzebnaveed/StarlingHermes-2.5-Mistral-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "llmixer/Midnight-Rose-103B-v2.0.3-4.0bpw-h6-exl2": [
    "output-00001-of-00007.safetensors",
    "output-00002-of-00007.safetensors",
    "output-00003-of-00007.safetensors",
    "output-00004-of-00007.safetensors",
    "output-00005-of-00007.safetensors",
    "output-00006-of-00007.safetensors",
    "output-00007-of-00007.safetensors"
  ],
  "lgodwangl/test3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "llmixer/Midnight-Rose-103B-v2.0.3-5.0bpw-h6-exl2": [
    "output-00001-of-00008.safetensors",
    "output-00002-of-00008.safetensors",
    "output-00003-of-00008.safetensors",
    "output-00004-of-00008.safetensors",
    "output-00005-of-00008.safetensors",
    "output-00006-of-00008.safetensors",
    "output-00007-of-00008.safetensors",
    "output-00008-of-00008.safetensors"
  ],
  "llmixer/Midnight-Rose-103B-v2.0.3-3.5bpw-h6-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "robinsmits/Mistral-Instruct-7B-v0.2-ChatAlpacaV2-DPO-4bit": [
    "model.safetensors"
  ],
  "El-chapoo/E_Llama2": [
    "model.safetensors",
    "tmp-checkpoint-100/model.safetensors"
  ],
  "kouki13/newfb": [
    "adapter_model.safetensors",
    "checkpoint-6/adapter_model.safetensors"
  ],
  "Jaredquek/NewOlierConvoFeb16Awq": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "asadmasad/ds-33b-lora-finetuned-39k": [
    "adapter_model.safetensors"
  ],
  "tomaszki/nous-thirty-two": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "yeniceriSGK/mistral-7b-pibrain-v3": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "aidonuts/forthright-smooch-141-s3600": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "bardsai/jaskier-7b-dpo-v5.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kheopss/kheops_llm_V0.12": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/Ultra-Smaug-125B-v0.1": [
    "model-00001-of-00026.safetensors",
    "model-00002-of-00026.safetensors",
    "model-00003-of-00026.safetensors",
    "model-00004-of-00026.safetensors",
    "model-00005-of-00026.safetensors",
    "model-00006-of-00026.safetensors",
    "model-00007-of-00026.safetensors",
    "model-00008-of-00026.safetensors",
    "model-00009-of-00026.safetensors",
    "model-00010-of-00026.safetensors",
    "model-00011-of-00026.safetensors",
    "model-00012-of-00026.safetensors",
    "model-00013-of-00026.safetensors",
    "model-00014-of-00026.safetensors",
    "model-00015-of-00026.safetensors",
    "model-00016-of-00026.safetensors",
    "model-00017-of-00026.safetensors",
    "model-00018-of-00026.safetensors",
    "model-00019-of-00026.safetensors",
    "model-00020-of-00026.safetensors",
    "model-00021-of-00026.safetensors",
    "model-00022-of-00026.safetensors",
    "model-00023-of-00026.safetensors",
    "model-00024-of-00026.safetensors",
    "model-00025-of-00026.safetensors",
    "model-00026-of-00026.safetensors"
  ],
  "davo15/mistral-7b-instruct02-quant": [
    "model.safetensors"
  ],
  "Owhslp/nous_researcher_tuning_1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "fzzhang/Marcoroni-neural-chat-7B-v2_gsm8k_merged_s": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "andreasnaoum/new_model": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "aevalone/aevalone": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "RaduGabriel/SirUkrainian2.0DPO": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "bardsai/jaskier-7b-dpo-v5.5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sethuiyer/Aika-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "aidonuts/forthright-smooch-141-s4000": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ankhamun/IxI00_00IxI": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/Supreme-Smaug-230B-v0.1": [
    "model-00001-of-00047.safetensors",
    "model-00002-of-00047.safetensors",
    "model-00003-of-00047.safetensors",
    "model-00004-of-00047.safetensors",
    "model-00005-of-00047.safetensors",
    "model-00006-of-00047.safetensors",
    "model-00007-of-00047.safetensors",
    "model-00008-of-00047.safetensors",
    "model-00009-of-00047.safetensors",
    "model-00010-of-00047.safetensors",
    "model-00011-of-00047.safetensors",
    "model-00012-of-00047.safetensors",
    "model-00013-of-00047.safetensors",
    "model-00014-of-00047.safetensors",
    "model-00015-of-00047.safetensors",
    "model-00016-of-00047.safetensors",
    "model-00017-of-00047.safetensors",
    "model-00018-of-00047.safetensors",
    "model-00019-of-00047.safetensors",
    "model-00020-of-00047.safetensors",
    "model-00021-of-00047.safetensors",
    "model-00022-of-00047.safetensors",
    "model-00023-of-00047.safetensors",
    "model-00024-of-00047.safetensors",
    "model-00025-of-00047.safetensors",
    "model-00026-of-00047.safetensors",
    "model-00027-of-00047.safetensors",
    "model-00028-of-00047.safetensors",
    "model-00029-of-00047.safetensors",
    "model-00030-of-00047.safetensors",
    "model-00031-of-00047.safetensors",
    "model-00032-of-00047.safetensors",
    "model-00033-of-00047.safetensors",
    "model-00034-of-00047.safetensors",
    "model-00035-of-00047.safetensors",
    "model-00036-of-00047.safetensors",
    "model-00037-of-00047.safetensors",
    "model-00038-of-00047.safetensors",
    "model-00039-of-00047.safetensors",
    "model-00040-of-00047.safetensors",
    "model-00041-of-00047.safetensors",
    "model-00042-of-00047.safetensors",
    "model-00043-of-00047.safetensors",
    "model-00044-of-00047.safetensors",
    "model-00045-of-00047.safetensors",
    "model-00046-of-00047.safetensors",
    "model-00047-of-00047.safetensors"
  ],
  "omniquad/ent_val_personal_just_lora_adpt": [
    "model.safetensors"
  ],
  "maramzarkaoui/mistra": [
    "adapter_model.safetensors",
    "checkpoint-9/adapter_model.safetensors"
  ],
  "xxx777xxxASD/10.7B-Loyal-Mistral-Maid-32k-v0.2-A": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Drewskidang/Textbook_AWQ_DARKSTAR": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-All-3600-per400-epoch8": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "atmansingh/medperp": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "fzzhang/mistralv1_gsm8k_merged_s": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "HsuanLLM/BreezeDolphinDPO-7B-DARE": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Viet-Mistral/Vistral-7B-Chat-mlx-4bit": [
    "model.safetensors"
  ],
  "cckevinn/SeeClick-mind2web": [
    "model-00001-of-00010.safetensors",
    "model-00002-of-00010.safetensors",
    "model-00003-of-00010.safetensors",
    "model-00004-of-00010.safetensors",
    "model-00005-of-00010.safetensors",
    "model-00006-of-00010.safetensors",
    "model-00007-of-00010.safetensors",
    "model-00008-of-00010.safetensors",
    "model-00009-of-00010.safetensors",
    "model-00010-of-00010.safetensors"
  ],
  "tsavage68/chat_1000STEPS_1e5rate_SFT_SFT": [
    "final_checkpoint/model-00001-of-00003.safetensors",
    "final_checkpoint/model-00002-of-00003.safetensors",
    "final_checkpoint/model-00003-of-00003.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "bardsai/jaskier-7b-dpo-v5.6": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "RickMartel/GPT2_FT_By_NT_RAND_v11": [
    "model.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-All-900-per100-epoch16": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "obamaTeo/mistral-finetune-16bit-ver4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Bazsalanszky/Mistral-7b-0.1-alpaca-hun-gemini": [
    "adapter_model.safetensors"
  ],
  "llmixer/Midnight-Rose-103B-v2.0.3-3.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "llmixer/Midnight-Rose-103B-v2.0.3-2.4bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "shidowake/swal-13B-base-bnb-4bit-default-tokenizer": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Owhslp/nous_researcher_tuning_2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "orionweller/legal-mistral-citation-remover": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "andrealexroom/LexLLMv0.0.0.x.10.8a": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ankhamun/Ixo_-_oxI": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-QA-1200-per400-epoch8": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "aidonuts/charming-cupid-142-s4600": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ashishkgpian/mixtral4bit": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "sonthenguyen/OpenHermes-2.5-Mistral-7B-mt-bench-DPO-original-v3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Xapien/starling_dre_sft_merged_002": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "El-chapoo/X_Llama2": [
    "model.safetensors"
  ],
  "deepnet/SN6-67a": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "deepnet/SN6-30b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-SA-800-per400-epoch8": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "johannhartmann/Brezn-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ken-miller/tris-2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "deepnet/SN6-67b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-QA-300-per100-epoch16": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Josephgflowers/TinyLlama-748M-Reason-With-Cinder-Test-2": [
    "model.safetensors"
  ],
  "Test157t/Prima-LelantaclesV2-7b": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "ankhamun/xv_-_vx": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mayacinka/NeuralZephyr-Beagle-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "shidowake/SOLAR-10.7B-base-bnb-4bit-revised": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "deepnetguy/t-3": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "aidonuts/charming-cupid-142-s5000": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "deepnetguy/t-4": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-TQA-400-epoch8": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/LWM-Text-Chat-1M-AWQ": [
    "model.safetensors"
  ],
  "aidonuts/morbid-stitch-677": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "macadeliccc/WestLake-2x7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "chasedreaminf/Dream-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "MAdAiLab/llama2_7b_base_adapter_merged_final": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "lgodwangl/test4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "macadeliccc/KunoichiLake-2x7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-TQA-100-epoch16": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Owhslp/nous_researcher_tuning_3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "alxcrypto/gpt2-l": [
    "model.safetensors"
  ],
  "ankhamun/xol_lox": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "NilanE/karasu-web-2": [
    "model.safetensors"
  ],
  "AlisaMenekse/BCPErrorCategoriesModel25k": [
    "adapter_model.safetensors",
    "checkpoint-258/adapter_model.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-SA-FPB-400-epoch8": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "deepnetguy/t-1820": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mateussj/tinyllama-moe-2x1.1B_v2": [
    "model-00001-of-00001.safetensors"
  ],
  "sakkke/aishd-0217": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mateussj/tinyllama-moe-2x1.1B_v3": [
    "model-00001-of-00001.safetensors"
  ],
  "deepnetguy/t-1856": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-SA-FPB-100-epoch16": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Dagonez/DialoGPT-small-Barney-Bot": [
    "model.safetensors"
  ],
  "rmihaylov/Inject-7B-v8": [
    "model.safetensors"
  ],
  "robinsmits/Mistral-Instruct-7B-v0.2-ChatAlpacaV2-DPOa-4bit": [
    "model.safetensors"
  ],
  "gregor160300/llama2-fine-tuned-sql-create-context-1000-steps": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "deepnet/SN6-30ab": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ambrosfitz/neural-history-chat_v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Lienid/nous-2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "deepnetguy/t-1906": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "HuggingFaceM4/idefics2-bnb-4bit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jaydeepb/gpt2-wikienron_16k": [
    "model.safetensors"
  ],
  "Exidna/dialoGPTTuned-v3": [
    "adapter_model.safetensors",
    "checkpoint-135/adapter_model.safetensors"
  ],
  "LiteLLMs/OGNO-7B-GGUF": [],
  "Yuma42/KangalKhan-Ruby-7B-Fixed": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "ankhamun/x0o0I_I0x0o": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "JakeTurner616/Adonalsium-gpt2": [
    "model.safetensors"
  ],
  "sherryycxie/finetuned_distilgpt2_sst2_negation0.0_pretrainedTrue_epochs3": [
    "model.safetensors"
  ],
  "anik424/OpenHermes-2.5-Mistral-7B_toxic-removed-dpo-v0.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Lienid/nous-3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "onlinex/phi-1_5-gptq-4bit": [
    "model.safetensors"
  ],
  "Omotayo/ainao-7B-slerp": [
    "model-00001-of-00011.safetensors",
    "model-00002-of-00011.safetensors",
    "model-00003-of-00011.safetensors",
    "model-00004-of-00011.safetensors",
    "model-00005-of-00011.safetensors",
    "model-00006-of-00011.safetensors",
    "model-00007-of-00011.safetensors",
    "model-00008-of-00011.safetensors",
    "model-00009-of-00011.safetensors",
    "model-00010-of-00011.safetensors",
    "model-00011-of-00011.safetensors"
  ],
  "jondurbin/bagel-34b-v0.4": [
    "model-00001-of-00018.safetensors",
    "model-00002-of-00018.safetensors",
    "model-00003-of-00018.safetensors",
    "model-00004-of-00018.safetensors",
    "model-00005-of-00018.safetensors",
    "model-00006-of-00018.safetensors",
    "model-00007-of-00018.safetensors",
    "model-00008-of-00018.safetensors",
    "model-00009-of-00018.safetensors",
    "model-00010-of-00018.safetensors",
    "model-00011-of-00018.safetensors",
    "model-00012-of-00018.safetensors",
    "model-00013-of-00018.safetensors",
    "model-00014-of-00018.safetensors",
    "model-00015-of-00018.safetensors",
    "model-00016-of-00018.safetensors",
    "model-00017-of-00018.safetensors",
    "model-00018-of-00018.safetensors"
  ],
  "CultriX/NeuralTrix-7B-NO-INST": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "anik424/OpenHermes-2.5-Mistral-7B_toxic-removed-dpo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "nesteggs/deepseek-moe-16b-chat": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "DrNicefellow/Qwen1.5-72B-Chat-4.65bpw-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "DrNicefellow/Qwen1.5-72B-Chat-5bpw-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "aidonuts/charming-cupid-142-s6000": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Weni/ZeroShot-3.3.0-Mistral-7b-Multilanguage-3.1.0-merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Weni/ZeroShot-3.3.0-Mistral-7b-Multilanguage-3.1.0-AWQ": [
    "model.safetensors"
  ],
  "levimorin/taonet-vali": [
    "model.safetensors"
  ],
  "DjSteker/spanish-gpt2": [
    "model.safetensors"
  ],
  "levimorin/taonet-vali3": [
    "model.safetensors"
  ],
  "Elizezen/Antler-7B-GPTQ": [
    "model.safetensors"
  ],
  "openvoid/prox-solar-10.7b": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "Drewskidang/MERGEBOY": [
    "model-00001-of-00009.safetensors",
    "model-00002-of-00009.safetensors",
    "model-00003-of-00009.safetensors",
    "model-00004-of-00009.safetensors",
    "model-00005-of-00009.safetensors",
    "model-00006-of-00009.safetensors",
    "model-00007-of-00009.safetensors",
    "model-00008-of-00009.safetensors",
    "model-00009-of-00009.safetensors"
  ],
  "ChaoticNeutrals/Cookie_7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "levimorin/taonet-vali4": [
    "model.safetensors"
  ],
  "lgodwangl/test5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "deepnetguy/t-1962": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Deadwalker0/Maverickcodellama-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Lienid/nous-four": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "DreadPoor/WhyAreWeStillHere-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "andyleetw/NeuralPipe-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "LoneStriker/LWM-Text-Chat-128K-AWQ": [
    "model.safetensors"
  ],
  "LoneStriker/LWM-Text-Chat-256K-AWQ": [
    "model.safetensors"
  ],
  "joanlei/llama-2-7b-chat-guanaco_2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "deepnetguy/t-2104": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "worldboss/tinyllama-1.8B-Chat-nia-elbowai-ft-v3": [
    "checkpoint-2/adapter_model.safetensors",
    "model.safetensors"
  ],
  "LoneStriker/LWM-Text-Chat-512K-AWQ": [
    "model.safetensors"
  ],
  "luaqi/sn9_v40": [
    "model.safetensors"
  ],
  "Lienid/nous-five": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "antiven0m/finch-truthy-dpo": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kaitchup/Qwen1.5-7B-gptq-4bit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "macadeliccc/SmaugDolphin-60B": [
    "model-00001-of-00013.safetensors",
    "model-00002-of-00013.safetensors",
    "model-00003-of-00013.safetensors",
    "model-00004-of-00013.safetensors",
    "model-00005-of-00013.safetensors",
    "model-00006-of-00013.safetensors",
    "model-00007-of-00013.safetensors",
    "model-00008-of-00013.safetensors",
    "model-00009-of-00013.safetensors",
    "model-00010-of-00013.safetensors",
    "model-00011-of-00013.safetensors",
    "model-00012-of-00013.safetensors",
    "model-00013-of-00013.safetensors"
  ],
  "MAdAiLab/llama2_7b_bf16_adapter_merged_final": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "crumb/transformer-118m-slimpajama-2-2GT": [
    "model.safetensors"
  ],
  "IBM-DTT/sap_abap_ft_model_orig_150_v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/ShoriRP-merged-v0.60-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/ShoriRP-merged-v0.60-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "cjsanjay/llama-2-7b-domain-tuned": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/ShoriRP-merged-v0.60-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "kaitchup/Qwen1.5-7B-awq-4bitt": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Xenon1/Oasis": [
    "final_checkpoint/adapter_model.safetensors",
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/ShoriRP-merged-v0.60-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "kaitchup/Qwen1.5-7B-awq-4bit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/ShoriRP-merged-v0.60-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "kaitchup/Qwen1.5-7B-bnb-4bit": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Xenon1/Voyage": [
    "final_checkpoint/adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "hbin0701/codellama_pot": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "10jqk1/Mistral-7B-Instruct-ADDTOKEN": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/ShoriRP-merged-v0.57-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "jan-hq/stealth-finance-v3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/ShoriRP-merged-v0.57-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "fzzhang/toten_gsm8k_merged_s": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/ShoriRP-merged-v0.57-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "Malmika/gpt2-wiki": [
    "model.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-NQA-1200-per400-epoch8": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/ShoriRP-merged-v0.57-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/ShoriRP-merged-v0.57-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "antiven0m/finch-shorirp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Locutusque/Hercules-3.0-Mistral-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "sonthenguyen/OpenHermes-2.5-Mistral-7B-mt-bench-DPO-recovered-v2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "onkpannu/tiny1": [
    "adapter_model.safetensors",
    "checkpoint-6/adapter_model.safetensors",
    "checkpoint-60/adapter_model.safetensors"
  ],
  "reachrkr/falcon-rw-1bt-gptq-4bit-ptb": [
    "model.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-SA-200-per100-epoch16": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-NQA-300-per100-epoch16": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "deepapaikar/llama_mistral": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "Harmj0y/nemesis-bge-small": [
    "model.safetensors"
  ],
  "gregor160300/llama2-fine-tuned-deny-sql-1-epoch": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Alkamal01/Malawi-Public-Health-Systems": [
    "model.safetensors"
  ],
  "tanamettpk/TC-instruct_v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "deepnetguy/f73dd4bb": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-SA-ESG-400-epoch8": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Haary/merak-2-7b-id": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "reachrkr/falcon-rw-1bt-gptq-2bit-ptb": [
    "model.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-NQA-ARI-400-epoch8": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "onkpannu/tiny5": [
    "adapter_model.safetensors",
    "checkpoint-18/adapter_model.safetensors",
    "checkpoint-6/adapter_model.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-SA-ESG-100-epoch16": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "solidrust/samantha-1.1-westlake-7b-laser-AWQ": [
    "model.safetensors"
  ],
  "s0wa48/miner_sn9_48": [
    "model.safetensors"
  ],
  "longcule123/book_132_merged": [
    "model.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-NQA-ARI-100-epoch16": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "phamnam/SeaLM-FT": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "phamnam/Vistral-FT": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "Owhslp/nous_researcher_tuning_4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "s0wa48/sn9_01_t": [
    "model.safetensors"
  ],
  "alxcrypto/gpt2-l-2": [
    "model.safetensors"
  ],
  "andrealexroom/LexLLMv0.0.0.x.10.9a": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Deadwalker0/maverickPhi-2": [
    "checkpoint-220/model-00001-of-00002.safetensors",
    "checkpoint-220/model-00002-of-00002.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-NQA-EXT-400-epoch8": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Jamie0510/Llama-2-7b-chat-finetune": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "murokhos/finetune-pantun": [
    "model.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-NQA-EXT-100-epoch16": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "RefalMachine/ruadapt_solar_10.7_part1": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "OEvortex/vortex-3b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-NQA-COM-400-epoch8": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "AlisaMenekse/BCPErrorCategoriesModel50_k": [
    "adapter_model.safetensors",
    "checkpoint-510/adapter_model.safetensors"
  ],
  "Owhslp/nous_researcher_tuning_5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "solidrust/dolphin-2.6-mistral-7b-dpo-laser-AWQ": [
    "model.safetensors"
  ],
  "El-chapoo/X-Treme_Mixtral": [
    "model.safetensors",
    "tmp-checkpoint-100/model.safetensors"
  ],
  "cloudyu/Mixtral_13B_Chat": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "mehdirafiei/SQLCODER7B2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "CesarChaMal/my-personal-model": [
    "model.safetensors"
  ],
  "Tann-dev/sex-chat-dirty-girlfriend": [
    "model.safetensors"
  ],
  "babybirdprd/moe-minicpm-x4-base": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "fzzhang/toten_alpaca_v1_tune_merged": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "feabries/TaiwanWordTranslator-v0.1": [
    "model.safetensors"
  ],
  "MAdAiLab/llama2_7b_chat_adapter_merged_final": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "fzzhang/mistralv1_gsm8k_qo_b4_merged_s": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "xxx777xxxASD/10.7B-Loyal-Toppy-Maid": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "sayhan/OpenHermes-2.5-Strix-Philosophy-Mistral-7B": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Owhslp/nous_researcher_tuning_6": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-NQA-COM-100-epoch16": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "lgodwangl/test6": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-QA-MCQA-400-epoch8": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "adamo1139/LWM-7B-1M-1000000ctx-AEZAKMI-3_1-1702": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "maywell/kiqu-70b": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "salangarica/finetune-mistral-DA": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "luaqi/sn9_v60": [
    "model.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-QA-MCQA-100-epoch16": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/Mistral-7B-Instruct-v0.2-Neural-Story-AWQ": [
    "model.safetensors"
  ],
  "LoneStriker/Mistral-7B-Instruct-v0.2-Neural-Story-GPTQ": [
    "gptq_model-4bit-32g.safetensors"
  ],
  "Owhslp/nous_researcher_tuning_7": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Qwen1.5-4B-Chat-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Qwen1.5-4B-Chat-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Qwen1.5-4B-Chat-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Qwen1.5-4B-Chat-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Qwen1.5-4B-Chat-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "tanamettpk/TC-instruc_v1_rp": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "IBM-DTT/sap_abap_ft_codelama_7b_orig_150_ds_v1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Aspik101/nous_m6": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "mazing/Tableshift-Assistments-64shots-Mistral-7B-Instruct-v0.2": [
    "model.safetensors"
  ],
  "LoneStriker/Qwen1.5-7B-Chat-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "CorticalStack/mistral-7b-dolphin-sft": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Qwen1.5-7B-Chat-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Qwen1.5-7B-Chat-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Qwen1.5-7B-Chat-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Qwen1.5-7B-Chat-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "lgodwangl/test7": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "CorticalStack/mistral-7b-openhermes-sft": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "DreadPoor/JustToSuffer-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "LoneStriker/Qwen1.5-14B-Chat-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Qwen1.5-14B-Chat-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Qwen1.5-14B-Chat-5.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "mosesdaudu/AfriXLM-MD": [
    "model.safetensors"
  ],
  "LoneStriker/Qwen1.5-14B-Chat-6.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "cookinai/OrcaHermes-Mistral-70B-miqu": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "mayacinka/Buttercup-Smaug": [
    "model-00001-of-00023.safetensors",
    "model-00002-of-00023.safetensors",
    "model-00003-of-00023.safetensors",
    "model-00004-of-00023.safetensors",
    "model-00005-of-00023.safetensors",
    "model-00006-of-00023.safetensors",
    "model-00007-of-00023.safetensors",
    "model-00008-of-00023.safetensors",
    "model-00009-of-00023.safetensors",
    "model-00010-of-00023.safetensors",
    "model-00011-of-00023.safetensors",
    "model-00012-of-00023.safetensors",
    "model-00013-of-00023.safetensors",
    "model-00014-of-00023.safetensors",
    "model-00015-of-00023.safetensors",
    "model-00016-of-00023.safetensors",
    "model-00017-of-00023.safetensors",
    "model-00018-of-00023.safetensors",
    "model-00019-of-00023.safetensors",
    "model-00020-of-00023.safetensors",
    "model-00021-of-00023.safetensors",
    "model-00022-of-00023.safetensors",
    "model-00023-of-00023.safetensors"
  ],
  "LoneStriker/Qwen1.5-14B-Chat-8.0bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "adalib/sqlmodel-cond-gen-CodeGPT-small-py": [
    "model.safetensors"
  ],
  "Heng666/Breeze-7B-Instruct-v0_1-AWQ": [
    "model.safetensors"
  ],
  "ken-miller/tris-3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "adalib/sfepy-cond-gen-CodeGPT-small-py": [
    "model.safetensors"
  ],
  "firstgradeai/llama-7-int4-dolly": [
    "model.safetensors"
  ],
  "vicgalle/ConfigurableBeagle-11B": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "nickypro/llama-7b-hf-rand": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "adalib/megengine-cond-gen-CodeGPT-small-py": [
    "model.safetensors"
  ],
  "Owhslp/nous_researcher_tuning_8": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "adalib/sqlmodel-cond-gen-codeparrot-small": [
    "model.safetensors"
  ],
  "adalib/sfepy-cond-gen-codeparrot-small": [
    "model.safetensors"
  ],
  "Yuma42/KangalKhan-RawEmerald-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Mihaiii/Bucharest-0.2": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "adalib/megengine-cond-gen-codeparrot-small": [
    "model.safetensors"
  ],
  "ConvexAI/Luminex-32B-v0.2": [
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "LoneStriker/Qwen1.5-72B-Chat-2.4bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "robertgshaw2/TinyLlama-1.1B-Chat-v1.0-g128-gptq": [
    "model.safetensors"
  ],
  "eduvedras/git-base-vqg": [
    "model.safetensors"
  ],
  "robertgshaw2/TinyLlama-1.1B-Chat-v1.0-g128-marlin": [
    "model.safetensors"
  ],
  "InnerI/InnerI-AI-merge-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "maywell/kiqu-70b-awq": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "vistagi/Mixtral-8x7b-v0.1-dpo": [
    "model-00001-of-00019.safetensors",
    "model-00002-of-00019.safetensors",
    "model-00003-of-00019.safetensors",
    "model-00004-of-00019.safetensors",
    "model-00005-of-00019.safetensors",
    "model-00006-of-00019.safetensors",
    "model-00007-of-00019.safetensors",
    "model-00008-of-00019.safetensors",
    "model-00009-of-00019.safetensors",
    "model-00010-of-00019.safetensors",
    "model-00011-of-00019.safetensors",
    "model-00012-of-00019.safetensors",
    "model-00013-of-00019.safetensors",
    "model-00014-of-00019.safetensors",
    "model-00015-of-00019.safetensors",
    "model-00016-of-00019.safetensors",
    "model-00017-of-00019.safetensors",
    "model-00018-of-00019.safetensors",
    "model-00019-of-00019.safetensors"
  ],
  "Drewskidang/AWG_MERGE": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Aspik101/nous_c66": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "BlackSamorez/Mixtral-8x7B-Instruct-v0.1-AQLM-2Bit-1x16-hf": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Qwen1.5-72B-Chat-3.5bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "Dagonez/DialoGPT-small-Homer-Bot": [
    "model.safetensors"
  ],
  "LoneStriker/Smaug-72B-v0.1-2.4bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "Guilherme34/Samanthav2.5-modelnotlora": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Yuma42/KangalKhan-ShinyEmerald-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "LoneStriker/Smaug-72B-v0.1-3.5bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "cyberminotaure/nous-thirty": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mehdirafiei/CODELLAMA13BACCV3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "DreadPoor/EveryNight-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "kheopss/kheops_dpo_v0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "InnerI/InnerI-sn6-merge-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "swap-uniba/Llamantino-2-13b-chat-ITA-MarketingAssistant": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "PhilSad/Claire-7b-0.1-instruct": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Smaug-72B-v0.1-4.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "adalib/sqlmodel-cond-gen-codeparrot": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Qwen1.5-72B-Chat-4.0bpw-h6-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "CreitinGameplays/elisa-chan-gpt2-large": [
    "model.safetensors"
  ],
  "LoneStriker/Smaug-72B-v0.1-4.65bpw-h6-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "mayacinka/DolphinChat-function-calling-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "SanjiWatsuki/stablelm-ultra-1.6b": [
    "model.safetensors"
  ],
  "adalib/sqlmodel-sfepy-cond-gen-CodeGPT-small-py": [
    "model.safetensors"
  ],
  "myra/opt_negation": [
    "model.safetensors"
  ],
  "onkpannu/tiny3": [
    "adapter_model.safetensors",
    "checkpoint-6/adapter_model.safetensors"
  ],
  "hachirokoo/code-llama-7b-text-to-sql-2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "deepnetguy/2151": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "adalib/sqlmodel-sfepy-megengine-cond-gen-CodeGPT-small-py": [
    "model.safetensors"
  ],
  "BioMistral/BioMistral-7B-SLERP-AWQ-QGS128-W4-GEMM": [
    "model.safetensors"
  ],
  "LoneStriker/Qwen1.5-72B-Chat-6.0bpw-h6-exl2": [
    "output-00001-of-00007.safetensors",
    "output-00002-of-00007.safetensors",
    "output-00003-of-00007.safetensors",
    "output-00004-of-00007.safetensors",
    "output-00005-of-00007.safetensors",
    "output-00006-of-00007.safetensors",
    "output-00007-of-00007.safetensors"
  ],
  "andrealexroom/LexLLMv0.0.0.x.10.9b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "InnerI/InnerI-AI-sn6-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "adalib/sqlmodel-sfepy-cond-gen-codeparrot-small": [
    "model.safetensors"
  ],
  "andrealexroom/LexLLMv0.0.0.x.10.8b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "adalib/sfepy-cond-gen-codeparrot": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "vicgalle/ConfigurableHermes-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/DARE_TIES_13B-GGUF": [],
  "deepnetguy/446": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Qwen1.5-72B-Chat-4.65bpw-h6-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "LoneStriker/Smaug-72B-v0.1-5.0bpw-h6-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "Komala/new_DialoGPT-medium": [
    "model.safetensors"
  ],
  "onkpannu/tiny6": [
    "adapter_model.safetensors",
    "checkpoint-6/adapter_model.safetensors"
  ],
  "adalib/sqlmodel-sfepy-megengine-cond-gen-codeparrot-small": [
    "model.safetensors"
  ],
  "affahrizain/gpt2-completion-finetune-id-review-gen": [
    "model.safetensors"
  ],
  "BioMistral/BioMistral-7B-DARE-AWQ-QGS128-W4-GEMM": [
    "model.safetensors"
  ],
  "adalib/sqlmodel-sfepy-cond-gen-codeparrot": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "BioMistral/BioMistral-7B-TIES-AWQ-QGS128-W4-GEMM": [
    "model.safetensors"
  ],
  "lunarsylph/mooncell_v11": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "MaziyarPanahi/Llama-2-7b-chat-hf-function-calling-v3-GGUF": [],
  "greatakela/mistral_multiclass_full": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/Qwen1.5-72B-Chat-5.0bpw-h6-exl2": [
    "output-00001-of-00006.safetensors",
    "output-00002-of-00006.safetensors",
    "output-00003-of-00006.safetensors",
    "output-00004-of-00006.safetensors",
    "output-00005-of-00006.safetensors",
    "output-00006-of-00006.safetensors"
  ],
  "CorticalStack/mistral-7b-dolphin-6.5bpw-exl2": [
    "cal_data.safetensors",
    "hidden_states.safetensors",
    "output.safetensors"
  ],
  "CorticalStack/mistral-7b-alpaca-sft": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "inventbot/Mixtral-8x7B-Instruct-v0.1-offloading-demo": [
    "model-00001-of-00257.safetensors",
    "model-00002-of-00257.safetensors",
    "model-00003-of-00257.safetensors",
    "model-00004-of-00257.safetensors",
    "model-00005-of-00257.safetensors",
    "model-00006-of-00257.safetensors",
    "model-00007-of-00257.safetensors",
    "model-00008-of-00257.safetensors",
    "model-00009-of-00257.safetensors",
    "model-00010-of-00257.safetensors",
    "model-00011-of-00257.safetensors",
    "model-00012-of-00257.safetensors",
    "model-00013-of-00257.safetensors",
    "model-00014-of-00257.safetensors",
    "model-00015-of-00257.safetensors",
    "model-00016-of-00257.safetensors",
    "model-00017-of-00257.safetensors",
    "model-00018-of-00257.safetensors",
    "model-00019-of-00257.safetensors",
    "model-00020-of-00257.safetensors",
    "model-00021-of-00257.safetensors",
    "model-00022-of-00257.safetensors",
    "model-00023-of-00257.safetensors",
    "model-00024-of-00257.safetensors",
    "model-00025-of-00257.safetensors",
    "model-00026-of-00257.safetensors",
    "model-00027-of-00257.safetensors",
    "model-00028-of-00257.safetensors",
    "model-00029-of-00257.safetensors",
    "model-00030-of-00257.safetensors",
    "model-00031-of-00257.safetensors",
    "model-00032-of-00257.safetensors",
    "model-00033-of-00257.safetensors",
    "model-00034-of-00257.safetensors",
    "model-00035-of-00257.safetensors",
    "model-00036-of-00257.safetensors",
    "model-00037-of-00257.safetensors",
    "model-00038-of-00257.safetensors",
    "model-00039-of-00257.safetensors",
    "model-00040-of-00257.safetensors",
    "model-00041-of-00257.safetensors",
    "model-00042-of-00257.safetensors",
    "model-00043-of-00257.safetensors",
    "model-00044-of-00257.safetensors",
    "model-00045-of-00257.safetensors",
    "model-00046-of-00257.safetensors",
    "model-00047-of-00257.safetensors",
    "model-00048-of-00257.safetensors",
    "model-00049-of-00257.safetensors",
    "model-00050-of-00257.safetensors",
    "model-00051-of-00257.safetensors",
    "model-00052-of-00257.safetensors",
    "model-00053-of-00257.safetensors",
    "model-00054-of-00257.safetensors",
    "model-00055-of-00257.safetensors",
    "model-00056-of-00257.safetensors",
    "model-00057-of-00257.safetensors",
    "model-00058-of-00257.safetensors",
    "model-00059-of-00257.safetensors",
    "model-00060-of-00257.safetensors",
    "model-00061-of-00257.safetensors",
    "model-00062-of-00257.safetensors",
    "model-00063-of-00257.safetensors",
    "model-00064-of-00257.safetensors",
    "model-00065-of-00257.safetensors",
    "model-00066-of-00257.safetensors",
    "model-00067-of-00257.safetensors",
    "model-00068-of-00257.safetensors",
    "model-00069-of-00257.safetensors",
    "model-00070-of-00257.safetensors",
    "model-00071-of-00257.safetensors",
    "model-00072-of-00257.safetensors",
    "model-00073-of-00257.safetensors",
    "model-00074-of-00257.safetensors",
    "model-00075-of-00257.safetensors",
    "model-00076-of-00257.safetensors",
    "model-00077-of-00257.safetensors",
    "model-00078-of-00257.safetensors",
    "model-00079-of-00257.safetensors",
    "model-00080-of-00257.safetensors",
    "model-00081-of-00257.safetensors",
    "model-00082-of-00257.safetensors",
    "model-00083-of-00257.safetensors",
    "model-00084-of-00257.safetensors",
    "model-00085-of-00257.safetensors",
    "model-00086-of-00257.safetensors",
    "model-00087-of-00257.safetensors",
    "model-00088-of-00257.safetensors",
    "model-00089-of-00257.safetensors",
    "model-00090-of-00257.safetensors",
    "model-00091-of-00257.safetensors",
    "model-00092-of-00257.safetensors",
    "model-00093-of-00257.safetensors",
    "model-00094-of-00257.safetensors",
    "model-00095-of-00257.safetensors",
    "model-00096-of-00257.safetensors",
    "model-00097-of-00257.safetensors",
    "model-00098-of-00257.safetensors",
    "model-00099-of-00257.safetensors",
    "model-00100-of-00257.safetensors",
    "model-00101-of-00257.safetensors",
    "model-00102-of-00257.safetensors",
    "model-00103-of-00257.safetensors",
    "model-00104-of-00257.safetensors",
    "model-00105-of-00257.safetensors",
    "model-00106-of-00257.safetensors",
    "model-00107-of-00257.safetensors",
    "model-00108-of-00257.safetensors",
    "model-00109-of-00257.safetensors",
    "model-00110-of-00257.safetensors",
    "model-00111-of-00257.safetensors",
    "model-00112-of-00257.safetensors",
    "model-00113-of-00257.safetensors",
    "model-00114-of-00257.safetensors",
    "model-00115-of-00257.safetensors",
    "model-00116-of-00257.safetensors",
    "model-00117-of-00257.safetensors",
    "model-00118-of-00257.safetensors",
    "model-00119-of-00257.safetensors",
    "model-00120-of-00257.safetensors",
    "model-00121-of-00257.safetensors",
    "model-00122-of-00257.safetensors",
    "model-00123-of-00257.safetensors",
    "model-00124-of-00257.safetensors",
    "model-00125-of-00257.safetensors",
    "model-00126-of-00257.safetensors",
    "model-00127-of-00257.safetensors",
    "model-00128-of-00257.safetensors",
    "model-00129-of-00257.safetensors",
    "model-00130-of-00257.safetensors",
    "model-00131-of-00257.safetensors",
    "model-00132-of-00257.safetensors",
    "model-00133-of-00257.safetensors",
    "model-00134-of-00257.safetensors",
    "model-00135-of-00257.safetensors",
    "model-00136-of-00257.safetensors",
    "model-00137-of-00257.safetensors",
    "model-00138-of-00257.safetensors",
    "model-00139-of-00257.safetensors",
    "model-00140-of-00257.safetensors",
    "model-00141-of-00257.safetensors",
    "model-00142-of-00257.safetensors",
    "model-00143-of-00257.safetensors",
    "model-00144-of-00257.safetensors",
    "model-00145-of-00257.safetensors",
    "model-00146-of-00257.safetensors",
    "model-00147-of-00257.safetensors",
    "model-00148-of-00257.safetensors",
    "model-00149-of-00257.safetensors",
    "model-00150-of-00257.safetensors",
    "model-00151-of-00257.safetensors",
    "model-00152-of-00257.safetensors",
    "model-00153-of-00257.safetensors",
    "model-00154-of-00257.safetensors",
    "model-00155-of-00257.safetensors",
    "model-00156-of-00257.safetensors",
    "model-00157-of-00257.safetensors",
    "model-00158-of-00257.safetensors",
    "model-00159-of-00257.safetensors",
    "model-00160-of-00257.safetensors",
    "model-00161-of-00257.safetensors",
    "model-00162-of-00257.safetensors",
    "model-00163-of-00257.safetensors",
    "model-00164-of-00257.safetensors",
    "model-00165-of-00257.safetensors",
    "model-00166-of-00257.safetensors",
    "model-00167-of-00257.safetensors",
    "model-00168-of-00257.safetensors",
    "model-00169-of-00257.safetensors",
    "model-00170-of-00257.safetensors",
    "model-00171-of-00257.safetensors",
    "model-00172-of-00257.safetensors",
    "model-00173-of-00257.safetensors",
    "model-00174-of-00257.safetensors",
    "model-00175-of-00257.safetensors",
    "model-00176-of-00257.safetensors",
    "model-00177-of-00257.safetensors",
    "model-00178-of-00257.safetensors",
    "model-00179-of-00257.safetensors",
    "model-00180-of-00257.safetensors",
    "model-00181-of-00257.safetensors",
    "model-00182-of-00257.safetensors",
    "model-00183-of-00257.safetensors",
    "model-00184-of-00257.safetensors",
    "model-00185-of-00257.safetensors",
    "model-00186-of-00257.safetensors",
    "model-00187-of-00257.safetensors",
    "model-00188-of-00257.safetensors",
    "model-00189-of-00257.safetensors",
    "model-00190-of-00257.safetensors",
    "model-00191-of-00257.safetensors",
    "model-00192-of-00257.safetensors",
    "model-00193-of-00257.safetensors",
    "model-00194-of-00257.safetensors",
    "model-00195-of-00257.safetensors",
    "model-00196-of-00257.safetensors",
    "model-00197-of-00257.safetensors",
    "model-00198-of-00257.safetensors",
    "model-00199-of-00257.safetensors",
    "model-00200-of-00257.safetensors",
    "model-00201-of-00257.safetensors",
    "model-00202-of-00257.safetensors",
    "model-00203-of-00257.safetensors",
    "model-00204-of-00257.safetensors",
    "model-00205-of-00257.safetensors",
    "model-00206-of-00257.safetensors",
    "model-00207-of-00257.safetensors",
    "model-00208-of-00257.safetensors",
    "model-00209-of-00257.safetensors",
    "model-00210-of-00257.safetensors",
    "model-00211-of-00257.safetensors",
    "model-00212-of-00257.safetensors",
    "model-00213-of-00257.safetensors",
    "model-00214-of-00257.safetensors",
    "model-00215-of-00257.safetensors",
    "model-00216-of-00257.safetensors",
    "model-00217-of-00257.safetensors",
    "model-00218-of-00257.safetensors",
    "model-00219-of-00257.safetensors",
    "model-00220-of-00257.safetensors",
    "model-00221-of-00257.safetensors",
    "model-00222-of-00257.safetensors",
    "model-00223-of-00257.safetensors",
    "model-00224-of-00257.safetensors",
    "model-00225-of-00257.safetensors",
    "model-00226-of-00257.safetensors",
    "model-00227-of-00257.safetensors",
    "model-00228-of-00257.safetensors",
    "model-00229-of-00257.safetensors",
    "model-00230-of-00257.safetensors",
    "model-00231-of-00257.safetensors",
    "model-00232-of-00257.safetensors",
    "model-00233-of-00257.safetensors",
    "model-00234-of-00257.safetensors",
    "model-00235-of-00257.safetensors",
    "model-00236-of-00257.safetensors",
    "model-00237-of-00257.safetensors",
    "model-00238-of-00257.safetensors",
    "model-00239-of-00257.safetensors",
    "model-00240-of-00257.safetensors",
    "model-00241-of-00257.safetensors",
    "model-00242-of-00257.safetensors",
    "model-00243-of-00257.safetensors",
    "model-00244-of-00257.safetensors",
    "model-00245-of-00257.safetensors",
    "model-00246-of-00257.safetensors",
    "model-00247-of-00257.safetensors",
    "model-00248-of-00257.safetensors",
    "model-00249-of-00257.safetensors",
    "model-00250-of-00257.safetensors",
    "model-00251-of-00257.safetensors",
    "model-00252-of-00257.safetensors",
    "model-00253-of-00257.safetensors",
    "model-00254-of-00257.safetensors",
    "model-00255-of-00257.safetensors",
    "model-00256-of-00257.safetensors",
    "model-00257-of-00257.safetensors"
  ],
  "LoneStriker/Smaug-72B-v0.1-6.0bpw-h6-exl2": [
    "output-00001-of-00007.safetensors",
    "output-00002-of-00007.safetensors",
    "output-00003-of-00007.safetensors",
    "output-00004-of-00007.safetensors",
    "output-00005-of-00007.safetensors",
    "output-00006-of-00007.safetensors",
    "output-00007-of-00007.safetensors"
  ],
  "MaziyarPanahi/Llama-2-7b-chat-hf-function-calling-v2-GGUF": [],
  "JakeTurner616/Adonalsium-gpt-neo-1.3B": [
    "model.safetensors"
  ],
  "whizkid/nous_ft": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "CorticalStack/mistral-7b-openhermes-6.5bpw-exl2": [
    "cal_data.safetensors",
    "hidden_states.safetensors",
    "output.safetensors"
  ],
  "Isotonic/smol_llama_x": [
    "model.safetensors"
  ],
  "kaist-ai/prometheus-zephyr-alpha-merged": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "Kukedlc/Neural-4-GSM8K-7B-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "CorticalStack/mistral-7b-alpaca-6.5bpw-exl2": [
    "cal_data.safetensors",
    "hidden_states.safetensors",
    "output.safetensors"
  ],
  "olemeyer/pmtest": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Kukedlc/Neural4gsm8k": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "CorticalStack/mistral-7b-metamathqa-sft": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "deepnet/SN6-30a": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "adalib/megengine-cond-gen-codeparrot": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Drewskidang/AWQ_MERGE": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "DrNicefellow/Qwen1.5-72B-Chat-2.2bpw-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "saracandu/vicuna-7b-harrypotter": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "DrNicefellow/Qwen1.5-72B-Chat-3.2bpw-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "ken-miller/tris-4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Bi0ll0/PPLtest_mistral_7b": [
    "adapter_model.safetensors"
  ],
  "DrNicefellow/Qwen1.5-72B-Chat-4bpw-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "CorticalStack/mistral-7b-metamathqa-6.5bpw-exl2": [
    "cal_data.safetensors",
    "hidden_states.safetensors",
    "output.safetensors"
  ],
  "notzero/model_combined": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "adalib/sqlmodel-sfepy-megengine-cond-gen-codeparrot": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "adalib/sqlmodel-cond-gen-codegen-350M-mono": [
    "model.safetensors"
  ],
  "TroyDoesAI/MermaidSolar_LASER": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "adalib/sfepy-cond-gen-codegen-350M-mono": [
    "model.safetensors"
  ],
  "mayacinka/Buttercup-7b-dpo-ties": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "CorticalStack/mistral-7b-alpaca-awq": [
    "model.safetensors"
  ],
  "Owhslp/nous_researcher_tuning_9": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Yuma42/KangalKhan-RawRuby-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "MAdAiLab/llama2_7b_nf4_adapter_merged_final": [
    "model.safetensors"
  ],
  "M4-ai/NeuralReyna-Mini-1.8B-v0.2": [
    "model.safetensors"
  ],
  "CorticalStack/mistral-7b-openhermes-2.5-sft": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "simonycl/sparseIT_Llama-2-7b-hf-stanford-alpaca": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "CorticalStack/mistral-7b-metamathqa-awq": [
    "model.safetensors"
  ],
  "INSAIT-Institute/BgGPT-7B-Instruct-v0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "adalib/megengine-cond-gen-codegen-350M-mono": [
    "model.safetensors"
  ],
  "simonycl/data_selection_Llama-2-7b-hf-multi_task-mask-mlp-by-dataset": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Kukedlc/Neural-Cosmic-7B-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mayacinka/frankencup-dpo": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "CorticalStack/mistral-7b-openhermes-2.5-awq": [
    "model.safetensors"
  ],
  "ChuckMcSneed/Euryale-1.3-L2-70B-LORA": [
    "adapter_model.safetensors"
  ],
  "CorticalStack/mistral-7b-openhermes-2.5-6.5bpw-exl2": [
    "cal_data.safetensors",
    "hidden_states.safetensors",
    "output.safetensors"
  ],
  "simonycl/sparseIT_Llama-2-7b-hf-multi-task-mask-by-cluster": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "alexbotov/Mistral-7B-v0.1-q": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors",
    "model.safetensors"
  ],
  "shradha01/codeparrot-ds-accelerate": [
    "model.safetensors"
  ],
  "ken-miller/tris-5": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Kukedlc/Neural-Cosmic-Boy-7B-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "DrNicefellow/Qwen1.5-72B-Chat-8bpw-h8-exl2": [
    "output-00001-of-00009.safetensors",
    "output-00002-of-00009.safetensors",
    "output-00003-of-00009.safetensors",
    "output-00004-of-00009.safetensors",
    "output-00005-of-00009.safetensors",
    "output-00006-of-00009.safetensors",
    "output-00007-of-00009.safetensors",
    "output-00008-of-00009.safetensors",
    "output-00009-of-00009.safetensors"
  ],
  "simonycl/sparseIT_Llama-2-7b-hf-multi_task": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "maywell/kiqu-70b-4.0bpw-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "deepnetguy/999": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LunaticPython161/Lily-v3": [
    "model-00001-of-00015.safetensors",
    "model-00002-of-00015.safetensors",
    "model-00003-of-00015.safetensors",
    "model-00004-of-00015.safetensors",
    "model-00005-of-00015.safetensors",
    "model-00006-of-00015.safetensors",
    "model-00007-of-00015.safetensors",
    "model-00008-of-00015.safetensors",
    "model-00009-of-00015.safetensors",
    "model-00010-of-00015.safetensors",
    "model-00011-of-00015.safetensors",
    "model-00012-of-00015.safetensors",
    "model-00013-of-00015.safetensors",
    "model-00014-of-00015.safetensors",
    "model-00015-of-00015.safetensors"
  ],
  "MAdAiLab/llama2_7b_fp4_adapter_merged_final": [
    "model.safetensors"
  ],
  "deepnetguy/888": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ManishThota/Thota": [
    "model.safetensors"
  ],
  "Raymondxzr/ppo_yelp": [
    "model.safetensors"
  ],
  "FPHam/MissLizzy_7b_HF": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Raymondxzr/ppo_movie": [
    "model.safetensors"
  ],
  "Raymondxzr/ppo_amazon": [
    "model.safetensors"
  ],
  "Test157t/Serpentina-Silentstep-7B-16k-test": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "NLUHOPOE/test-case-5": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "maywell/kiqu-70b-2.4bpw-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "maywell/kiqu-70b-3.0bpw-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "OpenBuddy/openbuddy-deepseek-67b-v18.1-4k": [
    "model-00001-of-00028.safetensors",
    "model-00002-of-00028.safetensors",
    "model-00003-of-00028.safetensors",
    "model-00004-of-00028.safetensors",
    "model-00005-of-00028.safetensors",
    "model-00006-of-00028.safetensors",
    "model-00007-of-00028.safetensors",
    "model-00008-of-00028.safetensors",
    "model-00009-of-00028.safetensors",
    "model-00010-of-00028.safetensors",
    "model-00011-of-00028.safetensors",
    "model-00012-of-00028.safetensors",
    "model-00013-of-00028.safetensors",
    "model-00014-of-00028.safetensors",
    "model-00015-of-00028.safetensors",
    "model-00016-of-00028.safetensors",
    "model-00017-of-00028.safetensors",
    "model-00018-of-00028.safetensors",
    "model-00019-of-00028.safetensors",
    "model-00020-of-00028.safetensors",
    "model-00021-of-00028.safetensors",
    "model-00022-of-00028.safetensors",
    "model-00023-of-00028.safetensors",
    "model-00024-of-00028.safetensors",
    "model-00025-of-00028.safetensors",
    "model-00026-of-00028.safetensors",
    "model-00027-of-00028.safetensors",
    "model-00028-of-00028.safetensors"
  ],
  "ghidav/gpt2-full-20g2s": [
    "checkpoint-650/model.safetensors",
    "model.safetensors"
  ],
  "0x0dad0/nous_nous_v3_0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Quyen-Pro-v0.1-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Quyen-Pro-v0.1-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Quyen-Pro-v0.1-5.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/Quyen-Pro-v0.1-6.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "lunarsylph/mooncell_v12": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/Quyen-Pro-v0.1-8.0bpw-h8-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "nerdabhayx69/phi-alpaca": [
    "checkpoint-220/model-00001-of-00002.safetensors",
    "checkpoint-220/model-00002-of-00002.safetensors"
  ],
  "deepnetguy/2923": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Quyen-Plus-v0.1-3.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Quyen-Plus-v0.1-4.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Quyen-Plus-v0.1-5.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "giraffe176/Open_Maid_Samantha_Hermes_Orca_dare_tiesv0.1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/Quyen-Plus-v0.1-6.0bpw-h6-exl2": [
    "output.safetensors"
  ],
  "LoneStriker/Quyen-Plus-v0.1-8.0bpw-h8-exl2": [
    "output.safetensors"
  ],
  "Test157t/Neuraltina-Silentstep-7B-16k-test": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "SiguienteGlobal/70b": [
    "model-00001-of-00025.safetensors",
    "model-00002-of-00025.safetensors",
    "model-00003-of-00025.safetensors",
    "model-00004-of-00025.safetensors",
    "model-00005-of-00025.safetensors",
    "model-00006-of-00025.safetensors",
    "model-00007-of-00025.safetensors",
    "model-00008-of-00025.safetensors",
    "model-00009-of-00025.safetensors",
    "model-00010-of-00025.safetensors",
    "model-00011-of-00025.safetensors",
    "model-00012-of-00025.safetensors",
    "model-00013-of-00025.safetensors",
    "model-00014-of-00025.safetensors",
    "model-00015-of-00025.safetensors",
    "model-00016-of-00025.safetensors",
    "model-00017-of-00025.safetensors",
    "model-00018-of-00025.safetensors",
    "model-00019-of-00025.safetensors",
    "model-00020-of-00025.safetensors",
    "model-00021-of-00025.safetensors",
    "model-00022-of-00025.safetensors",
    "model-00023-of-00025.safetensors",
    "model-00024-of-00025.safetensors",
    "model-00025-of-00025.safetensors"
  ],
  "NunYaBusi/pyg-2-7b": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Test157t/Kunotina-Silentstep-7b-16k-test": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "netcat420/MHENN5.2": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "jsfs11/SeverusMonarchDensityscheduled-7B-DARETIES": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "abeygeorge576/trial": [
    "gpt2-finetuned-intents_final/model.safetensors",
    "model.safetensors"
  ],
  "nerdabhayx69/phi-coder": [
    "checkpoint-312/model-00001-of-00002.safetensors",
    "checkpoint-312/model-00002-of-00002.safetensors"
  ],
  "greatakela/mistral_instruct_classifyFPB10k_full": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LunaticPython161/Trinary": [
    "model-00001-of-00020.safetensors",
    "model-00002-of-00020.safetensors",
    "model-00003-of-00020.safetensors",
    "model-00004-of-00020.safetensors",
    "model-00005-of-00020.safetensors",
    "model-00006-of-00020.safetensors",
    "model-00007-of-00020.safetensors",
    "model-00008-of-00020.safetensors",
    "model-00009-of-00020.safetensors",
    "model-00010-of-00020.safetensors",
    "model-00011-of-00020.safetensors",
    "model-00012-of-00020.safetensors",
    "model-00013-of-00020.safetensors",
    "model-00014-of-00020.safetensors",
    "model-00015-of-00020.safetensors",
    "model-00016-of-00020.safetensors",
    "model-00017-of-00020.safetensors",
    "model-00018-of-00020.safetensors",
    "model-00019-of-00020.safetensors",
    "model-00020-of-00020.safetensors"
  ],
  "drunkOnData/Phi-2-Damn-Good-Prose-GGUF": [
    "model.safetensors"
  ],
  "jrgoodner/Llama-2-7b-hf-diffdx-sup-1": [
    "model.safetensors"
  ],
  "Ruiz3/phi-2-kingshipAIv2-explainer": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "altomek/Midnight-Rose-70B-v2.0.3-3.75bpw-EXL2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "kam1run/DialoGPT-medium-kami": [
    "model.safetensors"
  ],
  "LoneStriker/bagel-34b-v0.4-3.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "cjsanjay/llama-2-7b-domain-tuned-anytool-18feb": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/bagel-34b-v0.4-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "oliverbob/lora_model": [
    "model.safetensors"
  ],
  "LoneStriker/bagel-34b-v0.4-4.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/bagel-34b-v0.4-5.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/bagel-34b-v0.4-6.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-QA-BQA-400-epoch8": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "LoneStriker/bagel-34b-v0.4-8.0bpw-h8-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "LoneStriker/bagel-34b-v0.4-AWQ": [
    "model-00001-of-00004.safetensors",
    "model-00002-of-00004.safetensors",
    "model-00003-of-00004.safetensors",
    "model-00004-of-00004.safetensors"
  ],
  "sethuiyer/Diana-7B": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-QA-BQA-100-epoch16": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "cfli/test_pretrain": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "cfli/test_passage": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "cfli/test_document": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "Owhslp/nous_researcher_tuning_10": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jeiku/SOLAR_Uncensored_LimaRP_10.7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "adalib/sqlmodel-sfepy-cond-gen-codegen-350M-mono": [
    "model.safetensors"
  ],
  "deepnetguy/3010": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "jeiku/SOLAR_Uncensored_Luna_10.7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "AsphyXIA/baarat-hindi-pretrained": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "adalib/sqlmodel-sfepy-megengine-cond-gen-codegen-350M-mono": [
    "model.safetensors"
  ],
  "yingmanji/dpo_llama2_merged": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "evaezekwem/mistralai-Code-Instruct-Finetune-test": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "CrypticMax/Pretrain": [
    "model.safetensors"
  ],
  "adalib/full-cond-gen-CodeGPT-small-py": [
    "model.safetensors"
  ],
  "minaamshahid/NeuralPipe-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "andrealexroom/LexLLMv0.0.0.x.10.9c": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "silk-road/Haruhi-Zero-1_8B-0_4": [
    "model.safetensors"
  ],
  "adalib/full-cond-gen-codeparrot-small": [
    "model.safetensors"
  ],
  "danielhanchen/lora_18022024": [
    "adapter_model.safetensors",
    "model.safetensors"
  ],
  "Owhslp/nous_researcher_tuning_11": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "adalib/full-cond-gen-codegen-350M-mono": [
    "model.safetensors"
  ],
  "Leptok/vdllava-v1.5-7b": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "andrealexroom/LexLLMv0.0.0.x.10.8c": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "gutianpei/mistral7b-merging": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "alwint3r/Mistral-7B-Instruct-v0.2-finetuned-mlx-4bit": [
    "model.safetensors"
  ],
  "CorticalStack/mistral-7b-alpaca-gptq": [
    "model.safetensors"
  ],
  "Rigard/german-gpt2-larger-finetuned-press-release": [
    "model.safetensors"
  ],
  "madroid/Qwen1.5-1.8B-Chat-4bit-mlx": [
    "model.safetensors"
  ],
  "CorticalStack/mistral-7b-openhermes-2.5-gptq": [
    "model.safetensors"
  ],
  "Palistha/finetuned-gpt2": [
    "model.safetensors"
  ],
  "kheopss/kheops_llm_hermes_0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "adalib/sqlmodel-cond-gen-codegen-2B-mono": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "CorticalStack/mistral-7b-dolphin-gptq": [
    "model.safetensors"
  ],
  "theoracle/mental7": [
    "model.safetensors"
  ],
  "kheopss/kheops_llm_beta_0.1": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LordNoah/latent_gpt2_medium_alpaca_e2": [
    "model.safetensors"
  ],
  "asadmasad/ds-33b-lora-finetuned-39k-merged": [
    "model-00001-of-00014.safetensors",
    "model-00002-of-00014.safetensors",
    "model-00003-of-00014.safetensors",
    "model-00004-of-00014.safetensors",
    "model-00005-of-00014.safetensors",
    "model-00006-of-00014.safetensors",
    "model-00007-of-00014.safetensors",
    "model-00008-of-00014.safetensors",
    "model-00009-of-00014.safetensors",
    "model-00010-of-00014.safetensors",
    "model-00011-of-00014.safetensors",
    "model-00012-of-00014.safetensors",
    "model-00013-of-00014.safetensors",
    "model-00014-of-00014.safetensors"
  ],
  "LordNoah/spin_gpt2_medium_alpaca_e2": [
    "model.safetensors"
  ],
  "AdamGrzesik/Mistral_7B_SamanthaPL": [
    "adapter_model.safetensors",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "tog/TinyLlama-1.1B-Chat-colors-v1.0": [
    "model.safetensors"
  ],
  "ssoh/llama-2-7b-mcq_2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "CorticalStack/mistral-7b-openhermes-gptq": [
    "model.safetensors"
  ],
  "deepnet/SN6-67": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "adalib/sfepy-cond-gen-codegen-2B-mono": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "deepnet/SN6-30": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "deepnet/SN6-70": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "orion-penner/Mixtral-8x7B-Instruct-v0.1-GPTQ": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "orion-penner/Mixtral-8x7B-Instruct-v0.1-GPTQ-Repush": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "CorticalStack/mistral-7b-metamathqa-gptq": [
    "model.safetensors"
  ],
  "AvishayDev/TEVA-LM": [
    "model.safetensors"
  ],
  "Owhslp/nous_researcher_tuning_13": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Isaak-Carter/JOSIE_1M_base": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "CorticalStack/mistral-7b-dolphin-awq": [
    "model.safetensors"
  ],
  "CorticalStack/mistral-7b-openhermes-awq": [
    "model.safetensors"
  ],
  "ralshinibr/Llama-2-7b-chat-hf-sft-test-push": [
    "model.safetensors"
  ],
  "AsphyXIA/baarat-kannada-pretrained": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "eduvedras/git-base-vqg-train-set": [
    "model.safetensors"
  ],
  "tyson0420/code-llama-alpaca50k": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Yuma42/KangalKhan-DesolatingRuby-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-SA-FULL-NEW-epoch3": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "samyak24jain/pretrained_gpt2": [
    "model.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-NQA-FULL-NEW-epoch3": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-QA-FULL-NEW-epoch3": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "adalib/full-cond-gen-codeparrot": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "Isotonic/TinyMixtral_4x220M-UniversalNER": [
    "model.safetensors"
  ],
  "Yuma42/KangalKhan-PrimordialSapphire-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "benschlagman/llama-2-7b-chat-esconv": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Yuma42/KangalKhan-ShatteredRuby-7B": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "orion-penner/Mixtral-8x7B-Instruct-v0.1-GPTQ_desc_actFalse": [
    "model-00001-of-00005.safetensors",
    "model-00002-of-00005.safetensors",
    "model-00003-of-00005.safetensors",
    "model-00004-of-00005.safetensors",
    "model-00005-of-00005.safetensors"
  ],
  "gobi11/phi2-2b-mwt": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "mazenj/mistral-instruct-medical-model": [
    "model.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-SA-FPB-FULL-NEW-epoch3": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-SA-ESG-FULL-NEW-epoch3": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "mwalol/json-deepseek-topic": [
    "model.safetensors"
  ],
  "sanjay920/cortex-small-feb18_colab-16bit": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "betajuned/unila-gpt2": [
    "adapter_model.safetensors",
    "checkpoint-267/adapter_model.safetensors"
  ],
  "rubra-ai/cortex-small-feb18_colab-lora": [
    "model.safetensors"
  ],
  "TachyHealthResearch/Llama2-70B-Medical-Finetune_V2": [
    "model-00001-of-00029.safetensors",
    "model-00002-of-00029.safetensors",
    "model-00003-of-00029.safetensors",
    "model-00004-of-00029.safetensors",
    "model-00005-of-00029.safetensors",
    "model-00006-of-00029.safetensors",
    "model-00007-of-00029.safetensors",
    "model-00008-of-00029.safetensors",
    "model-00009-of-00029.safetensors",
    "model-00010-of-00029.safetensors",
    "model-00011-of-00029.safetensors",
    "model-00012-of-00029.safetensors",
    "model-00013-of-00029.safetensors",
    "model-00014-of-00029.safetensors",
    "model-00015-of-00029.safetensors",
    "model-00016-of-00029.safetensors",
    "model-00017-of-00029.safetensors",
    "model-00018-of-00029.safetensors",
    "model-00019-of-00029.safetensors",
    "model-00020-of-00029.safetensors",
    "model-00021-of-00029.safetensors",
    "model-00022-of-00029.safetensors",
    "model-00023-of-00029.safetensors",
    "model-00024-of-00029.safetensors",
    "model-00025-of-00029.safetensors",
    "model-00026-of-00029.safetensors",
    "model-00027-of-00029.safetensors",
    "model-00028-of-00029.safetensors",
    "model-00029-of-00029.safetensors"
  ],
  "ThatOneCoder/Babbage-V1": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "adalib/full-cond-gen-codegen-2B-mono": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ken-miller/tris-6-2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Kukedlc/NeuralMaxime-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "gobi11/phi2-2b-mwt-qa": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "MaziyarPanahi/Valor-7B-v0.1-GGUF": [],
  "SR08/TinyLLAMA": [
    "model.safetensors"
  ],
  "Owhslp/nous_researcher_tuning_14": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "ken-miller/tris-7-2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-TQA-FULL-NEW-epoch3": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "FINNUMBER/Yi-Ko-6B-Finch-NQA-EXT-FULL-NEW-epoch3": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "danielhanchen/lora_model_19022024": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "jan-hq/stealth-finance-v4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "adalib/sqlmodel-sfepy-cond-gen-codegen-2B-mono": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "yam-peleg/Experiment15-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "DrNicefellow/Qwen1.5-72B-Chat-6bpw-exl2": [
    "output-00001-of-00007.safetensors",
    "output-00002-of-00007.safetensors",
    "output-00003-of-00007.safetensors",
    "output-00004-of-00007.safetensors",
    "output-00005-of-00007.safetensors",
    "output-00006-of-00007.safetensors",
    "output-00007-of-00007.safetensors"
  ],
  "LoneStriker/34b-beta-3.0bpw-h6-exl2": [
    "output-00001-of-00002.safetensors",
    "output-00002-of-00002.safetensors"
  ],
  "LoneStriker/34b-beta-4.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "LoneStriker/34b-beta-4.65bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "saransh03sharma/mintrec": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LoneStriker/34b-beta-5.0bpw-h6-exl2": [
    "output-00001-of-00003.safetensors",
    "output-00002-of-00003.safetensors",
    "output-00003-of-00003.safetensors"
  ],
  "CreitinGameplays/elisa-chan-gpt2-xl": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "kouki13/mistral": [
    "adapter_model.safetensors",
    "checkpoint-1/adapter_model.safetensors"
  ],
  "LoneStriker/34b-beta-6.0bpw-h6-exl2": [
    "output-00001-of-00004.safetensors",
    "output-00002-of-00004.safetensors",
    "output-00003-of-00004.safetensors",
    "output-00004-of-00004.safetensors"
  ],
  "omarelsayeed/Qwen-2b-1kSteps": [
    "model.safetensors"
  ],
  "Josephgflowers/Cinder-Phi-2-STEM": [],
  "deepnetguy/3051": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "LoneStriker/34b-beta-8.0bpw-h8-exl2": [
    "output-00001-of-00005.safetensors",
    "output-00002-of-00005.safetensors",
    "output-00003-of-00005.safetensors",
    "output-00004-of-00005.safetensors",
    "output-00005-of-00005.safetensors"
  ],
  "cjsanjay/llama-2-7b-instruction-tuned-anytool-18feb2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Kukedlc/NeuralKrishna-7B-slerp": [
    "model-00001-of-00008.safetensors",
    "model-00002-of-00008.safetensors",
    "model-00003-of-00008.safetensors",
    "model-00004-of-00008.safetensors",
    "model-00005-of-00008.safetensors",
    "model-00006-of-00008.safetensors",
    "model-00007-of-00008.safetensors",
    "model-00008-of-00008.safetensors"
  ],
  "dzagardo/quickstart_newdp_eps1": [
    "model.safetensors"
  ],
  "Gille/StrangeMerges_24-7B-slerp": [
    "model-00001-of-00002.safetensors",
    "model-00002-of-00002.safetensors"
  ],
  "pahautelman/phi2-ner-adv-v1": [
    "model.safetensors"
  ],
  "whizkid/nous_ft8ep": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "LunaticPython161/Trinary-v2": [
    "model-00001-of-00020.safetensors",
    "model-00002-of-00020.safetensors",
    "model-00003-of-00020.safetensors",
    "model-00004-of-00020.safetensors",
    "model-00005-of-00020.safetensors",
    "model-00006-of-00020.safetensors",
    "model-00007-of-00020.safetensors",
    "model-00008-of-00020.safetensors",
    "model-00009-of-00020.safetensors",
    "model-00010-of-00020.safetensors",
    "model-00011-of-00020.safetensors",
    "model-00012-of-00020.safetensors",
    "model-00013-of-00020.safetensors",
    "model-00014-of-00020.safetensors",
    "model-00015-of-00020.safetensors",
    "model-00016-of-00020.safetensors",
    "model-00017-of-00020.safetensors",
    "model-00018-of-00020.safetensors",
    "model-00019-of-00020.safetensors",
    "model-00020-of-00020.safetensors"
  ],
  "robertgshaw2/zephyr-7b-beta-channelwise-gptq": [
    "model.safetensors"
  ],
  "robertgshaw2/zephyr-7b-beta-channelwise-marlin": [
    "model.safetensors"
  ],
  "kimmypracha/llama-marunashop-v3-0.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kimmypracha/llama-marunashop-v3-0.4": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "rmihaylov/Inject-7B-v9": [
    "model.safetensors"
  ],
  "kimmypracha/llama-marunashop-v3-0.6": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "deepnet/SN6-77": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "RadAlienware/mis2ndphasemerge220k": [
    "model.safetensors"
  ],
  "Ai-Marshal/merged_adapters": [
    "model-00001-of-00006.safetensors",
    "model-00002-of-00006.safetensors",
    "model-00003-of-00006.safetensors",
    "model-00004-of-00006.safetensors",
    "model-00005-of-00006.safetensors",
    "model-00006-of-00006.safetensors"
  ],
  "deepnet/SN6-71": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "adalib/sqlmodel-sfepy-megengine-cond-gen-codegen-2B-mono": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "yam-peleg/Experiment17-7B": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kimmypracha/llama-marunashop-v3-0.8": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "andrealexroom/LexLLMv0.0.0.x.10.9d": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kimmypracha/llama-marunashop-v3-1.0": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "dzagardo/quickstart_newdp_eps0-01": [
    "model.safetensors"
  ],
  "ken-miller/tris-7-3": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "kimmypracha/llama-marunachef-v3-0.2": [
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "Ketan3101/chatbot_model": [
    "model.safetensors"
  ]
}